{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "rental-invitation",
   "metadata": {
    "tags": []
   },
   "source": [
    "# ML Applicaiton: Applying ML Models to the transition data\n",
    "\n",
    "### Tasks included:\n",
    "- Reading transition matrices \n",
    "- Reading P/AUC scores \n",
    "- Apply ML models \n",
    "- Select features and apply ML models "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "federal-chicago",
   "metadata": {},
   "source": [
    "## Imports and system info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "neutral-relative",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===========================================\n",
      "List of OS platforms and codes\n",
      "___________________________________________\n",
      "0 Darwin\n",
      "1 Windows\n",
      "2 Linux\n",
      "===> \"1 - Windows\" OS is detected.\n",
      "\n",
      "===========================================\n",
      "Processor (CPU) details: \n",
      "___________________________________________\n",
      "{'python_version': '3.7.10.final.0 (64 bit)', 'cpuinfo_version': [8, 0, 0], 'cpuinfo_version_string': '8.0.0', 'arch': 'X86_64', 'bits': 64, 'count': 24, 'arch_string_raw': 'AMD64', 'vendor_id_raw': 'GenuineIntel', 'brand_raw': 'Intel(R) Xeon(R) CPU E5-2690 v4 @ 2.60GHz', 'hz_advertised_friendly': '2.6000 GHz', 'hz_actual_friendly': '2.5940 GHz', 'hz_advertised': [2600000000, 0], 'hz_actual': [2594000000, 0], 'model': 58, 'family': 6, 'flags': ['3dnow', 'aes', 'apic', 'avx', 'clflush', 'cmov', 'cx16', 'cx8', 'de', 'dts', 'erms', 'f16c', 'fpu', 'fxsr', 'ht', 'hypervisor', 'ia64', 'lahf_lm', 'mca', 'mce', 'mmx', 'msr', 'mtrr', 'osxsave', 'pae', 'pat', 'pcid', 'pclmulqdq', 'pge', 'pni', 'popcnt', 'pse', 'pse36', 'rdrnd', 'sep', 'serial', 'smep', 'ss', 'sse', 'sse2', 'sse4_1', 'sse4_2', 'ssse3', 'tm', 'tsc', 'tscdeadline', 'vme', 'x2apic', 'xsave'], 'l2_cache_size': 65536, 'l2_cache_line_size': 256, 'l2_cache_associativity': 6}\n",
      "Brand_raw = Intel(R) Xeon(R) CPU E5-2690 v4 @ 2.60GHz\n",
      "Arch_string_raw = AMD64\n",
      "Arch = X86_64\n",
      "Count = 24\n",
      "Python_version = 3.7.10.final.0 (64 bit)\n",
      "___________________________________________\n",
      "Processor (CPU) usage: \n",
      "___________________________________________\n",
      "svmem(total=274876878848, available=213594820608, percent=22.3, used=61282058240, free=213594820608)\n",
      "Cpu_usage = 8.1\n",
      "Ram_usage = 22.3\n",
      "Total_ram = 256.0\n",
      "Used_ram = 57.1\n",
      "Available_ram = 198.9\n",
      "\n",
      "===========================================\n",
      "Processor (GPU) details: \n",
      "___________________________________________\n",
      "For GPU based tasks. There are 0 GPUs in the system and 0 are available. \n",
      "Available GPU IDs with MaxLoad>=0.5 and MaxMem>=0.5 are: []\n",
      "___________________________________________\n",
      "Processor (GPU) usage: \n",
      "___________________________________________\n",
      "| ID | GPU | MEM |\n",
      "------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1,\n",
       " 'Windows',\n",
       " {'brand_raw': 'Intel(R) Xeon(R) CPU E5-2690 v4 @ 2.60GHz',\n",
       "  'arch_string_raw': 'AMD64',\n",
       "  'arch': 'X86_64',\n",
       "  'count': 24,\n",
       "  'python_version': '3.7.10.final.0 (64 bit)',\n",
       "  'CPU_usage': 8.1,\n",
       "  'RAM_usage': 22.3,\n",
       "  'Total_RAM': 256.0,\n",
       "  'Used_RAM': 57.1,\n",
       "  'Available_RAM': 198.9},\n",
       " [],\n",
       " None)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import HumachLab_Global \n",
    "HumachLab_Global.get_system_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "legislative-rachel",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aliem\\Desktop\\aliem\\My Research\\HML_IHC_Sleep_Data_Analysis\n",
      "C:\\Users\\aliem\\Desktop\\aliem\\My Research\\HML_IHC_Sleep_Data_Analysis\\HumachLab\n",
      "\n",
      "===========================================\n",
      "List of OS platforms and codes\n",
      "___________________________________________\n",
      "0 Darwin\n",
      "1 Windows\n",
      "2 Linux\n",
      "===> \"1 - Windows\" OS is detected.\n",
      "\n",
      "===========================================\n",
      "Processor (CPU) details: \n",
      "___________________________________________\n",
      "{'python_version': '3.7.10.final.0 (64 bit)', 'cpuinfo_version': [8, 0, 0], 'cpuinfo_version_string': '8.0.0', 'arch': 'X86_64', 'bits': 64, 'count': 24, 'arch_string_raw': 'AMD64', 'vendor_id_raw': 'GenuineIntel', 'brand_raw': 'Intel(R) Xeon(R) CPU E5-2690 v4 @ 2.60GHz', 'hz_advertised_friendly': '2.6000 GHz', 'hz_actual_friendly': '2.5940 GHz', 'hz_advertised': [2600000000, 0], 'hz_actual': [2594000000, 0], 'model': 58, 'family': 6, 'flags': ['3dnow', 'aes', 'apic', 'avx', 'clflush', 'cmov', 'cx16', 'cx8', 'de', 'dts', 'erms', 'f16c', 'fpu', 'fxsr', 'ht', 'hypervisor', 'ia64', 'lahf_lm', 'mca', 'mce', 'mmx', 'msr', 'mtrr', 'osxsave', 'pae', 'pat', 'pcid', 'pclmulqdq', 'pge', 'pni', 'popcnt', 'pse', 'pse36', 'rdrnd', 'sep', 'serial', 'smep', 'ss', 'sse', 'sse2', 'sse4_1', 'sse4_2', 'ssse3', 'tm', 'tsc', 'tscdeadline', 'vme', 'x2apic', 'xsave'], 'l2_cache_size': 65536, 'l2_cache_line_size': 256, 'l2_cache_associativity': 6}\n",
      "Brand_raw = Intel(R) Xeon(R) CPU E5-2690 v4 @ 2.60GHz\n",
      "Arch_string_raw = AMD64\n",
      "Arch = X86_64\n",
      "Count = 24\n",
      "Python_version = 3.7.10.final.0 (64 bit)\n",
      "___________________________________________\n",
      "Processor (CPU) usage: \n",
      "___________________________________________\n",
      "svmem(total=274876878848, available=213432860672, percent=22.4, used=61444018176, free=213432860672)\n",
      "Cpu_usage = 6.7\n",
      "Ram_usage = 22.4\n",
      "Total_ram = 256.0\n",
      "Used_ram = 57.2\n",
      "Available_ram = 198.8\n",
      "\n",
      "===========================================\n",
      "Processor (GPU) details: \n",
      "___________________________________________\n",
      "For GPU based tasks. There are 0 GPUs in the system and 0 are available. \n",
      "Available GPU IDs with MaxLoad>=0.5 and MaxMem>=0.5 are: []\n",
      "___________________________________________\n",
      "Processor (GPU) usage: \n",
      "___________________________________________\n",
      "| ID | GPU | MEM |\n",
      "------------------\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Importing necessary modules\n",
    "'''\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import datetime\n",
    "\n",
    "print(os.getcwd())\n",
    "os.chdir(os.getcwd())\n",
    "print(f\"{os.getcwd()}\\HumachLab\")\n",
    "sys.path.append(f\"{os.getcwd()}\\HumachLab\")\n",
    "sys.path.insert(0, os.path.abspath('./HumachLab'))\n",
    "\n",
    "import itertools as it\n",
    "import re\n",
    "import pickle\n",
    "import json\n",
    "\n",
    "import copy\n",
    "from pprint import pprint\n",
    "\n",
    "import glob\n",
    "\n",
    "import math\n",
    "import numbers\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import figure\n",
    "from matplotlib import rc, rcParams\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "\n",
    "import HumachLab_Global\n",
    "from HumachLab import * \n",
    "# from HumachLab.HumachLab_Global import *\n",
    "# import HumachLab_Global\n",
    "HumachLab_Global.get_system_info()\n",
    "\n",
    "import mne\n",
    "\n",
    "# plt.rcParams[\"figure.figsize\"] = plt.rcParamsDefault[\"figure.figsize\"]\n",
    "plt.rcParams[\"figure.figsize\"] = (20,6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "english-country",
   "metadata": {},
   "source": [
    "## Get directory list: Subject-wise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "personal-treat",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Explore the contents/files in the directory\n",
    "'''\n",
    "\n",
    "def get_list_of_paths_from_a_directory(directory, path_type=None, containes=None, extension=None, exclude=None):\n",
    "    '''\n",
    "    directory: valid path string, path_type: p_file|p_dir, containes: string, extension: valid string file extension \n",
    "    '''\n",
    "    os_path = os.path\n",
    "    list_of_paths = []\n",
    "        \n",
    "    path_keywords = \"*\"\n",
    "    if containes:\n",
    "        path_keywords = f\"{path_keywords}{containes}*\"\n",
    "    \n",
    "    if extension:\n",
    "        path_keywords = f\"{path_keywords}.{extension}\"\n",
    "        \n",
    "    complete_path = f\"{directory}/{path_keywords}\"\n",
    "    print(f\"============> {path_keywords}, {path_type}, {complete_path}\")\n",
    "    \n",
    "    all_paths = glob.glob(complete_path) \n",
    "    all_temp_paths = None\n",
    "    list_of_paths = None\n",
    "    \n",
    "    if path_type:\n",
    "        if path_type==\"p_file\":\n",
    "            all_temp_paths = [path.replace(\"\\\\\", \"/\") for path in all_paths if (os_path.exists(path) and os_path.isfile(path))]\n",
    "        if path_type==\"p_dir\":\n",
    "            all_temp_paths = [path.replace(\"\\\\\", \"/\") for path in all_paths if (os_path.exists(path) and os_path.isdir(path))]   \n",
    "    else:\n",
    "        all_temp_paths = [path.replace(\"\\\\\", \"/\") for path in all_paths]\n",
    "        \n",
    "    if exclude:\n",
    "        # print(all_temp_paths)\n",
    "        # print(len(all_temp_paths), exclude)\n",
    "        # list_of_paths = [path for path in all_temp_paths for ex in exclude if ex not in path]\n",
    "        # list_of_paths = [path for ex in exclude for path in all_temp_paths if ex not in path]\n",
    "        list_of_paths = [path for path in all_temp_paths if not any((ex in path) for ex in exclude)]\n",
    "        # list_of_paths = [path for ex in exclude if any(ex not in path for path in all_temp_paths)]\n",
    "        # any(substring in string for substring in substring_list)\n",
    "        # print(len(list_of_paths))\n",
    "    else:\n",
    "        list_of_paths = all_temp_paths.copy()\n",
    "    \n",
    "    return list_of_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "joint-selling",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_directory = \"./Results/\" \n",
    "data_directory = \"/_Combined\"\n",
    "data_subdirectory = \"Subject_One_Night\"  ###\"Subject_Combined_Record\"  \"Subject_Separate_Record\"  \"Subject_One_Night\"  ## Change for new type of result\n",
    "result_directory = \"./Results/_Classification\" \n",
    "metadata_subdirectory = [\"CAP_Sleep\", \"Sleep_EDFX\"] \n",
    "dataset_list = [\"CAP_Sleep\", \"Sleep_EDFX\"] \n",
    "tran_matrix_type = [\"count\", \"dura\", \"proba\"] \n",
    "annotation_type = ['annot', 'tran']\n",
    "tran_level = 2\n",
    "exclude_contents_in_dataset_directory = [\"SHA256SUMS\", \"RECORDS\"]\n",
    "exclude_contents_in_result_directory = [\"SHA256SUMS\", \"RECORDS\", \"all_annotations\", \"annot_sequence\", \"transition_sequence\", \"hypno\", \"DATASET_CHANGELOG\"]\n",
    "sleep_stage_labels = ['W', 'S1', 'S2', 'S3', 'S4', 'REM']\n",
    "sleep_stage_labels_dict = {'W':0, 'S1':1, 'S2':2, 'S3':3, 'S4':4, 'REM':5}\n",
    "sleep_stage_names_dict = {'W':0, 'S1':1, 'S2':2, 'S3':3, 'S4':4, 'R':5}\n",
    "list_of_paths = None \n",
    "\n",
    "annot_type = annotation_type[0]\n",
    "\n",
    "# directory = dataset_directory\n",
    "# # list_of_paths = get_list_of_paths_from_a_directory(directory, path_type=None, containes=None, extension=None, exclude=None) \n",
    "# # list_of_paths = get_list_of_paths_from_a_directory(directory, path_type=\"p_file\", containes=None, extension=None, exclude=None) \n",
    "# # list_of_paths = get_list_of_paths_from_a_directory(directory, path_type=\"p_dir\", containes=None, extension=None, exclude=None) \n",
    "# # list_of_paths = get_list_of_paths_from_a_directory(directory, path_type=None, containes=\"nfle\", extension=None, exclude=None) \n",
    "# # list_of_paths = get_list_of_paths_from_a_directory(directory, path_type=None, containes=None, extension=\"edf\", exclude=None) \n",
    "# list_of_paths = get_list_of_paths_from_a_directory(directory, path_type=None, containes=None, extension=None, exclude=exclude_contents_in_dataset_directory) \n",
    "# # list_of_paths = get_list_of_paths_from_a_directory(directory, path_type=None, containes=None, extension=None, exclude=None) \n",
    "# # pprint(list_of_paths)\n",
    "# list_of_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dynamic-fusion",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "exempt-general",
   "metadata": {},
   "source": [
    "### Get basic information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "lovely-latter",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # annot_type = annotation_type[0]\n",
    "\n",
    "# all_demography_df = pd.DataFrame() \n",
    "# all_demography_detail_df = pd.DataFrame() \n",
    "# for dirr in metadata_subdirectory: \n",
    "#     demography_df = pd.read_csv(f\"{data_directory}{dirr}/Demography.csv\", index_col=False)\n",
    "#     demography_df.insert(1, 'Dataset', [dirr]*demography_df.shape[0])\n",
    "#     all_demography_df = pd.concat([all_demography_df, demography_df]) \n",
    "#     all_demography_df.reset_index(drop=True, inplace=True) \n",
    "\n",
    "#     demography_detail_df = pd.read_csv(f\"{data_directory}{dirr}/Demography_Details.csv\", index_col=False)\n",
    "#     demography_detail_df.insert(0, 'Dataset', [dirr]*demography_detail_df.shape[0])\n",
    "#     sub_name = demography_detail_df['File_Name'].str[:-1].values.tolist() if i==1 else demography_detail_df['File_Name'].values.tolist() \n",
    "#     demography_detail_df.insert(2, 'Subject_Name', sub_name)\n",
    "#     all_demography_detail_df = pd.concat([all_demography_detail_df, demography_detail_df]) \n",
    "#     all_demography_detail_df.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "# # list_of_tran_mat_paths\n",
    "\n",
    "def get_metadata_info(info_type, annot_type): \n",
    "    all_demography_df = pd.DataFrame() \n",
    "    all_demography_detail_df = pd.DataFrame() \n",
    "    for i, dirr in enumerate(metadata_subdirectory): \n",
    "        demography_df = pd.read_csv(f\"{root_directory}/{dirr}/Demography.csv\", index_col=False)\n",
    "        demography_df.insert(1, 'Dataset', [dirr]*demography_df.shape[0])\n",
    "        all_demography_df = pd.concat([all_demography_df, demography_df]) \n",
    "        all_demography_df.reset_index(drop=True, inplace=True) \n",
    "\n",
    "        demography_detail_df = pd.read_csv(f\"{root_directory}/{dirr}/Demography_Details.csv\", index_col=False)\n",
    "        demography_detail_df.insert(0, 'Dataset', [dirr]*demography_detail_df.shape[0])\n",
    "        sub_name = demography_detail_df['File_Name'].str[:-1].values.tolist() if i==1 else demography_detail_df['File_Name'].values.tolist() \n",
    "        demography_detail_df.insert(2, 'Subject_Name', sub_name)\n",
    "        all_demography_detail_df = pd.concat([all_demography_detail_df, demography_detail_df]) \n",
    "        all_demography_detail_df.reset_index(drop=True, inplace=True) \n",
    "\n",
    "    return all_demography_df, all_demography_detail_df \n",
    "\n",
    "\n",
    "info_type=\"file\" ##\"sub\"/\"file\"  ## Change for new type of result\n",
    "annot_type = annotation_type[1]   ## Change for different data preparation for 'annot' and 'tran' \n",
    "\n",
    "all_demography_df, all_demography_detail_df = get_metadata_info(info_type=info_type, annot_type=annot_type) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "informed-triumph",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>#</th>\n",
       "      <th>Dataset</th>\n",
       "      <th>Category_Name</th>\n",
       "      <th>Category</th>\n",
       "      <th>Total_Count</th>\n",
       "      <th>Male_Count</th>\n",
       "      <th>Female_Count</th>\n",
       "      <th>Total_AgeRange</th>\n",
       "      <th>Male_AgeRange</th>\n",
       "      <th>Female_AgeRange</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>CAP_Sleep</td>\n",
       "      <td>Bruxism</td>\n",
       "      <td>brux</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>23 - 34</td>\n",
       "      <td>23 - 34</td>\n",
       "      <td>0 - 0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>CAP_Sleep</td>\n",
       "      <td>Sleep-Disordered Breathing</td>\n",
       "      <td>sdb</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>65 - 78</td>\n",
       "      <td>65 - 78</td>\n",
       "      <td>0 - 0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>CAP_Sleep</td>\n",
       "      <td>Insomnia</td>\n",
       "      <td>ins</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>47 - 82</td>\n",
       "      <td>54 - 82</td>\n",
       "      <td>47 - 59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>CAP_Sleep</td>\n",
       "      <td>Narcolepsy</td>\n",
       "      <td>narco</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>18 - 44</td>\n",
       "      <td>24 - 43</td>\n",
       "      <td>18 - 44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>CAP_Sleep</td>\n",
       "      <td>Nocturnal Frontal Lobe Epilepsy</td>\n",
       "      <td>nfle</td>\n",
       "      <td>40</td>\n",
       "      <td>21</td>\n",
       "      <td>19</td>\n",
       "      <td>14 - 67</td>\n",
       "      <td>14 - 44</td>\n",
       "      <td>16 - 67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>CAP_Sleep</td>\n",
       "      <td>Periodic Leg Movements</td>\n",
       "      <td>plm</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>40 - 62</td>\n",
       "      <td>40 - 62</td>\n",
       "      <td>50 - 52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>CAP_Sleep</td>\n",
       "      <td>REM Behavior Disorder</td>\n",
       "      <td>rbd</td>\n",
       "      <td>22</td>\n",
       "      <td>19</td>\n",
       "      <td>3</td>\n",
       "      <td>58 - 82</td>\n",
       "      <td>58 - 82</td>\n",
       "      <td>73 - 76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>CAP_Sleep</td>\n",
       "      <td>No Pathology (Controls)</td>\n",
       "      <td>n</td>\n",
       "      <td>16</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>23 - 42</td>\n",
       "      <td>23 - 34</td>\n",
       "      <td>24 - 42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>10</td>\n",
       "      <td>CAP_Sleep</td>\n",
       "      <td>Total</td>\n",
       "      <td>NaN</td>\n",
       "      <td>108</td>\n",
       "      <td>66</td>\n",
       "      <td>42</td>\n",
       "      <td>14 - 82</td>\n",
       "      <td>14 - 82</td>\n",
       "      <td>16 - 76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>11</td>\n",
       "      <td>CAP_Sleep</td>\n",
       "      <td>Sleep Disorders</td>\n",
       "      <td>dis</td>\n",
       "      <td>92</td>\n",
       "      <td>59</td>\n",
       "      <td>33</td>\n",
       "      <td>14 - 82</td>\n",
       "      <td>14 - 82</td>\n",
       "      <td>16 - 76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>12</td>\n",
       "      <td>CAP_Sleep</td>\n",
       "      <td>No Pathology (Controls)</td>\n",
       "      <td>n</td>\n",
       "      <td>16</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>23 - 42</td>\n",
       "      <td>23 - 34</td>\n",
       "      <td>24 - 42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>Sleep_EDFX</td>\n",
       "      <td>SC</td>\n",
       "      <td>n</td>\n",
       "      <td>153</td>\n",
       "      <td>71</td>\n",
       "      <td>82</td>\n",
       "      <td>25 - 101</td>\n",
       "      <td>26 - 97</td>\n",
       "      <td>25 - 101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2</td>\n",
       "      <td>Sleep_EDFX</td>\n",
       "      <td>ST</td>\n",
       "      <td>n</td>\n",
       "      <td>44</td>\n",
       "      <td>30</td>\n",
       "      <td>14</td>\n",
       "      <td>18 - 79</td>\n",
       "      <td>18 - 79</td>\n",
       "      <td>20 - 60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>3</td>\n",
       "      <td>Sleep_EDFX</td>\n",
       "      <td>Total</td>\n",
       "      <td>n</td>\n",
       "      <td>197</td>\n",
       "      <td>101</td>\n",
       "      <td>96</td>\n",
       "      <td>19 - 101</td>\n",
       "      <td>19 - 97</td>\n",
       "      <td>21 - 101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>4</td>\n",
       "      <td>Sleep_EDFX</td>\n",
       "      <td>No Pathology (Controls)</td>\n",
       "      <td>n</td>\n",
       "      <td>197</td>\n",
       "      <td>101</td>\n",
       "      <td>96</td>\n",
       "      <td>18 - 101</td>\n",
       "      <td>18 - 97</td>\n",
       "      <td>20 - 101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>5</td>\n",
       "      <td>Sleep_EDFX</td>\n",
       "      <td>Total</td>\n",
       "      <td>n</td>\n",
       "      <td>197</td>\n",
       "      <td>101</td>\n",
       "      <td>96</td>\n",
       "      <td>19 - 101</td>\n",
       "      <td>19 - 97</td>\n",
       "      <td>21 - 101</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     #     Dataset                    Category_Name Category  Total_Count  \\\n",
       "0    1   CAP_Sleep                          Bruxism     brux            2   \n",
       "1    2   CAP_Sleep       Sleep-Disordered Breathing      sdb            4   \n",
       "2    3   CAP_Sleep                         Insomnia      ins            9   \n",
       "3    4   CAP_Sleep                       Narcolepsy    narco            5   \n",
       "4    5   CAP_Sleep  Nocturnal Frontal Lobe Epilepsy     nfle           40   \n",
       "5    6   CAP_Sleep           Periodic Leg Movements      plm           10   \n",
       "6    7   CAP_Sleep            REM Behavior Disorder      rbd           22   \n",
       "7    8   CAP_Sleep          No Pathology (Controls)        n           16   \n",
       "8   10   CAP_Sleep                            Total      NaN          108   \n",
       "9   11   CAP_Sleep                  Sleep Disorders      dis           92   \n",
       "10  12   CAP_Sleep          No Pathology (Controls)        n           16   \n",
       "11   1  Sleep_EDFX                               SC        n          153   \n",
       "12   2  Sleep_EDFX                               ST        n           44   \n",
       "13   3  Sleep_EDFX                            Total        n          197   \n",
       "14   4  Sleep_EDFX          No Pathology (Controls)        n          197   \n",
       "15   5  Sleep_EDFX                            Total        n          197   \n",
       "\n",
       "    Male_Count  Female_Count Total_AgeRange Male_AgeRange Female_AgeRange  \n",
       "0            2             0        23 - 34       23 - 34           0 - 0  \n",
       "1            4             0        65 - 78       65 - 78           0 - 0  \n",
       "2            4             5        47 - 82       54 - 82         47 - 59  \n",
       "3            2             3        18 - 44       24 - 43         18 - 44  \n",
       "4           21            19        14 - 67       14 - 44         16 - 67  \n",
       "5            7             3        40 - 62       40 - 62         50 - 52  \n",
       "6           19             3        58 - 82       58 - 82         73 - 76  \n",
       "7            7             9        23 - 42       23 - 34         24 - 42  \n",
       "8           66            42        14 - 82       14 - 82         16 - 76  \n",
       "9           59            33        14 - 82       14 - 82         16 - 76  \n",
       "10           7             9        23 - 42       23 - 34         24 - 42  \n",
       "11          71            82       25 - 101       26 - 97        25 - 101  \n",
       "12          30            14        18 - 79       18 - 79         20 - 60  \n",
       "13         101            96       19 - 101       19 - 97        21 - 101  \n",
       "14         101            96       18 - 101       18 - 97        20 - 101  \n",
       "15         101            96       19 - 101       19 - 97        21 - 101  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_demography_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "alive-movie",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset</th>\n",
       "      <th>File_Name</th>\n",
       "      <th>Subject_Name</th>\n",
       "      <th>Category</th>\n",
       "      <th>Subject_ID</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CAP_Sleep</td>\n",
       "      <td>brux1</td>\n",
       "      <td>brux1</td>\n",
       "      <td>brux</td>\n",
       "      <td>1</td>\n",
       "      <td>M</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CAP_Sleep</td>\n",
       "      <td>brux2</td>\n",
       "      <td>brux2</td>\n",
       "      <td>brux</td>\n",
       "      <td>2</td>\n",
       "      <td>M</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CAP_Sleep</td>\n",
       "      <td>sdb1</td>\n",
       "      <td>sdb1</td>\n",
       "      <td>sdb</td>\n",
       "      <td>1</td>\n",
       "      <td>M</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CAP_Sleep</td>\n",
       "      <td>sdb2</td>\n",
       "      <td>sdb2</td>\n",
       "      <td>sdb</td>\n",
       "      <td>2</td>\n",
       "      <td>M</td>\n",
       "      <td>77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CAP_Sleep</td>\n",
       "      <td>sdb3</td>\n",
       "      <td>sdb3</td>\n",
       "      <td>sdb</td>\n",
       "      <td>3</td>\n",
       "      <td>M</td>\n",
       "      <td>78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>Sleep_EDFX</td>\n",
       "      <td>ST7212</td>\n",
       "      <td>ST721</td>\n",
       "      <td>n</td>\n",
       "      <td>21</td>\n",
       "      <td>M</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301</th>\n",
       "      <td>Sleep_EDFX</td>\n",
       "      <td>ST7221</td>\n",
       "      <td>ST722</td>\n",
       "      <td>n</td>\n",
       "      <td>22</td>\n",
       "      <td>F</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>Sleep_EDFX</td>\n",
       "      <td>ST7222</td>\n",
       "      <td>ST722</td>\n",
       "      <td>n</td>\n",
       "      <td>22</td>\n",
       "      <td>F</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303</th>\n",
       "      <td>Sleep_EDFX</td>\n",
       "      <td>ST7241</td>\n",
       "      <td>ST724</td>\n",
       "      <td>n</td>\n",
       "      <td>24</td>\n",
       "      <td>M</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>304</th>\n",
       "      <td>Sleep_EDFX</td>\n",
       "      <td>ST7242</td>\n",
       "      <td>ST724</td>\n",
       "      <td>n</td>\n",
       "      <td>24</td>\n",
       "      <td>M</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>305 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Dataset File_Name Subject_Name Category  Subject_ID Gender  Age\n",
       "0     CAP_Sleep     brux1        brux1     brux           1      M   34\n",
       "1     CAP_Sleep     brux2        brux2     brux           2      M   23\n",
       "2     CAP_Sleep      sdb1         sdb1      sdb           1      M   65\n",
       "3     CAP_Sleep      sdb2         sdb2      sdb           2      M   77\n",
       "4     CAP_Sleep      sdb3         sdb3      sdb           3      M   78\n",
       "..          ...       ...          ...      ...         ...    ...  ...\n",
       "300  Sleep_EDFX    ST7212        ST721        n          21      M   34\n",
       "301  Sleep_EDFX    ST7221        ST722        n          22      F   56\n",
       "302  Sleep_EDFX    ST7222        ST722        n          22      F   56\n",
       "303  Sleep_EDFX    ST7241        ST724        n          24      M   48\n",
       "304  Sleep_EDFX    ST7242        ST724        n          24      M   48\n",
       "\n",
       "[305 rows x 7 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_demography_detail_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "guided-orlando",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       brux\n",
       "1       brux\n",
       "2        sdb\n",
       "3        sdb\n",
       "4        sdb\n",
       "       ...  \n",
       "300    ST721\n",
       "301    ST722\n",
       "302    ST722\n",
       "303    ST724\n",
       "304    ST724\n",
       "Name: File_Name, Length: 305, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_demography_detail_df['File_Name'].str[:-1]"
   ]
  },
  {
   "cell_type": "raw",
   "id": "victorian-johns",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "activated-radio",
   "metadata": {},
   "source": [
    "### Get transition matrix or features information from transition probabilities and P/AUC information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "spectacular-testament",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./Results//_Combined/Subject_One_Night/Annot_Proba_Transition2.csv'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f\"{root_directory}{data_directory}/{data_subdirectory}/Annot_Proba_Transition2.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "foster-testing",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset</th>\n",
       "      <th>Category</th>\n",
       "      <th>Subject_Name</th>\n",
       "      <th>W-&gt;W</th>\n",
       "      <th>W-&gt;S1</th>\n",
       "      <th>W-&gt;S2</th>\n",
       "      <th>W-&gt;S3</th>\n",
       "      <th>W-&gt;S4</th>\n",
       "      <th>W-&gt;REM</th>\n",
       "      <th>S1-&gt;W</th>\n",
       "      <th>...</th>\n",
       "      <th>S4-&gt;S2</th>\n",
       "      <th>S4-&gt;S3</th>\n",
       "      <th>S4-&gt;S4</th>\n",
       "      <th>S4-&gt;REM</th>\n",
       "      <th>REM-&gt;W</th>\n",
       "      <th>REM-&gt;S1</th>\n",
       "      <th>REM-&gt;S2</th>\n",
       "      <th>REM-&gt;S3</th>\n",
       "      <th>REM-&gt;S4</th>\n",
       "      <th>REM-&gt;REM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CAP_Sleep</td>\n",
       "      <td>brux</td>\n",
       "      <td>brux1</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.190476</td>\n",
       "      <td>0.009524</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.030769</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004926</td>\n",
       "      <td>0.024631</td>\n",
       "      <td>0.970443</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.033520</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.966480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CAP_Sleep</td>\n",
       "      <td>brux</td>\n",
       "      <td>brux2</td>\n",
       "      <td>0.825397</td>\n",
       "      <td>0.174603</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.061728</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.012048</td>\n",
       "      <td>0.984940</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.019324</td>\n",
       "      <td>0.004831</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.975845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CAP_Sleep</td>\n",
       "      <td>sdb</td>\n",
       "      <td>sdb1</td>\n",
       "      <td>0.876712</td>\n",
       "      <td>0.123288</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.099237</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005076</td>\n",
       "      <td>0.030457</td>\n",
       "      <td>0.949239</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.009346</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.028037</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.962617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CAP_Sleep</td>\n",
       "      <td>sdb</td>\n",
       "      <td>sdb2</td>\n",
       "      <td>0.948718</td>\n",
       "      <td>0.044872</td>\n",
       "      <td>0.006410</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.011364</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.016949</td>\n",
       "      <td>0.966102</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.025641</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.974359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CAP_Sleep</td>\n",
       "      <td>sdb</td>\n",
       "      <td>sdb3</td>\n",
       "      <td>0.934272</td>\n",
       "      <td>0.046948</td>\n",
       "      <td>0.018779</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.108696</td>\n",
       "      <td>...</td>\n",
       "      <td>0.025974</td>\n",
       "      <td>0.038961</td>\n",
       "      <td>0.935065</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.937500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>Sleep_EDFX</td>\n",
       "      <td>n</td>\n",
       "      <td>ST7191</td>\n",
       "      <td>0.742857</td>\n",
       "      <td>0.242857</td>\n",
       "      <td>0.014286</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.044118</td>\n",
       "      <td>...</td>\n",
       "      <td>0.013889</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.805556</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>0.015000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.965000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>Sleep_EDFX</td>\n",
       "      <td>n</td>\n",
       "      <td>ST7201</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.014493</td>\n",
       "      <td>...</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>0.346154</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.044776</td>\n",
       "      <td>0.007463</td>\n",
       "      <td>0.014925</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.932836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>Sleep_EDFX</td>\n",
       "      <td>n</td>\n",
       "      <td>ST7211</td>\n",
       "      <td>0.894737</td>\n",
       "      <td>0.099415</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.005848</td>\n",
       "      <td>0.116667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.016949</td>\n",
       "      <td>0.254237</td>\n",
       "      <td>0.728814</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.025641</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.019231</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.955128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>Sleep_EDFX</td>\n",
       "      <td>n</td>\n",
       "      <td>ST7221</td>\n",
       "      <td>0.820000</td>\n",
       "      <td>0.180000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.052133</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.021645</td>\n",
       "      <td>0.043290</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.935065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>Sleep_EDFX</td>\n",
       "      <td>n</td>\n",
       "      <td>ST7241</td>\n",
       "      <td>0.620690</td>\n",
       "      <td>0.275862</td>\n",
       "      <td>0.034483</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.068966</td>\n",
       "      <td>0.047619</td>\n",
       "      <td>...</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.016878</td>\n",
       "      <td>0.016878</td>\n",
       "      <td>0.008439</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.957806</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>208 rows × 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Dataset Category Subject_Name      W->W     W->S1     W->S2  W->S3  \\\n",
       "0     CAP_Sleep     brux        brux1  0.800000  0.190476  0.009524    0.0   \n",
       "1     CAP_Sleep     brux        brux2  0.825397  0.174603  0.000000    0.0   \n",
       "2     CAP_Sleep      sdb         sdb1  0.876712  0.123288  0.000000    0.0   \n",
       "3     CAP_Sleep      sdb         sdb2  0.948718  0.044872  0.006410    0.0   \n",
       "4     CAP_Sleep      sdb         sdb3  0.934272  0.046948  0.018779    0.0   \n",
       "..          ...      ...          ...       ...       ...       ...    ...   \n",
       "203  Sleep_EDFX        n       ST7191  0.742857  0.242857  0.014286    0.0   \n",
       "204  Sleep_EDFX        n       ST7201  0.333333  0.555556  0.055556    0.0   \n",
       "205  Sleep_EDFX        n       ST7211  0.894737  0.099415  0.000000    0.0   \n",
       "206  Sleep_EDFX        n       ST7221  0.820000  0.180000  0.000000    0.0   \n",
       "207  Sleep_EDFX        n       ST7241  0.620690  0.275862  0.034483    0.0   \n",
       "\n",
       "     W->S4    W->REM     S1->W  ...    S4->S2    S4->S3    S4->S4  S4->REM  \\\n",
       "0      0.0  0.000000  0.030769  ...  0.004926  0.024631  0.970443      0.0   \n",
       "1      0.0  0.000000  0.061728  ...  0.000000  0.012048  0.984940      0.0   \n",
       "2      0.0  0.000000  0.099237  ...  0.005076  0.030457  0.949239      0.0   \n",
       "3      0.0  0.000000  0.011364  ...  0.008475  0.016949  0.966102      0.0   \n",
       "4      0.0  0.000000  0.108696  ...  0.025974  0.038961  0.935065      0.0   \n",
       "..     ...       ...       ...  ...       ...       ...       ...      ...   \n",
       "203    0.0  0.000000  0.044118  ...  0.013889  0.166667  0.805556      0.0   \n",
       "204    0.0  0.055556  0.014493  ...  0.038462  0.615385  0.346154      0.0   \n",
       "205    0.0  0.005848  0.116667  ...  0.016949  0.254237  0.728814      0.0   \n",
       "206    0.0  0.000000  0.052133  ...  0.000000  0.000000  0.000000      0.0   \n",
       "207    0.0  0.068966  0.047619  ...  0.142857  0.571429  0.142857      0.0   \n",
       "\n",
       "       REM->W   REM->S1   REM->S2  REM->S3  REM->S4  REM->REM  \n",
       "0    0.033520  0.000000  0.000000      0.0      0.0  0.966480  \n",
       "1    0.019324  0.004831  0.000000      0.0      0.0  0.975845  \n",
       "2    0.009346  0.000000  0.028037      0.0      0.0  0.962617  \n",
       "3    0.000000  0.000000  0.025641      0.0      0.0  0.974359  \n",
       "4    0.062500  0.000000  0.000000      0.0      0.0  0.937500  \n",
       "..        ...       ...       ...      ...      ...       ...  \n",
       "203  0.000000  0.020000  0.015000      0.0      0.0  0.965000  \n",
       "204  0.044776  0.007463  0.014925      0.0      0.0  0.932836  \n",
       "205  0.025641  0.000000  0.019231      0.0      0.0  0.955128  \n",
       "206  0.021645  0.043290  0.000000      0.0      0.0  0.935065  \n",
       "207  0.016878  0.016878  0.008439      0.0      0.0  0.957806  \n",
       "\n",
       "[208 rows x 39 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "annot_proba_transition2_feature_df = pd.read_csv(f\"{root_directory}{data_directory}/{data_subdirectory}/Annot_Proba_Transition2.csv\", index_col=False)\n",
    "tran_proba_transition2_feature_df = pd.read_csv(f\"{root_directory}{data_directory}/{data_subdirectory}/Tran_Proba_Transition2.csv\", index_col=False)\n",
    "\n",
    "annot_proba_transition2_feature_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "impressed-haiti",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset</th>\n",
       "      <th>Category</th>\n",
       "      <th>Subject_Name</th>\n",
       "      <th>W-&gt;W</th>\n",
       "      <th>W-&gt;S1</th>\n",
       "      <th>W-&gt;S2</th>\n",
       "      <th>W-&gt;S3</th>\n",
       "      <th>W-&gt;S4</th>\n",
       "      <th>W-&gt;REM</th>\n",
       "      <th>S1-&gt;W</th>\n",
       "      <th>...</th>\n",
       "      <th>S4-&gt;S2</th>\n",
       "      <th>S4-&gt;S3</th>\n",
       "      <th>S4-&gt;S4</th>\n",
       "      <th>S4-&gt;REM</th>\n",
       "      <th>REM-&gt;W</th>\n",
       "      <th>REM-&gt;S1</th>\n",
       "      <th>REM-&gt;S2</th>\n",
       "      <th>REM-&gt;S3</th>\n",
       "      <th>REM-&gt;S4</th>\n",
       "      <th>REM-&gt;REM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CAP_Sleep</td>\n",
       "      <td>brux</td>\n",
       "      <td>brux1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>0.047619</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.160000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CAP_Sleep</td>\n",
       "      <td>brux</td>\n",
       "      <td>brux2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CAP_Sleep</td>\n",
       "      <td>sdb</td>\n",
       "      <td>sdb1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.419355</td>\n",
       "      <td>...</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CAP_Sleep</td>\n",
       "      <td>sdb</td>\n",
       "      <td>sdb2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.153846</td>\n",
       "      <td>...</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CAP_Sleep</td>\n",
       "      <td>sdb</td>\n",
       "      <td>sdb3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.692308</td>\n",
       "      <td>0.307692</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>Sleep_EDFX</td>\n",
       "      <td>n</td>\n",
       "      <td>ST7191</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.941176</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>Sleep_EDFX</td>\n",
       "      <td>n</td>\n",
       "      <td>ST7201</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>...</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.941176</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>Sleep_EDFX</td>\n",
       "      <td>n</td>\n",
       "      <td>ST7211</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.941176</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.225806</td>\n",
       "      <td>...</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>0.937500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>Sleep_EDFX</td>\n",
       "      <td>n</td>\n",
       "      <td>ST7221</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.196429</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>Sleep_EDFX</td>\n",
       "      <td>n</td>\n",
       "      <td>ST7241</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>208 rows × 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Dataset Category Subject_Name  W->W     W->S1     W->S2  W->S3  W->S4  \\\n",
       "0     CAP_Sleep     brux        brux1   0.0  0.952381  0.047619    0.0    0.0   \n",
       "1     CAP_Sleep     brux        brux2   0.0  1.000000  0.000000    0.0    0.0   \n",
       "2     CAP_Sleep      sdb         sdb1   0.0  1.000000  0.000000    0.0    0.0   \n",
       "3     CAP_Sleep      sdb         sdb2   0.0  0.857143  0.142857    0.0    0.0   \n",
       "4     CAP_Sleep      sdb         sdb3   0.0  0.692308  0.307692    0.0    0.0   \n",
       "..          ...      ...          ...   ...       ...       ...    ...    ...   \n",
       "203  Sleep_EDFX        n       ST7191   0.0  0.941176  0.058824    0.0    0.0   \n",
       "204  Sleep_EDFX        n       ST7201   0.0  0.833333  0.083333    0.0    0.0   \n",
       "205  Sleep_EDFX        n       ST7211   0.0  0.941176  0.000000    0.0    0.0   \n",
       "206  Sleep_EDFX        n       ST7221   0.0  1.000000  0.000000    0.0    0.0   \n",
       "207  Sleep_EDFX        n       ST7241   0.0  0.727273  0.090909    0.0    0.0   \n",
       "\n",
       "       W->REM     S1->W  ...    S4->S2    S4->S3  S4->S4  S4->REM    REM->W  \\\n",
       "0    0.000000  0.160000  ...  0.166667  0.833333     0.0      0.0  1.000000   \n",
       "1    0.000000  0.416667  ...  0.000000  0.800000     0.0      0.0  0.800000   \n",
       "2    0.000000  0.419355  ...  0.100000  0.600000     0.0      0.0  0.250000   \n",
       "3    0.000000  0.153846  ...  0.250000  0.500000     0.0      0.0  0.000000   \n",
       "4    0.000000  0.500000  ...  0.400000  0.600000     0.0      0.0  1.000000   \n",
       "..        ...       ...  ...       ...       ...     ...      ...       ...   \n",
       "203  0.000000  0.100000  ...  0.071429  0.857143     0.0      0.0  0.000000   \n",
       "204  0.083333  0.038462  ...  0.058824  0.941176     0.0      0.0  0.666667   \n",
       "205  0.058824  0.225806  ...  0.062500  0.937500     0.0      0.0  0.571429   \n",
       "206  0.000000  0.196429  ...  0.000000  0.000000     0.0      0.0  0.333333   \n",
       "207  0.181818  0.100000  ...  0.166667  0.666667     0.0      0.0  0.400000   \n",
       "\n",
       "      REM->S1   REM->S2  REM->S3  REM->S4  REM->REM  \n",
       "0    0.000000  0.000000      0.0      0.0       0.0  \n",
       "1    0.200000  0.000000      0.0      0.0       0.0  \n",
       "2    0.000000  0.750000      0.0      0.0       0.0  \n",
       "3    0.000000  1.000000      0.0      0.0       0.0  \n",
       "4    0.000000  0.000000      0.0      0.0       0.0  \n",
       "..        ...       ...      ...      ...       ...  \n",
       "203  0.571429  0.428571      0.0      0.0       0.0  \n",
       "204  0.111111  0.222222      0.0      0.0       0.0  \n",
       "205  0.000000  0.428571      0.0      0.0       0.0  \n",
       "206  0.666667  0.000000      0.0      0.0       0.0  \n",
       "207  0.400000  0.200000      0.0      0.0       0.0  \n",
       "\n",
       "[208 rows x 39 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tran_proba_transition2_feature_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "crazy-ontario",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "third-satisfaction",
   "metadata": {},
   "source": [
    "#### Prepare final dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "enclosed-bullet",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset</th>\n",
       "      <th>Category</th>\n",
       "      <th>Subject_Name</th>\n",
       "      <th>W-&gt;W</th>\n",
       "      <th>W-&gt;S1</th>\n",
       "      <th>W-&gt;S2</th>\n",
       "      <th>W-&gt;S3</th>\n",
       "      <th>W-&gt;S4</th>\n",
       "      <th>W-&gt;REM</th>\n",
       "      <th>S1-&gt;W</th>\n",
       "      <th>...</th>\n",
       "      <th>S4-&gt;S2</th>\n",
       "      <th>S4-&gt;S3</th>\n",
       "      <th>S4-&gt;S4</th>\n",
       "      <th>S4-&gt;REM</th>\n",
       "      <th>REM-&gt;W</th>\n",
       "      <th>REM-&gt;S1</th>\n",
       "      <th>REM-&gt;S2</th>\n",
       "      <th>REM-&gt;S3</th>\n",
       "      <th>REM-&gt;S4</th>\n",
       "      <th>REM-&gt;REM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CAP_Sleep</td>\n",
       "      <td>brux</td>\n",
       "      <td>brux1</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.190476</td>\n",
       "      <td>0.009524</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.030769</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004926</td>\n",
       "      <td>0.024631</td>\n",
       "      <td>0.970443</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.033520</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.966480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CAP_Sleep</td>\n",
       "      <td>brux</td>\n",
       "      <td>brux2</td>\n",
       "      <td>0.825397</td>\n",
       "      <td>0.174603</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.061728</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.012048</td>\n",
       "      <td>0.984940</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.019324</td>\n",
       "      <td>0.004831</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.975845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CAP_Sleep</td>\n",
       "      <td>sdb</td>\n",
       "      <td>sdb1</td>\n",
       "      <td>0.876712</td>\n",
       "      <td>0.123288</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.099237</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005076</td>\n",
       "      <td>0.030457</td>\n",
       "      <td>0.949239</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.009346</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.028037</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.962617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CAP_Sleep</td>\n",
       "      <td>sdb</td>\n",
       "      <td>sdb2</td>\n",
       "      <td>0.948718</td>\n",
       "      <td>0.044872</td>\n",
       "      <td>0.006410</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.011364</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.016949</td>\n",
       "      <td>0.966102</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.025641</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.974359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CAP_Sleep</td>\n",
       "      <td>sdb</td>\n",
       "      <td>sdb3</td>\n",
       "      <td>0.934272</td>\n",
       "      <td>0.046948</td>\n",
       "      <td>0.018779</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.108696</td>\n",
       "      <td>...</td>\n",
       "      <td>0.025974</td>\n",
       "      <td>0.038961</td>\n",
       "      <td>0.935065</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.937500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>Sleep_EDFX</td>\n",
       "      <td>n</td>\n",
       "      <td>ST7191</td>\n",
       "      <td>0.742857</td>\n",
       "      <td>0.242857</td>\n",
       "      <td>0.014286</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.044118</td>\n",
       "      <td>...</td>\n",
       "      <td>0.013889</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.805556</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>0.015000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.965000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>Sleep_EDFX</td>\n",
       "      <td>n</td>\n",
       "      <td>ST7201</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.014493</td>\n",
       "      <td>...</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>0.346154</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.044776</td>\n",
       "      <td>0.007463</td>\n",
       "      <td>0.014925</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.932836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>Sleep_EDFX</td>\n",
       "      <td>n</td>\n",
       "      <td>ST7211</td>\n",
       "      <td>0.894737</td>\n",
       "      <td>0.099415</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.005848</td>\n",
       "      <td>0.116667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.016949</td>\n",
       "      <td>0.254237</td>\n",
       "      <td>0.728814</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.025641</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.019231</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.955128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>Sleep_EDFX</td>\n",
       "      <td>n</td>\n",
       "      <td>ST7221</td>\n",
       "      <td>0.820000</td>\n",
       "      <td>0.180000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.052133</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.021645</td>\n",
       "      <td>0.043290</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.935065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>Sleep_EDFX</td>\n",
       "      <td>n</td>\n",
       "      <td>ST7241</td>\n",
       "      <td>0.620690</td>\n",
       "      <td>0.275862</td>\n",
       "      <td>0.034483</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.068966</td>\n",
       "      <td>0.047619</td>\n",
       "      <td>...</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.016878</td>\n",
       "      <td>0.016878</td>\n",
       "      <td>0.008439</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.957806</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>208 rows × 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Dataset Category Subject_Name      W->W     W->S1     W->S2  W->S3  \\\n",
       "0     CAP_Sleep     brux        brux1  0.800000  0.190476  0.009524    0.0   \n",
       "1     CAP_Sleep     brux        brux2  0.825397  0.174603  0.000000    0.0   \n",
       "2     CAP_Sleep      sdb         sdb1  0.876712  0.123288  0.000000    0.0   \n",
       "3     CAP_Sleep      sdb         sdb2  0.948718  0.044872  0.006410    0.0   \n",
       "4     CAP_Sleep      sdb         sdb3  0.934272  0.046948  0.018779    0.0   \n",
       "..          ...      ...          ...       ...       ...       ...    ...   \n",
       "203  Sleep_EDFX        n       ST7191  0.742857  0.242857  0.014286    0.0   \n",
       "204  Sleep_EDFX        n       ST7201  0.333333  0.555556  0.055556    0.0   \n",
       "205  Sleep_EDFX        n       ST7211  0.894737  0.099415  0.000000    0.0   \n",
       "206  Sleep_EDFX        n       ST7221  0.820000  0.180000  0.000000    0.0   \n",
       "207  Sleep_EDFX        n       ST7241  0.620690  0.275862  0.034483    0.0   \n",
       "\n",
       "     W->S4    W->REM     S1->W  ...    S4->S2    S4->S3    S4->S4  S4->REM  \\\n",
       "0      0.0  0.000000  0.030769  ...  0.004926  0.024631  0.970443      0.0   \n",
       "1      0.0  0.000000  0.061728  ...  0.000000  0.012048  0.984940      0.0   \n",
       "2      0.0  0.000000  0.099237  ...  0.005076  0.030457  0.949239      0.0   \n",
       "3      0.0  0.000000  0.011364  ...  0.008475  0.016949  0.966102      0.0   \n",
       "4      0.0  0.000000  0.108696  ...  0.025974  0.038961  0.935065      0.0   \n",
       "..     ...       ...       ...  ...       ...       ...       ...      ...   \n",
       "203    0.0  0.000000  0.044118  ...  0.013889  0.166667  0.805556      0.0   \n",
       "204    0.0  0.055556  0.014493  ...  0.038462  0.615385  0.346154      0.0   \n",
       "205    0.0  0.005848  0.116667  ...  0.016949  0.254237  0.728814      0.0   \n",
       "206    0.0  0.000000  0.052133  ...  0.000000  0.000000  0.000000      0.0   \n",
       "207    0.0  0.068966  0.047619  ...  0.142857  0.571429  0.142857      0.0   \n",
       "\n",
       "       REM->W   REM->S1   REM->S2  REM->S3  REM->S4  REM->REM  \n",
       "0    0.033520  0.000000  0.000000      0.0      0.0  0.966480  \n",
       "1    0.019324  0.004831  0.000000      0.0      0.0  0.975845  \n",
       "2    0.009346  0.000000  0.028037      0.0      0.0  0.962617  \n",
       "3    0.000000  0.000000  0.025641      0.0      0.0  0.974359  \n",
       "4    0.062500  0.000000  0.000000      0.0      0.0  0.937500  \n",
       "..        ...       ...       ...      ...      ...       ...  \n",
       "203  0.000000  0.020000  0.015000      0.0      0.0  0.965000  \n",
       "204  0.044776  0.007463  0.014925      0.0      0.0  0.932836  \n",
       "205  0.025641  0.000000  0.019231      0.0      0.0  0.955128  \n",
       "206  0.021645  0.043290  0.000000      0.0      0.0  0.935065  \n",
       "207  0.016878  0.016878  0.008439      0.0      0.0  0.957806  \n",
       "\n",
       "[208 rows x 39 columns]"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_name='Class'\n",
    "\n",
    "dataset = annot_proba_transition2_feature_df.copy() \n",
    "dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "random-privacy",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "czech-nirvana",
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_age_category_to_class(dat_set, demo_det, source_cols=['Subject_Name', 'File_Name'], age_col = 'Age', age_ranges = [[19, 30], [31, 40]], class_name='Class', multi_class=True):\n",
    "    tmp_df = dataset.merge(all_demography_detail_df, how='inner', left_on=[source_cols[0]], right_on=[source_cols[1]])\n",
    "    tmp_df\n",
    "\n",
    "    dat_set.insert(3, age_col, tmp_df[age_col].values) \n",
    "    dat_set\n",
    "\n",
    "    dat_set = dat_set[ ((dat_set[age_col]>=age_ranges[0][0]) & (dat_set[age_col]<=age_ranges[0][1])) | ((dat_set[age_col]>=age_ranges[1][0]) & (dat_set[age_col]<=age_ranges[1][1])) ]  \n",
    "    dat_set.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    tmp_age_range = [list(range(age_ranges[0][0], age_ranges[0][1]+1)), list(range(age_ranges[1][0], age_ranges[1][1]+1))] \n",
    "    tmp_age_range \n",
    "\n",
    "    cls_map = {} \n",
    "    for i, lst in enumerate(tmp_age_range): \n",
    "        for l in lst:\n",
    "            cls_map[l]=i\n",
    "    cls_map\n",
    "    \n",
    "    all_cols = dat_set.columns.values.tolist() \n",
    "    if (age_col in all_cols):\n",
    "        if (class_name in all_cols): \n",
    "            dat_set = dat_set.drop([class_name], axis=1)\n",
    "        dat_set = dat_set.rename(columns={age_col: class_name})\n",
    "    \n",
    "    all_cols2 = dat_set.columns.values.tolist() \n",
    "    if (class_name not in all_cols) and (class_name in all_cols2):\n",
    "        dat_set.replace({class_name: cls_map}, inplace=True) \n",
    "    return cls_map, dat_set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "elect-journalism",
   "metadata": {},
   "outputs": [],
   "source": [
    "# label_map, dataset = map_age_category_to_class(dataset.copy(), all_demography_detail_df.copy(), source_cols=['Subject_Name', 'File_Name'], age_col = 'Age', age_ranges = [[19, 30], [31, 40]], class_name='Class', multi_class=True) ##19-101 \n",
    "# print(label_map)\n",
    "# dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "geographic-lawyer",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "indonesian-literacy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['n', 'brux', 'sdb', 'ins', 'narco', 'nfle', 'plm', 'rbd']\n",
      "['n', 'brux', 'sdb', 'ins', 'narco', 'nfle', 'plm', 'rbd']\n",
      "{'n': 0, 'brux': 1, 'sdb': 1, 'ins': 1, 'narco': 1, 'nfle': 1, 'plm': 1, 'rbd': 1}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset</th>\n",
       "      <th>Category</th>\n",
       "      <th>Subject_Name</th>\n",
       "      <th>Class</th>\n",
       "      <th>W-&gt;W</th>\n",
       "      <th>W-&gt;S1</th>\n",
       "      <th>W-&gt;S2</th>\n",
       "      <th>W-&gt;S3</th>\n",
       "      <th>W-&gt;S4</th>\n",
       "      <th>W-&gt;REM</th>\n",
       "      <th>...</th>\n",
       "      <th>S4-&gt;S2</th>\n",
       "      <th>S4-&gt;S3</th>\n",
       "      <th>S4-&gt;S4</th>\n",
       "      <th>S4-&gt;REM</th>\n",
       "      <th>REM-&gt;W</th>\n",
       "      <th>REM-&gt;S1</th>\n",
       "      <th>REM-&gt;S2</th>\n",
       "      <th>REM-&gt;S3</th>\n",
       "      <th>REM-&gt;S4</th>\n",
       "      <th>REM-&gt;REM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CAP_Sleep</td>\n",
       "      <td>brux</td>\n",
       "      <td>brux1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.190476</td>\n",
       "      <td>0.009524</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004926</td>\n",
       "      <td>0.024631</td>\n",
       "      <td>0.970443</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.033520</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.966480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CAP_Sleep</td>\n",
       "      <td>brux</td>\n",
       "      <td>brux2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.825397</td>\n",
       "      <td>0.174603</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.012048</td>\n",
       "      <td>0.984940</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.019324</td>\n",
       "      <td>0.004831</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.975845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CAP_Sleep</td>\n",
       "      <td>sdb</td>\n",
       "      <td>sdb1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.876712</td>\n",
       "      <td>0.123288</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005076</td>\n",
       "      <td>0.030457</td>\n",
       "      <td>0.949239</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.009346</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.028037</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.962617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CAP_Sleep</td>\n",
       "      <td>sdb</td>\n",
       "      <td>sdb2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.948718</td>\n",
       "      <td>0.044872</td>\n",
       "      <td>0.006410</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.016949</td>\n",
       "      <td>0.966102</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.025641</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.974359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CAP_Sleep</td>\n",
       "      <td>sdb</td>\n",
       "      <td>sdb3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.934272</td>\n",
       "      <td>0.046948</td>\n",
       "      <td>0.018779</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.025974</td>\n",
       "      <td>0.038961</td>\n",
       "      <td>0.935065</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.937500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>Sleep_EDFX</td>\n",
       "      <td>n</td>\n",
       "      <td>ST7191</td>\n",
       "      <td>0</td>\n",
       "      <td>0.742857</td>\n",
       "      <td>0.242857</td>\n",
       "      <td>0.014286</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.013889</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.805556</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>0.015000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.965000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>Sleep_EDFX</td>\n",
       "      <td>n</td>\n",
       "      <td>ST7201</td>\n",
       "      <td>0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>...</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>0.346154</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.044776</td>\n",
       "      <td>0.007463</td>\n",
       "      <td>0.014925</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.932836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>Sleep_EDFX</td>\n",
       "      <td>n</td>\n",
       "      <td>ST7211</td>\n",
       "      <td>0</td>\n",
       "      <td>0.894737</td>\n",
       "      <td>0.099415</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.005848</td>\n",
       "      <td>...</td>\n",
       "      <td>0.016949</td>\n",
       "      <td>0.254237</td>\n",
       "      <td>0.728814</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.025641</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.019231</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.955128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>Sleep_EDFX</td>\n",
       "      <td>n</td>\n",
       "      <td>ST7221</td>\n",
       "      <td>0</td>\n",
       "      <td>0.820000</td>\n",
       "      <td>0.180000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.021645</td>\n",
       "      <td>0.043290</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.935065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>Sleep_EDFX</td>\n",
       "      <td>n</td>\n",
       "      <td>ST7241</td>\n",
       "      <td>0</td>\n",
       "      <td>0.620690</td>\n",
       "      <td>0.275862</td>\n",
       "      <td>0.034483</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.068966</td>\n",
       "      <td>...</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.016878</td>\n",
       "      <td>0.016878</td>\n",
       "      <td>0.008439</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.957806</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>208 rows × 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Dataset Category Subject_Name  Class      W->W     W->S1     W->S2  \\\n",
       "0     CAP_Sleep     brux        brux1      1  0.800000  0.190476  0.009524   \n",
       "1     CAP_Sleep     brux        brux2      1  0.825397  0.174603  0.000000   \n",
       "2     CAP_Sleep      sdb         sdb1      1  0.876712  0.123288  0.000000   \n",
       "3     CAP_Sleep      sdb         sdb2      1  0.948718  0.044872  0.006410   \n",
       "4     CAP_Sleep      sdb         sdb3      1  0.934272  0.046948  0.018779   \n",
       "..          ...      ...          ...    ...       ...       ...       ...   \n",
       "203  Sleep_EDFX        n       ST7191      0  0.742857  0.242857  0.014286   \n",
       "204  Sleep_EDFX        n       ST7201      0  0.333333  0.555556  0.055556   \n",
       "205  Sleep_EDFX        n       ST7211      0  0.894737  0.099415  0.000000   \n",
       "206  Sleep_EDFX        n       ST7221      0  0.820000  0.180000  0.000000   \n",
       "207  Sleep_EDFX        n       ST7241      0  0.620690  0.275862  0.034483   \n",
       "\n",
       "     W->S3  W->S4    W->REM  ...    S4->S2    S4->S3    S4->S4  S4->REM  \\\n",
       "0      0.0    0.0  0.000000  ...  0.004926  0.024631  0.970443      0.0   \n",
       "1      0.0    0.0  0.000000  ...  0.000000  0.012048  0.984940      0.0   \n",
       "2      0.0    0.0  0.000000  ...  0.005076  0.030457  0.949239      0.0   \n",
       "3      0.0    0.0  0.000000  ...  0.008475  0.016949  0.966102      0.0   \n",
       "4      0.0    0.0  0.000000  ...  0.025974  0.038961  0.935065      0.0   \n",
       "..     ...    ...       ...  ...       ...       ...       ...      ...   \n",
       "203    0.0    0.0  0.000000  ...  0.013889  0.166667  0.805556      0.0   \n",
       "204    0.0    0.0  0.055556  ...  0.038462  0.615385  0.346154      0.0   \n",
       "205    0.0    0.0  0.005848  ...  0.016949  0.254237  0.728814      0.0   \n",
       "206    0.0    0.0  0.000000  ...  0.000000  0.000000  0.000000      0.0   \n",
       "207    0.0    0.0  0.068966  ...  0.142857  0.571429  0.142857      0.0   \n",
       "\n",
       "       REM->W   REM->S1   REM->S2  REM->S3  REM->S4  REM->REM  \n",
       "0    0.033520  0.000000  0.000000      0.0      0.0  0.966480  \n",
       "1    0.019324  0.004831  0.000000      0.0      0.0  0.975845  \n",
       "2    0.009346  0.000000  0.028037      0.0      0.0  0.962617  \n",
       "3    0.000000  0.000000  0.025641      0.0      0.0  0.974359  \n",
       "4    0.062500  0.000000  0.000000      0.0      0.0  0.937500  \n",
       "..        ...       ...       ...      ...      ...       ...  \n",
       "203  0.000000  0.020000  0.015000      0.0      0.0  0.965000  \n",
       "204  0.044776  0.007463  0.014925      0.0      0.0  0.932836  \n",
       "205  0.025641  0.000000  0.019231      0.0      0.0  0.955128  \n",
       "206  0.021645  0.043290  0.000000      0.0      0.0  0.935065  \n",
       "207  0.016878  0.016878  0.008439      0.0      0.0  0.957806  \n",
       "\n",
       "[208 rows x 40 columns]"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def map_category_to_class(dat_set, source_col='Category', class_name='Class', removable_cats=None, multi_class=True): \n",
    "    if class_name in dat_set.columns.tolist():\n",
    "        dat_set = dat_set.drop(columns=[class_name])\n",
    "    dat_set.insert(3, class_name, dat_set[source_col].values) \n",
    "    dat_set\n",
    "\n",
    "    cat_val = dat_set[source_col].unique().tolist() \n",
    "    cat_val.remove('n')\n",
    "    cat_val.insert(0, 'n')\n",
    "    print(cat_val) \n",
    "    \n",
    "    if removable_cats:\n",
    "        cat_val = [c for c in cat_val if c not in removable_cats]\n",
    "        dat_set = dat_set[dat_set[source_col].isin(cat_val)]\n",
    "        dat_set.reset_index(drop=True, inplace=True)\n",
    "    print(cat_val) \n",
    "        \n",
    "    cls_map = dict(zip(cat_val, list(range(len(cat_val))))) \n",
    "    cls_map\n",
    "    \n",
    "    if not multi_class:\n",
    "        for k in cls_map.keys():\n",
    "            if cls_map[k]>1:\n",
    "                cls_map[k]=1\n",
    "\n",
    "    dat_set.replace({class_name: cls_map}, inplace=True) \n",
    "    return cls_map, dat_set \n",
    "    \n",
    "    \n",
    "class_name = 'Class'\n",
    "# label_map, dataset = map_category_to_class(dataset.copy(), source_col='Category', class_name=class_name, removable_cats=None, multi_class=True)\n",
    "label_map, dataset = map_category_to_class(dataset.copy(), source_col='Category', class_name=class_name, removable_cats=None, multi_class=False)\n",
    "# label_map, dataset = map_category_to_class(dataset.copy(), source_col='Category', class_name=class_name, removable_cats=['brux', 'sdb'], multi_class=True) \n",
    "print(label_map)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "violent-emperor",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(208,)"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['Subject_Name'].unique().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "upset-sierra",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "first-sunglasses",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "silver-stephen",
   "metadata": {},
   "source": [
    "#### Accessing P/AUC for binary class for annotation probability of transition-2 - annot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "rotary-direction",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./Results//_Combined/Subject_One_Night/Annot_Proba_Transition2_PAUC_bin.csv'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f\"{root_directory}{data_directory}/{data_subdirectory}/Annot_Proba_Transition2_PAUC_bin.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fancy-opinion",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Features</th>\n",
       "      <th>P_Value_bin</th>\n",
       "      <th>AUC_bin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>W-&gt;W</td>\n",
       "      <td>6.607903e-03</td>\n",
       "      <td>0.761807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>W-&gt;S1</td>\n",
       "      <td>8.354123e-02</td>\n",
       "      <td>0.286638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>W-&gt;S2</td>\n",
       "      <td>7.039615e-07</td>\n",
       "      <td>0.738240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>W-&gt;S3</td>\n",
       "      <td>3.838355e-02</td>\n",
       "      <td>0.506793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>W-&gt;S4</td>\n",
       "      <td>2.624921e-01</td>\n",
       "      <td>0.505435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>W-&gt;REM</td>\n",
       "      <td>9.173500e-02</td>\n",
       "      <td>0.574869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>S1-&gt;W</td>\n",
       "      <td>5.993076e-12</td>\n",
       "      <td>0.768132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>S1-&gt;S1</td>\n",
       "      <td>3.565621e-09</td>\n",
       "      <td>0.729198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>S1-&gt;S2</td>\n",
       "      <td>2.594834e-03</td>\n",
       "      <td>0.612303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>S1-&gt;S3</td>\n",
       "      <td>3.712097e-01</td>\n",
       "      <td>0.510682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>S1-&gt;S4</td>\n",
       "      <td>2.624921e-01</td>\n",
       "      <td>0.505435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>S1-&gt;REM</td>\n",
       "      <td>6.549215e-06</td>\n",
       "      <td>0.708396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>S2-&gt;W</td>\n",
       "      <td>4.899392e-05</td>\n",
       "      <td>0.336582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>S2-&gt;S1</td>\n",
       "      <td>3.180952e-13</td>\n",
       "      <td>0.801396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>S2-&gt;S2</td>\n",
       "      <td>1.728192e-16</td>\n",
       "      <td>0.835692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>S2-&gt;S3</td>\n",
       "      <td>8.418644e-09</td>\n",
       "      <td>0.706147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>S2-&gt;S4</td>\n",
       "      <td>9.245596e-03</td>\n",
       "      <td>0.454179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>S2-&gt;REM</td>\n",
       "      <td>7.072528e-05</td>\n",
       "      <td>0.685907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>S3-&gt;W</td>\n",
       "      <td>7.869910e-03</td>\n",
       "      <td>0.446074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>S3-&gt;S1</td>\n",
       "      <td>1.786866e-02</td>\n",
       "      <td>0.429816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>S3-&gt;S2</td>\n",
       "      <td>6.599695e-19</td>\n",
       "      <td>0.843094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>S3-&gt;S3</td>\n",
       "      <td>1.663935e-32</td>\n",
       "      <td>0.925834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>S3-&gt;S4</td>\n",
       "      <td>2.308459e-05</td>\n",
       "      <td>0.528907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>S3-&gt;REM</td>\n",
       "      <td>1.479591e-01</td>\n",
       "      <td>0.482196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>S4-&gt;W</td>\n",
       "      <td>3.832257e-01</td>\n",
       "      <td>0.367972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>S4-&gt;S1</td>\n",
       "      <td>3.574511e-01</td>\n",
       "      <td>0.496158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>S4-&gt;S2</td>\n",
       "      <td>4.530583e-01</td>\n",
       "      <td>0.374672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>S4-&gt;S3</td>\n",
       "      <td>4.998206e-08</td>\n",
       "      <td>0.542073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>S4-&gt;S4</td>\n",
       "      <td>3.372714e-22</td>\n",
       "      <td>0.868488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>S4-&gt;REM</td>\n",
       "      <td>9.896414e-01</td>\n",
       "      <td>0.493534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>REM-&gt;W</td>\n",
       "      <td>1.031399e-02</td>\n",
       "      <td>0.598295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>REM-&gt;S1</td>\n",
       "      <td>4.320113e-06</td>\n",
       "      <td>0.684876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>REM-&gt;S2</td>\n",
       "      <td>5.943015e-01</td>\n",
       "      <td>0.440826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>REM-&gt;S3</td>\n",
       "      <td>1.116319e-01</td>\n",
       "      <td>0.510870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>REM-&gt;REM</td>\n",
       "      <td>8.710803e-05</td>\n",
       "      <td>0.675037</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Features   P_Value_bin   AUC_bin\n",
       "0       W->W  6.607903e-03  0.761807\n",
       "1      W->S1  8.354123e-02  0.286638\n",
       "2      W->S2  7.039615e-07  0.738240\n",
       "3      W->S3  3.838355e-02  0.506793\n",
       "4      W->S4  2.624921e-01  0.505435\n",
       "5     W->REM  9.173500e-02  0.574869\n",
       "6      S1->W  5.993076e-12  0.768132\n",
       "7     S1->S1  3.565621e-09  0.729198\n",
       "8     S1->S2  2.594834e-03  0.612303\n",
       "9     S1->S3  3.712097e-01  0.510682\n",
       "10    S1->S4  2.624921e-01  0.505435\n",
       "11   S1->REM  6.549215e-06  0.708396\n",
       "12     S2->W  4.899392e-05  0.336582\n",
       "13    S2->S1  3.180952e-13  0.801396\n",
       "14    S2->S2  1.728192e-16  0.835692\n",
       "15    S2->S3  8.418644e-09  0.706147\n",
       "16    S2->S4  9.245596e-03  0.454179\n",
       "17   S2->REM  7.072528e-05  0.685907\n",
       "18     S3->W  7.869910e-03  0.446074\n",
       "19    S3->S1  1.786866e-02  0.429816\n",
       "20    S3->S2  6.599695e-19  0.843094\n",
       "21    S3->S3  1.663935e-32  0.925834\n",
       "22    S3->S4  2.308459e-05  0.528907\n",
       "23   S3->REM  1.479591e-01  0.482196\n",
       "24     S4->W  3.832257e-01  0.367972\n",
       "25    S4->S1  3.574511e-01  0.496158\n",
       "26    S4->S2  4.530583e-01  0.374672\n",
       "27    S4->S3  4.998206e-08  0.542073\n",
       "28    S4->S4  3.372714e-22  0.868488\n",
       "29   S4->REM  9.896414e-01  0.493534\n",
       "30    REM->W  1.031399e-02  0.598295\n",
       "31   REM->S1  4.320113e-06  0.684876\n",
       "32   REM->S2  5.943015e-01  0.440826\n",
       "33   REM->S3  1.116319e-01  0.510870\n",
       "34  REM->REM  8.710803e-05  0.675037"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "annot_proba_transition2_PAUC_bin_df = pd.read_csv(f\"{root_directory}{data_directory}/{data_subdirectory}/Annot_Proba_Transition2_PAUC_bin.csv\", index_col=False)\n",
    "annot_proba_transition2_PAUC_bin_df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "successful-packet",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "moved-chance",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_selected_feature_list_based_on_PAUC(tmp_df, p_threshold=0.05, auc_threshold=0.5, sort=False): \n",
    "    cols = tmp_df['Features'].values.tolist() \n",
    "    tmp_df = tmp_df[(tmp_df['P_Value_bin']<p_threshold) & (tmp_df['AUC_bin']>=auc_threshold)]\n",
    "    if sort:\n",
    "        tmp_df = tmp_df.sort_values(['P_Value_bin', 'AUC_bin'], ascending = [True, False])\n",
    "    selected_features = tmp_df['Features'].values.tolist() \n",
    "    return selected_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "alpha-import",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['W->W',\n",
       " 'W->S2',\n",
       " 'W->S3',\n",
       " 'S1->W',\n",
       " 'S1->S1',\n",
       " 'S1->S2',\n",
       " 'S1->REM',\n",
       " 'S2->S1',\n",
       " 'S2->S2',\n",
       " 'S2->S3',\n",
       " 'S2->REM',\n",
       " 'S3->S2',\n",
       " 'S3->S3',\n",
       " 'S3->S4',\n",
       " 'S4->S3',\n",
       " 'S4->S4',\n",
       " 'REM->W',\n",
       " 'REM->S1',\n",
       " 'REM->REM']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_PAUC_df = get_selected_feature_list_based_on_PAUC(annot_proba_transition2_PAUC_bin_df.copy(), p_threshold=0.05, auc_threshold=0.5) \n",
    "sorted_PAUC_df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "aquatic-communication",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['W->W',\n",
       " 'W->S2',\n",
       " 'S1->W',\n",
       " 'S1->S1',\n",
       " 'S1->REM',\n",
       " 'S2->S1',\n",
       " 'S2->S2',\n",
       " 'S2->S3',\n",
       " 'S3->S2',\n",
       " 'S3->S3',\n",
       " 'S4->S4']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_PAUC_df = get_selected_feature_list_based_on_PAUC(annot_proba_transition2_PAUC_bin_df.copy(), p_threshold=0.05, auc_threshold=0.7) \n",
    "sorted_PAUC_df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "strange-saturday",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dangerous-prototype",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "distributed-terrace",
   "metadata": {},
   "source": [
    "#### Statistical analysis with Wilcoxon rank-sum test and Mann-Whitney U test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "sitting-insertion",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "extraordinary-place",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset</th>\n",
       "      <th>Category</th>\n",
       "      <th>Subject_Name</th>\n",
       "      <th>Class</th>\n",
       "      <th>W-&gt;W</th>\n",
       "      <th>W-&gt;S1</th>\n",
       "      <th>W-&gt;S2</th>\n",
       "      <th>W-&gt;S3</th>\n",
       "      <th>W-&gt;S4</th>\n",
       "      <th>W-&gt;REM</th>\n",
       "      <th>...</th>\n",
       "      <th>S4-&gt;S2</th>\n",
       "      <th>S4-&gt;S3</th>\n",
       "      <th>S4-&gt;S4</th>\n",
       "      <th>S4-&gt;REM</th>\n",
       "      <th>REM-&gt;W</th>\n",
       "      <th>REM-&gt;S1</th>\n",
       "      <th>REM-&gt;S2</th>\n",
       "      <th>REM-&gt;S3</th>\n",
       "      <th>REM-&gt;S4</th>\n",
       "      <th>REM-&gt;REM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CAP_Sleep</td>\n",
       "      <td>brux</td>\n",
       "      <td>brux1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.190476</td>\n",
       "      <td>0.009524</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004926</td>\n",
       "      <td>0.024631</td>\n",
       "      <td>0.970443</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.033520</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.966480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CAP_Sleep</td>\n",
       "      <td>brux</td>\n",
       "      <td>brux2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.825397</td>\n",
       "      <td>0.174603</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.012048</td>\n",
       "      <td>0.984940</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.019324</td>\n",
       "      <td>0.004831</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.975845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CAP_Sleep</td>\n",
       "      <td>sdb</td>\n",
       "      <td>sdb1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.876712</td>\n",
       "      <td>0.123288</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005076</td>\n",
       "      <td>0.030457</td>\n",
       "      <td>0.949239</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.009346</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.028037</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.962617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CAP_Sleep</td>\n",
       "      <td>sdb</td>\n",
       "      <td>sdb2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.948718</td>\n",
       "      <td>0.044872</td>\n",
       "      <td>0.006410</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.016949</td>\n",
       "      <td>0.966102</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.025641</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.974359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CAP_Sleep</td>\n",
       "      <td>sdb</td>\n",
       "      <td>sdb3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.934272</td>\n",
       "      <td>0.046948</td>\n",
       "      <td>0.018779</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.025974</td>\n",
       "      <td>0.038961</td>\n",
       "      <td>0.935065</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.937500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>Sleep_EDFX</td>\n",
       "      <td>n</td>\n",
       "      <td>ST7191</td>\n",
       "      <td>0</td>\n",
       "      <td>0.742857</td>\n",
       "      <td>0.242857</td>\n",
       "      <td>0.014286</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.013889</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.805556</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>0.015000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.965000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>Sleep_EDFX</td>\n",
       "      <td>n</td>\n",
       "      <td>ST7201</td>\n",
       "      <td>0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>...</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>0.346154</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.044776</td>\n",
       "      <td>0.007463</td>\n",
       "      <td>0.014925</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.932836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>Sleep_EDFX</td>\n",
       "      <td>n</td>\n",
       "      <td>ST7211</td>\n",
       "      <td>0</td>\n",
       "      <td>0.894737</td>\n",
       "      <td>0.099415</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.005848</td>\n",
       "      <td>...</td>\n",
       "      <td>0.016949</td>\n",
       "      <td>0.254237</td>\n",
       "      <td>0.728814</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.025641</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.019231</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.955128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>Sleep_EDFX</td>\n",
       "      <td>n</td>\n",
       "      <td>ST7221</td>\n",
       "      <td>0</td>\n",
       "      <td>0.820000</td>\n",
       "      <td>0.180000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.021645</td>\n",
       "      <td>0.043290</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.935065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>Sleep_EDFX</td>\n",
       "      <td>n</td>\n",
       "      <td>ST7241</td>\n",
       "      <td>0</td>\n",
       "      <td>0.620690</td>\n",
       "      <td>0.275862</td>\n",
       "      <td>0.034483</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.068966</td>\n",
       "      <td>...</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.016878</td>\n",
       "      <td>0.016878</td>\n",
       "      <td>0.008439</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.957806</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>208 rows × 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Dataset Category Subject_Name  Class      W->W     W->S1     W->S2  \\\n",
       "0     CAP_Sleep     brux        brux1      1  0.800000  0.190476  0.009524   \n",
       "1     CAP_Sleep     brux        brux2      1  0.825397  0.174603  0.000000   \n",
       "2     CAP_Sleep      sdb         sdb1      1  0.876712  0.123288  0.000000   \n",
       "3     CAP_Sleep      sdb         sdb2      1  0.948718  0.044872  0.006410   \n",
       "4     CAP_Sleep      sdb         sdb3      1  0.934272  0.046948  0.018779   \n",
       "..          ...      ...          ...    ...       ...       ...       ...   \n",
       "203  Sleep_EDFX        n       ST7191      0  0.742857  0.242857  0.014286   \n",
       "204  Sleep_EDFX        n       ST7201      0  0.333333  0.555556  0.055556   \n",
       "205  Sleep_EDFX        n       ST7211      0  0.894737  0.099415  0.000000   \n",
       "206  Sleep_EDFX        n       ST7221      0  0.820000  0.180000  0.000000   \n",
       "207  Sleep_EDFX        n       ST7241      0  0.620690  0.275862  0.034483   \n",
       "\n",
       "     W->S3  W->S4    W->REM  ...    S4->S2    S4->S3    S4->S4  S4->REM  \\\n",
       "0      0.0    0.0  0.000000  ...  0.004926  0.024631  0.970443      0.0   \n",
       "1      0.0    0.0  0.000000  ...  0.000000  0.012048  0.984940      0.0   \n",
       "2      0.0    0.0  0.000000  ...  0.005076  0.030457  0.949239      0.0   \n",
       "3      0.0    0.0  0.000000  ...  0.008475  0.016949  0.966102      0.0   \n",
       "4      0.0    0.0  0.000000  ...  0.025974  0.038961  0.935065      0.0   \n",
       "..     ...    ...       ...  ...       ...       ...       ...      ...   \n",
       "203    0.0    0.0  0.000000  ...  0.013889  0.166667  0.805556      0.0   \n",
       "204    0.0    0.0  0.055556  ...  0.038462  0.615385  0.346154      0.0   \n",
       "205    0.0    0.0  0.005848  ...  0.016949  0.254237  0.728814      0.0   \n",
       "206    0.0    0.0  0.000000  ...  0.000000  0.000000  0.000000      0.0   \n",
       "207    0.0    0.0  0.068966  ...  0.142857  0.571429  0.142857      0.0   \n",
       "\n",
       "       REM->W   REM->S1   REM->S2  REM->S3  REM->S4  REM->REM  \n",
       "0    0.033520  0.000000  0.000000      0.0      0.0  0.966480  \n",
       "1    0.019324  0.004831  0.000000      0.0      0.0  0.975845  \n",
       "2    0.009346  0.000000  0.028037      0.0      0.0  0.962617  \n",
       "3    0.000000  0.000000  0.025641      0.0      0.0  0.974359  \n",
       "4    0.062500  0.000000  0.000000      0.0      0.0  0.937500  \n",
       "..        ...       ...       ...      ...      ...       ...  \n",
       "203  0.000000  0.020000  0.015000      0.0      0.0  0.965000  \n",
       "204  0.044776  0.007463  0.014925      0.0      0.0  0.932836  \n",
       "205  0.025641  0.000000  0.019231      0.0      0.0  0.955128  \n",
       "206  0.021645  0.043290  0.000000      0.0      0.0  0.935065  \n",
       "207  0.016878  0.016878  0.008439      0.0      0.0  0.957806  \n",
       "\n",
       "[208 rows x 40 columns]"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_name = 'Class'\n",
    "\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "linear-realtor",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Features</th>\n",
       "      <th>Wilcoxon_zscore</th>\n",
       "      <th>Wilcoxon_pvalue</th>\n",
       "      <th>MannWhitney_statistic</th>\n",
       "      <th>MannWhitney_pvalue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>W-&gt;W</td>\n",
       "      <td>6.480686</td>\n",
       "      <td>9.130657e-11</td>\n",
       "      <td>2542.0</td>\n",
       "      <td>4.599963e-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>W-&gt;S1</td>\n",
       "      <td>-5.281504</td>\n",
       "      <td>1.281278e-07</td>\n",
       "      <td>3059.0</td>\n",
       "      <td>6.446579e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>W-&gt;S2</td>\n",
       "      <td>-5.897331</td>\n",
       "      <td>3.694274e-09</td>\n",
       "      <td>2793.5</td>\n",
       "      <td>2.485725e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>W-&gt;S3</td>\n",
       "      <td>-0.168164</td>\n",
       "      <td>8.664544e-01</td>\n",
       "      <td>5263.5</td>\n",
       "      <td>3.261662e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>W-&gt;S4</td>\n",
       "      <td>-0.134531</td>\n",
       "      <td>8.929827e-01</td>\n",
       "      <td>5278.0</td>\n",
       "      <td>1.328103e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>W-&gt;REM</td>\n",
       "      <td>1.853281</td>\n",
       "      <td>6.384205e-02</td>\n",
       "      <td>4537.0</td>\n",
       "      <td>3.832078e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>S1-&gt;W</td>\n",
       "      <td>6.637252</td>\n",
       "      <td>3.195845e-11</td>\n",
       "      <td>2474.5</td>\n",
       "      <td>1.493540e-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>S1-&gt;S1</td>\n",
       "      <td>-5.673500</td>\n",
       "      <td>1.399095e-08</td>\n",
       "      <td>2890.0</td>\n",
       "      <td>7.037414e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>S1-&gt;S2</td>\n",
       "      <td>2.779922</td>\n",
       "      <td>5.437196e-03</td>\n",
       "      <td>4137.5</td>\n",
       "      <td>2.727311e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>S1-&gt;S3</td>\n",
       "      <td>0.264423</td>\n",
       "      <td>7.914539e-01</td>\n",
       "      <td>5222.0</td>\n",
       "      <td>1.997063e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>S1-&gt;S4</td>\n",
       "      <td>-0.134531</td>\n",
       "      <td>8.929827e-01</td>\n",
       "      <td>5278.0</td>\n",
       "      <td>1.328103e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>S1-&gt;REM</td>\n",
       "      <td>5.158570</td>\n",
       "      <td>2.488427e-07</td>\n",
       "      <td>3112.0</td>\n",
       "      <td>1.758797e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>S2-&gt;W</td>\n",
       "      <td>4.045210</td>\n",
       "      <td>5.227628e-05</td>\n",
       "      <td>3592.0</td>\n",
       "      <td>2.625410e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>S2-&gt;S1</td>\n",
       "      <td>7.460675</td>\n",
       "      <td>8.608028e-14</td>\n",
       "      <td>2119.5</td>\n",
       "      <td>3.876329e-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>S2-&gt;S2</td>\n",
       "      <td>-8.307293</td>\n",
       "      <td>9.791000e-17</td>\n",
       "      <td>1754.5</td>\n",
       "      <td>4.943446e-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>S2-&gt;S3</td>\n",
       "      <td>5.106382</td>\n",
       "      <td>3.283863e-07</td>\n",
       "      <td>3134.5</td>\n",
       "      <td>1.650235e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>S2-&gt;S4</td>\n",
       "      <td>1.134236</td>\n",
       "      <td>2.566956e-01</td>\n",
       "      <td>4847.0</td>\n",
       "      <td>8.539151e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>S2-&gt;REM</td>\n",
       "      <td>4.601890</td>\n",
       "      <td>4.186742e-06</td>\n",
       "      <td>3352.0</td>\n",
       "      <td>2.104875e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>S3-&gt;W</td>\n",
       "      <td>1.334873</td>\n",
       "      <td>1.819180e-01</td>\n",
       "      <td>4760.5</td>\n",
       "      <td>6.522211e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>S3-&gt;S1</td>\n",
       "      <td>1.737306</td>\n",
       "      <td>8.233312e-02</td>\n",
       "      <td>4587.0</td>\n",
       "      <td>7.518858e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>S3-&gt;S2</td>\n",
       "      <td>8.492853</td>\n",
       "      <td>2.016252e-17</td>\n",
       "      <td>1674.5</td>\n",
       "      <td>1.011512e-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>S3-&gt;S3</td>\n",
       "      <td>-10.540972</td>\n",
       "      <td>5.591765e-26</td>\n",
       "      <td>791.5</td>\n",
       "      <td>2.743893e-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>S3-&gt;S4</td>\n",
       "      <td>0.715566</td>\n",
       "      <td>4.742593e-01</td>\n",
       "      <td>5027.5</td>\n",
       "      <td>2.360325e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>S3-&gt;REM</td>\n",
       "      <td>0.440705</td>\n",
       "      <td>6.594264e-01</td>\n",
       "      <td>5146.0</td>\n",
       "      <td>1.474013e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>S4-&gt;W</td>\n",
       "      <td>-3.268177</td>\n",
       "      <td>1.082427e-03</td>\n",
       "      <td>3927.0</td>\n",
       "      <td>4.800361e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>S4-&gt;S1</td>\n",
       "      <td>-0.095100</td>\n",
       "      <td>9.242358e-01</td>\n",
       "      <td>5295.0</td>\n",
       "      <td>4.389017e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>S4-&gt;S2</td>\n",
       "      <td>-3.102333</td>\n",
       "      <td>1.920021e-03</td>\n",
       "      <td>3998.5</td>\n",
       "      <td>3.679183e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>S4-&gt;S3</td>\n",
       "      <td>1.041456</td>\n",
       "      <td>2.976640e-01</td>\n",
       "      <td>4887.0</td>\n",
       "      <td>1.464533e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>S4-&gt;S4</td>\n",
       "      <td>-9.121438</td>\n",
       "      <td>7.413415e-20</td>\n",
       "      <td>1403.5</td>\n",
       "      <td>1.770815e-20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>S4-&gt;REM</td>\n",
       "      <td>-0.293417</td>\n",
       "      <td>7.692035e-01</td>\n",
       "      <td>5209.5</td>\n",
       "      <td>1.096207e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>REM-&gt;W</td>\n",
       "      <td>2.433157</td>\n",
       "      <td>1.496783e-02</td>\n",
       "      <td>4287.0</td>\n",
       "      <td>7.072414e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>REM-&gt;S1</td>\n",
       "      <td>4.576376</td>\n",
       "      <td>4.731009e-06</td>\n",
       "      <td>3363.0</td>\n",
       "      <td>1.166662e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>REM-&gt;S2</td>\n",
       "      <td>-1.464765</td>\n",
       "      <td>1.429851e-01</td>\n",
       "      <td>4704.5</td>\n",
       "      <td>7.076484e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>REM-&gt;S3</td>\n",
       "      <td>-0.269062</td>\n",
       "      <td>7.878819e-01</td>\n",
       "      <td>5220.0</td>\n",
       "      <td>5.648677e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>REM-&gt;S4</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>REM-&gt;REM</td>\n",
       "      <td>-4.332828</td>\n",
       "      <td>1.472062e-05</td>\n",
       "      <td>3468.0</td>\n",
       "      <td>7.397736e-06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Features  Wilcoxon_zscore  Wilcoxon_pvalue  MannWhitney_statistic  \\\n",
       "0       W->W         6.480686     9.130657e-11                 2542.0   \n",
       "1      W->S1        -5.281504     1.281278e-07                 3059.0   \n",
       "2      W->S2        -5.897331     3.694274e-09                 2793.5   \n",
       "3      W->S3        -0.168164     8.664544e-01                 5263.5   \n",
       "4      W->S4        -0.134531     8.929827e-01                 5278.0   \n",
       "5     W->REM         1.853281     6.384205e-02                 4537.0   \n",
       "6      S1->W         6.637252     3.195845e-11                 2474.5   \n",
       "7     S1->S1        -5.673500     1.399095e-08                 2890.0   \n",
       "8     S1->S2         2.779922     5.437196e-03                 4137.5   \n",
       "9     S1->S3         0.264423     7.914539e-01                 5222.0   \n",
       "10    S1->S4        -0.134531     8.929827e-01                 5278.0   \n",
       "11   S1->REM         5.158570     2.488427e-07                 3112.0   \n",
       "12     S2->W         4.045210     5.227628e-05                 3592.0   \n",
       "13    S2->S1         7.460675     8.608028e-14                 2119.5   \n",
       "14    S2->S2        -8.307293     9.791000e-17                 1754.5   \n",
       "15    S2->S3         5.106382     3.283863e-07                 3134.5   \n",
       "16    S2->S4         1.134236     2.566956e-01                 4847.0   \n",
       "17   S2->REM         4.601890     4.186742e-06                 3352.0   \n",
       "18     S3->W         1.334873     1.819180e-01                 4760.5   \n",
       "19    S3->S1         1.737306     8.233312e-02                 4587.0   \n",
       "20    S3->S2         8.492853     2.016252e-17                 1674.5   \n",
       "21    S3->S3       -10.540972     5.591765e-26                  791.5   \n",
       "22    S3->S4         0.715566     4.742593e-01                 5027.5   \n",
       "23   S3->REM         0.440705     6.594264e-01                 5146.0   \n",
       "24     S4->W        -3.268177     1.082427e-03                 3927.0   \n",
       "25    S4->S1        -0.095100     9.242358e-01                 5295.0   \n",
       "26    S4->S2        -3.102333     1.920021e-03                 3998.5   \n",
       "27    S4->S3         1.041456     2.976640e-01                 4887.0   \n",
       "28    S4->S4        -9.121438     7.413415e-20                 1403.5   \n",
       "29   S4->REM        -0.293417     7.692035e-01                 5209.5   \n",
       "30    REM->W         2.433157     1.496783e-02                 4287.0   \n",
       "31   REM->S1         4.576376     4.731009e-06                 3363.0   \n",
       "32   REM->S2        -1.464765     1.429851e-01                 4704.5   \n",
       "33   REM->S3        -0.269062     7.878819e-01                 5220.0   \n",
       "34   REM->S4         0.000000     1.000000e+00                    0.0   \n",
       "35  REM->REM        -4.332828     1.472062e-05                 3468.0   \n",
       "\n",
       "    MannWhitney_pvalue  \n",
       "0         4.599963e-11  \n",
       "1         6.446579e-08  \n",
       "2         2.485725e-10  \n",
       "3         3.261662e-01  \n",
       "4         1.328103e-01  \n",
       "5         3.832078e-03  \n",
       "6         1.493540e-11  \n",
       "7         7.037414e-09  \n",
       "8         2.727311e-03  \n",
       "9         1.997063e-01  \n",
       "10        1.328103e-01  \n",
       "11        1.758797e-08  \n",
       "12        2.625410e-05  \n",
       "13        3.876329e-14  \n",
       "14        4.943446e-17  \n",
       "15        1.650235e-07  \n",
       "16        8.539151e-03  \n",
       "17        2.104875e-06  \n",
       "18        6.522211e-02  \n",
       "19        7.518858e-03  \n",
       "20        1.011512e-17  \n",
       "21        2.743893e-26  \n",
       "22        2.360325e-01  \n",
       "23        1.474013e-01  \n",
       "24        4.800361e-05  \n",
       "25        4.389017e-01  \n",
       "26        3.679183e-04  \n",
       "27        1.464533e-01  \n",
       "28        1.770815e-20  \n",
       "29        1.096207e-01  \n",
       "30        7.072414e-03  \n",
       "31        1.166662e-06  \n",
       "32        7.076484e-02  \n",
       "33        5.648677e-02  \n",
       "34        1.000000e+00  \n",
       "35        7.397736e-06  "
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# results = stats.ranksums(x, y)\n",
    "# results = stats.mannwhitneyu(x, y, use_continuity=True, alternative=None)\n",
    "\n",
    "def get_statistical_significant_using_wilcoxon_and_mannwhitney_u_test(tmp_df, class_name): \n",
    "    feats = tmp_df.columns.values.tolist()[4:] \n",
    "\n",
    "    stat_significace_df = pd.DataFrame(columns=['Features', 'Wilcoxon_zscore', 'Wilcoxon_pvalue', 'MannWhitney_statistic', 'MannWhitney_pvalue']) \n",
    "\n",
    "    for f in feats:\n",
    "        fd_0 = tmp_df[ (tmp_df[class_name]==0) ][f].values\n",
    "        fd_1 = tmp_df[ (tmp_df[class_name]==1) ][f].values\n",
    "    #     print(\"==>\", f, fd_0.shape, fd_1.shape)\n",
    "    #     print(\"==>\", f, fd_0.shape, fd_1.shape, np.mean(fd_0), np.mean(fd_1))\n",
    "        stat_value, p_value = stats.ranksums(fd_0, fd_1)\n",
    "    #     stat_value2, p_value2 = stats.mannwhitneyu(fd_0, fd_1, use_continuity=True, alternative=None) \n",
    "    #     stat_value2, p_value2 = 0.0, 1.0 if ( (np.mean(fd_0)==0) and (np.mean(fd_0)==np.mean(fd_1))==True) else stats.mannwhitneyu(fd_0, fd_1, use_continuity=True, alternative=None) \n",
    "        stat_value2, p_value2 = 0.0, 1.0 \n",
    "        if not ( (np.mean(fd_0)==0) and (np.mean(fd_0)==np.mean(fd_1))==True):\n",
    "            res = stats.mannwhitneyu(fd_0, fd_1, use_continuity=True, alternative=None) \n",
    "            stat_value2, p_value2 = res.statistic, res.pvalue \n",
    "    #     print(f, fd_0.shape, fd_1.shape, stat_value, p_value, stat_value2, p_value2) \n",
    "    #     print(f, fd_0.shape, fd_1.shape, stat_value, p_value, stat_value2, p_value2, p_value<0.05, p_value2<0.05, ((p_value<0.05)==(p_value2<0.05)) ) \n",
    "    #     print(f, p_value2<0.05, ((p_value<0.05)==(p_value2<0.05)) ) \n",
    "        new_row = {'Features':f, 'Wilcoxon_zscore':stat_value, 'Wilcoxon_pvalue':p_value, 'MannWhitney_statistic':stat_value2, 'MannWhitney_pvalue':p_value2}\n",
    "        stat_significace_df = stat_significace_df.append(new_row, ignore_index=True)\n",
    "    #     tdf = pd.DataFrame(new_row) \n",
    "    #     stat_significace_df = pd.concat([stat_significace_df, tdf]) \n",
    "\n",
    "    return stat_significace_df\n",
    "\n",
    "\n",
    "stat_significace_df = get_statistical_significant_using_wilcoxon_and_mannwhitney_u_test(dataset, class_name)\n",
    "stat_significace_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "bearing-alert",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./Results//_Combined/Subject_One_Night/Annot_Proba_Transition2_Wilcoxon_MannWitney_UTest_bin.csv'"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# stat_significace_df.to_csv(f\"{root_directory}{data_directory}/{data_subdirectory}/Annot_Proba_Transition2_Wilcoxon_MannWitney_UTest_bin.csv\", index=False) \n",
    "# result_save_path, f\"{root_directory}{data_directory}/{data_subdirectory}/Annot_Proba_Transition2_Wilcoxon_MannWitney_UTest_bin.csv\"\n",
    "f\"{root_directory}{data_directory}/{data_subdirectory}/Annot_Proba_Transition2_Wilcoxon_MannWitney_UTest_bin.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "falling-accreditation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Features</th>\n",
       "      <th>Wilcoxon_zscore</th>\n",
       "      <th>Wilcoxon_pvalue</th>\n",
       "      <th>MannWhitney_statistic</th>\n",
       "      <th>MannWhitney_pvalue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>W-&gt;W</td>\n",
       "      <td>6.480686</td>\n",
       "      <td>9.130657e-11</td>\n",
       "      <td>2542.0</td>\n",
       "      <td>4.599963e-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>W-&gt;S1</td>\n",
       "      <td>-5.281504</td>\n",
       "      <td>1.281278e-07</td>\n",
       "      <td>3059.0</td>\n",
       "      <td>6.446579e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>W-&gt;S2</td>\n",
       "      <td>-5.897331</td>\n",
       "      <td>3.694274e-09</td>\n",
       "      <td>2793.5</td>\n",
       "      <td>2.485725e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>W-&gt;S3</td>\n",
       "      <td>-0.168164</td>\n",
       "      <td>8.664544e-01</td>\n",
       "      <td>5263.5</td>\n",
       "      <td>3.261662e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>W-&gt;S4</td>\n",
       "      <td>-0.134531</td>\n",
       "      <td>8.929827e-01</td>\n",
       "      <td>5278.0</td>\n",
       "      <td>1.328103e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>W-&gt;REM</td>\n",
       "      <td>1.853281</td>\n",
       "      <td>6.384205e-02</td>\n",
       "      <td>4537.0</td>\n",
       "      <td>3.832078e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>S1-&gt;W</td>\n",
       "      <td>6.637252</td>\n",
       "      <td>3.195845e-11</td>\n",
       "      <td>2474.5</td>\n",
       "      <td>1.493540e-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>S1-&gt;S1</td>\n",
       "      <td>-5.673500</td>\n",
       "      <td>1.399095e-08</td>\n",
       "      <td>2890.0</td>\n",
       "      <td>7.037414e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>S1-&gt;S2</td>\n",
       "      <td>2.779922</td>\n",
       "      <td>5.437196e-03</td>\n",
       "      <td>4137.5</td>\n",
       "      <td>2.727311e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>S1-&gt;S3</td>\n",
       "      <td>0.264423</td>\n",
       "      <td>7.914539e-01</td>\n",
       "      <td>5222.0</td>\n",
       "      <td>1.997063e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>S1-&gt;S4</td>\n",
       "      <td>-0.134531</td>\n",
       "      <td>8.929827e-01</td>\n",
       "      <td>5278.0</td>\n",
       "      <td>1.328103e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>S1-&gt;REM</td>\n",
       "      <td>5.158570</td>\n",
       "      <td>2.488427e-07</td>\n",
       "      <td>3112.0</td>\n",
       "      <td>1.758797e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>S2-&gt;W</td>\n",
       "      <td>4.045210</td>\n",
       "      <td>5.227628e-05</td>\n",
       "      <td>3592.0</td>\n",
       "      <td>2.625410e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>S2-&gt;S1</td>\n",
       "      <td>7.460675</td>\n",
       "      <td>8.608028e-14</td>\n",
       "      <td>2119.5</td>\n",
       "      <td>3.876329e-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>S2-&gt;S2</td>\n",
       "      <td>-8.307293</td>\n",
       "      <td>9.791000e-17</td>\n",
       "      <td>1754.5</td>\n",
       "      <td>4.943446e-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>S2-&gt;S3</td>\n",
       "      <td>5.106382</td>\n",
       "      <td>3.283863e-07</td>\n",
       "      <td>3134.5</td>\n",
       "      <td>1.650235e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>S2-&gt;S4</td>\n",
       "      <td>1.134236</td>\n",
       "      <td>2.566956e-01</td>\n",
       "      <td>4847.0</td>\n",
       "      <td>8.539151e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>S2-&gt;REM</td>\n",
       "      <td>4.601890</td>\n",
       "      <td>4.186742e-06</td>\n",
       "      <td>3352.0</td>\n",
       "      <td>2.104875e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>S3-&gt;W</td>\n",
       "      <td>1.334873</td>\n",
       "      <td>1.819180e-01</td>\n",
       "      <td>4760.5</td>\n",
       "      <td>6.522211e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>S3-&gt;S1</td>\n",
       "      <td>1.737306</td>\n",
       "      <td>8.233312e-02</td>\n",
       "      <td>4587.0</td>\n",
       "      <td>7.518858e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>S3-&gt;S2</td>\n",
       "      <td>8.492853</td>\n",
       "      <td>2.016252e-17</td>\n",
       "      <td>1674.5</td>\n",
       "      <td>1.011512e-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>S3-&gt;S3</td>\n",
       "      <td>-10.540972</td>\n",
       "      <td>5.591765e-26</td>\n",
       "      <td>791.5</td>\n",
       "      <td>2.743893e-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>S3-&gt;S4</td>\n",
       "      <td>0.715566</td>\n",
       "      <td>4.742593e-01</td>\n",
       "      <td>5027.5</td>\n",
       "      <td>2.360325e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>S3-&gt;REM</td>\n",
       "      <td>0.440705</td>\n",
       "      <td>6.594264e-01</td>\n",
       "      <td>5146.0</td>\n",
       "      <td>1.474013e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>S4-&gt;W</td>\n",
       "      <td>-3.268177</td>\n",
       "      <td>1.082427e-03</td>\n",
       "      <td>3927.0</td>\n",
       "      <td>4.800361e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>S4-&gt;S1</td>\n",
       "      <td>-0.095100</td>\n",
       "      <td>9.242358e-01</td>\n",
       "      <td>5295.0</td>\n",
       "      <td>4.389017e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>S4-&gt;S2</td>\n",
       "      <td>-3.102333</td>\n",
       "      <td>1.920021e-03</td>\n",
       "      <td>3998.5</td>\n",
       "      <td>3.679183e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>S4-&gt;S3</td>\n",
       "      <td>1.041456</td>\n",
       "      <td>2.976640e-01</td>\n",
       "      <td>4887.0</td>\n",
       "      <td>1.464533e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>S4-&gt;S4</td>\n",
       "      <td>-9.121438</td>\n",
       "      <td>7.413415e-20</td>\n",
       "      <td>1403.5</td>\n",
       "      <td>1.770815e-20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>S4-&gt;REM</td>\n",
       "      <td>-0.293417</td>\n",
       "      <td>7.692035e-01</td>\n",
       "      <td>5209.5</td>\n",
       "      <td>1.096207e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>REM-&gt;W</td>\n",
       "      <td>2.433157</td>\n",
       "      <td>1.496783e-02</td>\n",
       "      <td>4287.0</td>\n",
       "      <td>7.072414e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>REM-&gt;S1</td>\n",
       "      <td>4.576376</td>\n",
       "      <td>4.731009e-06</td>\n",
       "      <td>3363.0</td>\n",
       "      <td>1.166662e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>REM-&gt;S2</td>\n",
       "      <td>-1.464765</td>\n",
       "      <td>1.429851e-01</td>\n",
       "      <td>4704.5</td>\n",
       "      <td>7.076484e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>REM-&gt;S3</td>\n",
       "      <td>-0.269062</td>\n",
       "      <td>7.878819e-01</td>\n",
       "      <td>5220.0</td>\n",
       "      <td>5.648677e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>REM-&gt;S4</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>REM-&gt;REM</td>\n",
       "      <td>-4.332828</td>\n",
       "      <td>1.472062e-05</td>\n",
       "      <td>3468.0</td>\n",
       "      <td>7.397736e-06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Features  Wilcoxon_zscore  Wilcoxon_pvalue  MannWhitney_statistic  \\\n",
       "0       W->W         6.480686     9.130657e-11                 2542.0   \n",
       "1      W->S1        -5.281504     1.281278e-07                 3059.0   \n",
       "2      W->S2        -5.897331     3.694274e-09                 2793.5   \n",
       "3      W->S3        -0.168164     8.664544e-01                 5263.5   \n",
       "4      W->S4        -0.134531     8.929827e-01                 5278.0   \n",
       "5     W->REM         1.853281     6.384205e-02                 4537.0   \n",
       "6      S1->W         6.637252     3.195845e-11                 2474.5   \n",
       "7     S1->S1        -5.673500     1.399095e-08                 2890.0   \n",
       "8     S1->S2         2.779922     5.437196e-03                 4137.5   \n",
       "9     S1->S3         0.264423     7.914539e-01                 5222.0   \n",
       "10    S1->S4        -0.134531     8.929827e-01                 5278.0   \n",
       "11   S1->REM         5.158570     2.488427e-07                 3112.0   \n",
       "12     S2->W         4.045210     5.227628e-05                 3592.0   \n",
       "13    S2->S1         7.460675     8.608028e-14                 2119.5   \n",
       "14    S2->S2        -8.307293     9.791000e-17                 1754.5   \n",
       "15    S2->S3         5.106382     3.283863e-07                 3134.5   \n",
       "16    S2->S4         1.134236     2.566956e-01                 4847.0   \n",
       "17   S2->REM         4.601890     4.186742e-06                 3352.0   \n",
       "18     S3->W         1.334873     1.819180e-01                 4760.5   \n",
       "19    S3->S1         1.737306     8.233312e-02                 4587.0   \n",
       "20    S3->S2         8.492853     2.016252e-17                 1674.5   \n",
       "21    S3->S3       -10.540972     5.591765e-26                  791.5   \n",
       "22    S3->S4         0.715566     4.742593e-01                 5027.5   \n",
       "23   S3->REM         0.440705     6.594264e-01                 5146.0   \n",
       "24     S4->W        -3.268177     1.082427e-03                 3927.0   \n",
       "25    S4->S1        -0.095100     9.242358e-01                 5295.0   \n",
       "26    S4->S2        -3.102333     1.920021e-03                 3998.5   \n",
       "27    S4->S3         1.041456     2.976640e-01                 4887.0   \n",
       "28    S4->S4        -9.121438     7.413415e-20                 1403.5   \n",
       "29   S4->REM        -0.293417     7.692035e-01                 5209.5   \n",
       "30    REM->W         2.433157     1.496783e-02                 4287.0   \n",
       "31   REM->S1         4.576376     4.731009e-06                 3363.0   \n",
       "32   REM->S2        -1.464765     1.429851e-01                 4704.5   \n",
       "33   REM->S3        -0.269062     7.878819e-01                 5220.0   \n",
       "34   REM->S4         0.000000     1.000000e+00                    0.0   \n",
       "35  REM->REM        -4.332828     1.472062e-05                 3468.0   \n",
       "\n",
       "    MannWhitney_pvalue  \n",
       "0         4.599963e-11  \n",
       "1         6.446579e-08  \n",
       "2         2.485725e-10  \n",
       "3         3.261662e-01  \n",
       "4         1.328103e-01  \n",
       "5         3.832078e-03  \n",
       "6         1.493540e-11  \n",
       "7         7.037414e-09  \n",
       "8         2.727311e-03  \n",
       "9         1.997063e-01  \n",
       "10        1.328103e-01  \n",
       "11        1.758797e-08  \n",
       "12        2.625410e-05  \n",
       "13        3.876329e-14  \n",
       "14        4.943446e-17  \n",
       "15        1.650235e-07  \n",
       "16        8.539151e-03  \n",
       "17        2.104875e-06  \n",
       "18        6.522211e-02  \n",
       "19        7.518858e-03  \n",
       "20        1.011512e-17  \n",
       "21        2.743893e-26  \n",
       "22        2.360325e-01  \n",
       "23        1.474013e-01  \n",
       "24        4.800361e-05  \n",
       "25        4.389017e-01  \n",
       "26        3.679183e-04  \n",
       "27        1.464533e-01  \n",
       "28        1.770815e-20  \n",
       "29        1.096207e-01  \n",
       "30        7.072414e-03  \n",
       "31        1.166662e-06  \n",
       "32        7.076484e-02  \n",
       "33        5.648677e-02  \n",
       "34        1.000000e+00  \n",
       "35        7.397736e-06  "
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stat_significace_df = pd.read_csv(f\"{root_directory}{data_directory}/{data_subdirectory}/Annot_Proba_Transition2_Wilcoxon_MannWitney_UTest_bin.csv\", index_col=False)\n",
    "stat_significace_df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "abstract-broadway",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Features</th>\n",
       "      <th>Wilcoxon_zscore</th>\n",
       "      <th>Wilcoxon_pvalue</th>\n",
       "      <th>MannWhitney_statistic</th>\n",
       "      <th>MannWhitney_pvalue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>W-&gt;W</td>\n",
       "      <td>6.480686</td>\n",
       "      <td>9.130657e-11</td>\n",
       "      <td>2542.0</td>\n",
       "      <td>4.599963e-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>W-&gt;S1</td>\n",
       "      <td>-5.281504</td>\n",
       "      <td>1.281278e-07</td>\n",
       "      <td>3059.0</td>\n",
       "      <td>6.446579e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>W-&gt;S2</td>\n",
       "      <td>-5.897331</td>\n",
       "      <td>3.694274e-09</td>\n",
       "      <td>2793.5</td>\n",
       "      <td>2.485725e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>S1-&gt;W</td>\n",
       "      <td>6.637252</td>\n",
       "      <td>3.195845e-11</td>\n",
       "      <td>2474.5</td>\n",
       "      <td>1.493540e-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>S1-&gt;S1</td>\n",
       "      <td>-5.673500</td>\n",
       "      <td>1.399095e-08</td>\n",
       "      <td>2890.0</td>\n",
       "      <td>7.037414e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>S1-&gt;S2</td>\n",
       "      <td>2.779922</td>\n",
       "      <td>5.437196e-03</td>\n",
       "      <td>4137.5</td>\n",
       "      <td>2.727311e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>S1-&gt;REM</td>\n",
       "      <td>5.158570</td>\n",
       "      <td>2.488427e-07</td>\n",
       "      <td>3112.0</td>\n",
       "      <td>1.758797e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>S2-&gt;W</td>\n",
       "      <td>4.045210</td>\n",
       "      <td>5.227628e-05</td>\n",
       "      <td>3592.0</td>\n",
       "      <td>2.625410e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>S2-&gt;S1</td>\n",
       "      <td>7.460675</td>\n",
       "      <td>8.608028e-14</td>\n",
       "      <td>2119.5</td>\n",
       "      <td>3.876329e-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>S2-&gt;S2</td>\n",
       "      <td>-8.307293</td>\n",
       "      <td>9.791000e-17</td>\n",
       "      <td>1754.5</td>\n",
       "      <td>4.943446e-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>S2-&gt;S3</td>\n",
       "      <td>5.106382</td>\n",
       "      <td>3.283863e-07</td>\n",
       "      <td>3134.5</td>\n",
       "      <td>1.650235e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>S2-&gt;REM</td>\n",
       "      <td>4.601890</td>\n",
       "      <td>4.186742e-06</td>\n",
       "      <td>3352.0</td>\n",
       "      <td>2.104875e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>S3-&gt;S2</td>\n",
       "      <td>8.492853</td>\n",
       "      <td>2.016252e-17</td>\n",
       "      <td>1674.5</td>\n",
       "      <td>1.011512e-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>S3-&gt;S3</td>\n",
       "      <td>-10.540972</td>\n",
       "      <td>5.591765e-26</td>\n",
       "      <td>791.5</td>\n",
       "      <td>2.743893e-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>S4-&gt;W</td>\n",
       "      <td>-3.268177</td>\n",
       "      <td>1.082427e-03</td>\n",
       "      <td>3927.0</td>\n",
       "      <td>4.800361e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>S4-&gt;S2</td>\n",
       "      <td>-3.102333</td>\n",
       "      <td>1.920021e-03</td>\n",
       "      <td>3998.5</td>\n",
       "      <td>3.679183e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>S4-&gt;S4</td>\n",
       "      <td>-9.121438</td>\n",
       "      <td>7.413415e-20</td>\n",
       "      <td>1403.5</td>\n",
       "      <td>1.770815e-20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>REM-&gt;W</td>\n",
       "      <td>2.433157</td>\n",
       "      <td>1.496783e-02</td>\n",
       "      <td>4287.0</td>\n",
       "      <td>7.072414e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>REM-&gt;S1</td>\n",
       "      <td>4.576376</td>\n",
       "      <td>4.731009e-06</td>\n",
       "      <td>3363.0</td>\n",
       "      <td>1.166662e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>REM-&gt;REM</td>\n",
       "      <td>-4.332828</td>\n",
       "      <td>1.472062e-05</td>\n",
       "      <td>3468.0</td>\n",
       "      <td>7.397736e-06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Features  Wilcoxon_zscore  Wilcoxon_pvalue  MannWhitney_statistic  \\\n",
       "0       W->W         6.480686     9.130657e-11                 2542.0   \n",
       "1      W->S1        -5.281504     1.281278e-07                 3059.0   \n",
       "2      W->S2        -5.897331     3.694274e-09                 2793.5   \n",
       "6      S1->W         6.637252     3.195845e-11                 2474.5   \n",
       "7     S1->S1        -5.673500     1.399095e-08                 2890.0   \n",
       "8     S1->S2         2.779922     5.437196e-03                 4137.5   \n",
       "11   S1->REM         5.158570     2.488427e-07                 3112.0   \n",
       "12     S2->W         4.045210     5.227628e-05                 3592.0   \n",
       "13    S2->S1         7.460675     8.608028e-14                 2119.5   \n",
       "14    S2->S2        -8.307293     9.791000e-17                 1754.5   \n",
       "15    S2->S3         5.106382     3.283863e-07                 3134.5   \n",
       "17   S2->REM         4.601890     4.186742e-06                 3352.0   \n",
       "20    S3->S2         8.492853     2.016252e-17                 1674.5   \n",
       "21    S3->S3       -10.540972     5.591765e-26                  791.5   \n",
       "24     S4->W        -3.268177     1.082427e-03                 3927.0   \n",
       "26    S4->S2        -3.102333     1.920021e-03                 3998.5   \n",
       "28    S4->S4        -9.121438     7.413415e-20                 1403.5   \n",
       "30    REM->W         2.433157     1.496783e-02                 4287.0   \n",
       "31   REM->S1         4.576376     4.731009e-06                 3363.0   \n",
       "35  REM->REM        -4.332828     1.472062e-05                 3468.0   \n",
       "\n",
       "    MannWhitney_pvalue  \n",
       "0         4.599963e-11  \n",
       "1         6.446579e-08  \n",
       "2         2.485725e-10  \n",
       "6         1.493540e-11  \n",
       "7         7.037414e-09  \n",
       "8         2.727311e-03  \n",
       "11        1.758797e-08  \n",
       "12        2.625410e-05  \n",
       "13        3.876329e-14  \n",
       "14        4.943446e-17  \n",
       "15        1.650235e-07  \n",
       "17        2.104875e-06  \n",
       "20        1.011512e-17  \n",
       "21        2.743893e-26  \n",
       "24        4.800361e-05  \n",
       "26        3.679183e-04  \n",
       "28        1.770815e-20  \n",
       "30        7.072414e-03  \n",
       "31        1.166662e-06  \n",
       "35        7.397736e-06  "
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wil_p = stat_significace_df[ (stat_significace_df['Wilcoxon_pvalue']<0.05) ]\n",
    "wil_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "worst-nomination",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Features</th>\n",
       "      <th>Wilcoxon_zscore</th>\n",
       "      <th>Wilcoxon_pvalue</th>\n",
       "      <th>MannWhitney_statistic</th>\n",
       "      <th>MannWhitney_pvalue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>W-&gt;W</td>\n",
       "      <td>6.480686</td>\n",
       "      <td>9.130657e-11</td>\n",
       "      <td>2542.0</td>\n",
       "      <td>4.599963e-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>W-&gt;S1</td>\n",
       "      <td>-5.281504</td>\n",
       "      <td>1.281278e-07</td>\n",
       "      <td>3059.0</td>\n",
       "      <td>6.446579e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>W-&gt;S2</td>\n",
       "      <td>-5.897331</td>\n",
       "      <td>3.694274e-09</td>\n",
       "      <td>2793.5</td>\n",
       "      <td>2.485725e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>W-&gt;REM</td>\n",
       "      <td>1.853281</td>\n",
       "      <td>6.384205e-02</td>\n",
       "      <td>4537.0</td>\n",
       "      <td>3.832078e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>S1-&gt;W</td>\n",
       "      <td>6.637252</td>\n",
       "      <td>3.195845e-11</td>\n",
       "      <td>2474.5</td>\n",
       "      <td>1.493540e-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>S1-&gt;S1</td>\n",
       "      <td>-5.673500</td>\n",
       "      <td>1.399095e-08</td>\n",
       "      <td>2890.0</td>\n",
       "      <td>7.037414e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>S1-&gt;S2</td>\n",
       "      <td>2.779922</td>\n",
       "      <td>5.437196e-03</td>\n",
       "      <td>4137.5</td>\n",
       "      <td>2.727311e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>S1-&gt;REM</td>\n",
       "      <td>5.158570</td>\n",
       "      <td>2.488427e-07</td>\n",
       "      <td>3112.0</td>\n",
       "      <td>1.758797e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>S2-&gt;W</td>\n",
       "      <td>4.045210</td>\n",
       "      <td>5.227628e-05</td>\n",
       "      <td>3592.0</td>\n",
       "      <td>2.625410e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>S2-&gt;S1</td>\n",
       "      <td>7.460675</td>\n",
       "      <td>8.608028e-14</td>\n",
       "      <td>2119.5</td>\n",
       "      <td>3.876329e-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>S2-&gt;S2</td>\n",
       "      <td>-8.307293</td>\n",
       "      <td>9.791000e-17</td>\n",
       "      <td>1754.5</td>\n",
       "      <td>4.943446e-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>S2-&gt;S3</td>\n",
       "      <td>5.106382</td>\n",
       "      <td>3.283863e-07</td>\n",
       "      <td>3134.5</td>\n",
       "      <td>1.650235e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>S2-&gt;S4</td>\n",
       "      <td>1.134236</td>\n",
       "      <td>2.566956e-01</td>\n",
       "      <td>4847.0</td>\n",
       "      <td>8.539151e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>S2-&gt;REM</td>\n",
       "      <td>4.601890</td>\n",
       "      <td>4.186742e-06</td>\n",
       "      <td>3352.0</td>\n",
       "      <td>2.104875e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>S3-&gt;S1</td>\n",
       "      <td>1.737306</td>\n",
       "      <td>8.233312e-02</td>\n",
       "      <td>4587.0</td>\n",
       "      <td>7.518858e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>S3-&gt;S2</td>\n",
       "      <td>8.492853</td>\n",
       "      <td>2.016252e-17</td>\n",
       "      <td>1674.5</td>\n",
       "      <td>1.011512e-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>S3-&gt;S3</td>\n",
       "      <td>-10.540972</td>\n",
       "      <td>5.591765e-26</td>\n",
       "      <td>791.5</td>\n",
       "      <td>2.743893e-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>S4-&gt;W</td>\n",
       "      <td>-3.268177</td>\n",
       "      <td>1.082427e-03</td>\n",
       "      <td>3927.0</td>\n",
       "      <td>4.800361e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>S4-&gt;S2</td>\n",
       "      <td>-3.102333</td>\n",
       "      <td>1.920021e-03</td>\n",
       "      <td>3998.5</td>\n",
       "      <td>3.679183e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>S4-&gt;S4</td>\n",
       "      <td>-9.121438</td>\n",
       "      <td>7.413415e-20</td>\n",
       "      <td>1403.5</td>\n",
       "      <td>1.770815e-20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>REM-&gt;W</td>\n",
       "      <td>2.433157</td>\n",
       "      <td>1.496783e-02</td>\n",
       "      <td>4287.0</td>\n",
       "      <td>7.072414e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>REM-&gt;S1</td>\n",
       "      <td>4.576376</td>\n",
       "      <td>4.731009e-06</td>\n",
       "      <td>3363.0</td>\n",
       "      <td>1.166662e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>REM-&gt;REM</td>\n",
       "      <td>-4.332828</td>\n",
       "      <td>1.472062e-05</td>\n",
       "      <td>3468.0</td>\n",
       "      <td>7.397736e-06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Features  Wilcoxon_zscore  Wilcoxon_pvalue  MannWhitney_statistic  \\\n",
       "0       W->W         6.480686     9.130657e-11                 2542.0   \n",
       "1      W->S1        -5.281504     1.281278e-07                 3059.0   \n",
       "2      W->S2        -5.897331     3.694274e-09                 2793.5   \n",
       "5     W->REM         1.853281     6.384205e-02                 4537.0   \n",
       "6      S1->W         6.637252     3.195845e-11                 2474.5   \n",
       "7     S1->S1        -5.673500     1.399095e-08                 2890.0   \n",
       "8     S1->S2         2.779922     5.437196e-03                 4137.5   \n",
       "11   S1->REM         5.158570     2.488427e-07                 3112.0   \n",
       "12     S2->W         4.045210     5.227628e-05                 3592.0   \n",
       "13    S2->S1         7.460675     8.608028e-14                 2119.5   \n",
       "14    S2->S2        -8.307293     9.791000e-17                 1754.5   \n",
       "15    S2->S3         5.106382     3.283863e-07                 3134.5   \n",
       "16    S2->S4         1.134236     2.566956e-01                 4847.0   \n",
       "17   S2->REM         4.601890     4.186742e-06                 3352.0   \n",
       "19    S3->S1         1.737306     8.233312e-02                 4587.0   \n",
       "20    S3->S2         8.492853     2.016252e-17                 1674.5   \n",
       "21    S3->S3       -10.540972     5.591765e-26                  791.5   \n",
       "24     S4->W        -3.268177     1.082427e-03                 3927.0   \n",
       "26    S4->S2        -3.102333     1.920021e-03                 3998.5   \n",
       "28    S4->S4        -9.121438     7.413415e-20                 1403.5   \n",
       "30    REM->W         2.433157     1.496783e-02                 4287.0   \n",
       "31   REM->S1         4.576376     4.731009e-06                 3363.0   \n",
       "35  REM->REM        -4.332828     1.472062e-05                 3468.0   \n",
       "\n",
       "    MannWhitney_pvalue  \n",
       "0         4.599963e-11  \n",
       "1         6.446579e-08  \n",
       "2         2.485725e-10  \n",
       "5         3.832078e-03  \n",
       "6         1.493540e-11  \n",
       "7         7.037414e-09  \n",
       "8         2.727311e-03  \n",
       "11        1.758797e-08  \n",
       "12        2.625410e-05  \n",
       "13        3.876329e-14  \n",
       "14        4.943446e-17  \n",
       "15        1.650235e-07  \n",
       "16        8.539151e-03  \n",
       "17        2.104875e-06  \n",
       "19        7.518858e-03  \n",
       "20        1.011512e-17  \n",
       "21        2.743893e-26  \n",
       "24        4.800361e-05  \n",
       "26        3.679183e-04  \n",
       "28        1.770815e-20  \n",
       "30        7.072414e-03  \n",
       "31        1.166662e-06  \n",
       "35        7.397736e-06  "
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mann_p = stat_significace_df[ (stat_significace_df['MannWhitney_pvalue']<0.05) ]\n",
    "mann_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "above-viewer",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Features</th>\n",
       "      <th>Wilcoxon_zscore</th>\n",
       "      <th>Wilcoxon_pvalue</th>\n",
       "      <th>MannWhitney_statistic</th>\n",
       "      <th>MannWhitney_pvalue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>S3-&gt;S3</td>\n",
       "      <td>-10.540972</td>\n",
       "      <td>5.591765e-26</td>\n",
       "      <td>791.5</td>\n",
       "      <td>2.743893e-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>S4-&gt;S4</td>\n",
       "      <td>-9.121438</td>\n",
       "      <td>7.413415e-20</td>\n",
       "      <td>1403.5</td>\n",
       "      <td>1.770815e-20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>S3-&gt;S2</td>\n",
       "      <td>8.492853</td>\n",
       "      <td>2.016252e-17</td>\n",
       "      <td>1674.5</td>\n",
       "      <td>1.011512e-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>S2-&gt;S2</td>\n",
       "      <td>-8.307293</td>\n",
       "      <td>9.791000e-17</td>\n",
       "      <td>1754.5</td>\n",
       "      <td>4.943446e-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>S2-&gt;S1</td>\n",
       "      <td>7.460675</td>\n",
       "      <td>8.608028e-14</td>\n",
       "      <td>2119.5</td>\n",
       "      <td>3.876329e-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>S1-&gt;W</td>\n",
       "      <td>6.637252</td>\n",
       "      <td>3.195845e-11</td>\n",
       "      <td>2474.5</td>\n",
       "      <td>1.493540e-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>W-&gt;W</td>\n",
       "      <td>6.480686</td>\n",
       "      <td>9.130657e-11</td>\n",
       "      <td>2542.0</td>\n",
       "      <td>4.599963e-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>W-&gt;S2</td>\n",
       "      <td>-5.897331</td>\n",
       "      <td>3.694274e-09</td>\n",
       "      <td>2793.5</td>\n",
       "      <td>2.485725e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>S1-&gt;S1</td>\n",
       "      <td>-5.673500</td>\n",
       "      <td>1.399095e-08</td>\n",
       "      <td>2890.0</td>\n",
       "      <td>7.037414e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>W-&gt;S1</td>\n",
       "      <td>-5.281504</td>\n",
       "      <td>1.281278e-07</td>\n",
       "      <td>3059.0</td>\n",
       "      <td>6.446579e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>S1-&gt;REM</td>\n",
       "      <td>5.158570</td>\n",
       "      <td>2.488427e-07</td>\n",
       "      <td>3112.0</td>\n",
       "      <td>1.758797e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>S2-&gt;S3</td>\n",
       "      <td>5.106382</td>\n",
       "      <td>3.283863e-07</td>\n",
       "      <td>3134.5</td>\n",
       "      <td>1.650235e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>S2-&gt;REM</td>\n",
       "      <td>4.601890</td>\n",
       "      <td>4.186742e-06</td>\n",
       "      <td>3352.0</td>\n",
       "      <td>2.104875e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>REM-&gt;S1</td>\n",
       "      <td>4.576376</td>\n",
       "      <td>4.731009e-06</td>\n",
       "      <td>3363.0</td>\n",
       "      <td>1.166662e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>REM-&gt;REM</td>\n",
       "      <td>-4.332828</td>\n",
       "      <td>1.472062e-05</td>\n",
       "      <td>3468.0</td>\n",
       "      <td>7.397736e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>S2-&gt;W</td>\n",
       "      <td>4.045210</td>\n",
       "      <td>5.227628e-05</td>\n",
       "      <td>3592.0</td>\n",
       "      <td>2.625410e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>S4-&gt;W</td>\n",
       "      <td>-3.268177</td>\n",
       "      <td>1.082427e-03</td>\n",
       "      <td>3927.0</td>\n",
       "      <td>4.800361e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>S4-&gt;S2</td>\n",
       "      <td>-3.102333</td>\n",
       "      <td>1.920021e-03</td>\n",
       "      <td>3998.5</td>\n",
       "      <td>3.679183e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>S1-&gt;S2</td>\n",
       "      <td>2.779922</td>\n",
       "      <td>5.437196e-03</td>\n",
       "      <td>4137.5</td>\n",
       "      <td>2.727311e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>REM-&gt;W</td>\n",
       "      <td>2.433157</td>\n",
       "      <td>1.496783e-02</td>\n",
       "      <td>4287.0</td>\n",
       "      <td>7.072414e-03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Features  Wilcoxon_zscore  Wilcoxon_pvalue  MannWhitney_statistic  \\\n",
       "21    S3->S3       -10.540972     5.591765e-26                  791.5   \n",
       "28    S4->S4        -9.121438     7.413415e-20                 1403.5   \n",
       "20    S3->S2         8.492853     2.016252e-17                 1674.5   \n",
       "14    S2->S2        -8.307293     9.791000e-17                 1754.5   \n",
       "13    S2->S1         7.460675     8.608028e-14                 2119.5   \n",
       "6      S1->W         6.637252     3.195845e-11                 2474.5   \n",
       "0       W->W         6.480686     9.130657e-11                 2542.0   \n",
       "2      W->S2        -5.897331     3.694274e-09                 2793.5   \n",
       "7     S1->S1        -5.673500     1.399095e-08                 2890.0   \n",
       "1      W->S1        -5.281504     1.281278e-07                 3059.0   \n",
       "11   S1->REM         5.158570     2.488427e-07                 3112.0   \n",
       "15    S2->S3         5.106382     3.283863e-07                 3134.5   \n",
       "17   S2->REM         4.601890     4.186742e-06                 3352.0   \n",
       "31   REM->S1         4.576376     4.731009e-06                 3363.0   \n",
       "35  REM->REM        -4.332828     1.472062e-05                 3468.0   \n",
       "12     S2->W         4.045210     5.227628e-05                 3592.0   \n",
       "24     S4->W        -3.268177     1.082427e-03                 3927.0   \n",
       "26    S4->S2        -3.102333     1.920021e-03                 3998.5   \n",
       "8     S1->S2         2.779922     5.437196e-03                 4137.5   \n",
       "30    REM->W         2.433157     1.496783e-02                 4287.0   \n",
       "\n",
       "    MannWhitney_pvalue  \n",
       "21        2.743893e-26  \n",
       "28        1.770815e-20  \n",
       "20        1.011512e-17  \n",
       "14        4.943446e-17  \n",
       "13        3.876329e-14  \n",
       "6         1.493540e-11  \n",
       "0         4.599963e-11  \n",
       "2         2.485725e-10  \n",
       "7         7.037414e-09  \n",
       "1         6.446579e-08  \n",
       "11        1.758797e-08  \n",
       "15        1.650235e-07  \n",
       "17        2.104875e-06  \n",
       "31        1.166662e-06  \n",
       "35        7.397736e-06  \n",
       "12        2.625410e-05  \n",
       "24        4.800361e-05  \n",
       "26        3.679183e-04  \n",
       "8         2.727311e-03  \n",
       "30        7.072414e-03  "
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wil_p = wil_p.sort_values('Wilcoxon_pvalue', ascending=True)\n",
    "wil_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "working-running",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Features</th>\n",
       "      <th>Wilcoxon_zscore</th>\n",
       "      <th>Wilcoxon_pvalue</th>\n",
       "      <th>MannWhitney_statistic</th>\n",
       "      <th>MannWhitney_pvalue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>S3-&gt;S3</td>\n",
       "      <td>-10.540972</td>\n",
       "      <td>5.591765e-26</td>\n",
       "      <td>791.5</td>\n",
       "      <td>2.743893e-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>S4-&gt;S4</td>\n",
       "      <td>-9.121438</td>\n",
       "      <td>7.413415e-20</td>\n",
       "      <td>1403.5</td>\n",
       "      <td>1.770815e-20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>S3-&gt;S2</td>\n",
       "      <td>8.492853</td>\n",
       "      <td>2.016252e-17</td>\n",
       "      <td>1674.5</td>\n",
       "      <td>1.011512e-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>S2-&gt;S2</td>\n",
       "      <td>-8.307293</td>\n",
       "      <td>9.791000e-17</td>\n",
       "      <td>1754.5</td>\n",
       "      <td>4.943446e-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>S2-&gt;S1</td>\n",
       "      <td>7.460675</td>\n",
       "      <td>8.608028e-14</td>\n",
       "      <td>2119.5</td>\n",
       "      <td>3.876329e-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>S1-&gt;W</td>\n",
       "      <td>6.637252</td>\n",
       "      <td>3.195845e-11</td>\n",
       "      <td>2474.5</td>\n",
       "      <td>1.493540e-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>W-&gt;W</td>\n",
       "      <td>6.480686</td>\n",
       "      <td>9.130657e-11</td>\n",
       "      <td>2542.0</td>\n",
       "      <td>4.599963e-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>W-&gt;S2</td>\n",
       "      <td>-5.897331</td>\n",
       "      <td>3.694274e-09</td>\n",
       "      <td>2793.5</td>\n",
       "      <td>2.485725e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>S1-&gt;S1</td>\n",
       "      <td>-5.673500</td>\n",
       "      <td>1.399095e-08</td>\n",
       "      <td>2890.0</td>\n",
       "      <td>7.037414e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>S1-&gt;REM</td>\n",
       "      <td>5.158570</td>\n",
       "      <td>2.488427e-07</td>\n",
       "      <td>3112.0</td>\n",
       "      <td>1.758797e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>W-&gt;S1</td>\n",
       "      <td>-5.281504</td>\n",
       "      <td>1.281278e-07</td>\n",
       "      <td>3059.0</td>\n",
       "      <td>6.446579e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>S2-&gt;S3</td>\n",
       "      <td>5.106382</td>\n",
       "      <td>3.283863e-07</td>\n",
       "      <td>3134.5</td>\n",
       "      <td>1.650235e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>REM-&gt;S1</td>\n",
       "      <td>4.576376</td>\n",
       "      <td>4.731009e-06</td>\n",
       "      <td>3363.0</td>\n",
       "      <td>1.166662e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>S2-&gt;REM</td>\n",
       "      <td>4.601890</td>\n",
       "      <td>4.186742e-06</td>\n",
       "      <td>3352.0</td>\n",
       "      <td>2.104875e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>REM-&gt;REM</td>\n",
       "      <td>-4.332828</td>\n",
       "      <td>1.472062e-05</td>\n",
       "      <td>3468.0</td>\n",
       "      <td>7.397736e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>S2-&gt;W</td>\n",
       "      <td>4.045210</td>\n",
       "      <td>5.227628e-05</td>\n",
       "      <td>3592.0</td>\n",
       "      <td>2.625410e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>S4-&gt;W</td>\n",
       "      <td>-3.268177</td>\n",
       "      <td>1.082427e-03</td>\n",
       "      <td>3927.0</td>\n",
       "      <td>4.800361e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>S4-&gt;S2</td>\n",
       "      <td>-3.102333</td>\n",
       "      <td>1.920021e-03</td>\n",
       "      <td>3998.5</td>\n",
       "      <td>3.679183e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>S1-&gt;S2</td>\n",
       "      <td>2.779922</td>\n",
       "      <td>5.437196e-03</td>\n",
       "      <td>4137.5</td>\n",
       "      <td>2.727311e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>W-&gt;REM</td>\n",
       "      <td>1.853281</td>\n",
       "      <td>6.384205e-02</td>\n",
       "      <td>4537.0</td>\n",
       "      <td>3.832078e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>REM-&gt;W</td>\n",
       "      <td>2.433157</td>\n",
       "      <td>1.496783e-02</td>\n",
       "      <td>4287.0</td>\n",
       "      <td>7.072414e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>S3-&gt;S1</td>\n",
       "      <td>1.737306</td>\n",
       "      <td>8.233312e-02</td>\n",
       "      <td>4587.0</td>\n",
       "      <td>7.518858e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>S2-&gt;S4</td>\n",
       "      <td>1.134236</td>\n",
       "      <td>2.566956e-01</td>\n",
       "      <td>4847.0</td>\n",
       "      <td>8.539151e-03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Features  Wilcoxon_zscore  Wilcoxon_pvalue  MannWhitney_statistic  \\\n",
       "21    S3->S3       -10.540972     5.591765e-26                  791.5   \n",
       "28    S4->S4        -9.121438     7.413415e-20                 1403.5   \n",
       "20    S3->S2         8.492853     2.016252e-17                 1674.5   \n",
       "14    S2->S2        -8.307293     9.791000e-17                 1754.5   \n",
       "13    S2->S1         7.460675     8.608028e-14                 2119.5   \n",
       "6      S1->W         6.637252     3.195845e-11                 2474.5   \n",
       "0       W->W         6.480686     9.130657e-11                 2542.0   \n",
       "2      W->S2        -5.897331     3.694274e-09                 2793.5   \n",
       "7     S1->S1        -5.673500     1.399095e-08                 2890.0   \n",
       "11   S1->REM         5.158570     2.488427e-07                 3112.0   \n",
       "1      W->S1        -5.281504     1.281278e-07                 3059.0   \n",
       "15    S2->S3         5.106382     3.283863e-07                 3134.5   \n",
       "31   REM->S1         4.576376     4.731009e-06                 3363.0   \n",
       "17   S2->REM         4.601890     4.186742e-06                 3352.0   \n",
       "35  REM->REM        -4.332828     1.472062e-05                 3468.0   \n",
       "12     S2->W         4.045210     5.227628e-05                 3592.0   \n",
       "24     S4->W        -3.268177     1.082427e-03                 3927.0   \n",
       "26    S4->S2        -3.102333     1.920021e-03                 3998.5   \n",
       "8     S1->S2         2.779922     5.437196e-03                 4137.5   \n",
       "5     W->REM         1.853281     6.384205e-02                 4537.0   \n",
       "30    REM->W         2.433157     1.496783e-02                 4287.0   \n",
       "19    S3->S1         1.737306     8.233312e-02                 4587.0   \n",
       "16    S2->S4         1.134236     2.566956e-01                 4847.0   \n",
       "\n",
       "    MannWhitney_pvalue  \n",
       "21        2.743893e-26  \n",
       "28        1.770815e-20  \n",
       "20        1.011512e-17  \n",
       "14        4.943446e-17  \n",
       "13        3.876329e-14  \n",
       "6         1.493540e-11  \n",
       "0         4.599963e-11  \n",
       "2         2.485725e-10  \n",
       "7         7.037414e-09  \n",
       "11        1.758797e-08  \n",
       "1         6.446579e-08  \n",
       "15        1.650235e-07  \n",
       "31        1.166662e-06  \n",
       "17        2.104875e-06  \n",
       "35        7.397736e-06  \n",
       "12        2.625410e-05  \n",
       "24        4.800361e-05  \n",
       "26        3.679183e-04  \n",
       "8         2.727311e-03  \n",
       "5         3.832078e-03  \n",
       "30        7.072414e-03  \n",
       "19        7.518858e-03  \n",
       "16        8.539151e-03  "
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mann_p = mann_p.sort_values('MannWhitney_pvalue', ascending=True)\n",
    "mann_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "quiet-christopher",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((20, 5), (23, 5))"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wil_p.shape, mann_p.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "blond-bread",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['S3->S3', 'S4->S4', 'S3->S2', 'S2->S2', 'S2->S1', 'S1->W', 'W->W', 'W->S2', 'S1->S1', 'W->S1', 'S1->REM', 'S2->S3', 'S2->REM', 'REM->S1', 'REM->REM', 'S2->W', 'S4->W', 'S4->S2', 'S1->S2', 'REM->W']\n"
     ]
    }
   ],
   "source": [
    "print(wil_p.Features.values.tolist()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "combined-commerce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['S3->S3', 'S4->S4', 'S3->S2', 'S2->S2', 'S2->S1', 'S1->W', 'W->W', 'W->S2', 'S1->S1', 'S1->REM', 'W->S1', 'S2->S3', 'REM->S1', 'S2->REM', 'REM->REM', 'S2->W', 'S4->W', 'S4->S2', 'S1->S2', 'W->REM', 'REM->W', 'S3->S1', 'S2->S4']\n"
     ]
    }
   ],
   "source": [
    "print(mann_p.Features.values.tolist()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "turned-gardening",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "arranged-celebrity",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "tracked-representative",
   "metadata": {},
   "source": [
    "#### Mean-SD of dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "greenhouse-somerset",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset</th>\n",
       "      <th>Category</th>\n",
       "      <th>Subject_Name</th>\n",
       "      <th>Class</th>\n",
       "      <th>W-&gt;W</th>\n",
       "      <th>W-&gt;S1</th>\n",
       "      <th>W-&gt;S2</th>\n",
       "      <th>W-&gt;S3</th>\n",
       "      <th>W-&gt;S4</th>\n",
       "      <th>W-&gt;REM</th>\n",
       "      <th>...</th>\n",
       "      <th>S4-&gt;S2</th>\n",
       "      <th>S4-&gt;S3</th>\n",
       "      <th>S4-&gt;S4</th>\n",
       "      <th>S4-&gt;REM</th>\n",
       "      <th>REM-&gt;W</th>\n",
       "      <th>REM-&gt;S1</th>\n",
       "      <th>REM-&gt;S2</th>\n",
       "      <th>REM-&gt;S3</th>\n",
       "      <th>REM-&gt;S4</th>\n",
       "      <th>REM-&gt;REM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CAP_Sleep</td>\n",
       "      <td>brux</td>\n",
       "      <td>brux1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.190476</td>\n",
       "      <td>0.009524</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004926</td>\n",
       "      <td>0.024631</td>\n",
       "      <td>0.970443</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.033520</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.966480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CAP_Sleep</td>\n",
       "      <td>brux</td>\n",
       "      <td>brux2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.825397</td>\n",
       "      <td>0.174603</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.012048</td>\n",
       "      <td>0.984940</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.019324</td>\n",
       "      <td>0.004831</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.975845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CAP_Sleep</td>\n",
       "      <td>sdb</td>\n",
       "      <td>sdb1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.876712</td>\n",
       "      <td>0.123288</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005076</td>\n",
       "      <td>0.030457</td>\n",
       "      <td>0.949239</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.009346</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.028037</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.962617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CAP_Sleep</td>\n",
       "      <td>sdb</td>\n",
       "      <td>sdb2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.948718</td>\n",
       "      <td>0.044872</td>\n",
       "      <td>0.006410</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.016949</td>\n",
       "      <td>0.966102</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.025641</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.974359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CAP_Sleep</td>\n",
       "      <td>sdb</td>\n",
       "      <td>sdb3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.934272</td>\n",
       "      <td>0.046948</td>\n",
       "      <td>0.018779</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.025974</td>\n",
       "      <td>0.038961</td>\n",
       "      <td>0.935065</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.937500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>Sleep_EDFX</td>\n",
       "      <td>n</td>\n",
       "      <td>ST7191</td>\n",
       "      <td>0</td>\n",
       "      <td>0.742857</td>\n",
       "      <td>0.242857</td>\n",
       "      <td>0.014286</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.013889</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.805556</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>0.015000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.965000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>Sleep_EDFX</td>\n",
       "      <td>n</td>\n",
       "      <td>ST7201</td>\n",
       "      <td>0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>...</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>0.346154</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.044776</td>\n",
       "      <td>0.007463</td>\n",
       "      <td>0.014925</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.932836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>Sleep_EDFX</td>\n",
       "      <td>n</td>\n",
       "      <td>ST7211</td>\n",
       "      <td>0</td>\n",
       "      <td>0.894737</td>\n",
       "      <td>0.099415</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.005848</td>\n",
       "      <td>...</td>\n",
       "      <td>0.016949</td>\n",
       "      <td>0.254237</td>\n",
       "      <td>0.728814</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.025641</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.019231</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.955128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>Sleep_EDFX</td>\n",
       "      <td>n</td>\n",
       "      <td>ST7221</td>\n",
       "      <td>0</td>\n",
       "      <td>0.820000</td>\n",
       "      <td>0.180000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.021645</td>\n",
       "      <td>0.043290</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.935065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>Sleep_EDFX</td>\n",
       "      <td>n</td>\n",
       "      <td>ST7241</td>\n",
       "      <td>0</td>\n",
       "      <td>0.620690</td>\n",
       "      <td>0.275862</td>\n",
       "      <td>0.034483</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.068966</td>\n",
       "      <td>...</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.016878</td>\n",
       "      <td>0.016878</td>\n",
       "      <td>0.008439</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.957806</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>208 rows × 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Dataset Category Subject_Name  Class      W->W     W->S1     W->S2  \\\n",
       "0     CAP_Sleep     brux        brux1      1  0.800000  0.190476  0.009524   \n",
       "1     CAP_Sleep     brux        brux2      1  0.825397  0.174603  0.000000   \n",
       "2     CAP_Sleep      sdb         sdb1      1  0.876712  0.123288  0.000000   \n",
       "3     CAP_Sleep      sdb         sdb2      1  0.948718  0.044872  0.006410   \n",
       "4     CAP_Sleep      sdb         sdb3      1  0.934272  0.046948  0.018779   \n",
       "..          ...      ...          ...    ...       ...       ...       ...   \n",
       "203  Sleep_EDFX        n       ST7191      0  0.742857  0.242857  0.014286   \n",
       "204  Sleep_EDFX        n       ST7201      0  0.333333  0.555556  0.055556   \n",
       "205  Sleep_EDFX        n       ST7211      0  0.894737  0.099415  0.000000   \n",
       "206  Sleep_EDFX        n       ST7221      0  0.820000  0.180000  0.000000   \n",
       "207  Sleep_EDFX        n       ST7241      0  0.620690  0.275862  0.034483   \n",
       "\n",
       "     W->S3  W->S4    W->REM  ...    S4->S2    S4->S3    S4->S4  S4->REM  \\\n",
       "0      0.0    0.0  0.000000  ...  0.004926  0.024631  0.970443      0.0   \n",
       "1      0.0    0.0  0.000000  ...  0.000000  0.012048  0.984940      0.0   \n",
       "2      0.0    0.0  0.000000  ...  0.005076  0.030457  0.949239      0.0   \n",
       "3      0.0    0.0  0.000000  ...  0.008475  0.016949  0.966102      0.0   \n",
       "4      0.0    0.0  0.000000  ...  0.025974  0.038961  0.935065      0.0   \n",
       "..     ...    ...       ...  ...       ...       ...       ...      ...   \n",
       "203    0.0    0.0  0.000000  ...  0.013889  0.166667  0.805556      0.0   \n",
       "204    0.0    0.0  0.055556  ...  0.038462  0.615385  0.346154      0.0   \n",
       "205    0.0    0.0  0.005848  ...  0.016949  0.254237  0.728814      0.0   \n",
       "206    0.0    0.0  0.000000  ...  0.000000  0.000000  0.000000      0.0   \n",
       "207    0.0    0.0  0.068966  ...  0.142857  0.571429  0.142857      0.0   \n",
       "\n",
       "       REM->W   REM->S1   REM->S2  REM->S3  REM->S4  REM->REM  \n",
       "0    0.033520  0.000000  0.000000      0.0      0.0  0.966480  \n",
       "1    0.019324  0.004831  0.000000      0.0      0.0  0.975845  \n",
       "2    0.009346  0.000000  0.028037      0.0      0.0  0.962617  \n",
       "3    0.000000  0.000000  0.025641      0.0      0.0  0.974359  \n",
       "4    0.062500  0.000000  0.000000      0.0      0.0  0.937500  \n",
       "..        ...       ...       ...      ...      ...       ...  \n",
       "203  0.000000  0.020000  0.015000      0.0      0.0  0.965000  \n",
       "204  0.044776  0.007463  0.014925      0.0      0.0  0.932836  \n",
       "205  0.025641  0.000000  0.019231      0.0      0.0  0.955128  \n",
       "206  0.021645  0.043290  0.000000      0.0      0.0  0.935065  \n",
       "207  0.016878  0.016878  0.008439      0.0      0.0  0.957806  \n",
       "\n",
       "[208 rows x 40 columns]"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "functioning-density",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['W->W', 'W->S1', 'W->S2', 'W->S3', 'W->S4', 'W->REM', 'S1->W',\n",
       "       'S1->S1', 'S1->S2', 'S1->S3', 'S1->S4', 'S1->REM', 'S2->W',\n",
       "       'S2->S1', 'S2->S2', 'S2->S3', 'S2->S4', 'S2->REM', 'S3->W',\n",
       "       'S3->S1', 'S3->S2', 'S3->S3', 'S3->S4', 'S3->REM', 'S4->W',\n",
       "       'S4->S1', 'S4->S2', 'S4->S3', 'S4->S4', 'S4->REM', 'REM->W',\n",
       "       'REM->S1', 'REM->S2', 'REM->S3', 'REM->S4', 'REM->REM'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feat_names = dataset.columns.values[4:]\n",
    "feat_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "proprietary-flashing",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>Sum</th>\n",
       "      <th>Mean</th>\n",
       "      <th>STD</th>\n",
       "      <th>P-value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>W-&gt;W</td>\n",
       "      <td>192.343048</td>\n",
       "      <td>0.925</td>\n",
       "      <td>0.095</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>W-&gt;S1</td>\n",
       "      <td>12.936016</td>\n",
       "      <td>0.062</td>\n",
       "      <td>0.080</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>W-&gt;S2</td>\n",
       "      <td>2.315395</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>W-&gt;S3</td>\n",
       "      <td>0.095430</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.866454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>W-&gt;S4</td>\n",
       "      <td>0.008065</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.892983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>W-&gt;REM</td>\n",
       "      <td>0.302046</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.063842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>S1-&gt;W</td>\n",
       "      <td>12.773324</td>\n",
       "      <td>0.061</td>\n",
       "      <td>0.050</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>S1-&gt;S1</td>\n",
       "      <td>151.035246</td>\n",
       "      <td>0.726</td>\n",
       "      <td>0.137</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>S1-&gt;S2</td>\n",
       "      <td>40.671520</td>\n",
       "      <td>0.196</td>\n",
       "      <td>0.110</td>\n",
       "      <td>0.005437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>S1-&gt;S3</td>\n",
       "      <td>0.149284</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.791454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>S1-&gt;S4</td>\n",
       "      <td>0.023810</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.892983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>S1-&gt;REM</td>\n",
       "      <td>3.346817</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.026</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>S2-&gt;W</td>\n",
       "      <td>2.380687</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.000052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>S2-&gt;S1</td>\n",
       "      <td>2.968244</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.018</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>S2-&gt;S2</td>\n",
       "      <td>194.407953</td>\n",
       "      <td>0.935</td>\n",
       "      <td>0.047</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>S2-&gt;S3</td>\n",
       "      <td>6.174997</td>\n",
       "      <td>0.030</td>\n",
       "      <td>0.032</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>S2-&gt;S4</td>\n",
       "      <td>0.059653</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.256696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>S2-&gt;REM</td>\n",
       "      <td>2.008467</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.000004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>S3-&gt;W</td>\n",
       "      <td>1.520770</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.181918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>S3-&gt;S1</td>\n",
       "      <td>0.774745</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.082333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>S3-&gt;S2</td>\n",
       "      <td>40.421263</td>\n",
       "      <td>0.194</td>\n",
       "      <td>0.261</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>S3-&gt;S3</td>\n",
       "      <td>144.023127</td>\n",
       "      <td>0.692</td>\n",
       "      <td>0.307</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>S3-&gt;S4</td>\n",
       "      <td>12.112397</td>\n",
       "      <td>0.058</td>\n",
       "      <td>0.082</td>\n",
       "      <td>0.474259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>S3-&gt;REM</td>\n",
       "      <td>0.147698</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.659426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>S4-&gt;W</td>\n",
       "      <td>0.852400</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.001082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>S4-&gt;S1</td>\n",
       "      <td>0.401657</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.924236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>S4-&gt;S2</td>\n",
       "      <td>1.745950</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.019</td>\n",
       "      <td>0.001920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>S4-&gt;S3</td>\n",
       "      <td>22.581159</td>\n",
       "      <td>0.109</td>\n",
       "      <td>0.225</td>\n",
       "      <td>0.297664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>S4-&gt;S4</td>\n",
       "      <td>133.350372</td>\n",
       "      <td>0.641</td>\n",
       "      <td>0.421</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>S4-&gt;REM</td>\n",
       "      <td>0.068463</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.769204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>REM-&gt;W</td>\n",
       "      <td>3.062163</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.018</td>\n",
       "      <td>0.014968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>REM-&gt;S1</td>\n",
       "      <td>3.180310</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.022</td>\n",
       "      <td>0.000005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>REM-&gt;S2</td>\n",
       "      <td>3.258263</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.142985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>REM-&gt;S3</td>\n",
       "      <td>0.013770</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.787882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>REM-&gt;S4</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>REM-&gt;REM</td>\n",
       "      <td>198.485493</td>\n",
       "      <td>0.954</td>\n",
       "      <td>0.034</td>\n",
       "      <td>0.000015</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Feature         Sum   Mean    STD   P-value\n",
       "0       W->W  192.343048  0.925  0.095  0.000000\n",
       "1      W->S1   12.936016  0.062  0.080  0.000000\n",
       "2      W->S2    2.315395  0.011  0.025  0.000000\n",
       "3      W->S3    0.095430  0.000  0.003  0.866454\n",
       "4      W->S4    0.008065  0.000  0.001  0.892983\n",
       "5     W->REM    0.302046  0.001  0.007  0.063842\n",
       "6      S1->W   12.773324  0.061  0.050  0.000000\n",
       "7     S1->S1  151.035246  0.726  0.137  0.000000\n",
       "8     S1->S2   40.671520  0.196  0.110  0.005437\n",
       "9     S1->S3    0.149284  0.001  0.006  0.791454\n",
       "10    S1->S4    0.023810  0.000  0.002  0.892983\n",
       "11   S1->REM    3.346817  0.016  0.026  0.000000\n",
       "12     S2->W    2.380687  0.011  0.009  0.000052\n",
       "13    S2->S1    2.968244  0.014  0.018  0.000000\n",
       "14    S2->S2  194.407953  0.935  0.047  0.000000\n",
       "15    S2->S3    6.174997  0.030  0.032  0.000000\n",
       "16    S2->S4    0.059653  0.000  0.001  0.256696\n",
       "17   S2->REM    2.008467  0.010  0.006  0.000004\n",
       "18     S3->W    1.520770  0.007  0.020  0.181918\n",
       "19    S3->S1    0.774745  0.004  0.016  0.082333\n",
       "20    S3->S2   40.421263  0.194  0.261  0.000000\n",
       "21    S3->S3  144.023127  0.692  0.307  0.000000\n",
       "22    S3->S4   12.112397  0.058  0.082  0.474259\n",
       "23   S3->REM    0.147698  0.001  0.003  0.659426\n",
       "24     S4->W    0.852400  0.004  0.010  0.001082\n",
       "25    S4->S1    0.401657  0.002  0.011  0.924236\n",
       "26    S4->S2    1.745950  0.008  0.019  0.001920\n",
       "27    S4->S3   22.581159  0.109  0.225  0.297664\n",
       "28    S4->S4  133.350372  0.641  0.421  0.000000\n",
       "29   S4->REM    0.068463  0.000  0.003  0.769204\n",
       "30    REM->W    3.062163  0.015  0.018  0.014968\n",
       "31   REM->S1    3.180310  0.015  0.022  0.000005\n",
       "32   REM->S2    3.258263  0.016  0.017  0.142985\n",
       "33   REM->S3    0.013770  0.000  0.001  0.787882\n",
       "34   REM->S4    0.000000  0.000  0.000  1.000000\n",
       "35  REM->REM  198.485493  0.954  0.034  0.000015"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "study1_feature_statistics_df = None\n",
    "study1_feature_statistics_df = pd.DataFrame(columns=['Feature', 'Sum', 'Mean', 'STD', 'P-value']) \n",
    "for f in feat_names:\n",
    "#     print(f, '=== ', round(dataset[f].sum(),2), '||', round(dataset[f].mean(),2), '+/-', round(dataset[f].std(),2), round(stat_significace_df[(stat_significace_df['Features']==f)]['Wilcoxon_pvalue'],6)) # stat_significace_df | Features\tWilcoxon_zscore\tWilcoxon_pvalue\n",
    "    study1_feature_statistics_df.loc[(study1_feature_statistics_df.shape[0])] = [f, round(dataset[f].sum(),6), round(dataset[f].mean(),3), round(dataset[f].std(),3), round(stat_significace_df[(stat_significace_df['Features']==f)]['Wilcoxon_pvalue'].values[0],6)] \n",
    "\n",
    "study1_feature_statistics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "inappropriate-brunei",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./Results//_Combined/Subject_One_Night/Annot_Proba_Transition2_feature_statistics_bin.csv'"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# study1_feature_statistics_df.to_csv(f\"{root_directory}{data_directory}/{data_subdirectory}/Annot_Proba_Transition2_feature_statistics_bin.csv\", index=False) \n",
    "f\"{root_directory}{data_directory}/{data_subdirectory}/Annot_Proba_Transition2_feature_statistics_bin.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "direct-luxury",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>Sum</th>\n",
       "      <th>Mean</th>\n",
       "      <th>STD</th>\n",
       "      <th>P-value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>W-&gt;W</td>\n",
       "      <td>192.343048</td>\n",
       "      <td>0.925</td>\n",
       "      <td>0.095</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>W-&gt;S1</td>\n",
       "      <td>12.936016</td>\n",
       "      <td>0.062</td>\n",
       "      <td>0.080</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>W-&gt;S2</td>\n",
       "      <td>2.315395</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>W-&gt;S3</td>\n",
       "      <td>0.095430</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.866454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>W-&gt;S4</td>\n",
       "      <td>0.008065</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.892983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>W-&gt;REM</td>\n",
       "      <td>0.302046</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.063842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>S1-&gt;W</td>\n",
       "      <td>12.773324</td>\n",
       "      <td>0.061</td>\n",
       "      <td>0.050</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>S1-&gt;S1</td>\n",
       "      <td>151.035246</td>\n",
       "      <td>0.726</td>\n",
       "      <td>0.137</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>S1-&gt;S2</td>\n",
       "      <td>40.671520</td>\n",
       "      <td>0.196</td>\n",
       "      <td>0.110</td>\n",
       "      <td>0.005437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>S1-&gt;S3</td>\n",
       "      <td>0.149284</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.791454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>S1-&gt;S4</td>\n",
       "      <td>0.023810</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.892983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>S1-&gt;REM</td>\n",
       "      <td>3.346817</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.026</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>S2-&gt;W</td>\n",
       "      <td>2.380687</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.000052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>S2-&gt;S1</td>\n",
       "      <td>2.968244</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.018</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>S2-&gt;S2</td>\n",
       "      <td>194.407953</td>\n",
       "      <td>0.935</td>\n",
       "      <td>0.047</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>S2-&gt;S3</td>\n",
       "      <td>6.174997</td>\n",
       "      <td>0.030</td>\n",
       "      <td>0.032</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>S2-&gt;S4</td>\n",
       "      <td>0.059653</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.256696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>S2-&gt;REM</td>\n",
       "      <td>2.008467</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.000004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>S3-&gt;W</td>\n",
       "      <td>1.520770</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.181918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>S3-&gt;S1</td>\n",
       "      <td>0.774745</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.082333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>S3-&gt;S2</td>\n",
       "      <td>40.421263</td>\n",
       "      <td>0.194</td>\n",
       "      <td>0.261</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>S3-&gt;S3</td>\n",
       "      <td>144.023127</td>\n",
       "      <td>0.692</td>\n",
       "      <td>0.307</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>S3-&gt;S4</td>\n",
       "      <td>12.112397</td>\n",
       "      <td>0.058</td>\n",
       "      <td>0.082</td>\n",
       "      <td>0.474259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>S3-&gt;REM</td>\n",
       "      <td>0.147698</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.659426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>S4-&gt;W</td>\n",
       "      <td>0.852400</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.001082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>S4-&gt;S1</td>\n",
       "      <td>0.401657</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.924236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>S4-&gt;S2</td>\n",
       "      <td>1.745950</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.019</td>\n",
       "      <td>0.001920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>S4-&gt;S3</td>\n",
       "      <td>22.581159</td>\n",
       "      <td>0.109</td>\n",
       "      <td>0.225</td>\n",
       "      <td>0.297664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>S4-&gt;S4</td>\n",
       "      <td>133.350372</td>\n",
       "      <td>0.641</td>\n",
       "      <td>0.421</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>S4-&gt;REM</td>\n",
       "      <td>0.068463</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.769204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>REM-&gt;W</td>\n",
       "      <td>3.062163</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.018</td>\n",
       "      <td>0.014968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>REM-&gt;S1</td>\n",
       "      <td>3.180310</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.022</td>\n",
       "      <td>0.000005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>REM-&gt;S2</td>\n",
       "      <td>3.258263</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.142985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>REM-&gt;S3</td>\n",
       "      <td>0.013770</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.787882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>REM-&gt;S4</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>REM-&gt;REM</td>\n",
       "      <td>198.485493</td>\n",
       "      <td>0.954</td>\n",
       "      <td>0.034</td>\n",
       "      <td>0.000015</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Feature         Sum   Mean    STD   P-value\n",
       "0       W->W  192.343048  0.925  0.095  0.000000\n",
       "1      W->S1   12.936016  0.062  0.080  0.000000\n",
       "2      W->S2    2.315395  0.011  0.025  0.000000\n",
       "3      W->S3    0.095430  0.000  0.003  0.866454\n",
       "4      W->S4    0.008065  0.000  0.001  0.892983\n",
       "5     W->REM    0.302046  0.001  0.007  0.063842\n",
       "6      S1->W   12.773324  0.061  0.050  0.000000\n",
       "7     S1->S1  151.035246  0.726  0.137  0.000000\n",
       "8     S1->S2   40.671520  0.196  0.110  0.005437\n",
       "9     S1->S3    0.149284  0.001  0.006  0.791454\n",
       "10    S1->S4    0.023810  0.000  0.002  0.892983\n",
       "11   S1->REM    3.346817  0.016  0.026  0.000000\n",
       "12     S2->W    2.380687  0.011  0.009  0.000052\n",
       "13    S2->S1    2.968244  0.014  0.018  0.000000\n",
       "14    S2->S2  194.407953  0.935  0.047  0.000000\n",
       "15    S2->S3    6.174997  0.030  0.032  0.000000\n",
       "16    S2->S4    0.059653  0.000  0.001  0.256696\n",
       "17   S2->REM    2.008467  0.010  0.006  0.000004\n",
       "18     S3->W    1.520770  0.007  0.020  0.181918\n",
       "19    S3->S1    0.774745  0.004  0.016  0.082333\n",
       "20    S3->S2   40.421263  0.194  0.261  0.000000\n",
       "21    S3->S3  144.023127  0.692  0.307  0.000000\n",
       "22    S3->S4   12.112397  0.058  0.082  0.474259\n",
       "23   S3->REM    0.147698  0.001  0.003  0.659426\n",
       "24     S4->W    0.852400  0.004  0.010  0.001082\n",
       "25    S4->S1    0.401657  0.002  0.011  0.924236\n",
       "26    S4->S2    1.745950  0.008  0.019  0.001920\n",
       "27    S4->S3   22.581159  0.109  0.225  0.297664\n",
       "28    S4->S4  133.350372  0.641  0.421  0.000000\n",
       "29   S4->REM    0.068463  0.000  0.003  0.769204\n",
       "30    REM->W    3.062163  0.015  0.018  0.014968\n",
       "31   REM->S1    3.180310  0.015  0.022  0.000005\n",
       "32   REM->S2    3.258263  0.016  0.017  0.142985\n",
       "33   REM->S3    0.013770  0.000  0.001  0.787882\n",
       "34   REM->S4    0.000000  0.000  0.000  1.000000\n",
       "35  REM->REM  198.485493  0.954  0.034  0.000015"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "study1_feature_statistics_df = pd.read_csv(f\"{root_directory}{data_directory}/{data_subdirectory}/Annot_Proba_Transition2_feature_statistics_bin.csv\", index_col=False)\n",
    "study1_feature_statistics_df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "based-england",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset</th>\n",
       "      <th>Category</th>\n",
       "      <th>Subject_Name</th>\n",
       "      <th>Class</th>\n",
       "      <th>W-&gt;W</th>\n",
       "      <th>W-&gt;S1</th>\n",
       "      <th>W-&gt;S2</th>\n",
       "      <th>W-&gt;S3</th>\n",
       "      <th>W-&gt;S4</th>\n",
       "      <th>W-&gt;REM</th>\n",
       "      <th>...</th>\n",
       "      <th>S4-&gt;S2</th>\n",
       "      <th>S4-&gt;S3</th>\n",
       "      <th>S4-&gt;S4</th>\n",
       "      <th>S4-&gt;REM</th>\n",
       "      <th>REM-&gt;W</th>\n",
       "      <th>REM-&gt;S1</th>\n",
       "      <th>REM-&gt;S2</th>\n",
       "      <th>REM-&gt;S3</th>\n",
       "      <th>REM-&gt;S4</th>\n",
       "      <th>REM-&gt;REM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CAP_Sleep</td>\n",
       "      <td>brux</td>\n",
       "      <td>brux1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.190476</td>\n",
       "      <td>0.009524</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004926</td>\n",
       "      <td>0.024631</td>\n",
       "      <td>0.970443</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.033520</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.966480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CAP_Sleep</td>\n",
       "      <td>brux</td>\n",
       "      <td>brux2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.825397</td>\n",
       "      <td>0.174603</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.012048</td>\n",
       "      <td>0.984940</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.019324</td>\n",
       "      <td>0.004831</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.975845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CAP_Sleep</td>\n",
       "      <td>sdb</td>\n",
       "      <td>sdb1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.876712</td>\n",
       "      <td>0.123288</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005076</td>\n",
       "      <td>0.030457</td>\n",
       "      <td>0.949239</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.009346</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.028037</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.962617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CAP_Sleep</td>\n",
       "      <td>sdb</td>\n",
       "      <td>sdb2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.948718</td>\n",
       "      <td>0.044872</td>\n",
       "      <td>0.006410</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.016949</td>\n",
       "      <td>0.966102</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.025641</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.974359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CAP_Sleep</td>\n",
       "      <td>sdb</td>\n",
       "      <td>sdb3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.934272</td>\n",
       "      <td>0.046948</td>\n",
       "      <td>0.018779</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.025974</td>\n",
       "      <td>0.038961</td>\n",
       "      <td>0.935065</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.937500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>Sleep_EDFX</td>\n",
       "      <td>n</td>\n",
       "      <td>ST7191</td>\n",
       "      <td>0</td>\n",
       "      <td>0.742857</td>\n",
       "      <td>0.242857</td>\n",
       "      <td>0.014286</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.013889</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.805556</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>0.015000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.965000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>Sleep_EDFX</td>\n",
       "      <td>n</td>\n",
       "      <td>ST7201</td>\n",
       "      <td>0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>...</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>0.346154</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.044776</td>\n",
       "      <td>0.007463</td>\n",
       "      <td>0.014925</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.932836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>Sleep_EDFX</td>\n",
       "      <td>n</td>\n",
       "      <td>ST7211</td>\n",
       "      <td>0</td>\n",
       "      <td>0.894737</td>\n",
       "      <td>0.099415</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.005848</td>\n",
       "      <td>...</td>\n",
       "      <td>0.016949</td>\n",
       "      <td>0.254237</td>\n",
       "      <td>0.728814</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.025641</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.019231</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.955128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>Sleep_EDFX</td>\n",
       "      <td>n</td>\n",
       "      <td>ST7221</td>\n",
       "      <td>0</td>\n",
       "      <td>0.820000</td>\n",
       "      <td>0.180000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.021645</td>\n",
       "      <td>0.043290</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.935065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>Sleep_EDFX</td>\n",
       "      <td>n</td>\n",
       "      <td>ST7241</td>\n",
       "      <td>0</td>\n",
       "      <td>0.620690</td>\n",
       "      <td>0.275862</td>\n",
       "      <td>0.034483</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.068966</td>\n",
       "      <td>...</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.016878</td>\n",
       "      <td>0.016878</td>\n",
       "      <td>0.008439</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.957806</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>208 rows × 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Dataset Category Subject_Name  Class      W->W     W->S1     W->S2  \\\n",
       "0     CAP_Sleep     brux        brux1      1  0.800000  0.190476  0.009524   \n",
       "1     CAP_Sleep     brux        brux2      1  0.825397  0.174603  0.000000   \n",
       "2     CAP_Sleep      sdb         sdb1      1  0.876712  0.123288  0.000000   \n",
       "3     CAP_Sleep      sdb         sdb2      1  0.948718  0.044872  0.006410   \n",
       "4     CAP_Sleep      sdb         sdb3      1  0.934272  0.046948  0.018779   \n",
       "..          ...      ...          ...    ...       ...       ...       ...   \n",
       "203  Sleep_EDFX        n       ST7191      0  0.742857  0.242857  0.014286   \n",
       "204  Sleep_EDFX        n       ST7201      0  0.333333  0.555556  0.055556   \n",
       "205  Sleep_EDFX        n       ST7211      0  0.894737  0.099415  0.000000   \n",
       "206  Sleep_EDFX        n       ST7221      0  0.820000  0.180000  0.000000   \n",
       "207  Sleep_EDFX        n       ST7241      0  0.620690  0.275862  0.034483   \n",
       "\n",
       "     W->S3  W->S4    W->REM  ...    S4->S2    S4->S3    S4->S4  S4->REM  \\\n",
       "0      0.0    0.0  0.000000  ...  0.004926  0.024631  0.970443      0.0   \n",
       "1      0.0    0.0  0.000000  ...  0.000000  0.012048  0.984940      0.0   \n",
       "2      0.0    0.0  0.000000  ...  0.005076  0.030457  0.949239      0.0   \n",
       "3      0.0    0.0  0.000000  ...  0.008475  0.016949  0.966102      0.0   \n",
       "4      0.0    0.0  0.000000  ...  0.025974  0.038961  0.935065      0.0   \n",
       "..     ...    ...       ...  ...       ...       ...       ...      ...   \n",
       "203    0.0    0.0  0.000000  ...  0.013889  0.166667  0.805556      0.0   \n",
       "204    0.0    0.0  0.055556  ...  0.038462  0.615385  0.346154      0.0   \n",
       "205    0.0    0.0  0.005848  ...  0.016949  0.254237  0.728814      0.0   \n",
       "206    0.0    0.0  0.000000  ...  0.000000  0.000000  0.000000      0.0   \n",
       "207    0.0    0.0  0.068966  ...  0.142857  0.571429  0.142857      0.0   \n",
       "\n",
       "       REM->W   REM->S1   REM->S2  REM->S3  REM->S4  REM->REM  \n",
       "0    0.033520  0.000000  0.000000      0.0      0.0  0.966480  \n",
       "1    0.019324  0.004831  0.000000      0.0      0.0  0.975845  \n",
       "2    0.009346  0.000000  0.028037      0.0      0.0  0.962617  \n",
       "3    0.000000  0.000000  0.025641      0.0      0.0  0.974359  \n",
       "4    0.062500  0.000000  0.000000      0.0      0.0  0.937500  \n",
       "..        ...       ...       ...      ...      ...       ...  \n",
       "203  0.000000  0.020000  0.015000      0.0      0.0  0.965000  \n",
       "204  0.044776  0.007463  0.014925      0.0      0.0  0.932836  \n",
       "205  0.025641  0.000000  0.019231      0.0      0.0  0.955128  \n",
       "206  0.021645  0.043290  0.000000      0.0      0.0  0.935065  \n",
       "207  0.016878  0.016878  0.008439      0.0      0.0  0.957806  \n",
       "\n",
       "[208 rows x 40 columns]"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "enhanced-documentary",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features_with_zero_values(tmp_df):\n",
    "    feat_names = tmp_df.columns.values[4:] \n",
    "    feat_names\n",
    "    zero_feats = [] \n",
    "    for f in feat_names:\n",
    "        if tmp_df[f].values.sum() == 0:\n",
    "            zero_feats.append(f)\n",
    "    return zero_feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "verbal-electron",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['REM->S4']"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zero_feats = get_features_with_zero_values(dataset)\n",
    "zero_feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hollow-oakland",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "varying-reggae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "pharmaceutical-study",
   "metadata": {},
   "source": [
    "# Classification "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "supreme-jacksonville",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from HumachLab_ML_CLassifiers import * \n",
    "# import HumachLab_ML_CLassifiers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "herbal-cloud",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_experiment_directory(path, exp_name): \n",
    "    exp_directory = f\"{path}/{exp_name}/\"\n",
    "\n",
    "    if (not os.path.exists(exp_directory)):\n",
    "        try:\n",
    "            os.makedirs(exp_directory, exist_ok = True)\n",
    "            print(f\"Directory successfully created at path: {exp_directory}\") \n",
    "        except OSError as error:\n",
    "            print(f\"Directory cannot be created at path: {exp_directory}\") \n",
    "    else:\n",
    "        print(f\"Directory already exists at path: {exp_directory}\") \n",
    "\n",
    "    return exp_directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "resistant-affiliation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ML_Classifiers.SVC: 'support_vector_classifier'>"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ML_Classifiers.SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "civic-electron",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset</th>\n",
       "      <th>Category</th>\n",
       "      <th>Subject_Name</th>\n",
       "      <th>Class</th>\n",
       "      <th>W-&gt;W</th>\n",
       "      <th>W-&gt;S1</th>\n",
       "      <th>W-&gt;S2</th>\n",
       "      <th>W-&gt;S3</th>\n",
       "      <th>W-&gt;S4</th>\n",
       "      <th>W-&gt;REM</th>\n",
       "      <th>...</th>\n",
       "      <th>S4-&gt;S2</th>\n",
       "      <th>S4-&gt;S3</th>\n",
       "      <th>S4-&gt;S4</th>\n",
       "      <th>S4-&gt;REM</th>\n",
       "      <th>REM-&gt;W</th>\n",
       "      <th>REM-&gt;S1</th>\n",
       "      <th>REM-&gt;S2</th>\n",
       "      <th>REM-&gt;S3</th>\n",
       "      <th>REM-&gt;S4</th>\n",
       "      <th>REM-&gt;REM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CAP_Sleep</td>\n",
       "      <td>brux</td>\n",
       "      <td>brux1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.190476</td>\n",
       "      <td>0.009524</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004926</td>\n",
       "      <td>0.024631</td>\n",
       "      <td>0.970443</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.033520</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.966480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CAP_Sleep</td>\n",
       "      <td>brux</td>\n",
       "      <td>brux2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.825397</td>\n",
       "      <td>0.174603</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.012048</td>\n",
       "      <td>0.984940</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.019324</td>\n",
       "      <td>0.004831</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.975845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CAP_Sleep</td>\n",
       "      <td>sdb</td>\n",
       "      <td>sdb1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.876712</td>\n",
       "      <td>0.123288</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005076</td>\n",
       "      <td>0.030457</td>\n",
       "      <td>0.949239</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.009346</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.028037</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.962617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CAP_Sleep</td>\n",
       "      <td>sdb</td>\n",
       "      <td>sdb2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.948718</td>\n",
       "      <td>0.044872</td>\n",
       "      <td>0.006410</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.016949</td>\n",
       "      <td>0.966102</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.025641</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.974359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CAP_Sleep</td>\n",
       "      <td>sdb</td>\n",
       "      <td>sdb3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.934272</td>\n",
       "      <td>0.046948</td>\n",
       "      <td>0.018779</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.025974</td>\n",
       "      <td>0.038961</td>\n",
       "      <td>0.935065</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.937500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>Sleep_EDFX</td>\n",
       "      <td>n</td>\n",
       "      <td>ST7191</td>\n",
       "      <td>0</td>\n",
       "      <td>0.742857</td>\n",
       "      <td>0.242857</td>\n",
       "      <td>0.014286</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.013889</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.805556</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>0.015000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.965000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>Sleep_EDFX</td>\n",
       "      <td>n</td>\n",
       "      <td>ST7201</td>\n",
       "      <td>0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>...</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>0.346154</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.044776</td>\n",
       "      <td>0.007463</td>\n",
       "      <td>0.014925</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.932836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>Sleep_EDFX</td>\n",
       "      <td>n</td>\n",
       "      <td>ST7211</td>\n",
       "      <td>0</td>\n",
       "      <td>0.894737</td>\n",
       "      <td>0.099415</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.005848</td>\n",
       "      <td>...</td>\n",
       "      <td>0.016949</td>\n",
       "      <td>0.254237</td>\n",
       "      <td>0.728814</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.025641</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.019231</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.955128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>Sleep_EDFX</td>\n",
       "      <td>n</td>\n",
       "      <td>ST7221</td>\n",
       "      <td>0</td>\n",
       "      <td>0.820000</td>\n",
       "      <td>0.180000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.021645</td>\n",
       "      <td>0.043290</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.935065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>Sleep_EDFX</td>\n",
       "      <td>n</td>\n",
       "      <td>ST7241</td>\n",
       "      <td>0</td>\n",
       "      <td>0.620690</td>\n",
       "      <td>0.275862</td>\n",
       "      <td>0.034483</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.068966</td>\n",
       "      <td>...</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.016878</td>\n",
       "      <td>0.016878</td>\n",
       "      <td>0.008439</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.957806</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>208 rows × 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Dataset Category Subject_Name  Class      W->W     W->S1     W->S2  \\\n",
       "0     CAP_Sleep     brux        brux1      1  0.800000  0.190476  0.009524   \n",
       "1     CAP_Sleep     brux        brux2      1  0.825397  0.174603  0.000000   \n",
       "2     CAP_Sleep      sdb         sdb1      1  0.876712  0.123288  0.000000   \n",
       "3     CAP_Sleep      sdb         sdb2      1  0.948718  0.044872  0.006410   \n",
       "4     CAP_Sleep      sdb         sdb3      1  0.934272  0.046948  0.018779   \n",
       "..          ...      ...          ...    ...       ...       ...       ...   \n",
       "203  Sleep_EDFX        n       ST7191      0  0.742857  0.242857  0.014286   \n",
       "204  Sleep_EDFX        n       ST7201      0  0.333333  0.555556  0.055556   \n",
       "205  Sleep_EDFX        n       ST7211      0  0.894737  0.099415  0.000000   \n",
       "206  Sleep_EDFX        n       ST7221      0  0.820000  0.180000  0.000000   \n",
       "207  Sleep_EDFX        n       ST7241      0  0.620690  0.275862  0.034483   \n",
       "\n",
       "     W->S3  W->S4    W->REM  ...    S4->S2    S4->S3    S4->S4  S4->REM  \\\n",
       "0      0.0    0.0  0.000000  ...  0.004926  0.024631  0.970443      0.0   \n",
       "1      0.0    0.0  0.000000  ...  0.000000  0.012048  0.984940      0.0   \n",
       "2      0.0    0.0  0.000000  ...  0.005076  0.030457  0.949239      0.0   \n",
       "3      0.0    0.0  0.000000  ...  0.008475  0.016949  0.966102      0.0   \n",
       "4      0.0    0.0  0.000000  ...  0.025974  0.038961  0.935065      0.0   \n",
       "..     ...    ...       ...  ...       ...       ...       ...      ...   \n",
       "203    0.0    0.0  0.000000  ...  0.013889  0.166667  0.805556      0.0   \n",
       "204    0.0    0.0  0.055556  ...  0.038462  0.615385  0.346154      0.0   \n",
       "205    0.0    0.0  0.005848  ...  0.016949  0.254237  0.728814      0.0   \n",
       "206    0.0    0.0  0.000000  ...  0.000000  0.000000  0.000000      0.0   \n",
       "207    0.0    0.0  0.068966  ...  0.142857  0.571429  0.142857      0.0   \n",
       "\n",
       "       REM->W   REM->S1   REM->S2  REM->S3  REM->S4  REM->REM  \n",
       "0    0.033520  0.000000  0.000000      0.0      0.0  0.966480  \n",
       "1    0.019324  0.004831  0.000000      0.0      0.0  0.975845  \n",
       "2    0.009346  0.000000  0.028037      0.0      0.0  0.962617  \n",
       "3    0.000000  0.000000  0.025641      0.0      0.0  0.974359  \n",
       "4    0.062500  0.000000  0.000000      0.0      0.0  0.937500  \n",
       "..        ...       ...       ...      ...      ...       ...  \n",
       "203  0.000000  0.020000  0.015000      0.0      0.0  0.965000  \n",
       "204  0.044776  0.007463  0.014925      0.0      0.0  0.932836  \n",
       "205  0.025641  0.000000  0.019231      0.0      0.0  0.955128  \n",
       "206  0.021645  0.043290  0.000000      0.0      0.0  0.935065  \n",
       "207  0.016878  0.016878  0.008439      0.0      0.0  0.957806  \n",
       "\n",
       "[208 rows x 40 columns]"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "steady-quantity",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sys.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "australian-houston",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "applicable-stone",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('__main__',\n",
       " 'C:\\\\Users\\\\aliem\\\\Desktop\\\\aliem\\\\My Research\\\\HML_IHC_Sleep_Data_Analysis')"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "__name__, os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "flush-doctrine",
   "metadata": {},
   "outputs": [],
   "source": [
    "def start_logger(result_save_path, exp_name): \n",
    "    util = Humachlab_Utility() \n",
    "    all_log_file_name = f'{result_save_path}/all_logs_{exp_name}.txt'\n",
    "    # logger = util.get_logger(logger_name=__name__, log_file_name=all_log_file_name)\n",
    "    logger = util.get_logger(logger_name=\"Sleep ML Model Analysis\", log_file_name=all_log_file_name)\n",
    "    util, all_log_file_name, logger \n",
    "    return util, logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "popular-boxing",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stop_logger(logger): \n",
    "    handlers = logger.handlers[:]\n",
    "    for handler in handlers:\n",
    "        logger.removeHandler(handler)\n",
    "        handler.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "id": "lovely-ecology",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>exp_name</th>\n",
       "      <th>exp_description</th>\n",
       "      <th>datasets</th>\n",
       "      <th>feature_selection</th>\n",
       "      <th>special_consideration</th>\n",
       "      <th>classification_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ML001</td>\n",
       "      <td>Wake vs sleep binary classification using slee...</td>\n",
       "      <td>2 datasets- CAP_Sleep, Sleep_EDFX</td>\n",
       "      <td>No feature selection</td>\n",
       "      <td>No special consideration</td>\n",
       "      <td>Binary classification: wake vs sleep</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ML002</td>\n",
       "      <td>Wake vs sleep binary classification using slee...</td>\n",
       "      <td>2 datasets- CAP_Sleep, Sleep_EDFX</td>\n",
       "      <td>No feature selection</td>\n",
       "      <td>W-&gt;W stage transition removed</td>\n",
       "      <td>Binary classification: wake vs sleep</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ML003</td>\n",
       "      <td>Wake vs sleep binary classification using slee...</td>\n",
       "      <td>2 datasets- CAP_Sleep, Sleep_EDFX</td>\n",
       "      <td>AUC based selection with AUC&gt;0.7</td>\n",
       "      <td>No special consideration</td>\n",
       "      <td>Binary classification: wake vs sleep</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ML004</td>\n",
       "      <td>Wake vs sleep binary classification using slee...</td>\n",
       "      <td>2 datasets- CAP_Sleep, Sleep_EDFX</td>\n",
       "      <td>AUC based selection with AUC&gt;0.7</td>\n",
       "      <td>W-&gt;W stage transition removed</td>\n",
       "      <td>Binary classification: wake vs sleep</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ML005</td>\n",
       "      <td>Wake vs sleep binary classification using slee...</td>\n",
       "      <td>2 datasets- CAP_Sleep, Sleep_EDFX</td>\n",
       "      <td>No feature selection</td>\n",
       "      <td>No special consideration</td>\n",
       "      <td>Binary classification: wake vs sleep</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ML006</td>\n",
       "      <td>Wake vs sleep binary classification using slee...</td>\n",
       "      <td>2 datasets- CAP_Sleep, Sleep_EDFX</td>\n",
       "      <td>No feature selection</td>\n",
       "      <td>W-&gt;W stage transition removed</td>\n",
       "      <td>Binary classification: wake vs sleep</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ML007</td>\n",
       "      <td>Wake vs sleep binary classification using slee...</td>\n",
       "      <td>2 datasets- CAP_Sleep, Sleep_EDFX</td>\n",
       "      <td>AUC based &gt;0.7</td>\n",
       "      <td>No special consideration</td>\n",
       "      <td>Binary classification: wake vs sleep</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ML008</td>\n",
       "      <td>Wake vs sleep binary classification using slee...</td>\n",
       "      <td>2 datasets- CAP_Sleep, Sleep_EDFX</td>\n",
       "      <td>AUC based &gt;0.7</td>\n",
       "      <td>W-&gt;W stage transition removed</td>\n",
       "      <td>Binary classification: wake vs sleep</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ML009</td>\n",
       "      <td>Wake vs sleep binary classification using slee...</td>\n",
       "      <td>2 datasets- CAP_Sleep, Sleep_EDFX</td>\n",
       "      <td>No feature selection</td>\n",
       "      <td>nxx balanced over the folds</td>\n",
       "      <td>Binary classification: wake vs sleep</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ML010</td>\n",
       "      <td>Wake vs sleep binary classification using slee...</td>\n",
       "      <td>2 datasets- CAP_Sleep, Sleep_EDFX</td>\n",
       "      <td>No feature selection</td>\n",
       "      <td>nxx balanced over the folds | W-&gt;W stage trans...</td>\n",
       "      <td>Binary classification: wake vs sleep</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ML011</td>\n",
       "      <td>Wake vs sleep binary classification using slee...</td>\n",
       "      <td>2 datasets- CAP_Sleep, Sleep_EDFX</td>\n",
       "      <td>AUC based &gt;0.7</td>\n",
       "      <td>nxx balanced over the folds</td>\n",
       "      <td>Binary classification: wake vs sleep</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>ML012</td>\n",
       "      <td>Wake vs sleep binary classification using slee...</td>\n",
       "      <td>2 datasets- CAP_Sleep, Sleep_EDFX</td>\n",
       "      <td>AUC based &gt;0.7</td>\n",
       "      <td>W-&gt;W stage transition removed</td>\n",
       "      <td>Binary classification: wake vs sleep</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>ML021</td>\n",
       "      <td>Wake vs sleep binary classification using slee...</td>\n",
       "      <td>2 datasets- CAP_Sleep, Sleep_EDFX</td>\n",
       "      <td>No feature selection</td>\n",
       "      <td>W-&gt;W stage transition removed, nxx balanced ov...</td>\n",
       "      <td>Binary classification: Healthy vs disordered</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>ML022</td>\n",
       "      <td>Wake vs sleep binary classification using slee...</td>\n",
       "      <td>2 datasets- CAP_Sleep, Sleep_EDFX</td>\n",
       "      <td>AUC based &gt;0.7</td>\n",
       "      <td>W-&gt;W stage transition removed, nxx balanced ov...</td>\n",
       "      <td>Binary classification: Healthy vs disordered</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>ML023</td>\n",
       "      <td>Wake vs sleep binary classification using slee...</td>\n",
       "      <td>2 datasets- CAP_Sleep, Sleep_EDFX</td>\n",
       "      <td>No feature selection</td>\n",
       "      <td>W-&gt;W stage transition removed, imbalanced over...</td>\n",
       "      <td>Binary classification: Healthy vs disordered</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>ML024</td>\n",
       "      <td>Wake vs sleep binary classification using slee...</td>\n",
       "      <td>2 datasets- CAP_Sleep, Sleep_EDFX</td>\n",
       "      <td>AUC based &gt;0.7</td>\n",
       "      <td>W-&gt;W stage transition removed, imbalanced over...</td>\n",
       "      <td>Binary classification: Healthy vs disordered</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>ML027</td>\n",
       "      <td>Wake vs sleep binary classification using slee...</td>\n",
       "      <td>2 datasets- CAP_Sleep, Sleep_EDFX</td>\n",
       "      <td>No feature selection</td>\n",
       "      <td>No special consideration</td>\n",
       "      <td>Multi-class classification: Wake vs sleep</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>ML028</td>\n",
       "      <td>Wake vs all disorders multi-class classificati...</td>\n",
       "      <td>2 datasets- CAP_Sleep, Sleep_EDFX</td>\n",
       "      <td>No feature selection</td>\n",
       "      <td>No special consideration</td>\n",
       "      <td>Multi-class classification: Healthy vs 7 diffe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>ML029</td>\n",
       "      <td>Wake vs all disorders multi-class classificati...</td>\n",
       "      <td>2 datasets- CAP_Sleep, Sleep_EDFX</td>\n",
       "      <td>No feature selection</td>\n",
       "      <td>No special consideration</td>\n",
       "      <td>Multi-class classification: Healthy vs 7 diffe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>ML030</td>\n",
       "      <td>Wake vs all disorders multi-class classificati...</td>\n",
       "      <td>2 datasets- CAP_Sleep, Sleep_EDFX</td>\n",
       "      <td>No feature selection</td>\n",
       "      <td>No special consideration</td>\n",
       "      <td>Multi-class classification: Healthy vs 7 diffe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>ML031</td>\n",
       "      <td>Wake vs all disorders multi-class classificati...</td>\n",
       "      <td>2 datasets- CAP_Sleep, Sleep_EDFX</td>\n",
       "      <td>No feature selection</td>\n",
       "      <td>No special consideration</td>\n",
       "      <td>Multi-class classification: Healthy vs 7 diffe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>ML041</td>\n",
       "      <td>Wake vs all disorders multi-class classificati...</td>\n",
       "      <td>2 datasets- CAP_Sleep, Sleep_EDFX</td>\n",
       "      <td>No feature selection</td>\n",
       "      <td>No special consideration</td>\n",
       "      <td>Multi-class classification: Healthy vs 7 diffe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>ML1002</td>\n",
       "      <td>Wake vs all disorders multi-class classificati...</td>\n",
       "      <td>2 datasets- CAP_Sleep, Sleep_EDFX</td>\n",
       "      <td>AUC based training set only feature selection</td>\n",
       "      <td>Remove W-&gt;W and all zero transitions,</td>\n",
       "      <td>Multi-class classification: Binary classificat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>ML1003</td>\n",
       "      <td>Wake vs all disorders multi-class classificati...</td>\n",
       "      <td>2 datasets- CAP_Sleep, Sleep_EDFX</td>\n",
       "      <td>No feature selection</td>\n",
       "      <td>Remove W-&gt;W and all zero transitions, nxx bala...</td>\n",
       "      <td>Multi-class classification: Binary classificat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>ML1004</td>\n",
       "      <td>Wake vs all disorders multi-class classificati...</td>\n",
       "      <td>2 datasets- CAP_Sleep, Sleep_EDFX</td>\n",
       "      <td>AUC based training set only feature selection</td>\n",
       "      <td>Remove W-&gt;W and all zero transitions, nxx bala...</td>\n",
       "      <td>Multi-class classification: Binary classificat...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   exp_name                                    exp_description  \\\n",
       "0     ML001  Wake vs sleep binary classification using slee...   \n",
       "1     ML002  Wake vs sleep binary classification using slee...   \n",
       "2     ML003  Wake vs sleep binary classification using slee...   \n",
       "3     ML004  Wake vs sleep binary classification using slee...   \n",
       "4     ML005  Wake vs sleep binary classification using slee...   \n",
       "5     ML006  Wake vs sleep binary classification using slee...   \n",
       "6     ML007  Wake vs sleep binary classification using slee...   \n",
       "7     ML008  Wake vs sleep binary classification using slee...   \n",
       "8     ML009  Wake vs sleep binary classification using slee...   \n",
       "9     ML010  Wake vs sleep binary classification using slee...   \n",
       "10    ML011  Wake vs sleep binary classification using slee...   \n",
       "11    ML012  Wake vs sleep binary classification using slee...   \n",
       "12    ML021  Wake vs sleep binary classification using slee...   \n",
       "13    ML022  Wake vs sleep binary classification using slee...   \n",
       "14    ML023  Wake vs sleep binary classification using slee...   \n",
       "15    ML024  Wake vs sleep binary classification using slee...   \n",
       "16    ML027  Wake vs sleep binary classification using slee...   \n",
       "17    ML028  Wake vs all disorders multi-class classificati...   \n",
       "18    ML029  Wake vs all disorders multi-class classificati...   \n",
       "19    ML030  Wake vs all disorders multi-class classificati...   \n",
       "20    ML031  Wake vs all disorders multi-class classificati...   \n",
       "21    ML041  Wake vs all disorders multi-class classificati...   \n",
       "22   ML1002  Wake vs all disorders multi-class classificati...   \n",
       "23   ML1003  Wake vs all disorders multi-class classificati...   \n",
       "24   ML1004  Wake vs all disorders multi-class classificati...   \n",
       "\n",
       "                             datasets  \\\n",
       "0   2 datasets- CAP_Sleep, Sleep_EDFX   \n",
       "1   2 datasets- CAP_Sleep, Sleep_EDFX   \n",
       "2   2 datasets- CAP_Sleep, Sleep_EDFX   \n",
       "3   2 datasets- CAP_Sleep, Sleep_EDFX   \n",
       "4   2 datasets- CAP_Sleep, Sleep_EDFX   \n",
       "5   2 datasets- CAP_Sleep, Sleep_EDFX   \n",
       "6   2 datasets- CAP_Sleep, Sleep_EDFX   \n",
       "7   2 datasets- CAP_Sleep, Sleep_EDFX   \n",
       "8   2 datasets- CAP_Sleep, Sleep_EDFX   \n",
       "9   2 datasets- CAP_Sleep, Sleep_EDFX   \n",
       "10  2 datasets- CAP_Sleep, Sleep_EDFX   \n",
       "11  2 datasets- CAP_Sleep, Sleep_EDFX   \n",
       "12  2 datasets- CAP_Sleep, Sleep_EDFX   \n",
       "13  2 datasets- CAP_Sleep, Sleep_EDFX   \n",
       "14  2 datasets- CAP_Sleep, Sleep_EDFX   \n",
       "15  2 datasets- CAP_Sleep, Sleep_EDFX   \n",
       "16  2 datasets- CAP_Sleep, Sleep_EDFX   \n",
       "17  2 datasets- CAP_Sleep, Sleep_EDFX   \n",
       "18  2 datasets- CAP_Sleep, Sleep_EDFX   \n",
       "19  2 datasets- CAP_Sleep, Sleep_EDFX   \n",
       "20  2 datasets- CAP_Sleep, Sleep_EDFX   \n",
       "21  2 datasets- CAP_Sleep, Sleep_EDFX   \n",
       "22  2 datasets- CAP_Sleep, Sleep_EDFX   \n",
       "23  2 datasets- CAP_Sleep, Sleep_EDFX   \n",
       "24  2 datasets- CAP_Sleep, Sleep_EDFX   \n",
       "\n",
       "                                feature_selection  \\\n",
       "0                            No feature selection   \n",
       "1                            No feature selection   \n",
       "2                AUC based selection with AUC>0.7   \n",
       "3                AUC based selection with AUC>0.7   \n",
       "4                            No feature selection   \n",
       "5                            No feature selection   \n",
       "6                                  AUC based >0.7   \n",
       "7                                  AUC based >0.7   \n",
       "8                            No feature selection   \n",
       "9                            No feature selection   \n",
       "10                                 AUC based >0.7   \n",
       "11                                 AUC based >0.7   \n",
       "12                           No feature selection   \n",
       "13                                 AUC based >0.7   \n",
       "14                           No feature selection   \n",
       "15                                 AUC based >0.7   \n",
       "16                           No feature selection   \n",
       "17                           No feature selection   \n",
       "18                           No feature selection   \n",
       "19                           No feature selection   \n",
       "20                           No feature selection   \n",
       "21                           No feature selection   \n",
       "22  AUC based training set only feature selection   \n",
       "23                           No feature selection   \n",
       "24  AUC based training set only feature selection   \n",
       "\n",
       "                                special_consideration  \\\n",
       "0                            No special consideration   \n",
       "1                       W->W stage transition removed   \n",
       "2                            No special consideration   \n",
       "3                       W->W stage transition removed   \n",
       "4                            No special consideration   \n",
       "5                       W->W stage transition removed   \n",
       "6                            No special consideration   \n",
       "7                       W->W stage transition removed   \n",
       "8                         nxx balanced over the folds   \n",
       "9   nxx balanced over the folds | W->W stage trans...   \n",
       "10                        nxx balanced over the folds   \n",
       "11                      W->W stage transition removed   \n",
       "12  W->W stage transition removed, nxx balanced ov...   \n",
       "13  W->W stage transition removed, nxx balanced ov...   \n",
       "14  W->W stage transition removed, imbalanced over...   \n",
       "15  W->W stage transition removed, imbalanced over...   \n",
       "16                           No special consideration   \n",
       "17                           No special consideration   \n",
       "18                           No special consideration   \n",
       "19                           No special consideration   \n",
       "20                           No special consideration   \n",
       "21                           No special consideration   \n",
       "22             Remove W->W and all zero transitions,    \n",
       "23  Remove W->W and all zero transitions, nxx bala...   \n",
       "24  Remove W->W and all zero transitions, nxx bala...   \n",
       "\n",
       "                                  classification_type  \n",
       "0                Binary classification: wake vs sleep  \n",
       "1                Binary classification: wake vs sleep  \n",
       "2                Binary classification: wake vs sleep  \n",
       "3                Binary classification: wake vs sleep  \n",
       "4                Binary classification: wake vs sleep  \n",
       "5                Binary classification: wake vs sleep  \n",
       "6                Binary classification: wake vs sleep  \n",
       "7                Binary classification: wake vs sleep  \n",
       "8                Binary classification: wake vs sleep  \n",
       "9                Binary classification: wake vs sleep  \n",
       "10               Binary classification: wake vs sleep  \n",
       "11               Binary classification: wake vs sleep  \n",
       "12       Binary classification: Healthy vs disordered  \n",
       "13       Binary classification: Healthy vs disordered  \n",
       "14       Binary classification: Healthy vs disordered  \n",
       "15       Binary classification: Healthy vs disordered  \n",
       "16          Multi-class classification: Wake vs sleep  \n",
       "17  Multi-class classification: Healthy vs 7 diffe...  \n",
       "18  Multi-class classification: Healthy vs 7 diffe...  \n",
       "19  Multi-class classification: Healthy vs 7 diffe...  \n",
       "20  Multi-class classification: Healthy vs 7 diffe...  \n",
       "21  Multi-class classification: Healthy vs 7 diffe...  \n",
       "22  Multi-class classification: Binary classificat...  \n",
       "23  Multi-class classification: Binary classificat...  \n",
       "24  Multi-class classification: Binary classificat...  "
      ]
     },
     "execution_count": 389,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def modify_experiment_information_summarry(exp_dir, dict_dat=None):\n",
    "    exp_sum_dir = f'{exp_dir}/Experiment_Information.csv'\n",
    "    df = pd.DataFrame(columns=['exp_name', 'exp_description', 'datasets', 'feature_selection', 'special_consideration', 'classification_type'])\n",
    "    if (os.path.exists(exp_sum_dir)):\n",
    "        df = pd.read_csv(exp_sum_dir, index_col=False) \n",
    "    if dict_dat:\n",
    "        if df.shape[0]>0:\n",
    "            print(dict_dat['exp_name'], (df['exp_name'].values.tolist()))\n",
    "            if dict_dat['exp_name'] in (df['exp_name'].values.tolist()):\n",
    "                # nn = 1 \n",
    "                # print(f'Cannot add this data. this experiment is already exited. Please recheck and do a new experiment')\n",
    "                # assert nn < 0, f'Cannot add this data. this experiment is already exited. Please recheck and do a new experiment' \n",
    "                print(f'This experiment is already exited. So this data is removed...')\n",
    "                df = df.loc[df[\"exp_name\"] != dict_dat['exp_name']] \n",
    "                df.reset_index(drop=True, inplace=True) \n",
    "                \n",
    "        df.loc[len(df)] = dict_dat\n",
    "        df.sort_values(by=['exp_name'], ascending=[True], inplace=True)\n",
    "        df.reset_index(drop=True, inplace=True) \n",
    "        df.to_csv(exp_sum_dir, index=False) \n",
    "        print(f'Data is successfully inserted...')\n",
    "    return df\n",
    "\n",
    "exp_sum_df = modify_experiment_information_summarry(result_directory) \n",
    "exp_sum_df \n",
    "\n",
    "# exp_sum_df = modify_experiment_information_summarry(result_directory, dict_dat=exp_detail) \n",
    "# exp_sum_df \n",
    "\n",
    "# exp_sum_df = modify_experiment_information_summarry(result_directory) \n",
    "# exp_sum_df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "former-prior",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.read_csv?\n",
    "# exp_detail\n",
    "# exp_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "id": "capable-opera",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory successfully created at path: ./Results/_Classification/ML1001/\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'./Results/_Classification/ML1001/'"
      ]
     },
     "execution_count": 390,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp_name = 'ML1001' \n",
    "exp_detail = {'exp_name':exp_name, 'exp_description':'Wake vs all disorders multi-class classification using sleep transition matrix', 'datasets':'2 datasets- CAP_Sleep, Sleep_EDFX', \n",
    "              'feature_selection':'No feature selection', 'special_consideration':'Remove W->W and all zero transitions, ', \n",
    "              'classification_type':'Binary classification: Healthy vs disordered'}\n",
    "\n",
    "# exp_detail = {'exp_name':exp_name, 'exp_description':'Wake vs all disorders multi-class classification using sleep transition matrix', 'datasets':'2 datasets- CAP_Sleep, Sleep_EDFX', \n",
    "#               'feature_selection':'No feature selection', 'special_consideration':'No special consideration', \n",
    "#               'classification_type':'Multi-class classification: Healthy vs 7 different disordered'}\n",
    "# exp_detail = {'exp_name':exp_name, 'exp_description':'Wake vs sleep binary classification using sleep transition matrix', 'datasets':'2 datasets- CAP_Sleep, Sleep_EDFX', \n",
    "#               'feature_selection':'AAUC based training set only feature selection with AUC>=0.7', 'special_consideration':'W->W stage transition removed, imbalanced over the folds', \n",
    "#               'classification_type':'Binary classification: Healthy vs disordered'} \n",
    "# exp_detail = {'exp_name':exp_name, 'exp_description':'Wake vs sleep binary classification using sleep transition matrix', 'datasets':'2 datasets- CAP_Sleep, Sleep_EDFX', \n",
    "#               'feature_selection':'No feature selection', 'special_consideration':'No special consideration, nxx balanced over the folds', 'classification_type':'Binary classification: Healthy vs disordered'} \n",
    "# exp_detail = {'exp_name':exp_name, 'exp_description':'Wake vs sleep binary classification using sleep transition matrix', 'datasets':'2 datasets- CAP_Sleep, Sleep_EDFX', \n",
    "#               'feature_selection':'AUC based >0.7', 'special_consideration':'W->W stage transition removed, nxx balanced over the folds', 'classification_type':'Binary classification: Healthy vs disordered'} \n",
    "result_save_path = create_experiment_directory(result_directory, exp_name)\n",
    "result_save_path "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "id": "instrumental-paris",
   "metadata": {},
   "outputs": [],
   "source": [
    "# logger.info(\"Hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "id": "purple-organization",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Class',\n",
       " ['Dataset', 'Category', 'Subject_Name'],\n",
       " 'Subject_Name',\n",
       " ['Dataset', 'Category', 'Subject_Name', 'Class'],\n",
       " './Results/_Classification/ML1001/')"
      ]
     },
     "execution_count": 391,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_state_value = 312\n",
    "class_name = \"Class\" \n",
    "metadata_column = [\"Dataset\", \"Category\", \"Subject_Name\"] \n",
    "all_metadata_columns = metadata_column+[class_name]\n",
    "# ### #Binary/Multi-class healthy vs disorders \n",
    "split_column = \"Subject_Name\"  #\"Subject_Name\" for binary or multi-class \n",
    "split_balance_pattern = [['n'], ['SC', 'ST']] # [['n'], ['SC', 'ST'], ['brux'], ['sdb'], ['ins'], ['narco'], ['nfle'], ['plm'], ['rbd']] #[['n'], ['SC', 'ST']]  for binary, [['n'], ['SC', 'ST'], ['brux'], ['sdb'], ['ins'], ['narco'], ['nfle'], ['plm'], ['rbd']] for multi-class \n",
    "# ### #Binary/Multi-class age-group detection  \n",
    "# split_column = class_name\n",
    "# split_balance_pattern = [[1]]\n",
    "class_name, metadata_column, split_column, all_metadata_columns, result_save_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "id": "existing-universe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset</th>\n",
       "      <th>Category</th>\n",
       "      <th>Subject_Name</th>\n",
       "      <th>Class</th>\n",
       "      <th>W-&gt;S1</th>\n",
       "      <th>W-&gt;S2</th>\n",
       "      <th>W-&gt;S3</th>\n",
       "      <th>W-&gt;S4</th>\n",
       "      <th>W-&gt;REM</th>\n",
       "      <th>S1-&gt;W</th>\n",
       "      <th>...</th>\n",
       "      <th>S4-&gt;S1</th>\n",
       "      <th>S4-&gt;S2</th>\n",
       "      <th>S4-&gt;S3</th>\n",
       "      <th>S4-&gt;S4</th>\n",
       "      <th>S4-&gt;REM</th>\n",
       "      <th>REM-&gt;W</th>\n",
       "      <th>REM-&gt;S1</th>\n",
       "      <th>REM-&gt;S2</th>\n",
       "      <th>REM-&gt;S3</th>\n",
       "      <th>REM-&gt;REM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CAP_Sleep</td>\n",
       "      <td>brux</td>\n",
       "      <td>brux1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.190476</td>\n",
       "      <td>0.009524</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.030769</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004926</td>\n",
       "      <td>0.024631</td>\n",
       "      <td>0.970443</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.033520</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.966480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CAP_Sleep</td>\n",
       "      <td>brux</td>\n",
       "      <td>brux2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.174603</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.061728</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.012048</td>\n",
       "      <td>0.984940</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.019324</td>\n",
       "      <td>0.004831</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.975845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CAP_Sleep</td>\n",
       "      <td>sdb</td>\n",
       "      <td>sdb1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.123288</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.099237</td>\n",
       "      <td>...</td>\n",
       "      <td>0.010152</td>\n",
       "      <td>0.005076</td>\n",
       "      <td>0.030457</td>\n",
       "      <td>0.949239</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.009346</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.028037</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.962617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CAP_Sleep</td>\n",
       "      <td>sdb</td>\n",
       "      <td>sdb2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.044872</td>\n",
       "      <td>0.006410</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.011364</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.016949</td>\n",
       "      <td>0.966102</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.025641</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.974359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CAP_Sleep</td>\n",
       "      <td>sdb</td>\n",
       "      <td>sdb3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.046948</td>\n",
       "      <td>0.018779</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.108696</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.025974</td>\n",
       "      <td>0.038961</td>\n",
       "      <td>0.935065</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.937500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>Sleep_EDFX</td>\n",
       "      <td>n</td>\n",
       "      <td>ST7191</td>\n",
       "      <td>0</td>\n",
       "      <td>0.242857</td>\n",
       "      <td>0.014286</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.044118</td>\n",
       "      <td>...</td>\n",
       "      <td>0.013889</td>\n",
       "      <td>0.013889</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.805556</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>0.015000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.965000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>Sleep_EDFX</td>\n",
       "      <td>n</td>\n",
       "      <td>ST7201</td>\n",
       "      <td>0</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.014493</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>0.346154</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.044776</td>\n",
       "      <td>0.007463</td>\n",
       "      <td>0.014925</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.932836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>Sleep_EDFX</td>\n",
       "      <td>n</td>\n",
       "      <td>ST7211</td>\n",
       "      <td>0</td>\n",
       "      <td>0.099415</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.005848</td>\n",
       "      <td>0.116667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.016949</td>\n",
       "      <td>0.254237</td>\n",
       "      <td>0.728814</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.025641</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.019231</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.955128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>Sleep_EDFX</td>\n",
       "      <td>n</td>\n",
       "      <td>ST7221</td>\n",
       "      <td>0</td>\n",
       "      <td>0.180000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.052133</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.021645</td>\n",
       "      <td>0.043290</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.935065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>Sleep_EDFX</td>\n",
       "      <td>n</td>\n",
       "      <td>ST7241</td>\n",
       "      <td>0</td>\n",
       "      <td>0.275862</td>\n",
       "      <td>0.034483</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.068966</td>\n",
       "      <td>0.047619</td>\n",
       "      <td>...</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.016878</td>\n",
       "      <td>0.016878</td>\n",
       "      <td>0.008439</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.957806</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>208 rows × 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Dataset Category Subject_Name  Class     W->S1     W->S2  W->S3  \\\n",
       "0     CAP_Sleep     brux        brux1      1  0.190476  0.009524    0.0   \n",
       "1     CAP_Sleep     brux        brux2      1  0.174603  0.000000    0.0   \n",
       "2     CAP_Sleep      sdb         sdb1      1  0.123288  0.000000    0.0   \n",
       "3     CAP_Sleep      sdb         sdb2      1  0.044872  0.006410    0.0   \n",
       "4     CAP_Sleep      sdb         sdb3      1  0.046948  0.018779    0.0   \n",
       "..          ...      ...          ...    ...       ...       ...    ...   \n",
       "203  Sleep_EDFX        n       ST7191      0  0.242857  0.014286    0.0   \n",
       "204  Sleep_EDFX        n       ST7201      0  0.555556  0.055556    0.0   \n",
       "205  Sleep_EDFX        n       ST7211      0  0.099415  0.000000    0.0   \n",
       "206  Sleep_EDFX        n       ST7221      0  0.180000  0.000000    0.0   \n",
       "207  Sleep_EDFX        n       ST7241      0  0.275862  0.034483    0.0   \n",
       "\n",
       "     W->S4    W->REM     S1->W  ...    S4->S1    S4->S2    S4->S3    S4->S4  \\\n",
       "0      0.0  0.000000  0.030769  ...  0.000000  0.004926  0.024631  0.970443   \n",
       "1      0.0  0.000000  0.061728  ...  0.000000  0.000000  0.012048  0.984940   \n",
       "2      0.0  0.000000  0.099237  ...  0.010152  0.005076  0.030457  0.949239   \n",
       "3      0.0  0.000000  0.011364  ...  0.000000  0.008475  0.016949  0.966102   \n",
       "4      0.0  0.000000  0.108696  ...  0.000000  0.025974  0.038961  0.935065   \n",
       "..     ...       ...       ...  ...       ...       ...       ...       ...   \n",
       "203    0.0  0.000000  0.044118  ...  0.013889  0.013889  0.166667  0.805556   \n",
       "204    0.0  0.055556  0.014493  ...  0.000000  0.038462  0.615385  0.346154   \n",
       "205    0.0  0.005848  0.116667  ...  0.000000  0.016949  0.254237  0.728814   \n",
       "206    0.0  0.000000  0.052133  ...  0.000000  0.000000  0.000000  0.000000   \n",
       "207    0.0  0.068966  0.047619  ...  0.142857  0.142857  0.571429  0.142857   \n",
       "\n",
       "     S4->REM    REM->W   REM->S1   REM->S2  REM->S3  REM->REM  \n",
       "0        0.0  0.033520  0.000000  0.000000      0.0  0.966480  \n",
       "1        0.0  0.019324  0.004831  0.000000      0.0  0.975845  \n",
       "2        0.0  0.009346  0.000000  0.028037      0.0  0.962617  \n",
       "3        0.0  0.000000  0.000000  0.025641      0.0  0.974359  \n",
       "4        0.0  0.062500  0.000000  0.000000      0.0  0.937500  \n",
       "..       ...       ...       ...       ...      ...       ...  \n",
       "203      0.0  0.000000  0.020000  0.015000      0.0  0.965000  \n",
       "204      0.0  0.044776  0.007463  0.014925      0.0  0.932836  \n",
       "205      0.0  0.025641  0.000000  0.019231      0.0  0.955128  \n",
       "206      0.0  0.021645  0.043290  0.000000      0.0  0.935065  \n",
       "207      0.0  0.016878  0.016878  0.008439      0.0  0.957806  \n",
       "\n",
       "[208 rows x 38 columns]"
      ]
     },
     "execution_count": 392,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# processed_dataset = dataset.copy() if not random_state_value else dataset.copy().sample(frac=1, random_state=random_state_value).reset_index(drop=True) \n",
    "processed_dataset = dataset.copy()\n",
    "zero_feats = get_features_with_zero_values(processed_dataset)\n",
    "zero_feats\n",
    "removable_feats = ['W->W']\n",
    "removable_feats.extend(zero_feats)\n",
    "removable_feats \n",
    "# processed_dataset = processed_dataset[all_metadata_columns+sorted_PAUC_df]\n",
    "processed_dataset = processed_dataset.drop(removable_feats, axis=1)\n",
    "\n",
    "# ### #Binary/Multi-class healthy vs disorders \n",
    "# # processed_dataset = processed_dataset[~processed_dataset['Category'].isin(['brux', 'sdb'])]### Brux and sdb is cancelled coz of low number to fit in 5 fold\n",
    "# # class_map, processed_dataset = map_category_to_class(processed_dataset.copy(), source_col='Category', class_name='Class', removable_cats=None, multi_class=True)\n",
    "# # label_map, processed_dataset = map_category_to_class(processed_dataset.copy(), source_col='Category', class_name='Class', removable_cats=['brux', 'sdb', 'narco', 'ins', 'plm'], multi_class=True) \n",
    "# label_map, processed_dataset = map_category_to_class(processed_dataset.copy(), source_col='Category', class_name='Class', removable_cats=['brux', 'sdb', 'narco', 'ins', 'plm'], multi_class=True) \n",
    "# print(label_map)\n",
    "# # processed_dataset = processed_dataset[~processed_dataset['Subject_Name'].str.startswith('SC')] \n",
    "# processed_dataset = processed_dataset[~processed_dataset['Subject_Name'].str.startswith('ST')] \n",
    "\n",
    "# ### #Binary/Multi-class age-group detection  \n",
    "# label_map, processed_dataset = map_age_category_to_class(processed_dataset.copy(), all_demography_detail_df.copy(), source_cols=['Subject_Name', 'File_Name'], age_col = 'Age', age_ranges = [[19, 30], [31, 40]], class_name='Class', multi_class=True) ##19-101 \n",
    "# print(label_map)\n",
    "# processed_dataset\n",
    "\n",
    "processed_dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "id": "hidden-strengthening",
   "metadata": {},
   "outputs": [],
   "source": [
    "# processed_dataset[~processed_dataset['Subject_Name'].str.startswith('SC')].groupby('Category')['Class'].value_counts() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "id": "flexible-declaration",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Category  Class\n",
       "brux      1          2\n",
       "ins       1          9\n",
       "n         0        116\n",
       "narco     1          5\n",
       "nfle      1         40\n",
       "plm       1         10\n",
       "rbd       1         22\n",
       "sdb       1          4\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 393,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_dataset['Class'].unique()\n",
    "processed_dataset.groupby('Category')['Class'].value_counts()\n",
    "# processed_dataset['Category'].unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "id": "julian-hotel",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "        Object is initialised with the following properties: \n",
      "        ###################################################################################################\n",
      "        Dataset size: (208, 38), Columns: ['Dataset', 'Category', 'Subject_Name', 'Class', 'W->S1', 'W->S2', 'W->S3', 'W->S4', 'W->REM', 'S1->W', 'S1->S1', 'S1->S2', 'S1->S3', 'S1->S4', 'S1->REM', 'S2->W', 'S2->S1', 'S2->S2', 'S2->S3', 'S2->S4', 'S2->REM', 'S3->W', 'S3->S1', 'S3->S2', 'S3->S3', 'S3->S4', 'S3->REM', 'S4->W', 'S4->S1', 'S4->S2', 'S4->S3', 'S4->S4', 'S4->REM', 'REM->W', 'REM->S1', 'REM->S2', 'REM->S3', 'REM->REM']\n",
      "        Target class column name: Class\n",
      "        Metadata column names: ['Dataset', 'Category', 'Subject_Name']\n",
      "        Dataset split column on which the training and test sets will be devided: Subject_Name\n",
      "        Is multi-class classification: False\n",
      "        \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<__main__.HumachLab_ML_CLassifiers at 0x1961b1a1c88>"
      ]
     },
     "execution_count": 394,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if logger:\n",
    "    stop_logger(logger) \n",
    "util, logger = start_logger(result_save_path, exp_name)\n",
    "\n",
    "# classifier_obj = HumachLab_ML_CLassifiers(logger=logger, directory=result_save_path, dataset=dataset.copy(), class_name=class_name, metadata_column=metadata_column, split_column=split_column) \n",
    "classifier_obj = HumachLab_ML_CLassifiers(logger=logger, directory=result_save_path, dataset=processed_dataset.copy(), class_name=class_name, label_map=label_map, metadata_column=metadata_column, split_column=split_column, random_state_value=random_state_value, split_balance_pattern=split_balance_pattern) \n",
    "\n",
    "classifier_obj \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "id": "ecological-catholic",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello from HumachLab_ML_CLassifiers class\n"
     ]
    }
   ],
   "source": [
    "classifier_obj.print_message()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "id": "minor-jamaica",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([(5, 0), (5, 20)],\n",
       " [<ML_Classifiers.LogReg: 'logistic_regression'>,\n",
       "  <ML_Classifiers.SVC: 'support_vector_classifier'>,\n",
       "  <ML_Classifiers.NB: 'naive_bayes'>,\n",
       "  <ML_Classifiers.kNN: 'k_nearest_neighbors'>,\n",
       "  <ML_Classifiers.DT: 'decision_tree'>,\n",
       "  <ML_Classifiers.RF: 'random_forest'>,\n",
       "  <ML_Classifiers.GBoost: 'gradient_boosting'>],\n",
       " './Results/_Classification/ML1001/',\n",
       " True)"
      ]
     },
     "execution_count": 396,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# splitting_crieteria = [(10, 0), (5, 20)]     ### for test & training (validation) splitting_crieteria (m, n)-m folds, n%:  m=0: loso, m>0: m-fold, (n>0 given m>0) -shuffled random splitting with m-fold, n% testing \n",
    "splitting_crieteria = [(5, 0), (5, 20)]     ### for test & training (validation) splitting_crieteria (m, n)-m folds, n%:  m=0: loso, m>0: m-fold, (n>0 given m>0) -shuffled random splitting with m-fold, n% testing \n",
    "model_list = [ML_Classifiers.LogReg, ML_Classifiers.SVC, ML_Classifiers.NB, ML_Classifiers.kNN, ML_Classifiers.DT, ML_Classifiers.RF, ML_Classifiers.GBoost] # [ML_Classifiers.LogReg, ML_Classifiers.SVC, ML_Classifiers.NB, ML_Classifiers.kNN, ML_Classifiers.DT, ML_Classifiers.RF, ML_Classifiers.GBoost] \n",
    "should_use_params = True \n",
    "is_validate_models = True\n",
    "# is_binary_classification = False \n",
    "apply_feature_selection = False  \n",
    "custom_splitter = False\n",
    "exp_name = exp_name\n",
    "\n",
    "splitting_crieteria, model_list, result_save_path, should_use_params "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "id": "annoying-currency",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Class', 'Subject_Name')"
      ]
     },
     "execution_count": 397,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier_obj.class_name, classifier_obj.split_column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tired-schema",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "        Classification is set with the following parameters: \n",
      "        ###################################################################################################\n",
      "        Splitting crieteria: [(5, 0), (5, 20)]\n",
      "        Test split: 5-fold cross validation\n",
      "        Training split: 5-fold 20% random test splitting\n",
      "        List of ML models that will be applied: ['logistic_regression', 'support_vector_classifier', 'naive_bayes', 'k_nearest_neighbors', 'decision_tree', 'random_forest', 'gradient_boosting']\n",
      "        Use parameters for model: True\n",
      "        Is validate the model (or only train): True \n",
      "        Classification results will be saved in the directory: ./Results/_Classification/ML1001/\n",
      "        \n",
      "5-fold testing\n",
      "\n",
      "            ### MODEL TEST PHASE \n",
      "            TEST 1 START... XXXXX \n",
      "            ===================================================================================================\n",
      "            Test=> 42 ['brux1', 'brux2', 'sdb1', 'sdb2', 'sdb3', 'sdb4', 'ins1', 'ins2', 'ins3', 'ins4', 'ins5', 'ins6', 'ins7', 'ins8', 'ins9', 'narco1', 'narco2', 'narco3', 'narco4', 'n1', 'n2', 'n3', 'n4', 'n5', 'n6', 'n7', 'n8', 'n9', 'n10', 'n11', 'n12', 'n13', 'n14', 'n15', 'n16', 'SC4001', 'SC4011', 'SC4021', 'SC4031', 'SC4041', 'SC4051', 'SC4061'] \n",
      "            Training (Including Validation)=> 166 ['narco5', 'nfle1', 'nfle2', 'nfle3', 'nfle4', 'nfle5', 'nfle6', 'nfle7', 'nfle8', 'nfle9', 'nfle10', 'nfle11', 'nfle12', 'nfle13', 'nfle14', 'nfle15', 'nfle16', 'nfle17', 'nfle18', 'nfle19', 'nfle20', 'nfle21', 'nfle22', 'nfle23', 'nfle24', 'nfle25', 'nfle26', 'nfle27', 'nfle28', 'nfle29', 'nfle30', 'nfle31', 'nfle32', 'nfle33', 'nfle34', 'nfle35', 'nfle36', 'nfle37', 'nfle38', 'nfle39', 'nfle40', 'plm1', 'plm2', 'plm3', 'plm4', 'plm5', 'plm6', 'plm7', 'plm8', 'plm9', 'plm10', 'rbd1', 'rbd2', 'rbd3', 'rbd4', 'rbd5', 'rbd6', 'rbd7', 'rbd8', 'rbd9', 'rbd10', 'rbd11', 'rbd12', 'rbd13', 'rbd14', 'rbd15', 'rbd16', 'rbd17', 'rbd18', 'rbd19', 'rbd20', 'rbd21', 'rbd22', 'SC4071', 'SC4081', 'SC4091', 'SC4101', 'SC4111', 'SC4121', 'SC4131', 'SC4141', 'SC4151', 'SC4161', 'SC4171', 'SC4181', 'SC4191', 'SC4201', 'SC4211', 'SC4221', 'SC4231', 'SC4241', 'SC4251', 'SC4261', 'SC4271', 'SC4281', 'SC4291', 'SC4301', 'SC4311', 'SC4321', 'SC4331', 'SC4341', 'SC4351', 'SC4362', 'SC4371', 'SC4381', 'SC4401', 'SC4411', 'SC4421', 'SC4431', 'SC4441', 'SC4451', 'SC4461', 'SC4471', 'SC4481', 'SC4491', 'SC4501', 'SC4511', 'SC4522', 'SC4531', 'SC4541', 'SC4551', 'SC4561', 'SC4571', 'SC4581', 'SC4591', 'SC4601', 'SC4611', 'SC4621', 'SC4631', 'SC4641', 'SC4651', 'SC4661', 'SC4671', 'SC4701', 'SC4711', 'SC4721', 'SC4731', 'SC4741', 'SC4751', 'SC4761', 'SC4771', 'SC4801', 'SC4811', 'SC4821', 'ST7011', 'ST7021', 'ST7041', 'ST7051', 'ST7061', 'ST7071', 'ST7081', 'ST7091', 'ST7101', 'ST7111', 'ST7121', 'ST7131', 'ST7141', 'ST7151', 'ST7161', 'ST7171', 'ST7181', 'ST7191', 'ST7201', 'ST7211', 'ST7221', 'ST7241'] \n",
      "            \n",
      "Random 20 percentage splitting testing...\n",
      "\n",
      "            *** MODEL TRAINING AND VALIDATION PHASE FOR TEST 1 \n",
      "            TRAINING 1 START... XXXXX \n",
      "            ***************************************************************************************************\n",
      "            Validation=> 20 ['plm4', 'ins6', 'SC4351', 'SC4311', 'SC4211', 'nfle23', 'rbd6', 'nfle29', 'n2', 'nfle25', 'SC4231', 'SC4121', 'nfle40', 'SC4491', 'ins5', 'rbd4', 'n14', 'nfle15', 'SC4561', 'nfle13'] \n",
      "            Training=> 146 ['nfle11', 'nfle6', 'SC4401', 'SC4581', 'SC4191', 'nfle31', 'SC4071', 'rbd19', 'SC4291', 'SC4141', 'nfle2', 'nfle32', 'SC4381', 'nfle21', 'rbd11', 'plm9', 'nfle27', 'sdb2', 'nfle33', 'nfle18', 'narco5', 'rbd16', 'SC4551', 'SC4281', 'rbd8', 'rbd13', 'SC4301', 'nfle9', 'n10', 'n12', 'n1', 'rbd10', 'SC4321', 'n13', 'rbd7', 'nfle35', 'SC4001', 'n5', 'nfle28', 'ins9', 'plm1', 'SC4091', 'rbd17', 'rbd15', 'nfle5', 'nfle26', 'SC4371', 'SC4571', 'SC4151', 'nfle24', 'n11', 'rbd2', 'SC4131', 'nfle8', 'SC4471', 'nfle12', 'SC4421', 'SC4261', 'SC4431', 'SC4441', 'plm6', 'ins4', 'nfle14', 'nfle36', 'ins8', 'n3', 'rbd21', 'SC4061', 'SC4461', 'n7', 'nfle1', 'n8', 'plm3', 'narco4', 'SC4331', 'SC4501', 'SC4101', 'SC4341', 'brux2', 'rbd20', 'nfle38', 'rbd3', 'rbd14', 'SC4511', 'SC4481', 'n16', 'nfle10', 'SC4201', 'SC4081', 'rbd5', 'SC4271', 'SC4041', 'nfle22', 'rbd12', 'narco3', 'sdb3', 'SC4181', 'nfle39', 'SC4411', 'n4', 'SC4051', 'rbd9', 'SC4522', 'n6', 'SC4011', 'nfle16', 'nfle4', 'plm5', 'nfle7', 'SC4541', 'SC4021', 'nfle19', 'SC4111', 'SC4241', 'sdb1', 'SC4161', 'rbd22', 'SC4251', 'rbd18', 'nfle20', 'plm8', 'n9', 'plm7', 'nfle17', 'SC4221', 'nfle3', 'ins3', 'n15', 'SC4362', 'narco1', 'plm2', 'ins7', 'nfle37', 'nfle30', 'ins1', 'narco2', 'sdb4', 'brux1', 'SC4171', 'SC4451', 'ins2', 'plm10', 'nfle34', 'SC4031', 'SC4531', 'rbd1'] \n",
      "            \n",
      "\n",
      "            *** ML MODEL FOR TEST:1, TRAINING:1 AND MODEL: LR \n",
      "            ---------------------------------------------------------------------------------------------------\n",
      "            \n",
      "Calling method: logistic_regression_parameters\n",
      "All parameters: ['penalty', 'solver', 'max_iter', 'C'], [['l2', 'elasticnet'], [50, 100, 130, 150, 170, 200], [0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1.0]], [0, 2, 3]\n",
      "Parameters:  {'penalty': ['l2', 'elasticnet'], 'max_iter': [50, 100, 130, 150, 170, 200], 'C': [0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1.0]}\n",
      "\n",
      "        From training? True, Data shape: (146, 38), Indices: [ 30  25 147 165 127  50 115  88 137 122  21  51 146  40  80  68  46   3\n",
      "  52  37  19  85 162 136  77  82 138  28 101 103  92  79 140 104  76  54\n",
      " 108  96  47  14  60 117  86  84  24  45 145 164 123  43 102  71 121  27\n",
      " 154  31 149 134 150 151  65   9  33  55  13  94  90 114 153  98  20  99\n",
      "  62  18 141 157 118 142   1  89  57  72  83 158 155 107  29 128 116  74\n",
      " 135 112  41  81  17   4 126  58 148  95 113  78 159  97 109  35  23  64\n",
      "  26 161 110  38 119 132   2 124  91 133  87  39  67 100  66  36 130  22\n",
      "   8 106 144  15  61  12  56  49   6  16   5   0 125 152   7  69  53 111\n",
      " 160  70]\n",
      "        All Columns: ['Dataset', 'Category', 'Subject_Name', 'Class', 'W->S1', 'W->S2', 'W->S3', 'W->S4', 'W->REM', 'S1->W', 'S1->S1', 'S1->S2', 'S1->S3', 'S1->S4', 'S1->REM', 'S2->W', 'S2->S1', 'S2->S2', 'S2->S3', 'S2->S4', 'S2->REM', 'S3->W', 'S3->S1', 'S3->S2', 'S3->S3', 'S3->S4', 'S3->REM', 'S4->W', 'S4->S1', 'S4->S2', 'S4->S3', 'S4->S4', 'S4->REM', 'REM->W', 'REM->S1', 'REM->S2', 'REM->S3', 'REM->REM']\n",
      "        \n",
      "\"\n",
      "            Selected features: ['W->S1', 'W->S2', 'W->S3', 'W->S4', 'W->REM', 'S1->W', 'S1->S1', 'S1->S2', 'S1->S3', 'S1->S4', 'S1->REM', 'S2->W', 'S2->S1', 'S2->S2', 'S2->S3', 'S2->S4', 'S2->REM', 'S3->W', 'S3->S1', 'S3->S2', 'S3->S3', 'S3->S4', 'S3->REM', 'S4->W', 'S4->S1', 'S4->S2', 'S4->S3', 'S4->S4', 'S4->REM', 'REM->W', 'REM->S1', 'REM->S2', 'REM->S3', 'REM->REM']\n",
      "            \n",
      "\n",
      "        Feature shape: (146, 34), Target shape: (146,), Metadata: (146, 3) \n",
      "        \n",
      "\n",
      "        GridSearch: LR - {'penalty': ['l2', 'elasticnet'], 'max_iter': [50, 100, 130, 150, 170, 200], 'C': [0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1.0]} \n",
      "        ---------------------------------------------------------------------------------------------------\n",
      "        \n",
      "Refitting the model with best parameter f1 == True\n",
      "Fitting 5 folds for each of 84 candidates, totalling 420 fits\n",
      "\n",
      "        From training? False, Data shape: (20, 38), Indices: [ 63  11 143 139 129  42  75  48  93  44 131 120  59 156  10  73 105  34\n",
      " 163  32]\n",
      "        All Columns: ['Dataset', 'Category', 'Subject_Name', 'Class', 'W->S1', 'W->S2', 'W->S3', 'W->S4', 'W->REM', 'S1->W', 'S1->S1', 'S1->S2', 'S1->S3', 'S1->S4', 'S1->REM', 'S2->W', 'S2->S1', 'S2->S2', 'S2->S3', 'S2->S4', 'S2->REM', 'S3->W', 'S3->S1', 'S3->S2', 'S3->S3', 'S3->S4', 'S3->REM', 'S4->W', 'S4->S1', 'S4->S2', 'S4->S3', 'S4->S4', 'S4->REM', 'REM->W', 'REM->S1', 'REM->S2', 'REM->S3', 'REM->REM']\n",
      "        \n",
      "\n",
      "        Feature shape: (20, 34), Target shape: (20,), Metadata: (20, 3) \n",
      "        \n",
      "[0 1] [0 1]\n",
      "[1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1] [1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1]\n",
      "[[ 7  2]\n",
      " [ 0 11]]\n",
      "[[11  0  2  7]\n",
      " [ 7  2  0 11]]\n",
      "[[18  2]\n",
      " [ 2 18]]\n",
      "Class-wise info: For multilevel internal scores fo label 0: \n",
      " Accuracy = 90.0\n",
      " Precision = [0.84615385 1.        ]\n",
      " Recall = [1.         0.77777778]\n",
      " F1 score = [0.91666667 0.875     ]\n",
      " AUC score = 88.88888888888889\n",
      " Support = [11  9]\n",
      "\n",
      "Class-wise info: For multilevel internal scores fo label 1: \n",
      " Accuracy = 90.0\n",
      " Precision = [1.         0.84615385]\n",
      " Recall = [0.77777778 1.        ]\n",
      " F1 score = [0.875      0.91666667]\n",
      " AUC score = 88.88888888888889\n",
      " Support = [ 9 11]\n",
      "\n",
      "CLASSIFICATION MERICS:\n",
      " _______________________________________________________\n",
      " Confusion Matrix: \n",
      "[[ 7  2]\n",
      " [ 0 11]]\n",
      " Accuracy (acc): 90.0\n",
      " Precision (prc): 84.615\n",
      " Recall (rec): 100.0\n",
      " Sensitivity (sns): 100.0\n",
      " Specificity (spc): 77.778\n",
      " F1 Score (f1s): 91.667\n",
      " ROC AUC (AUC): 0.889\n",
      "Score columns: (1, 12) ['method', 'model', 'model_parameters', 'model_scores', 'confusion_matrix', 'accuracy', 'precision', 'recall', 'sensitivity', 'specificity', 'f1_score', 'roc_auc']\n",
      "\n",
      "        Best model (GriveSearchCV): GridSearchCV(cv=5, estimator=LogisticRegression(), n_jobs=50,\n",
      "             param_grid={'C': [0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1.0],\n",
      "                         'max_iter': [50, 100, 130, 150, 170, 200],\n",
      "                         'penalty': ['l2', 'elasticnet']},\n",
      "             return_train_score=True, scoring='f1', verbose=2) \n",
      "        Best model: GridSearchCV(cv=5, estimator=LogisticRegression(), n_jobs=50,\n",
      "             param_grid={'C': [0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1.0],\n",
      "                         'max_iter': [50, 100, 130, 150, 170, 200],\n",
      "                         'penalty': ['l2', 'elasticnet']},\n",
      "             return_train_score=True, scoring='f1', verbose=2) \n",
      "        Best estimator of the model: LogisticRegression(max_iter=50) \n",
      "        Best parameters of the model: {'C': 1.0, 'max_iter': 50, 'penalty': 'l2'} \n",
      "        ---------------------------------------------------------------------------------------------------\n",
      "        \n",
      "\n",
      "            *** ML MODEL FOR TEST:1, TRAINING:1 AND MODEL: SVC \n",
      "            ---------------------------------------------------------------------------------------------------\n",
      "            \n",
      "Calling method: support_vector_classifier_parameters\n",
      "All parameters: ['probability', 'C', 'kernel', 'gamma', 'degree', 'class_weightdict'], [[True], [0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1.0], ['linear', 'rbf', 'poly']], [0, 1, 2]\n",
      "Parameters:  {'probability': [True], 'C': [0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1.0], 'kernel': ['linear', 'rbf', 'poly']}\n",
      "\n",
      "        From training? True, Data shape: (146, 38), Indices: [ 30  25 147 165 127  50 115  88 137 122  21  51 146  40  80  68  46   3\n",
      "  52  37  19  85 162 136  77  82 138  28 101 103  92  79 140 104  76  54\n",
      " 108  96  47  14  60 117  86  84  24  45 145 164 123  43 102  71 121  27\n",
      " 154  31 149 134 150 151  65   9  33  55  13  94  90 114 153  98  20  99\n",
      "  62  18 141 157 118 142   1  89  57  72  83 158 155 107  29 128 116  74\n",
      " 135 112  41  81  17   4 126  58 148  95 113  78 159  97 109  35  23  64\n",
      "  26 161 110  38 119 132   2 124  91 133  87  39  67 100  66  36 130  22\n",
      "   8 106 144  15  61  12  56  49   6  16   5   0 125 152   7  69  53 111\n",
      " 160  70]\n",
      "        All Columns: ['Dataset', 'Category', 'Subject_Name', 'Class', 'W->S1', 'W->S2', 'W->S3', 'W->S4', 'W->REM', 'S1->W', 'S1->S1', 'S1->S2', 'S1->S3', 'S1->S4', 'S1->REM', 'S2->W', 'S2->S1', 'S2->S2', 'S2->S3', 'S2->S4', 'S2->REM', 'S3->W', 'S3->S1', 'S3->S2', 'S3->S3', 'S3->S4', 'S3->REM', 'S4->W', 'S4->S1', 'S4->S2', 'S4->S3', 'S4->S4', 'S4->REM', 'REM->W', 'REM->S1', 'REM->S2', 'REM->S3', 'REM->REM']\n",
      "        \n",
      "\n",
      "        Feature shape: (146, 34), Target shape: (146,), Metadata: (146, 3) \n",
      "        \n",
      "\n",
      "        GridSearch: SVC - {'probability': [True], 'C': [0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1.0], 'kernel': ['linear', 'rbf', 'poly']} \n",
      "        ---------------------------------------------------------------------------------------------------\n",
      "        \n",
      "Refitting the model with best parameter f1 == True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aliem\\.conda\\envs\\MyPython37Work\\lib\\site-packages\\sklearn\\model_selection\\_search.py:921: UserWarning: One or more of the test scores are non-finite: [0.71356974        nan 0.71356974        nan 0.71356974        nan\n",
      " 0.71356974        nan 0.71356974        nan 0.71356974        nan\n",
      " 0.71356974        nan 0.71356974        nan 0.71356974        nan\n",
      " 0.71356974        nan 0.71356974        nan 0.71356974        nan\n",
      " 0.71356974        nan 0.71356974        nan 0.71356974        nan\n",
      " 0.71356974        nan 0.71356974        nan 0.71356974        nan\n",
      " 0.84462064        nan 0.84462064        nan 0.84462064        nan\n",
      " 0.84462064        nan 0.84462064        nan 0.84462064        nan\n",
      " 0.86374248        nan 0.86374248        nan 0.86374248        nan\n",
      " 0.86374248        nan 0.86374248        nan 0.86374248        nan\n",
      " 0.89258609        nan 0.89258609        nan 0.89258609        nan\n",
      " 0.89258609        nan 0.89258609        nan 0.89258609        nan\n",
      " 0.90909403        nan 0.90909403        nan 0.90909403        nan\n",
      " 0.90909403        nan 0.90909403        nan 0.90909403        nan]\n",
      "  category=UserWarning\n",
      "C:\\Users\\aliem\\.conda\\envs\\MyPython37Work\\lib\\site-packages\\sklearn\\model_selection\\_search.py:921: UserWarning: One or more of the train scores are non-finite: [0.71365079        nan 0.71365079        nan 0.71365079        nan\n",
      " 0.71365079        nan 0.71365079        nan 0.71365079        nan\n",
      " 0.71365079        nan 0.71365079        nan 0.71365079        nan\n",
      " 0.71365079        nan 0.71365079        nan 0.71365079        nan\n",
      " 0.72410808        nan 0.72410808        nan 0.72410808        nan\n",
      " 0.72410808        nan 0.72410808        nan 0.72410808        nan\n",
      " 0.84750111        nan 0.84750111        nan 0.84750111        nan\n",
      " 0.84750111        nan 0.84750111        nan 0.84750111        nan\n",
      " 0.8717572         nan 0.8717572         nan 0.8717572         nan\n",
      " 0.8717572         nan 0.8717572         nan 0.8717572         nan\n",
      " 0.89297535        nan 0.89297535        nan 0.89297535        nan\n",
      " 0.89297535        nan 0.89297535        nan 0.89297535        nan\n",
      " 0.90937444        nan 0.90937444        nan 0.90937444        nan\n",
      " 0.90937444        nan 0.90937444        nan 0.90937444        nan]\n",
      "  category=UserWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 21 candidates, totalling 105 fits\n",
      "\n",
      "        From training? False, Data shape: (20, 38), Indices: [ 63  11 143 139 129  42  75  48  93  44 131 120  59 156  10  73 105  34\n",
      " 163  32]\n",
      "        All Columns: ['Dataset', 'Category', 'Subject_Name', 'Class', 'W->S1', 'W->S2', 'W->S3', 'W->S4', 'W->REM', 'S1->W', 'S1->S1', 'S1->S2', 'S1->S3', 'S1->S4', 'S1->REM', 'S2->W', 'S2->S1', 'S2->S2', 'S2->S3', 'S2->S4', 'S2->REM', 'S3->W', 'S3->S1', 'S3->S2', 'S3->S3', 'S3->S4', 'S3->REM', 'S4->W', 'S4->S1', 'S4->S2', 'S4->S3', 'S4->S4', 'S4->REM', 'REM->W', 'REM->S1', 'REM->S2', 'REM->S3', 'REM->REM']\n",
      "        \n",
      "\n",
      "        Feature shape: (20, 34), Target shape: (20,), Metadata: (20, 3) \n",
      "        \n",
      "[0 1] [0 1]\n",
      "[1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1] [1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1]\n",
      "[[ 7  2]\n",
      " [ 0 11]]\n",
      "[[11  0  2  7]\n",
      " [ 7  2  0 11]]\n",
      "[[18  2]\n",
      " [ 2 18]]\n",
      "Class-wise info: For multilevel internal scores fo label 0: \n",
      " Accuracy = 90.0\n",
      " Precision = [0.84615385 1.        ]\n",
      " Recall = [1.         0.77777778]\n",
      " F1 score = [0.91666667 0.875     ]\n",
      " AUC score = 88.88888888888889\n",
      " Support = [11  9]\n",
      "\n",
      "Class-wise info: For multilevel internal scores fo label 1: \n",
      " Accuracy = 90.0\n",
      " Precision = [1.         0.84615385]\n",
      " Recall = [0.77777778 1.        ]\n",
      " F1 score = [0.875      0.91666667]\n",
      " AUC score = 88.88888888888889\n",
      " Support = [ 9 11]\n",
      "\n",
      "CLASSIFICATION MERICS:\n",
      " _______________________________________________________\n",
      " Confusion Matrix: \n",
      "[[ 7  2]\n",
      " [ 0 11]]\n",
      " Accuracy (acc): 90.0\n",
      " Precision (prc): 84.615\n",
      " Recall (rec): 100.0\n",
      " Sensitivity (sns): 100.0\n",
      " Specificity (spc): 77.778\n",
      " F1 Score (f1s): 91.667\n",
      " ROC AUC (AUC): 0.889\n",
      "Score columns: (1, 12) ['method', 'model', 'model_parameters', 'model_scores', 'confusion_matrix', 'accuracy', 'precision', 'recall', 'sensitivity', 'specificity', 'f1_score', 'roc_auc']\n",
      "\n",
      "        Best model (GriveSearchCV): GridSearchCV(cv=5, estimator=SVC(), n_jobs=50,\n",
      "             param_grid={'C': [0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1.0],\n",
      "                         'kernel': ['linear', 'rbf', 'poly'],\n",
      "                         'probability': [True]},\n",
      "             return_train_score=True, scoring='f1', verbose=2) \n",
      "        Best model: GridSearchCV(cv=5, estimator=SVC(), n_jobs=50,\n",
      "             param_grid={'C': [0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1.0],\n",
      "                         'kernel': ['linear', 'rbf', 'poly'],\n",
      "                         'probability': [True]},\n",
      "             return_train_score=True, scoring='f1', verbose=2) \n",
      "        Best estimator of the model: SVC(kernel='linear', probability=True) \n",
      "        Best parameters of the model: {'C': 1.0, 'kernel': 'linear', 'probability': True} \n",
      "        ---------------------------------------------------------------------------------------------------\n",
      "        \n",
      "\n",
      "            *** ML MODEL FOR TEST:1, TRAINING:1 AND MODEL: NB \n",
      "            ---------------------------------------------------------------------------------------------------\n",
      "            \n",
      "Calling method: naive_bayes_parameters\n",
      "All parameters: ['var_smoothing'], [[1.0, 0.005623413251903491, 3.1622776601683795e-05, 1.7782794100389227e-07, 1e-09]], [0]\n",
      "Parameters:  {'var_smoothing': [1.0, 0.005623413251903491, 3.1622776601683795e-05, 1.7782794100389227e-07, 1e-09]}\n",
      "\n",
      "        From training? True, Data shape: (146, 38), Indices: [ 30  25 147 165 127  50 115  88 137 122  21  51 146  40  80  68  46   3\n",
      "  52  37  19  85 162 136  77  82 138  28 101 103  92  79 140 104  76  54\n",
      " 108  96  47  14  60 117  86  84  24  45 145 164 123  43 102  71 121  27\n",
      " 154  31 149 134 150 151  65   9  33  55  13  94  90 114 153  98  20  99\n",
      "  62  18 141 157 118 142   1  89  57  72  83 158 155 107  29 128 116  74\n",
      " 135 112  41  81  17   4 126  58 148  95 113  78 159  97 109  35  23  64\n",
      "  26 161 110  38 119 132   2 124  91 133  87  39  67 100  66  36 130  22\n",
      "   8 106 144  15  61  12  56  49   6  16   5   0 125 152   7  69  53 111\n",
      " 160  70]\n",
      "        All Columns: ['Dataset', 'Category', 'Subject_Name', 'Class', 'W->S1', 'W->S2', 'W->S3', 'W->S4', 'W->REM', 'S1->W', 'S1->S1', 'S1->S2', 'S1->S3', 'S1->S4', 'S1->REM', 'S2->W', 'S2->S1', 'S2->S2', 'S2->S3', 'S2->S4', 'S2->REM', 'S3->W', 'S3->S1', 'S3->S2', 'S3->S3', 'S3->S4', 'S3->REM', 'S4->W', 'S4->S1', 'S4->S2', 'S4->S3', 'S4->S4', 'S4->REM', 'REM->W', 'REM->S1', 'REM->S2', 'REM->S3', 'REM->REM']\n",
      "        \n",
      "\n",
      "        Feature shape: (146, 34), Target shape: (146,), Metadata: (146, 3) \n",
      "        \n",
      "\n",
      "        GridSearch: NB - {'var_smoothing': [1.0, 0.005623413251903491, 3.1622776601683795e-05, 1.7782794100389227e-07, 1e-09]} \n",
      "        ---------------------------------------------------------------------------------------------------\n",
      "        \n",
      "Refitting the model with best parameter f1 == True\n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "\n",
      "        From training? False, Data shape: (20, 38), Indices: [ 63  11 143 139 129  42  75  48  93  44 131 120  59 156  10  73 105  34\n",
      " 163  32]\n",
      "        All Columns: ['Dataset', 'Category', 'Subject_Name', 'Class', 'W->S1', 'W->S2', 'W->S3', 'W->S4', 'W->REM', 'S1->W', 'S1->S1', 'S1->S2', 'S1->S3', 'S1->S4', 'S1->REM', 'S2->W', 'S2->S1', 'S2->S2', 'S2->S3', 'S2->S4', 'S2->REM', 'S3->W', 'S3->S1', 'S3->S2', 'S3->S3', 'S3->S4', 'S3->REM', 'S4->W', 'S4->S1', 'S4->S2', 'S4->S3', 'S4->S4', 'S4->REM', 'REM->W', 'REM->S1', 'REM->S2', 'REM->S3', 'REM->REM']\n",
      "        \n",
      "\n",
      "        Feature shape: (20, 34), Target shape: (20,), Metadata: (20, 3) \n",
      "        \n",
      "[0 1] [0 1]\n",
      "[1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1] [1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1]\n",
      "[[ 7  2]\n",
      " [ 0 11]]\n",
      "[[11  0  2  7]\n",
      " [ 7  2  0 11]]\n",
      "[[18  2]\n",
      " [ 2 18]]\n",
      "Class-wise info: For multilevel internal scores fo label 0: \n",
      " Accuracy = 90.0\n",
      " Precision = [0.84615385 1.        ]\n",
      " Recall = [1.         0.77777778]\n",
      " F1 score = [0.91666667 0.875     ]\n",
      " AUC score = 88.88888888888889\n",
      " Support = [11  9]\n",
      "\n",
      "Class-wise info: For multilevel internal scores fo label 1: \n",
      " Accuracy = 90.0\n",
      " Precision = [1.         0.84615385]\n",
      " Recall = [0.77777778 1.        ]\n",
      " F1 score = [0.875      0.91666667]\n",
      " AUC score = 88.88888888888889\n",
      " Support = [ 9 11]\n",
      "\n",
      "CLASSIFICATION MERICS:\n",
      " _______________________________________________________\n",
      " Confusion Matrix: \n",
      "[[ 7  2]\n",
      " [ 0 11]]\n",
      " Accuracy (acc): 90.0\n",
      " Precision (prc): 84.615\n",
      " Recall (rec): 100.0\n",
      " Sensitivity (sns): 100.0\n",
      " Specificity (spc): 77.778\n",
      " F1 Score (f1s): 91.667\n",
      " ROC AUC (AUC): 0.889\n",
      "Score columns: (1, 12) ['method', 'model', 'model_parameters', 'model_scores', 'confusion_matrix', 'accuracy', 'precision', 'recall', 'sensitivity', 'specificity', 'f1_score', 'roc_auc']\n",
      "\n",
      "        Best model (GriveSearchCV): GridSearchCV(cv=5, estimator=GaussianNB(), n_jobs=50,\n",
      "             param_grid={'var_smoothing': [1.0, 0.005623413251903491,\n",
      "                                           3.1622776601683795e-05,\n",
      "                                           1.7782794100389227e-07, 1e-09]},\n",
      "             return_train_score=True, scoring='f1', verbose=2) \n",
      "        Best model: GridSearchCV(cv=5, estimator=GaussianNB(), n_jobs=50,\n",
      "             param_grid={'var_smoothing': [1.0, 0.005623413251903491,\n",
      "                                           3.1622776601683795e-05,\n",
      "                                           1.7782794100389227e-07, 1e-09]},\n",
      "             return_train_score=True, scoring='f1', verbose=2) \n",
      "        Best estimator of the model: GaussianNB(var_smoothing=0.005623413251903491) \n",
      "        Best parameters of the model: {'var_smoothing': 0.005623413251903491} \n",
      "        ---------------------------------------------------------------------------------------------------\n",
      "        \n",
      "\n",
      "            *** ML MODEL FOR TEST:1, TRAINING:1 AND MODEL: KNN \n",
      "            ---------------------------------------------------------------------------------------------------\n",
      "            \n",
      "Calling method: k_nearest_neighbors_parameters\n",
      "All parameters: ['n_neighbors', 'p', 'metric', 'n_splits'], [[2, 3, 5, 10, 15, 25, 35], ['manhattan', 'minkowski', 'euclidean']], [0, 2]\n",
      "Parameters:  {'n_neighbors': [2, 3, 5, 10, 15, 25, 35], 'metric': ['manhattan', 'minkowski', 'euclidean']}\n",
      "\n",
      "        From training? True, Data shape: (146, 38), Indices: [ 30  25 147 165 127  50 115  88 137 122  21  51 146  40  80  68  46   3\n",
      "  52  37  19  85 162 136  77  82 138  28 101 103  92  79 140 104  76  54\n",
      " 108  96  47  14  60 117  86  84  24  45 145 164 123  43 102  71 121  27\n",
      " 154  31 149 134 150 151  65   9  33  55  13  94  90 114 153  98  20  99\n",
      "  62  18 141 157 118 142   1  89  57  72  83 158 155 107  29 128 116  74\n",
      " 135 112  41  81  17   4 126  58 148  95 113  78 159  97 109  35  23  64\n",
      "  26 161 110  38 119 132   2 124  91 133  87  39  67 100  66  36 130  22\n",
      "   8 106 144  15  61  12  56  49   6  16   5   0 125 152   7  69  53 111\n",
      " 160  70]\n",
      "        All Columns: ['Dataset', 'Category', 'Subject_Name', 'Class', 'W->S1', 'W->S2', 'W->S3', 'W->S4', 'W->REM', 'S1->W', 'S1->S1', 'S1->S2', 'S1->S3', 'S1->S4', 'S1->REM', 'S2->W', 'S2->S1', 'S2->S2', 'S2->S3', 'S2->S4', 'S2->REM', 'S3->W', 'S3->S1', 'S3->S2', 'S3->S3', 'S3->S4', 'S3->REM', 'S4->W', 'S4->S1', 'S4->S2', 'S4->S3', 'S4->S4', 'S4->REM', 'REM->W', 'REM->S1', 'REM->S2', 'REM->S3', 'REM->REM']\n",
      "        \n",
      "\n",
      "        Feature shape: (146, 34), Target shape: (146,), Metadata: (146, 3) \n",
      "        \n",
      "\n",
      "        GridSearch: KNN - {'n_neighbors': [2, 3, 5, 10, 15, 25, 35], 'metric': ['manhattan', 'minkowski', 'euclidean']} \n",
      "        ---------------------------------------------------------------------------------------------------\n",
      "        \n",
      "Refitting the model with best parameter f1 == True\n",
      "Fitting 5 folds for each of 21 candidates, totalling 105 fits\n",
      "\n",
      "        From training? False, Data shape: (20, 38), Indices: [ 63  11 143 139 129  42  75  48  93  44 131 120  59 156  10  73 105  34\n",
      " 163  32]\n",
      "        All Columns: ['Dataset', 'Category', 'Subject_Name', 'Class', 'W->S1', 'W->S2', 'W->S3', 'W->S4', 'W->REM', 'S1->W', 'S1->S1', 'S1->S2', 'S1->S3', 'S1->S4', 'S1->REM', 'S2->W', 'S2->S1', 'S2->S2', 'S2->S3', 'S2->S4', 'S2->REM', 'S3->W', 'S3->S1', 'S3->S2', 'S3->S3', 'S3->S4', 'S3->REM', 'S4->W', 'S4->S1', 'S4->S2', 'S4->S3', 'S4->S4', 'S4->REM', 'REM->W', 'REM->S1', 'REM->S2', 'REM->S3', 'REM->REM']\n",
      "        \n",
      "\n",
      "        Feature shape: (20, 34), Target shape: (20,), Metadata: (20, 3) \n",
      "        \n",
      "[0 1] [0 1]\n",
      "[1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1] [1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1]\n",
      "[[ 7  2]\n",
      " [ 0 11]]\n",
      "[[11  0  2  7]\n",
      " [ 7  2  0 11]]\n",
      "[[18  2]\n",
      " [ 2 18]]\n",
      "Class-wise info: For multilevel internal scores fo label 0: \n",
      " Accuracy = 90.0\n",
      " Precision = [0.84615385 1.        ]\n",
      " Recall = [1.         0.77777778]\n",
      " F1 score = [0.91666667 0.875     ]\n",
      " AUC score = 88.88888888888889\n",
      " Support = [11  9]\n",
      "\n",
      "Class-wise info: For multilevel internal scores fo label 1: \n",
      " Accuracy = 90.0\n",
      " Precision = [1.         0.84615385]\n",
      " Recall = [0.77777778 1.        ]\n",
      " F1 score = [0.875      0.91666667]\n",
      " AUC score = 88.88888888888889\n",
      " Support = [ 9 11]\n",
      "\n",
      "CLASSIFICATION MERICS:\n",
      " _______________________________________________________\n",
      " Confusion Matrix: \n",
      "[[ 7  2]\n",
      " [ 0 11]]\n",
      " Accuracy (acc): 90.0\n",
      " Precision (prc): 84.615\n",
      " Recall (rec): 100.0\n",
      " Sensitivity (sns): 100.0\n",
      " Specificity (spc): 77.778\n",
      " F1 Score (f1s): 91.667\n",
      " ROC AUC (AUC): 0.889\n",
      "Score columns: (1, 12) ['method', 'model', 'model_parameters', 'model_scores', 'confusion_matrix', 'accuracy', 'precision', 'recall', 'sensitivity', 'specificity', 'f1_score', 'roc_auc']\n",
      "\n",
      "        Best model (GriveSearchCV): GridSearchCV(cv=5, estimator=KNeighborsClassifier(), n_jobs=50,\n",
      "             param_grid={'metric': ['manhattan', 'minkowski', 'euclidean'],\n",
      "                         'n_neighbors': [2, 3, 5, 10, 15, 25, 35]},\n",
      "             return_train_score=True, scoring='f1', verbose=2) \n",
      "        Best model: GridSearchCV(cv=5, estimator=KNeighborsClassifier(), n_jobs=50,\n",
      "             param_grid={'metric': ['manhattan', 'minkowski', 'euclidean'],\n",
      "                         'n_neighbors': [2, 3, 5, 10, 15, 25, 35]},\n",
      "             return_train_score=True, scoring='f1', verbose=2) \n",
      "        Best estimator of the model: KNeighborsClassifier(metric='manhattan', n_neighbors=15) \n",
      "        Best parameters of the model: {'metric': 'manhattan', 'n_neighbors': 15} \n",
      "        ---------------------------------------------------------------------------------------------------\n",
      "        \n",
      "\n",
      "            *** ML MODEL FOR TEST:1, TRAINING:1 AND MODEL: DT \n",
      "            ---------------------------------------------------------------------------------------------------\n",
      "            \n",
      "Calling method: decision_tree_parameters\n",
      "All parameters: ['max_depth', 'criterion', 'splitter', 'min_samples_split', 'min_samples_leaf', 'max_leaf_nodes'], [[2, 3, 5, 7, 10, 15, 20, 25, 30], ['gini', 'entropy', 'log_loss']], [0, 1]\n",
      "Parameters:  {'max_depth': [2, 3, 5, 7, 10, 15, 20, 25, 30], 'criterion': ['gini', 'entropy', 'log_loss']}\n",
      "\n",
      "        From training? True, Data shape: (146, 38), Indices: [ 30  25 147 165 127  50 115  88 137 122  21  51 146  40  80  68  46   3\n",
      "  52  37  19  85 162 136  77  82 138  28 101 103  92  79 140 104  76  54\n",
      " 108  96  47  14  60 117  86  84  24  45 145 164 123  43 102  71 121  27\n",
      " 154  31 149 134 150 151  65   9  33  55  13  94  90 114 153  98  20  99\n",
      "  62  18 141 157 118 142   1  89  57  72  83 158 155 107  29 128 116  74\n",
      " 135 112  41  81  17   4 126  58 148  95 113  78 159  97 109  35  23  64\n",
      "  26 161 110  38 119 132   2 124  91 133  87  39  67 100  66  36 130  22\n",
      "   8 106 144  15  61  12  56  49   6  16   5   0 125 152   7  69  53 111\n",
      " 160  70]\n",
      "        All Columns: ['Dataset', 'Category', 'Subject_Name', 'Class', 'W->S1', 'W->S2', 'W->S3', 'W->S4', 'W->REM', 'S1->W', 'S1->S1', 'S1->S2', 'S1->S3', 'S1->S4', 'S1->REM', 'S2->W', 'S2->S1', 'S2->S2', 'S2->S3', 'S2->S4', 'S2->REM', 'S3->W', 'S3->S1', 'S3->S2', 'S3->S3', 'S3->S4', 'S3->REM', 'S4->W', 'S4->S1', 'S4->S2', 'S4->S3', 'S4->S4', 'S4->REM', 'REM->W', 'REM->S1', 'REM->S2', 'REM->S3', 'REM->REM']\n",
      "        \n",
      "\n",
      "        Feature shape: (146, 34), Target shape: (146,), Metadata: (146, 3) \n",
      "        \n",
      "\n",
      "        GridSearch: DT - {'max_depth': [2, 3, 5, 7, 10, 15, 20, 25, 30], 'criterion': ['gini', 'entropy', 'log_loss']} \n",
      "        ---------------------------------------------------------------------------------------------------\n",
      "        \n",
      "Refitting the model with best parameter f1 == True\n",
      "Fitting 5 folds for each of 27 candidates, totalling 135 fits\n",
      "\n",
      "        From training? False, Data shape: (20, 38), Indices: [ 63  11 143 139 129  42  75  48  93  44 131 120  59 156  10  73 105  34\n",
      " 163  32]\n",
      "        All Columns: ['Dataset', 'Category', 'Subject_Name', 'Class', 'W->S1', 'W->S2', 'W->S3', 'W->S4', 'W->REM', 'S1->W', 'S1->S1', 'S1->S2', 'S1->S3', 'S1->S4', 'S1->REM', 'S2->W', 'S2->S1', 'S2->S2', 'S2->S3', 'S2->S4', 'S2->REM', 'S3->W', 'S3->S1', 'S3->S2', 'S3->S3', 'S3->S4', 'S3->REM', 'S4->W', 'S4->S1', 'S4->S2', 'S4->S3', 'S4->S4', 'S4->REM', 'REM->W', 'REM->S1', 'REM->S2', 'REM->S3', 'REM->REM']\n",
      "        \n",
      "\n",
      "        Feature shape: (20, 34), Target shape: (20,), Metadata: (20, 3) \n",
      "        \n",
      "[0 1] [0 1]\n",
      "[1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1] [1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0]\n",
      "[[ 7  2]\n",
      " [ 1 10]]\n",
      "[[10  1  2  7]\n",
      " [ 7  2  1 10]]\n",
      "[[17  3]\n",
      " [ 3 17]]\n",
      "Class-wise info: For multilevel internal scores fo label 0: \n",
      " Accuracy = 85.0\n",
      " Precision = [0.83333333 0.875     ]\n",
      " Recall = [0.90909091 0.77777778]\n",
      " F1 score = [0.86956522 0.82352941]\n",
      " AUC score = 84.34343434343432\n",
      " Support = [11  9]\n",
      "\n",
      "Class-wise info: For multilevel internal scores fo label 1: \n",
      " Accuracy = 85.0\n",
      " Precision = [0.875      0.83333333]\n",
      " Recall = [0.77777778 0.90909091]\n",
      " F1 score = [0.82352941 0.86956522]\n",
      " AUC score = 84.34343434343434\n",
      " Support = [ 9 11]\n",
      "\n",
      "CLASSIFICATION MERICS:\n",
      " _______________________________________________________\n",
      " Confusion Matrix: \n",
      "[[ 7  2]\n",
      " [ 1 10]]\n",
      " Accuracy (acc): 85.0\n",
      " Precision (prc): 83.333\n",
      " Recall (rec): 90.909\n",
      " Sensitivity (sns): 90.909\n",
      " Specificity (spc): 77.778\n",
      " F1 Score (f1s): 86.957\n",
      " ROC AUC (AUC): 0.843\n",
      "Score columns: (1, 12) ['method', 'model', 'model_parameters', 'model_scores', 'confusion_matrix', 'accuracy', 'precision', 'recall', 'sensitivity', 'specificity', 'f1_score', 'roc_auc']\n",
      "\n",
      "        Best model (GriveSearchCV): GridSearchCV(cv=5, estimator=DecisionTreeClassifier(), n_jobs=50,\n",
      "             param_grid={'criterion': ['gini', 'entropy', 'log_loss'],\n",
      "                         'max_depth': [2, 3, 5, 7, 10, 15, 20, 25, 30]},\n",
      "             return_train_score=True, scoring='f1', verbose=2) \n",
      "        Best model: GridSearchCV(cv=5, estimator=DecisionTreeClassifier(), n_jobs=50,\n",
      "             param_grid={'criterion': ['gini', 'entropy', 'log_loss'],\n",
      "                         'max_depth': [2, 3, 5, 7, 10, 15, 20, 25, 30]},\n",
      "             return_train_score=True, scoring='f1', verbose=2) \n",
      "        Best estimator of the model: DecisionTreeClassifier(criterion='entropy', max_depth=10) \n",
      "        Best parameters of the model: {'criterion': 'entropy', 'max_depth': 10} \n",
      "        ---------------------------------------------------------------------------------------------------\n",
      "        \n",
      "\n",
      "            *** ML MODEL FOR TEST:1, TRAINING:1 AND MODEL: RF \n",
      "            ---------------------------------------------------------------------------------------------------\n",
      "            \n",
      "Calling method: random_forest_parameters\n",
      "All parameters: ['n_estimators', 'max_depth', 'criterion', 'splitter', 'max_features', 'min_samples_split', 'min_samples_leaf', 'max_leaf_nodes'], [[3, 5, 10, 15, 21, 30, 50, 75, 100], [2, 3, 5, 7, 10, 15, 20, 25, 30], ['gini', 'entropy', 'log_loss']], [0, 1, 2]\n",
      "Parameters:  {'n_estimators': [3, 5, 10, 15, 21, 30, 50, 75, 100], 'max_depth': [2, 3, 5, 7, 10, 15, 20, 25, 30], 'criterion': ['gini', 'entropy', 'log_loss']}\n",
      "\n",
      "        From training? True, Data shape: (146, 38), Indices: [ 30  25 147 165 127  50 115  88 137 122  21  51 146  40  80  68  46   3\n",
      "  52  37  19  85 162 136  77  82 138  28 101 103  92  79 140 104  76  54\n",
      " 108  96  47  14  60 117  86  84  24  45 145 164 123  43 102  71 121  27\n",
      " 154  31 149 134 150 151  65   9  33  55  13  94  90 114 153  98  20  99\n",
      "  62  18 141 157 118 142   1  89  57  72  83 158 155 107  29 128 116  74\n",
      " 135 112  41  81  17   4 126  58 148  95 113  78 159  97 109  35  23  64\n",
      "  26 161 110  38 119 132   2 124  91 133  87  39  67 100  66  36 130  22\n",
      "   8 106 144  15  61  12  56  49   6  16   5   0 125 152   7  69  53 111\n",
      " 160  70]\n",
      "        All Columns: ['Dataset', 'Category', 'Subject_Name', 'Class', 'W->S1', 'W->S2', 'W->S3', 'W->S4', 'W->REM', 'S1->W', 'S1->S1', 'S1->S2', 'S1->S3', 'S1->S4', 'S1->REM', 'S2->W', 'S2->S1', 'S2->S2', 'S2->S3', 'S2->S4', 'S2->REM', 'S3->W', 'S3->S1', 'S3->S2', 'S3->S3', 'S3->S4', 'S3->REM', 'S4->W', 'S4->S1', 'S4->S2', 'S4->S3', 'S4->S4', 'S4->REM', 'REM->W', 'REM->S1', 'REM->S2', 'REM->S3', 'REM->REM']\n",
      "        \n",
      "\n",
      "        Feature shape: (146, 34), Target shape: (146,), Metadata: (146, 3) \n",
      "        \n",
      "\n",
      "        GridSearch: RF - {'n_estimators': [3, 5, 10, 15, 21, 30, 50, 75, 100], 'max_depth': [2, 3, 5, 7, 10, 15, 20, 25, 30], 'criterion': ['gini', 'entropy', 'log_loss']} \n",
      "        ---------------------------------------------------------------------------------------------------\n",
      "        \n",
      "Refitting the model with best parameter f1 == True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aliem\\.conda\\envs\\MyPython37Work\\lib\\site-packages\\sklearn\\model_selection\\_search.py:921: UserWarning: One or more of the test scores are non-finite: [0.91417339 0.89782597 0.89378437 0.8912316  0.90736598 0.89647059\n",
      " 0.90910279 0.88969697 0.89107376 0.91417339 0.89462667 0.90468487\n",
      " 0.91792017 0.92250361 0.90864528 0.90173102 0.89690285 0.91567763\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan]\n",
      "  category=UserWarning\n",
      "C:\\Users\\aliem\\.conda\\envs\\MyPython37Work\\lib\\site-packages\\sklearn\\model_selection\\_search.py:921: UserWarning: One or more of the train scores are non-finite: [0.92571268 0.94696191 0.99062481 1.         1.         1.\n",
      " 1.         1.         1.         0.92571268 0.93523169 0.98567067\n",
      " 1.         1.         1.         1.         1.         1.\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan]\n",
      "  category=UserWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 243 candidates, totalling 1215 fits\n",
      "\n",
      "        From training? False, Data shape: (20, 38), Indices: [ 63  11 143 139 129  42  75  48  93  44 131 120  59 156  10  73 105  34\n",
      " 163  32]\n",
      "        All Columns: ['Dataset', 'Category', 'Subject_Name', 'Class', 'W->S1', 'W->S2', 'W->S3', 'W->S4', 'W->REM', 'S1->W', 'S1->S1', 'S1->S2', 'S1->S3', 'S1->S4', 'S1->REM', 'S2->W', 'S2->S1', 'S2->S2', 'S2->S3', 'S2->S4', 'S2->REM', 'S3->W', 'S3->S1', 'S3->S2', 'S3->S3', 'S3->S4', 'S3->REM', 'S4->W', 'S4->S1', 'S4->S2', 'S4->S3', 'S4->S4', 'S4->REM', 'REM->W', 'REM->S1', 'REM->S2', 'REM->S3', 'REM->REM']\n",
      "        \n",
      "\n",
      "        Feature shape: (20, 34), Target shape: (20,), Metadata: (20, 3) \n",
      "        \n",
      "[0 1] [0 1]\n",
      "[1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1] [1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1]\n",
      "[[ 7  2]\n",
      " [ 0 11]]\n",
      "[[11  0  2  7]\n",
      " [ 7  2  0 11]]\n",
      "[[18  2]\n",
      " [ 2 18]]\n",
      "Class-wise info: For multilevel internal scores fo label 0: \n",
      " Accuracy = 90.0\n",
      " Precision = [0.84615385 1.        ]\n",
      " Recall = [1.         0.77777778]\n",
      " F1 score = [0.91666667 0.875     ]\n",
      " AUC score = 88.88888888888889\n",
      " Support = [11  9]\n",
      "\n",
      "Class-wise info: For multilevel internal scores fo label 1: \n",
      " Accuracy = 90.0\n",
      " Precision = [1.         0.84615385]\n",
      " Recall = [0.77777778 1.        ]\n",
      " F1 score = [0.875      0.91666667]\n",
      " AUC score = 88.88888888888889\n",
      " Support = [ 9 11]\n",
      "\n",
      "CLASSIFICATION MERICS:\n",
      " _______________________________________________________\n",
      " Confusion Matrix: \n",
      "[[ 7  2]\n",
      " [ 0 11]]\n",
      " Accuracy (acc): 90.0\n",
      " Precision (prc): 84.615\n",
      " Recall (rec): 100.0\n",
      " Sensitivity (sns): 100.0\n",
      " Specificity (spc): 77.778\n",
      " F1 Score (f1s): 91.667\n",
      " ROC AUC (AUC): 0.889\n",
      "Score columns: (1, 12) ['method', 'model', 'model_parameters', 'model_scores', 'confusion_matrix', 'accuracy', 'precision', 'recall', 'sensitivity', 'specificity', 'f1_score', 'roc_auc']\n",
      "\n",
      "        Best model (GriveSearchCV): GridSearchCV(cv=5, estimator=RandomForestClassifier(), n_jobs=50,\n",
      "             param_grid={'criterion': ['gini', 'entropy', 'log_loss'],\n",
      "                         'max_depth': [2, 3, 5, 7, 10, 15, 20, 25, 30],\n",
      "                         'n_estimators': [3, 5, 10, 15, 21, 30, 50, 75, 100]},\n",
      "             return_train_score=True, scoring='f1', verbose=2) \n",
      "        Best model: GridSearchCV(cv=5, estimator=RandomForestClassifier(), n_jobs=50,\n",
      "             param_grid={'criterion': ['gini', 'entropy', 'log_loss'],\n",
      "                         'max_depth': [2, 3, 5, 7, 10, 15, 20, 25, 30],\n",
      "                         'n_estimators': [3, 5, 10, 15, 21, 30, 50, 75, 100]},\n",
      "             return_train_score=True, scoring='f1', verbose=2) \n",
      "        Best estimator of the model: RandomForestClassifier(max_depth=5, n_estimators=10) \n",
      "        Best parameters of the model: {'criterion': 'gini', 'max_depth': 5, 'n_estimators': 10} \n",
      "        ---------------------------------------------------------------------------------------------------\n",
      "        \n",
      "\n",
      "            *** ML MODEL FOR TEST:1, TRAINING:1 AND MODEL: GB \n",
      "            ---------------------------------------------------------------------------------------------------\n",
      "            \n",
      "Calling method: gradient_boosting_parameters\n",
      "All parameters: ['n_estimators', 'max_depth', 'learning_rate', 'max_features', 'loss', 'min_samples_split', 'min_samples_leaf'], [[3, 5, 10, 15, 21, 30, 50, 75, 100], [2, 3, 5, 7, 10, 15, 20, 25, 30], [0.01, 0.05, 0.1, 0.5, 1.0]], [0, 1, 2]\n",
      "Parameters:  {'n_estimators': [3, 5, 10, 15, 21, 30, 50, 75, 100], 'max_depth': [2, 3, 5, 7, 10, 15, 20, 25, 30], 'learning_rate': [0.01, 0.05, 0.1, 0.5, 1.0]}\n",
      "\n",
      "        From training? True, Data shape: (146, 38), Indices: [ 30  25 147 165 127  50 115  88 137 122  21  51 146  40  80  68  46   3\n",
      "  52  37  19  85 162 136  77  82 138  28 101 103  92  79 140 104  76  54\n",
      " 108  96  47  14  60 117  86  84  24  45 145 164 123  43 102  71 121  27\n",
      " 154  31 149 134 150 151  65   9  33  55  13  94  90 114 153  98  20  99\n",
      "  62  18 141 157 118 142   1  89  57  72  83 158 155 107  29 128 116  74\n",
      " 135 112  41  81  17   4 126  58 148  95 113  78 159  97 109  35  23  64\n",
      "  26 161 110  38 119 132   2 124  91 133  87  39  67 100  66  36 130  22\n",
      "   8 106 144  15  61  12  56  49   6  16   5   0 125 152   7  69  53 111\n",
      " 160  70]\n",
      "        All Columns: ['Dataset', 'Category', 'Subject_Name', 'Class', 'W->S1', 'W->S2', 'W->S3', 'W->S4', 'W->REM', 'S1->W', 'S1->S1', 'S1->S2', 'S1->S3', 'S1->S4', 'S1->REM', 'S2->W', 'S2->S1', 'S2->S2', 'S2->S3', 'S2->S4', 'S2->REM', 'S3->W', 'S3->S1', 'S3->S2', 'S3->S3', 'S3->S4', 'S3->REM', 'S4->W', 'S4->S1', 'S4->S2', 'S4->S3', 'S4->S4', 'S4->REM', 'REM->W', 'REM->S1', 'REM->S2', 'REM->S3', 'REM->REM']\n",
      "        \n",
      "\n",
      "        Feature shape: (146, 34), Target shape: (146,), Metadata: (146, 3) \n",
      "        \n",
      "\n",
      "        GridSearch: GB - {'n_estimators': [3, 5, 10, 15, 21, 30, 50, 75, 100], 'max_depth': [2, 3, 5, 7, 10, 15, 20, 25, 30], 'learning_rate': [0.01, 0.05, 0.1, 0.5, 1.0]} \n",
      "        ---------------------------------------------------------------------------------------------------\n",
      "        \n",
      "Refitting the model with best parameter f1 == True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aliem\\.conda\\envs\\MyPython37Work\\lib\\site-packages\\sklearn\\model_selection\\_search.py:921: UserWarning: One or more of the test scores are non-finite: [0.84695696 0.90178083 0.90778684 0.92059051 0.92059051 0.92059051\n",
      " 0.92059051 0.92059051 0.92059051 0.87811858 0.93167276 0.91417339\n",
      " 0.90735521 0.91417339 0.92059051 0.92059051 0.92059051 0.92059051\n",
      " 0.91289194 0.87284271 0.93677786 0.9070821  0.91955155 0.92059051\n",
      " 0.92059051 0.92059051 0.91420395 0.89934641 0.84984403 0.88766017\n",
      " 0.90468014 0.92465665 0.93107376 0.92059051 0.91420395 0.90778684\n",
      " 0.91780303 0.88598967 0.89370003 0.9078174  0.91417339 0.9050348\n",
      " 0.92525565 0.91289194 0.90778684 0.83581594 0.90237287 0.889266\n",
      " 0.9306338  0.91313443 0.92468721 0.92525565 0.91417339 0.91417339\n",
      " 0.83591083 0.89102313 0.90339738 0.91289194 0.91185298 0.91289194\n",
      " 0.92596866 0.9192785  0.91289194 0.88428317 0.92523024 0.88757448\n",
      " 0.9192785  0.91420395 0.91253544 0.91417339 0.90778684 0.92059051\n",
      " 0.89100312 0.89341887 0.90408964 0.92465665 0.92364825 0.91930906\n",
      " 0.91955155 0.91420395 0.91289194 0.90428922 0.90273803 0.92059051\n",
      " 0.92059051 0.91417339 0.92059051 0.92059051 0.92059051 0.92059051\n",
      " 0.8874297  0.90805507 0.91417339 0.91420395 0.91417339 0.91417339\n",
      " 0.91417339 0.91417339 0.92059051 0.80971326 0.88009613 0.90039593\n",
      " 0.91289194 0.91316499 0.92059051 0.91930906 0.92059051 0.92059051\n",
      " 0.88162361 0.88759227 0.91650242 0.9182701  0.91955155 0.91289194\n",
      " 0.90778684 0.9239742  0.90778684 0.88619939 0.89086156 0.91002637\n",
      " 0.91289194 0.91420395 0.92465665 0.91289194 0.90778684 0.91417339\n",
      " 0.88510759 0.8831463  0.91679951 0.92424724 0.91327731 0.92465665\n",
      " 0.92465665 0.90778684 0.90778684 0.8683518  0.92298447 0.93516488\n",
      " 0.91289194 0.92596866 0.9306338  0.92059051 0.90778684 0.91316499\n",
      " 0.90320819 0.88780848 0.91576055 0.91176952 0.92569561 0.91420395\n",
      " 0.90778684 0.91316499 0.92468721 0.85819137 0.92858085 0.89081169\n",
      " 0.90096866 0.92596866 0.93134681 0.91417339 0.92596866 0.92364825\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan]\n",
      "  category=UserWarning\n",
      "C:\\Users\\aliem\\.conda\\envs\\MyPython37Work\\lib\\site-packages\\sklearn\\model_selection\\_search.py:921: UserWarning: One or more of the train scores are non-finite: [0.91998484 0.91867428 0.91839142 0.91892272 0.92177987 0.92046274\n",
      " 0.92046274 0.92046274 0.92177987 0.92428188 0.93197335 0.93386638\n",
      " 0.9257491  0.93376636 0.92973878 0.93105739 0.93105739 0.92704727\n",
      " 0.94861412 0.97600482 0.97445699 0.97306648 0.9774412  0.9803814\n",
      " 0.98193019 0.97894478 0.98341135 0.97266686 0.98790034 0.9923422\n",
      " 0.99544298 0.99083916 0.99544298 1.         1.         1.\n",
      " 0.98158052 0.98787773 0.99847328 0.99692289 0.99694656 0.99847328\n",
      " 1.         1.         1.         0.97880247 0.98778626 1.\n",
      " 0.99847328 0.99539618 1.         1.         1.         1.\n",
      " 0.97100892 0.98926582 0.99391626 1.         0.99847328 1.\n",
      " 1.         1.         1.         0.97077056 0.98928895 0.99689848\n",
      " 0.99539618 0.99844961 1.         1.         1.         1.\n",
      " 0.98329864 0.98623552 0.99227136 0.99544298 0.99847328 1.\n",
      " 0.99847328 1.         1.         0.91261744 0.91493024 0.92307844\n",
      " 0.92046274 0.92285394 0.92439556 0.92046274 0.92046274 0.92046274\n",
      " 0.93749569 0.9336151  0.9406233  0.94190067 0.92973741 0.92704876\n",
      " 0.92571268 0.92309699 0.92704876 0.95333243 0.965587   0.97299413\n",
      " 0.98035982 0.97607214 0.9803814  0.98049311 0.98044737 0.98345506\n",
      " 0.96773744 0.98183938 0.99389259 0.99694656 0.99847328 0.99694656\n",
      " 0.99847328 1.         1.         0.97540738 0.99079235 0.99694656\n",
      " 0.99692289 1.         1.         1.         1.         1.\n",
      " 0.97275335 0.98151101 0.99539618 0.99544298 1.         0.99847328\n",
      " 1.         1.         1.         0.98160782 0.98613788 0.99539618\n",
      " 0.9969697  0.99539618 0.99844961 1.         1.         1.\n",
      " 0.97966804 0.97883119 0.9984252  0.99844961 1.         1.\n",
      " 1.         1.         1.         0.97702427 0.99231944 0.99844961\n",
      " 0.99544298 1.         0.99847328 1.         1.         1.\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan]\n",
      "  category=UserWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 405 candidates, totalling 2025 fits\n",
      "\n",
      "        From training? False, Data shape: (20, 38), Indices: [ 63  11 143 139 129  42  75  48  93  44 131 120  59 156  10  73 105  34\n",
      " 163  32]\n",
      "        All Columns: ['Dataset', 'Category', 'Subject_Name', 'Class', 'W->S1', 'W->S2', 'W->S3', 'W->S4', 'W->REM', 'S1->W', 'S1->S1', 'S1->S2', 'S1->S3', 'S1->S4', 'S1->REM', 'S2->W', 'S2->S1', 'S2->S2', 'S2->S3', 'S2->S4', 'S2->REM', 'S3->W', 'S3->S1', 'S3->S2', 'S3->S3', 'S3->S4', 'S3->REM', 'S4->W', 'S4->S1', 'S4->S2', 'S4->S3', 'S4->S4', 'S4->REM', 'REM->W', 'REM->S1', 'REM->S2', 'REM->S3', 'REM->REM']\n",
      "        \n",
      "\n",
      "        Feature shape: (20, 34), Target shape: (20,), Metadata: (20, 3) \n",
      "        \n",
      "[0 1] [0 1]\n",
      "[1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1] [1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0]\n",
      "[[7 2]\n",
      " [2 9]]\n",
      "[[9 2 2 7]\n",
      " [7 2 2 9]]\n",
      "[[16  4]\n",
      " [ 4 16]]\n",
      "Class-wise info: For multilevel internal scores fo label 0: \n",
      " Accuracy = 80.0\n",
      " Precision = [0.81818182 0.77777778]\n",
      " Recall = [0.81818182 0.77777778]\n",
      " F1 score = [0.81818182 0.77777778]\n",
      " AUC score = 79.79797979797979\n",
      " Support = [11  9]\n",
      "\n",
      "Class-wise info: For multilevel internal scores fo label 1: \n",
      " Accuracy = 80.0\n",
      " Precision = [0.77777778 0.81818182]\n",
      " Recall = [0.77777778 0.81818182]\n",
      " F1 score = [0.77777778 0.81818182]\n",
      " AUC score = 79.7979797979798\n",
      " Support = [ 9 11]\n",
      "\n",
      "CLASSIFICATION MERICS:\n",
      " _______________________________________________________\n",
      " Confusion Matrix: \n",
      "[[7 2]\n",
      " [2 9]]\n",
      " Accuracy (acc): 80.0\n",
      " Precision (prc): 81.818\n",
      " Recall (rec): 81.818\n",
      " Sensitivity (sns): 81.818\n",
      " Specificity (spc): 77.778\n",
      " F1 Score (f1s): 81.818\n",
      " ROC AUC (AUC): 0.798\n",
      "Score columns: (1, 12) ['method', 'model', 'model_parameters', 'model_scores', 'confusion_matrix', 'accuracy', 'precision', 'recall', 'sensitivity', 'specificity', 'f1_score', 'roc_auc']\n",
      "\n",
      "        Best model (GriveSearchCV): GridSearchCV(cv=5, estimator=GradientBoostingClassifier(), n_jobs=50,\n",
      "             param_grid={'learning_rate': [0.01, 0.05, 0.1, 0.5, 1.0],\n",
      "                         'max_depth': [2, 3, 5, 7, 10, 15, 20, 25, 30],\n",
      "                         'n_estimators': [3, 5, 10, 15, 21, 30, 50, 75, 100]},\n",
      "             return_train_score=True, scoring='f1', verbose=2) \n",
      "        Best model: GridSearchCV(cv=5, estimator=GradientBoostingClassifier(), n_jobs=50,\n",
      "             param_grid={'learning_rate': [0.01, 0.05, 0.1, 0.5, 1.0],\n",
      "                         'max_depth': [2, 3, 5, 7, 10, 15, 20, 25, 30],\n",
      "                         'n_estimators': [3, 5, 10, 15, 21, 30, 50, 75, 100]},\n",
      "             return_train_score=True, scoring='f1', verbose=2) \n",
      "        Best estimator of the model: GradientBoostingClassifier(learning_rate=0.5, n_estimators=21) \n",
      "        Best parameters of the model: {'learning_rate': 0.5, 'max_depth': 3, 'n_estimators': 21} \n",
      "        ---------------------------------------------------------------------------------------------------\n",
      "        \n",
      "\n",
      "            ---------------------------------------------------------------------------------------------------\n",
      "            Best model index calculation  \n",
      "            \n",
      "\n",
      "            ***************************************************************************************************\n",
      "            TRAINING 1 END... \n",
      "            \n",
      "\n",
      "            *** MODEL TRAINING AND VALIDATION PHASE FOR TEST 1 \n",
      "            TRAINING 2 START... XXXXX \n",
      "            ***************************************************************************************************\n",
      "            Validation=> 20 ['SC4241', 'SC4441', 'SC4401', 'SC4261', 'nfle10', 'nfle15', 'SC4321', 'plm8', 'nfle8', 'plm1', 'rbd21', 'SC4011', 'ins2', 'SC4541', 'nfle37', 'nfle27', 'SC4021', 'n14', 'SC4371', 'rbd2'] \n",
      "            Training=> 146 ['SC4141', 'n16', 'SC4251', 'SC4411', 'sdb1', 'SC4161', 'nfle29', 'nfle2', 'SC4311', 'rbd13', 'rbd5', 'rbd19', 'SC4461', 'SC4331', 'plm10', 'nfle22', 'SC4211', 'rbd12', 'SC4531', 'SC4581', 'SC4231', 'nfle12', 'SC4091', 'SC4471', 'n4', 'SC4381', 'n6', 'SC4362', 'nfle16', 'n8', 'n15', 'n1', 'rbd18', 'SC4491', 'rbd15', 'nfle4', 'brux1', 'narco1', 'SC4571', 'nfle34', 'nfle5', 'SC4131', 'plm6', 'SC4151', 'SC4301', 'rbd20', 'rbd7', 'ins9', 'rbd9', 'nfle18', 'SC4061', 'SC4431', 'rbd10', 'SC4501', 'SC4481', 'plm2', 'SC4201', 'rbd14', 'nfle20', 'ins7', 'narco5', 'narco4', 'SC4451', 'nfle26', 'rbd16', 'SC4051', 'nfle1', 'plm9', 'SC4271', 'ins5', 'nfle11', 'SC4171', 'SC4522', 'nfle36', 'SC4071', 'rbd3', 'narco3', 'nfle32', 'ins4', 'nfle17', 'nfle14', 'rbd11', 'n12', 'sdb2', 'n3', 'SC4191', 'nfle23', 'SC4341', 'plm5', 'ins3', 'n9', 'SC4181', 'n2', 'ins1', 'rbd4', 'rbd8', 'nfle38', 'SC4351', 'narco2', 'SC4031', 'SC4121', 'SC4221', 'n7', 'n11', 'nfle25', 'SC4111', 'plm4', 'SC4291', 'plm3', 'rbd17', 'nfle7', 'nfle30', 'SC4281', 'ins8', 'rbd1', 'n13', 'nfle13', 'SC4551', 'SC4001', 'SC4421', 'SC4561', 'SC4511', 'plm7', 'SC4101', 'SC4041', 'nfle28', 'brux2', 'rbd22', 'nfle33', 'nfle21', 'nfle19', 'sdb3', 'nfle35', 'nfle3', 'rbd6', 'n10', 'nfle31', 'n5', 'ins6', 'nfle9', 'nfle6', 'sdb4', 'nfle24', 'nfle39', 'nfle40', 'SC4081'] \n",
      "            \n",
      "\n",
      "            *** ML MODEL FOR TEST:1, TRAINING:2 AND MODEL: LR \n",
      "            ---------------------------------------------------------------------------------------------------\n",
      "            \n",
      "Calling method: logistic_regression_parameters\n",
      "All parameters: ['penalty', 'solver', 'max_iter', 'C'], [['l2', 'elasticnet'], [50, 100, 130, 150, 170, 200], [0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1.0]], [0, 2, 3]\n",
      "Parameters:  {'penalty': ['l2', 'elasticnet'], 'max_iter': [50, 100, 130, 150, 170, 200], 'C': [0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1.0]}\n",
      "\n",
      "        From training? True, Data shape: (146, 38), Indices: [122 107 133 148   2 124  48  21 139  82  74  88 153 141  69  41 129  81\n",
      " 160 165 131  31 117 154  95 146  97 144  35  99 106  92  87 156  84  23\n",
      "   0  15 164  53  24 121  65 123 138  89  76  14  78  37 114 150  79 157\n",
      " 155  61 128  83  39  12  19  18 152  45  85 113  20  68 135  10  30 125\n",
      " 159  55 115  72  17  51   9  36  33  80 103   3  94 127  42 142  64   8\n",
      " 100 126  93   6  73  77  57 143  16 111 120 130  98 102  44 119  63 137\n",
      "  62  86  26  49 136  13  70 104  32 162 108 149 163 158  66 118 112  47\n",
      "   1  91  52  40  38   4  54  22  75 101  50  96  11  28  25   5  43  58\n",
      "  59 116]\n",
      "        All Columns: ['Dataset', 'Category', 'Subject_Name', 'Class', 'W->S1', 'W->S2', 'W->S3', 'W->S4', 'W->REM', 'S1->W', 'S1->S1', 'S1->S2', 'S1->S3', 'S1->S4', 'S1->REM', 'S2->W', 'S2->S1', 'S2->S2', 'S2->S3', 'S2->S4', 'S2->REM', 'S3->W', 'S3->S1', 'S3->S2', 'S3->S3', 'S3->S4', 'S3->REM', 'S4->W', 'S4->S1', 'S4->S2', 'S4->S3', 'S4->S4', 'S4->REM', 'REM->W', 'REM->S1', 'REM->S2', 'REM->S3', 'REM->REM']\n",
      "        \n",
      "\n",
      "        Feature shape: (146, 34), Target shape: (146,), Metadata: (146, 3) \n",
      "        \n",
      "\n",
      "        GridSearch: LR - {'penalty': ['l2', 'elasticnet'], 'max_iter': [50, 100, 130, 150, 170, 200], 'C': [0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1.0]} \n",
      "        ---------------------------------------------------------------------------------------------------\n",
      "        \n",
      "Refitting the model with best parameter f1 == True\n",
      "Fitting 5 folds for each of 84 candidates, totalling 420 fits\n",
      "\n",
      "        From training? False, Data shape: (20, 38), Indices: [132 151 147 134  29  34 140  67  27  60  90 109   7 161  56  46 110 105\n",
      " 145  71]\n",
      "        All Columns: ['Dataset', 'Category', 'Subject_Name', 'Class', 'W->S1', 'W->S2', 'W->S3', 'W->S4', 'W->REM', 'S1->W', 'S1->S1', 'S1->S2', 'S1->S3', 'S1->S4', 'S1->REM', 'S2->W', 'S2->S1', 'S2->S2', 'S2->S3', 'S2->S4', 'S2->REM', 'S3->W', 'S3->S1', 'S3->S2', 'S3->S3', 'S3->S4', 'S3->REM', 'S4->W', 'S4->S1', 'S4->S2', 'S4->S3', 'S4->S4', 'S4->REM', 'REM->W', 'REM->S1', 'REM->S2', 'REM->S3', 'REM->REM']\n",
      "        \n",
      "\n",
      "        Feature shape: (20, 34), Target shape: (20,), Metadata: (20, 3) \n",
      "        \n",
      "[0 1] [0 1]\n",
      "[0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1] [0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1]\n",
      "[[9 1]\n",
      " [1 9]]\n",
      "[[9 1 1 9]\n",
      " [9 1 1 9]]\n",
      "[[18  2]\n",
      " [ 2 18]]\n",
      "Class-wise info: For multilevel internal scores fo label 0: \n",
      " Accuracy = 90.0\n",
      " Precision = [0.9 0.9]\n",
      " Recall = [0.9 0.9]\n",
      " F1 score = [0.9 0.9]\n",
      " AUC score = 90.0\n",
      " Support = [10 10]\n",
      "\n",
      "Class-wise info: For multilevel internal scores fo label 1: \n",
      " Accuracy = 90.0\n",
      " Precision = [0.9 0.9]\n",
      " Recall = [0.9 0.9]\n",
      " F1 score = [0.9 0.9]\n",
      " AUC score = 90.0\n",
      " Support = [10 10]\n",
      "\n",
      "CLASSIFICATION MERICS:\n",
      " _______________________________________________________\n",
      " Confusion Matrix: \n",
      "[[9 1]\n",
      " [1 9]]\n",
      " Accuracy (acc): 90.0\n",
      " Precision (prc): 90.0\n",
      " Recall (rec): 90.0\n",
      " Sensitivity (sns): 90.0\n",
      " Specificity (spc): 90.0\n",
      " F1 Score (f1s): 90.0\n",
      " ROC AUC (AUC): 0.9\n",
      "Score columns: (1, 12) ['method', 'model', 'model_parameters', 'model_scores', 'confusion_matrix', 'accuracy', 'precision', 'recall', 'sensitivity', 'specificity', 'f1_score', 'roc_auc']\n",
      "\n",
      "        Best model (GriveSearchCV): GridSearchCV(cv=5, estimator=LogisticRegression(), n_jobs=50,\n",
      "             param_grid={'C': [0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1.0],\n",
      "                         'max_iter': [50, 100, 130, 150, 170, 200],\n",
      "                         'penalty': ['l2', 'elasticnet']},\n",
      "             return_train_score=True, scoring='f1', verbose=2) \n",
      "        Best model: GridSearchCV(cv=5, estimator=LogisticRegression(), n_jobs=50,\n",
      "             param_grid={'C': [0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1.0],\n",
      "                         'max_iter': [50, 100, 130, 150, 170, 200],\n",
      "                         'penalty': ['l2', 'elasticnet']},\n",
      "             return_train_score=True, scoring='f1', verbose=2) \n",
      "        Best estimator of the model: LogisticRegression(max_iter=50) \n",
      "        Best parameters of the model: {'C': 1.0, 'max_iter': 50, 'penalty': 'l2'} \n",
      "        ---------------------------------------------------------------------------------------------------\n",
      "        \n",
      "\n",
      "            *** ML MODEL FOR TEST:1, TRAINING:2 AND MODEL: SVC \n",
      "            ---------------------------------------------------------------------------------------------------\n",
      "            \n",
      "Calling method: support_vector_classifier_parameters\n",
      "All parameters: ['probability', 'C', 'kernel', 'gamma', 'degree', 'class_weightdict'], [[True], [0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1.0], ['linear', 'rbf', 'poly']], [0, 1, 2]\n",
      "Parameters:  {'probability': [True], 'C': [0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1.0], 'kernel': ['linear', 'rbf', 'poly']}\n",
      "\n",
      "        From training? True, Data shape: (146, 38), Indices: [122 107 133 148   2 124  48  21 139  82  74  88 153 141  69  41 129  81\n",
      " 160 165 131  31 117 154  95 146  97 144  35  99 106  92  87 156  84  23\n",
      "   0  15 164  53  24 121  65 123 138  89  76  14  78  37 114 150  79 157\n",
      " 155  61 128  83  39  12  19  18 152  45  85 113  20  68 135  10  30 125\n",
      " 159  55 115  72  17  51   9  36  33  80 103   3  94 127  42 142  64   8\n",
      " 100 126  93   6  73  77  57 143  16 111 120 130  98 102  44 119  63 137\n",
      "  62  86  26  49 136  13  70 104  32 162 108 149 163 158  66 118 112  47\n",
      "   1  91  52  40  38   4  54  22  75 101  50  96  11  28  25   5  43  58\n",
      "  59 116]\n",
      "        All Columns: ['Dataset', 'Category', 'Subject_Name', 'Class', 'W->S1', 'W->S2', 'W->S3', 'W->S4', 'W->REM', 'S1->W', 'S1->S1', 'S1->S2', 'S1->S3', 'S1->S4', 'S1->REM', 'S2->W', 'S2->S1', 'S2->S2', 'S2->S3', 'S2->S4', 'S2->REM', 'S3->W', 'S3->S1', 'S3->S2', 'S3->S3', 'S3->S4', 'S3->REM', 'S4->W', 'S4->S1', 'S4->S2', 'S4->S3', 'S4->S4', 'S4->REM', 'REM->W', 'REM->S1', 'REM->S2', 'REM->S3', 'REM->REM']\n",
      "        \n",
      "\n",
      "        Feature shape: (146, 34), Target shape: (146,), Metadata: (146, 3) \n",
      "        \n",
      "\n",
      "        GridSearch: SVC - {'probability': [True], 'C': [0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1.0], 'kernel': ['linear', 'rbf', 'poly']} \n",
      "        ---------------------------------------------------------------------------------------------------\n",
      "        \n",
      "Refitting the model with best parameter f1 == True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aliem\\.conda\\envs\\MyPython37Work\\lib\\site-packages\\sklearn\\model_selection\\_search.py:921: UserWarning: One or more of the test scores are non-finite: [0.7191736         nan 0.7191736         nan 0.7191736         nan\n",
      " 0.7191736         nan 0.7191736         nan 0.7191736         nan\n",
      " 0.7191736         nan 0.7191736         nan 0.7191736         nan\n",
      " 0.7191736         nan 0.7191736         nan 0.7191736         nan\n",
      " 0.7191736         nan 0.7191736         nan 0.7191736         nan\n",
      " 0.7191736         nan 0.7191736         nan 0.7191736         nan\n",
      " 0.84220484        nan 0.84220484        nan 0.84220484        nan\n",
      " 0.84220484        nan 0.84220484        nan 0.84220484        nan\n",
      " 0.87678927        nan 0.87678927        nan 0.87678927        nan\n",
      " 0.87678927        nan 0.87678927        nan 0.87678927        nan\n",
      " 0.88295827        nan 0.88295827        nan 0.88295827        nan\n",
      " 0.88295827        nan 0.88295827        nan 0.88295827        nan\n",
      " 0.90532819        nan 0.90532819        nan 0.90532819        nan\n",
      " 0.90532819        nan 0.90532819        nan 0.90532819        nan]\n",
      "  category=UserWarning\n",
      "C:\\Users\\aliem\\.conda\\envs\\MyPython37Work\\lib\\site-packages\\sklearn\\model_selection\\_search.py:921: UserWarning: One or more of the train scores are non-finite: [0.71929044        nan 0.71929044        nan 0.71929044        nan\n",
      " 0.71929044        nan 0.71929044        nan 0.71929044        nan\n",
      " 0.71929044        nan 0.71929044        nan 0.71929044        nan\n",
      " 0.71929044        nan 0.71929044        nan 0.71929044        nan\n",
      " 0.7200797         nan 0.7200797         nan 0.7200797         nan\n",
      " 0.7200797         nan 0.7200797         nan 0.7200797         nan\n",
      " 0.84214248        nan 0.84214248        nan 0.84214248        nan\n",
      " 0.84214248        nan 0.84214248        nan 0.84214248        nan\n",
      " 0.87557072        nan 0.87557072        nan 0.87557072        nan\n",
      " 0.87557072        nan 0.87557072        nan 0.87557072        nan\n",
      " 0.89812996        nan 0.89812996        nan 0.89812996        nan\n",
      " 0.89812996        nan 0.89812996        nan 0.89812996        nan\n",
      " 0.90833159        nan 0.90833159        nan 0.90833159        nan\n",
      " 0.90833159        nan 0.90833159        nan 0.90833159        nan]\n",
      "  category=UserWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 21 candidates, totalling 105 fits\n",
      "\n",
      "        From training? False, Data shape: (20, 38), Indices: [132 151 147 134  29  34 140  67  27  60  90 109   7 161  56  46 110 105\n",
      " 145  71]\n",
      "        All Columns: ['Dataset', 'Category', 'Subject_Name', 'Class', 'W->S1', 'W->S2', 'W->S3', 'W->S4', 'W->REM', 'S1->W', 'S1->S1', 'S1->S2', 'S1->S3', 'S1->S4', 'S1->REM', 'S2->W', 'S2->S1', 'S2->S2', 'S2->S3', 'S2->S4', 'S2->REM', 'S3->W', 'S3->S1', 'S3->S2', 'S3->S3', 'S3->S4', 'S3->REM', 'S4->W', 'S4->S1', 'S4->S2', 'S4->S3', 'S4->S4', 'S4->REM', 'REM->W', 'REM->S1', 'REM->S2', 'REM->S3', 'REM->REM']\n",
      "        \n",
      "\n",
      "        Feature shape: (20, 34), Target shape: (20,), Metadata: (20, 3) \n",
      "        \n",
      "[0 1] [0 1]\n",
      "[0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1] [0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1]\n",
      "[[ 9  1]\n",
      " [ 0 10]]\n",
      "[[10  0  1  9]\n",
      " [ 9  1  0 10]]\n",
      "[[19  1]\n",
      " [ 1 19]]\n",
      "Class-wise info: For multilevel internal scores fo label 0: \n",
      " Accuracy = 95.0\n",
      " Precision = [0.90909091 1.        ]\n",
      " Recall = [1.  0.9]\n",
      " F1 score = [0.95238095 0.94736842]\n",
      " AUC score = 95.0\n",
      " Support = [10 10]\n",
      "\n",
      "Class-wise info: For multilevel internal scores fo label 1: \n",
      " Accuracy = 95.0\n",
      " Precision = [1.         0.90909091]\n",
      " Recall = [0.9 1. ]\n",
      " F1 score = [0.94736842 0.95238095]\n",
      " AUC score = 95.0\n",
      " Support = [10 10]\n",
      "\n",
      "CLASSIFICATION MERICS:\n",
      " _______________________________________________________\n",
      " Confusion Matrix: \n",
      "[[ 9  1]\n",
      " [ 0 10]]\n",
      " Accuracy (acc): 95.0\n",
      " Precision (prc): 90.909\n",
      " Recall (rec): 100.0\n",
      " Sensitivity (sns): 100.0\n",
      " Specificity (spc): 90.0\n",
      " F1 Score (f1s): 95.238\n",
      " ROC AUC (AUC): 0.95\n",
      "Score columns: (1, 12) ['method', 'model', 'model_parameters', 'model_scores', 'confusion_matrix', 'accuracy', 'precision', 'recall', 'sensitivity', 'specificity', 'f1_score', 'roc_auc']\n",
      "\n",
      "        Best model (GriveSearchCV): GridSearchCV(cv=5, estimator=SVC(), n_jobs=50,\n",
      "             param_grid={'C': [0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1.0],\n",
      "                         'kernel': ['linear', 'rbf', 'poly'],\n",
      "                         'probability': [True]},\n",
      "             return_train_score=True, scoring='f1', verbose=2) \n",
      "        Best model: GridSearchCV(cv=5, estimator=SVC(), n_jobs=50,\n",
      "             param_grid={'C': [0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1.0],\n",
      "                         'kernel': ['linear', 'rbf', 'poly'],\n",
      "                         'probability': [True]},\n",
      "             return_train_score=True, scoring='f1', verbose=2) \n",
      "        Best estimator of the model: SVC(kernel='linear', probability=True) \n",
      "        Best parameters of the model: {'C': 1.0, 'kernel': 'linear', 'probability': True} \n",
      "        ---------------------------------------------------------------------------------------------------\n",
      "        \n",
      "\n",
      "            *** ML MODEL FOR TEST:1, TRAINING:2 AND MODEL: NB \n",
      "            ---------------------------------------------------------------------------------------------------\n",
      "            \n",
      "Calling method: naive_bayes_parameters\n",
      "All parameters: ['var_smoothing'], [[1.0, 0.005623413251903491, 3.1622776601683795e-05, 1.7782794100389227e-07, 1e-09]], [0]\n",
      "Parameters:  {'var_smoothing': [1.0, 0.005623413251903491, 3.1622776601683795e-05, 1.7782794100389227e-07, 1e-09]}\n",
      "\n",
      "        From training? True, Data shape: (146, 38), Indices: [122 107 133 148   2 124  48  21 139  82  74  88 153 141  69  41 129  81\n",
      " 160 165 131  31 117 154  95 146  97 144  35  99 106  92  87 156  84  23\n",
      "   0  15 164  53  24 121  65 123 138  89  76  14  78  37 114 150  79 157\n",
      " 155  61 128  83  39  12  19  18 152  45  85 113  20  68 135  10  30 125\n",
      " 159  55 115  72  17  51   9  36  33  80 103   3  94 127  42 142  64   8\n",
      " 100 126  93   6  73  77  57 143  16 111 120 130  98 102  44 119  63 137\n",
      "  62  86  26  49 136  13  70 104  32 162 108 149 163 158  66 118 112  47\n",
      "   1  91  52  40  38   4  54  22  75 101  50  96  11  28  25   5  43  58\n",
      "  59 116]\n",
      "        All Columns: ['Dataset', 'Category', 'Subject_Name', 'Class', 'W->S1', 'W->S2', 'W->S3', 'W->S4', 'W->REM', 'S1->W', 'S1->S1', 'S1->S2', 'S1->S3', 'S1->S4', 'S1->REM', 'S2->W', 'S2->S1', 'S2->S2', 'S2->S3', 'S2->S4', 'S2->REM', 'S3->W', 'S3->S1', 'S3->S2', 'S3->S3', 'S3->S4', 'S3->REM', 'S4->W', 'S4->S1', 'S4->S2', 'S4->S3', 'S4->S4', 'S4->REM', 'REM->W', 'REM->S1', 'REM->S2', 'REM->S3', 'REM->REM']\n",
      "        \n",
      "\n",
      "        Feature shape: (146, 34), Target shape: (146,), Metadata: (146, 3) \n",
      "        \n",
      "\n",
      "        GridSearch: NB - {'var_smoothing': [1.0, 0.005623413251903491, 3.1622776601683795e-05, 1.7782794100389227e-07, 1e-09]} \n",
      "        ---------------------------------------------------------------------------------------------------\n",
      "        \n",
      "Refitting the model with best parameter f1 == True\n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "\n",
      "        From training? False, Data shape: (20, 38), Indices: [132 151 147 134  29  34 140  67  27  60  90 109   7 161  56  46 110 105\n",
      " 145  71]\n",
      "        All Columns: ['Dataset', 'Category', 'Subject_Name', 'Class', 'W->S1', 'W->S2', 'W->S3', 'W->S4', 'W->REM', 'S1->W', 'S1->S1', 'S1->S2', 'S1->S3', 'S1->S4', 'S1->REM', 'S2->W', 'S2->S1', 'S2->S2', 'S2->S3', 'S2->S4', 'S2->REM', 'S3->W', 'S3->S1', 'S3->S2', 'S3->S3', 'S3->S4', 'S3->REM', 'S4->W', 'S4->S1', 'S4->S2', 'S4->S3', 'S4->S4', 'S4->REM', 'REM->W', 'REM->S1', 'REM->S2', 'REM->S3', 'REM->REM']\n",
      "        \n",
      "\n",
      "        Feature shape: (20, 34), Target shape: (20,), Metadata: (20, 3) \n",
      "        \n",
      "[0 1] [0 1]\n",
      "[0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1] [0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1]\n",
      "[[9 1]\n",
      " [1 9]]\n",
      "[[9 1 1 9]\n",
      " [9 1 1 9]]\n",
      "[[18  2]\n",
      " [ 2 18]]\n",
      "Class-wise info: For multilevel internal scores fo label 0: \n",
      " Accuracy = 90.0\n",
      " Precision = [0.9 0.9]\n",
      " Recall = [0.9 0.9]\n",
      " F1 score = [0.9 0.9]\n",
      " AUC score = 90.0\n",
      " Support = [10 10]\n",
      "\n",
      "Class-wise info: For multilevel internal scores fo label 1: \n",
      " Accuracy = 90.0\n",
      " Precision = [0.9 0.9]\n",
      " Recall = [0.9 0.9]\n",
      " F1 score = [0.9 0.9]\n",
      " AUC score = 90.0\n",
      " Support = [10 10]\n",
      "\n",
      "CLASSIFICATION MERICS:\n",
      " _______________________________________________________\n",
      " Confusion Matrix: \n",
      "[[9 1]\n",
      " [1 9]]\n",
      " Accuracy (acc): 90.0\n",
      " Precision (prc): 90.0\n",
      " Recall (rec): 90.0\n",
      " Sensitivity (sns): 90.0\n",
      " Specificity (spc): 90.0\n",
      " F1 Score (f1s): 90.0\n",
      " ROC AUC (AUC): 0.9\n",
      "Score columns: (1, 12) ['method', 'model', 'model_parameters', 'model_scores', 'confusion_matrix', 'accuracy', 'precision', 'recall', 'sensitivity', 'specificity', 'f1_score', 'roc_auc']\n",
      "\n",
      "        Best model (GriveSearchCV): GridSearchCV(cv=5, estimator=GaussianNB(), n_jobs=50,\n",
      "             param_grid={'var_smoothing': [1.0, 0.005623413251903491,\n",
      "                                           3.1622776601683795e-05,\n",
      "                                           1.7782794100389227e-07, 1e-09]},\n",
      "             return_train_score=True, scoring='f1', verbose=2) \n",
      "        Best model: GridSearchCV(cv=5, estimator=GaussianNB(), n_jobs=50,\n",
      "             param_grid={'var_smoothing': [1.0, 0.005623413251903491,\n",
      "                                           3.1622776601683795e-05,\n",
      "                                           1.7782794100389227e-07, 1e-09]},\n",
      "             return_train_score=True, scoring='f1', verbose=2) \n",
      "        Best estimator of the model: GaussianNB(var_smoothing=0.005623413251903491) \n",
      "        Best parameters of the model: {'var_smoothing': 0.005623413251903491} \n",
      "        ---------------------------------------------------------------------------------------------------\n",
      "        \n",
      "\n",
      "            *** ML MODEL FOR TEST:1, TRAINING:2 AND MODEL: KNN \n",
      "            ---------------------------------------------------------------------------------------------------\n",
      "            \n",
      "Calling method: k_nearest_neighbors_parameters\n",
      "All parameters: ['n_neighbors', 'p', 'metric', 'n_splits'], [[2, 3, 5, 10, 15, 25, 35], ['manhattan', 'minkowski', 'euclidean']], [0, 2]\n",
      "Parameters:  {'n_neighbors': [2, 3, 5, 10, 15, 25, 35], 'metric': ['manhattan', 'minkowski', 'euclidean']}\n",
      "\n",
      "        From training? True, Data shape: (146, 38), Indices: [122 107 133 148   2 124  48  21 139  82  74  88 153 141  69  41 129  81\n",
      " 160 165 131  31 117 154  95 146  97 144  35  99 106  92  87 156  84  23\n",
      "   0  15 164  53  24 121  65 123 138  89  76  14  78  37 114 150  79 157\n",
      " 155  61 128  83  39  12  19  18 152  45  85 113  20  68 135  10  30 125\n",
      " 159  55 115  72  17  51   9  36  33  80 103   3  94 127  42 142  64   8\n",
      " 100 126  93   6  73  77  57 143  16 111 120 130  98 102  44 119  63 137\n",
      "  62  86  26  49 136  13  70 104  32 162 108 149 163 158  66 118 112  47\n",
      "   1  91  52  40  38   4  54  22  75 101  50  96  11  28  25   5  43  58\n",
      "  59 116]\n",
      "        All Columns: ['Dataset', 'Category', 'Subject_Name', 'Class', 'W->S1', 'W->S2', 'W->S3', 'W->S4', 'W->REM', 'S1->W', 'S1->S1', 'S1->S2', 'S1->S3', 'S1->S4', 'S1->REM', 'S2->W', 'S2->S1', 'S2->S2', 'S2->S3', 'S2->S4', 'S2->REM', 'S3->W', 'S3->S1', 'S3->S2', 'S3->S3', 'S3->S4', 'S3->REM', 'S4->W', 'S4->S1', 'S4->S2', 'S4->S3', 'S4->S4', 'S4->REM', 'REM->W', 'REM->S1', 'REM->S2', 'REM->S3', 'REM->REM']\n",
      "        \n",
      "\n",
      "        Feature shape: (146, 34), Target shape: (146,), Metadata: (146, 3) \n",
      "        \n",
      "\n",
      "        GridSearch: KNN - {'n_neighbors': [2, 3, 5, 10, 15, 25, 35], 'metric': ['manhattan', 'minkowski', 'euclidean']} \n",
      "        ---------------------------------------------------------------------------------------------------\n",
      "        \n",
      "Refitting the model with best parameter f1 == True\n",
      "Fitting 5 folds for each of 21 candidates, totalling 105 fits\n",
      "\n",
      "        From training? False, Data shape: (20, 38), Indices: [132 151 147 134  29  34 140  67  27  60  90 109   7 161  56  46 110 105\n",
      " 145  71]\n",
      "        All Columns: ['Dataset', 'Category', 'Subject_Name', 'Class', 'W->S1', 'W->S2', 'W->S3', 'W->S4', 'W->REM', 'S1->W', 'S1->S1', 'S1->S2', 'S1->S3', 'S1->S4', 'S1->REM', 'S2->W', 'S2->S1', 'S2->S2', 'S2->S3', 'S2->S4', 'S2->REM', 'S3->W', 'S3->S1', 'S3->S2', 'S3->S3', 'S3->S4', 'S3->REM', 'S4->W', 'S4->S1', 'S4->S2', 'S4->S3', 'S4->S4', 'S4->REM', 'REM->W', 'REM->S1', 'REM->S2', 'REM->S3', 'REM->REM']\n",
      "        \n",
      "\n",
      "        Feature shape: (20, 34), Target shape: (20,), Metadata: (20, 3) \n",
      "        \n",
      "[0 1] [0 1]\n",
      "[0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1] [0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1]\n",
      "[[ 9  1]\n",
      " [ 0 10]]\n",
      "[[10  0  1  9]\n",
      " [ 9  1  0 10]]\n",
      "[[19  1]\n",
      " [ 1 19]]\n",
      "Class-wise info: For multilevel internal scores fo label 0: \n",
      " Accuracy = 95.0\n",
      " Precision = [0.90909091 1.        ]\n",
      " Recall = [1.  0.9]\n",
      " F1 score = [0.95238095 0.94736842]\n",
      " AUC score = 95.0\n",
      " Support = [10 10]\n",
      "\n",
      "Class-wise info: For multilevel internal scores fo label 1: \n",
      " Accuracy = 95.0\n",
      " Precision = [1.         0.90909091]\n",
      " Recall = [0.9 1. ]\n",
      " F1 score = [0.94736842 0.95238095]\n",
      " AUC score = 95.0\n",
      " Support = [10 10]\n",
      "\n",
      "CLASSIFICATION MERICS:\n",
      " _______________________________________________________\n",
      " Confusion Matrix: \n",
      "[[ 9  1]\n",
      " [ 0 10]]\n",
      " Accuracy (acc): 95.0\n",
      " Precision (prc): 90.909\n",
      " Recall (rec): 100.0\n",
      " Sensitivity (sns): 100.0\n",
      " Specificity (spc): 90.0\n",
      " F1 Score (f1s): 95.238\n",
      " ROC AUC (AUC): 0.95\n",
      "Score columns: (1, 12) ['method', 'model', 'model_parameters', 'model_scores', 'confusion_matrix', 'accuracy', 'precision', 'recall', 'sensitivity', 'specificity', 'f1_score', 'roc_auc']\n",
      "\n",
      "        Best model (GriveSearchCV): GridSearchCV(cv=5, estimator=KNeighborsClassifier(), n_jobs=50,\n",
      "             param_grid={'metric': ['manhattan', 'minkowski', 'euclidean'],\n",
      "                         'n_neighbors': [2, 3, 5, 10, 15, 25, 35]},\n",
      "             return_train_score=True, scoring='f1', verbose=2) \n",
      "        Best model: GridSearchCV(cv=5, estimator=KNeighborsClassifier(), n_jobs=50,\n",
      "             param_grid={'metric': ['manhattan', 'minkowski', 'euclidean'],\n",
      "                         'n_neighbors': [2, 3, 5, 10, 15, 25, 35]},\n",
      "             return_train_score=True, scoring='f1', verbose=2) \n",
      "        Best estimator of the model: KNeighborsClassifier(metric='manhattan') \n",
      "        Best parameters of the model: {'metric': 'manhattan', 'n_neighbors': 5} \n",
      "        ---------------------------------------------------------------------------------------------------\n",
      "        \n",
      "\n",
      "            *** ML MODEL FOR TEST:1, TRAINING:2 AND MODEL: DT \n",
      "            ---------------------------------------------------------------------------------------------------\n",
      "            \n",
      "Calling method: decision_tree_parameters\n",
      "All parameters: ['max_depth', 'criterion', 'splitter', 'min_samples_split', 'min_samples_leaf', 'max_leaf_nodes'], [[2, 3, 5, 7, 10, 15, 20, 25, 30], ['gini', 'entropy', 'log_loss']], [0, 1]\n",
      "Parameters:  {'max_depth': [2, 3, 5, 7, 10, 15, 20, 25, 30], 'criterion': ['gini', 'entropy', 'log_loss']}\n",
      "\n",
      "        From training? True, Data shape: (146, 38), Indices: [122 107 133 148   2 124  48  21 139  82  74  88 153 141  69  41 129  81\n",
      " 160 165 131  31 117 154  95 146  97 144  35  99 106  92  87 156  84  23\n",
      "   0  15 164  53  24 121  65 123 138  89  76  14  78  37 114 150  79 157\n",
      " 155  61 128  83  39  12  19  18 152  45  85 113  20  68 135  10  30 125\n",
      " 159  55 115  72  17  51   9  36  33  80 103   3  94 127  42 142  64   8\n",
      " 100 126  93   6  73  77  57 143  16 111 120 130  98 102  44 119  63 137\n",
      "  62  86  26  49 136  13  70 104  32 162 108 149 163 158  66 118 112  47\n",
      "   1  91  52  40  38   4  54  22  75 101  50  96  11  28  25   5  43  58\n",
      "  59 116]\n",
      "        All Columns: ['Dataset', 'Category', 'Subject_Name', 'Class', 'W->S1', 'W->S2', 'W->S3', 'W->S4', 'W->REM', 'S1->W', 'S1->S1', 'S1->S2', 'S1->S3', 'S1->S4', 'S1->REM', 'S2->W', 'S2->S1', 'S2->S2', 'S2->S3', 'S2->S4', 'S2->REM', 'S3->W', 'S3->S1', 'S3->S2', 'S3->S3', 'S3->S4', 'S3->REM', 'S4->W', 'S4->S1', 'S4->S2', 'S4->S3', 'S4->S4', 'S4->REM', 'REM->W', 'REM->S1', 'REM->S2', 'REM->S3', 'REM->REM']\n",
      "        \n",
      "\n",
      "        Feature shape: (146, 34), Target shape: (146,), Metadata: (146, 3) \n",
      "        \n",
      "\n",
      "        GridSearch: DT - {'max_depth': [2, 3, 5, 7, 10, 15, 20, 25, 30], 'criterion': ['gini', 'entropy', 'log_loss']} \n",
      "        ---------------------------------------------------------------------------------------------------\n",
      "        \n",
      "Refitting the model with best parameter f1 == True\n",
      "Fitting 5 folds for each of 27 candidates, totalling 135 fits\n",
      "\n",
      "        From training? False, Data shape: (20, 38), Indices: [132 151 147 134  29  34 140  67  27  60  90 109   7 161  56  46 110 105\n",
      " 145  71]\n",
      "        All Columns: ['Dataset', 'Category', 'Subject_Name', 'Class', 'W->S1', 'W->S2', 'W->S3', 'W->S4', 'W->REM', 'S1->W', 'S1->S1', 'S1->S2', 'S1->S3', 'S1->S4', 'S1->REM', 'S2->W', 'S2->S1', 'S2->S2', 'S2->S3', 'S2->S4', 'S2->REM', 'S3->W', 'S3->S1', 'S3->S2', 'S3->S3', 'S3->S4', 'S3->REM', 'S4->W', 'S4->S1', 'S4->S2', 'S4->S3', 'S4->S4', 'S4->REM', 'REM->W', 'REM->S1', 'REM->S2', 'REM->S3', 'REM->REM']\n",
      "        \n",
      "\n",
      "        Feature shape: (20, 34), Target shape: (20,), Metadata: (20, 3) \n",
      "        \n",
      "[0 1] [0 1]\n",
      "[0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1] [0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1]\n",
      "[[ 9  1]\n",
      " [ 0 10]]\n",
      "[[10  0  1  9]\n",
      " [ 9  1  0 10]]\n",
      "[[19  1]\n",
      " [ 1 19]]\n",
      "Class-wise info: For multilevel internal scores fo label 0: \n",
      " Accuracy = 95.0\n",
      " Precision = [0.90909091 1.        ]\n",
      " Recall = [1.  0.9]\n",
      " F1 score = [0.95238095 0.94736842]\n",
      " AUC score = 95.0\n",
      " Support = [10 10]\n",
      "\n",
      "Class-wise info: For multilevel internal scores fo label 1: \n",
      " Accuracy = 95.0\n",
      " Precision = [1.         0.90909091]\n",
      " Recall = [0.9 1. ]\n",
      " F1 score = [0.94736842 0.95238095]\n",
      " AUC score = 95.0\n",
      " Support = [10 10]\n",
      "\n",
      "CLASSIFICATION MERICS:\n",
      " _______________________________________________________\n",
      " Confusion Matrix: \n",
      "[[ 9  1]\n",
      " [ 0 10]]\n",
      " Accuracy (acc): 95.0\n",
      " Precision (prc): 90.909\n",
      " Recall (rec): 100.0\n",
      " Sensitivity (sns): 100.0\n",
      " Specificity (spc): 90.0\n",
      " F1 Score (f1s): 95.238\n",
      " ROC AUC (AUC): 0.95\n",
      "Score columns: (1, 12) ['method', 'model', 'model_parameters', 'model_scores', 'confusion_matrix', 'accuracy', 'precision', 'recall', 'sensitivity', 'specificity', 'f1_score', 'roc_auc']\n",
      "\n",
      "        Best model (GriveSearchCV): GridSearchCV(cv=5, estimator=DecisionTreeClassifier(), n_jobs=50,\n",
      "             param_grid={'criterion': ['gini', 'entropy', 'log_loss'],\n",
      "                         'max_depth': [2, 3, 5, 7, 10, 15, 20, 25, 30]},\n",
      "             return_train_score=True, scoring='f1', verbose=2) \n",
      "        Best model: GridSearchCV(cv=5, estimator=DecisionTreeClassifier(), n_jobs=50,\n",
      "             param_grid={'criterion': ['gini', 'entropy', 'log_loss'],\n",
      "                         'max_depth': [2, 3, 5, 7, 10, 15, 20, 25, 30]},\n",
      "             return_train_score=True, scoring='f1', verbose=2) \n",
      "        Best estimator of the model: DecisionTreeClassifier(max_depth=2) \n",
      "        Best parameters of the model: {'criterion': 'gini', 'max_depth': 2} \n",
      "        ---------------------------------------------------------------------------------------------------\n",
      "        \n",
      "\n",
      "            *** ML MODEL FOR TEST:1, TRAINING:2 AND MODEL: RF \n",
      "            ---------------------------------------------------------------------------------------------------\n",
      "            \n",
      "Calling method: random_forest_parameters\n",
      "All parameters: ['n_estimators', 'max_depth', 'criterion', 'splitter', 'max_features', 'min_samples_split', 'min_samples_leaf', 'max_leaf_nodes'], [[3, 5, 10, 15, 21, 30, 50, 75, 100], [2, 3, 5, 7, 10, 15, 20, 25, 30], ['gini', 'entropy', 'log_loss']], [0, 1, 2]\n",
      "Parameters:  {'n_estimators': [3, 5, 10, 15, 21, 30, 50, 75, 100], 'max_depth': [2, 3, 5, 7, 10, 15, 20, 25, 30], 'criterion': ['gini', 'entropy', 'log_loss']}\n",
      "\n",
      "        From training? True, Data shape: (146, 38), Indices: [122 107 133 148   2 124  48  21 139  82  74  88 153 141  69  41 129  81\n",
      " 160 165 131  31 117 154  95 146  97 144  35  99 106  92  87 156  84  23\n",
      "   0  15 164  53  24 121  65 123 138  89  76  14  78  37 114 150  79 157\n",
      " 155  61 128  83  39  12  19  18 152  45  85 113  20  68 135  10  30 125\n",
      " 159  55 115  72  17  51   9  36  33  80 103   3  94 127  42 142  64   8\n",
      " 100 126  93   6  73  77  57 143  16 111 120 130  98 102  44 119  63 137\n",
      "  62  86  26  49 136  13  70 104  32 162 108 149 163 158  66 118 112  47\n",
      "   1  91  52  40  38   4  54  22  75 101  50  96  11  28  25   5  43  58\n",
      "  59 116]\n",
      "        All Columns: ['Dataset', 'Category', 'Subject_Name', 'Class', 'W->S1', 'W->S2', 'W->S3', 'W->S4', 'W->REM', 'S1->W', 'S1->S1', 'S1->S2', 'S1->S3', 'S1->S4', 'S1->REM', 'S2->W', 'S2->S1', 'S2->S2', 'S2->S3', 'S2->S4', 'S2->REM', 'S3->W', 'S3->S1', 'S3->S2', 'S3->S3', 'S3->S4', 'S3->REM', 'S4->W', 'S4->S1', 'S4->S2', 'S4->S3', 'S4->S4', 'S4->REM', 'REM->W', 'REM->S1', 'REM->S2', 'REM->S3', 'REM->REM']\n",
      "        \n",
      "\n",
      "        Feature shape: (146, 34), Target shape: (146,), Metadata: (146, 3) \n",
      "        \n",
      "\n",
      "        GridSearch: RF - {'n_estimators': [3, 5, 10, 15, 21, 30, 50, 75, 100], 'max_depth': [2, 3, 5, 7, 10, 15, 20, 25, 30], 'criterion': ['gini', 'entropy', 'log_loss']} \n",
      "        ---------------------------------------------------------------------------------------------------\n",
      "        \n",
      "Refitting the model with best parameter f1 == True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aliem\\.conda\\envs\\MyPython37Work\\lib\\site-packages\\sklearn\\model_selection\\_search.py:921: UserWarning: One or more of the test scores are non-finite: [0.91100512 0.83896514 0.86359389 0.8544436  0.84145494 0.86615546\n",
      " 0.85976891 0.85032193 0.85976891 0.91100512 0.81422342 0.86712866\n",
      " 0.87259486 0.8671876  0.85826166 0.85976891 0.87259486 0.86617774\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan]\n",
      "  category=UserWarning\n",
      "C:\\Users\\aliem\\.conda\\envs\\MyPython37Work\\lib\\site-packages\\sklearn\\model_selection\\_search.py:921: UserWarning: One or more of the train scores are non-finite: [0.92139964 0.93984613 0.99071952 1.         1.         1.\n",
      " 1.         1.         1.         0.92139964 0.93435031 0.99071952\n",
      " 1.         1.         1.         1.         1.         1.\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan]\n",
      "  category=UserWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 243 candidates, totalling 1215 fits\n",
      "\n",
      "        From training? False, Data shape: (20, 38), Indices: [132 151 147 134  29  34 140  67  27  60  90 109   7 161  56  46 110 105\n",
      " 145  71]\n",
      "        All Columns: ['Dataset', 'Category', 'Subject_Name', 'Class', 'W->S1', 'W->S2', 'W->S3', 'W->S4', 'W->REM', 'S1->W', 'S1->S1', 'S1->S2', 'S1->S3', 'S1->S4', 'S1->REM', 'S2->W', 'S2->S1', 'S2->S2', 'S2->S3', 'S2->S4', 'S2->REM', 'S3->W', 'S3->S1', 'S3->S2', 'S3->S3', 'S3->S4', 'S3->REM', 'S4->W', 'S4->S1', 'S4->S2', 'S4->S3', 'S4->S4', 'S4->REM', 'REM->W', 'REM->S1', 'REM->S2', 'REM->S3', 'REM->REM']\n",
      "        \n",
      "\n",
      "        Feature shape: (20, 34), Target shape: (20,), Metadata: (20, 3) \n",
      "        \n",
      "[0 1] [0 1]\n",
      "[0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1] [0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1]\n",
      "[[9 1]\n",
      " [1 9]]\n",
      "[[9 1 1 9]\n",
      " [9 1 1 9]]\n",
      "[[18  2]\n",
      " [ 2 18]]\n",
      "Class-wise info: For multilevel internal scores fo label 0: \n",
      " Accuracy = 90.0\n",
      " Precision = [0.9 0.9]\n",
      " Recall = [0.9 0.9]\n",
      " F1 score = [0.9 0.9]\n",
      " AUC score = 90.0\n",
      " Support = [10 10]\n",
      "\n",
      "Class-wise info: For multilevel internal scores fo label 1: \n",
      " Accuracy = 90.0\n",
      " Precision = [0.9 0.9]\n",
      " Recall = [0.9 0.9]\n",
      " F1 score = [0.9 0.9]\n",
      " AUC score = 90.0\n",
      " Support = [10 10]\n",
      "\n",
      "CLASSIFICATION MERICS:\n",
      " _______________________________________________________\n",
      " Confusion Matrix: \n",
      "[[9 1]\n",
      " [1 9]]\n",
      " Accuracy (acc): 90.0\n",
      " Precision (prc): 90.0\n",
      " Recall (rec): 90.0\n",
      " Sensitivity (sns): 90.0\n",
      " Specificity (spc): 90.0\n",
      " F1 Score (f1s): 90.0\n",
      " ROC AUC (AUC): 0.9\n",
      "Score columns: (1, 12) ['method', 'model', 'model_parameters', 'model_scores', 'confusion_matrix', 'accuracy', 'precision', 'recall', 'sensitivity', 'specificity', 'f1_score', 'roc_auc']\n",
      "\n",
      "        Best model (GriveSearchCV): GridSearchCV(cv=5, estimator=RandomForestClassifier(), n_jobs=50,\n",
      "             param_grid={'criterion': ['gini', 'entropy', 'log_loss'],\n",
      "                         'max_depth': [2, 3, 5, 7, 10, 15, 20, 25, 30],\n",
      "                         'n_estimators': [3, 5, 10, 15, 21, 30, 50, 75, 100]},\n",
      "             return_train_score=True, scoring='f1', verbose=2) \n",
      "        Best model: GridSearchCV(cv=5, estimator=RandomForestClassifier(), n_jobs=50,\n",
      "             param_grid={'criterion': ['gini', 'entropy', 'log_loss'],\n",
      "                         'max_depth': [2, 3, 5, 7, 10, 15, 20, 25, 30],\n",
      "                         'n_estimators': [3, 5, 10, 15, 21, 30, 50, 75, 100]},\n",
      "             return_train_score=True, scoring='f1', verbose=2) \n",
      "        Best estimator of the model: RandomForestClassifier(criterion='entropy', max_depth=10, n_estimators=21) \n",
      "        Best parameters of the model: {'criterion': 'entropy', 'max_depth': 10, 'n_estimators': 21} \n",
      "        ---------------------------------------------------------------------------------------------------\n",
      "        \n",
      "\n",
      "            *** ML MODEL FOR TEST:1, TRAINING:2 AND MODEL: GB \n",
      "            ---------------------------------------------------------------------------------------------------\n",
      "            \n",
      "Calling method: gradient_boosting_parameters\n",
      "All parameters: ['n_estimators', 'max_depth', 'learning_rate', 'max_features', 'loss', 'min_samples_split', 'min_samples_leaf'], [[3, 5, 10, 15, 21, 30, 50, 75, 100], [2, 3, 5, 7, 10, 15, 20, 25, 30], [0.01, 0.05, 0.1, 0.5, 1.0]], [0, 1, 2]\n",
      "Parameters:  {'n_estimators': [3, 5, 10, 15, 21, 30, 50, 75, 100], 'max_depth': [2, 3, 5, 7, 10, 15, 20, 25, 30], 'learning_rate': [0.01, 0.05, 0.1, 0.5, 1.0]}\n",
      "\n",
      "        From training? True, Data shape: (146, 38), Indices: [122 107 133 148   2 124  48  21 139  82  74  88 153 141  69  41 129  81\n",
      " 160 165 131  31 117 154  95 146  97 144  35  99 106  92  87 156  84  23\n",
      "   0  15 164  53  24 121  65 123 138  89  76  14  78  37 114 150  79 157\n",
      " 155  61 128  83  39  12  19  18 152  45  85 113  20  68 135  10  30 125\n",
      " 159  55 115  72  17  51   9  36  33  80 103   3  94 127  42 142  64   8\n",
      " 100 126  93   6  73  77  57 143  16 111 120 130  98 102  44 119  63 137\n",
      "  62  86  26  49 136  13  70 104  32 162 108 149 163 158  66 118 112  47\n",
      "   1  91  52  40  38   4  54  22  75 101  50  96  11  28  25   5  43  58\n",
      "  59 116]\n",
      "        All Columns: ['Dataset', 'Category', 'Subject_Name', 'Class', 'W->S1', 'W->S2', 'W->S3', 'W->S4', 'W->REM', 'S1->W', 'S1->S1', 'S1->S2', 'S1->S3', 'S1->S4', 'S1->REM', 'S2->W', 'S2->S1', 'S2->S2', 'S2->S3', 'S2->S4', 'S2->REM', 'S3->W', 'S3->S1', 'S3->S2', 'S3->S3', 'S3->S4', 'S3->REM', 'S4->W', 'S4->S1', 'S4->S2', 'S4->S3', 'S4->S4', 'S4->REM', 'REM->W', 'REM->S1', 'REM->S2', 'REM->S3', 'REM->REM']\n",
      "        \n",
      "\n",
      "        Feature shape: (146, 34), Target shape: (146,), Metadata: (146, 3) \n",
      "        \n",
      "\n",
      "        GridSearch: GB - {'n_estimators': [3, 5, 10, 15, 21, 30, 50, 75, 100], 'max_depth': [2, 3, 5, 7, 10, 15, 20, 25, 30], 'learning_rate': [0.01, 0.05, 0.1, 0.5, 1.0]} \n",
      "        ---------------------------------------------------------------------------------------------------\n",
      "        \n",
      "Refitting the model with best parameter f1 == True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aliem\\.conda\\envs\\MyPython37Work\\lib\\site-packages\\sklearn\\model_selection\\_search.py:921: UserWarning: One or more of the test scores are non-finite: [0.848454   0.90624473 0.90465592 0.91705554 0.91705554 0.91705554\n",
      " 0.91705554 0.91705554 0.91705554 0.91100512 0.92151403 0.91670922\n",
      " 0.91705554 0.91705554 0.92275964 0.91705554 0.91705554 0.91705554\n",
      " 0.88854247 0.87116013 0.91641044 0.91645334 0.91641044 0.91641044\n",
      " 0.92275964 0.92275964 0.92275964 0.84020926 0.88975259 0.91340587\n",
      " 0.90368174 0.91675364 0.92145245 0.91544645 0.92275964 0.92275964\n",
      " 0.88357143 0.84724067 0.88848967 0.91675364 0.92783901 0.92275964\n",
      " 0.92145245 0.92275964 0.91641044 0.90441558 0.90476575 0.89512665\n",
      " 0.91070322 0.92145245 0.90823944 0.91031424 0.92275964 0.91641044\n",
      " 0.86380231 0.90188711 0.932219   0.92145245 0.91040443 0.92145245\n",
      " 0.92275964 0.92275964 0.92275964 0.84814785 0.88322638 0.89407247\n",
      " 0.91645334 0.90968775 0.91645334 0.90968775 0.92275964 0.92275964\n",
      " 0.88295391 0.8788044  0.87641775 0.92275964 0.92275964 0.92275964\n",
      " 0.92275964 0.92275964 0.92275964 0.88731231 0.9167825  0.90530951\n",
      " 0.91705554 0.91705554 0.91705554 0.91705554 0.91705554 0.91705554\n",
      " 0.87326791 0.90075759 0.91632025 0.91705554 0.92275964 0.92275964\n",
      " 0.91705554 0.91705554 0.91705554 0.9037437  0.89489489 0.91008697\n",
      " 0.92275964 0.92145245 0.92275964 0.92275964 0.92275964 0.92275964\n",
      " 0.8702848  0.8910449  0.89595911 0.90872543 0.91981786 0.92275964\n",
      " 0.92151554 0.92275964 0.92145245 0.88494866 0.8896078  0.89358771\n",
      " 0.89982057 0.93294411 0.91641044 0.92275964 0.92275964 0.92275964\n",
      " 0.88001196 0.89560127 0.89584591 0.90805316 0.91040443 0.91449255\n",
      " 0.92275964 0.92786475 0.93264381 0.86973329 0.88175676 0.90232211\n",
      " 0.93264381 0.92625726 0.91550802 0.92786475 0.92275964 0.92275964\n",
      " 0.92212482 0.8814861  0.88180072 0.92121524 0.92783901 0.92121524\n",
      " 0.92625726 0.92275964 0.91641044 0.85478992 0.88884433 0.91965368\n",
      " 0.93266955 0.92756445 0.91347763 0.92275964 0.92275964 0.92275964\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan]\n",
      "  category=UserWarning\n",
      "C:\\Users\\aliem\\.conda\\envs\\MyPython37Work\\lib\\site-packages\\sklearn\\model_selection\\_search.py:921: UserWarning: One or more of the train scores are non-finite: [0.89366843 0.91316315 0.9175541  0.91751662 0.92008109 0.91751662\n",
      " 0.91883517 0.91883517 0.91625399 0.92355341 0.93445048 0.93061063\n",
      " 0.92526067 0.92400024 0.9292367  0.92137994 0.92139964 0.92529881\n",
      " 0.96018719 0.97755583 0.9690379  0.97210607 0.97771013 0.97043428\n",
      " 0.98058495 0.97476944 0.98204383 0.97415556 0.98498311 0.99541914\n",
      " 0.99696952 0.99696952 0.99699248 1.         1.         1.\n",
      " 0.97907106 0.98637451 0.99849624 0.99400741 0.99696952 1.\n",
      " 1.         1.         1.         0.9818831  0.97878404 0.99391556\n",
      " 0.99696952 0.99546594 0.99849624 0.99847328 1.         1.\n",
      " 0.97364047 0.9878297  0.9969697  0.99847328 0.99701493 1.\n",
      " 1.         1.         1.         0.96654253 0.98345695 0.9864881\n",
      " 0.99245842 0.99847328 1.         1.         1.         1.\n",
      " 0.97442997 0.99099836 0.99849624 0.99548821 0.99847328 1.\n",
      " 1.         1.         1.         0.90393873 0.9170542  0.91861869\n",
      " 0.91883691 0.91757254 0.91625399 0.91881847 0.91625399 0.91751662\n",
      " 0.92464535 0.92761719 0.92770485 0.92401908 0.92006304 0.92658076\n",
      " 0.9214744  0.92013527 0.92139964 0.94336003 0.96040854 0.9721909\n",
      " 0.97189251 0.98498451 0.9791911  0.97479028 0.96762383 0.97618574\n",
      " 0.97258355 0.9909771  0.99393922 0.99696952 0.99546576 1.\n",
      " 1.         0.99849624 0.99849624 0.96495957 0.98947111 0.99696952\n",
      " 0.99847328 0.99849624 0.99847328 1.         1.         1.\n",
      " 0.97260685 0.98931298 0.99847328 0.99849624 0.99701493 1.\n",
      " 1.         1.         1.         0.9670227  0.99076815 0.98940377\n",
      " 0.99699248 0.99849624 0.99847328 1.         1.         1.\n",
      " 0.97436449 0.98486935 0.99847328 0.99696952 0.99548821 1.\n",
      " 1.         1.         1.         0.97584546 0.98794541 0.99696952\n",
      " 0.99248086 1.         1.         1.         1.         1.\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan]\n",
      "  category=UserWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 405 candidates, totalling 2025 fits\n",
      "\n",
      "        From training? False, Data shape: (20, 38), Indices: [132 151 147 134  29  34 140  67  27  60  90 109   7 161  56  46 110 105\n",
      " 145  71]\n",
      "        All Columns: ['Dataset', 'Category', 'Subject_Name', 'Class', 'W->S1', 'W->S2', 'W->S3', 'W->S4', 'W->REM', 'S1->W', 'S1->S1', 'S1->S2', 'S1->S3', 'S1->S4', 'S1->REM', 'S2->W', 'S2->S1', 'S2->S2', 'S2->S3', 'S2->S4', 'S2->REM', 'S3->W', 'S3->S1', 'S3->S2', 'S3->S3', 'S3->S4', 'S3->REM', 'S4->W', 'S4->S1', 'S4->S2', 'S4->S3', 'S4->S4', 'S4->REM', 'REM->W', 'REM->S1', 'REM->S2', 'REM->S3', 'REM->REM']\n",
      "        \n",
      "\n",
      "        Feature shape: (20, 34), Target shape: (20,), Metadata: (20, 3) \n",
      "        \n",
      "[0 1] [0 1]\n",
      "[0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1] [0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1]\n",
      "[[9 1]\n",
      " [2 8]]\n",
      "[[8 2 1 9]\n",
      " [9 1 2 8]]\n",
      "[[17  3]\n",
      " [ 3 17]]\n",
      "Class-wise info: For multilevel internal scores fo label 0: \n",
      " Accuracy = 85.0\n",
      " Precision = [0.88888889 0.81818182]\n",
      " Recall = [0.8 0.9]\n",
      " F1 score = [0.84210526 0.85714286]\n",
      " AUC score = 85.0\n",
      " Support = [10 10]\n",
      "\n",
      "Class-wise info: For multilevel internal scores fo label 1: \n",
      " Accuracy = 85.0\n",
      " Precision = [0.81818182 0.88888889]\n",
      " Recall = [0.9 0.8]\n",
      " F1 score = [0.85714286 0.84210526]\n",
      " AUC score = 85.00000000000001\n",
      " Support = [10 10]\n",
      "\n",
      "CLASSIFICATION MERICS:\n",
      " _______________________________________________________\n",
      " Confusion Matrix: \n",
      "[[9 1]\n",
      " [2 8]]\n",
      " Accuracy (acc): 85.0\n",
      " Precision (prc): 88.889\n",
      " Recall (rec): 80.0\n",
      " Sensitivity (sns): 80.0\n",
      " Specificity (spc): 90.0\n",
      " F1 Score (f1s): 84.211\n",
      " ROC AUC (AUC): 0.85\n",
      "Score columns: (1, 12) ['method', 'model', 'model_parameters', 'model_scores', 'confusion_matrix', 'accuracy', 'precision', 'recall', 'sensitivity', 'specificity', 'f1_score', 'roc_auc']\n",
      "\n",
      "        Best model (GriveSearchCV): GridSearchCV(cv=5, estimator=GradientBoostingClassifier(), n_jobs=50,\n",
      "             param_grid={'learning_rate': [0.01, 0.05, 0.1, 0.5, 1.0],\n",
      "                         'max_depth': [2, 3, 5, 7, 10, 15, 20, 25, 30],\n",
      "                         'n_estimators': [3, 5, 10, 15, 21, 30, 50, 75, 100]},\n",
      "             return_train_score=True, scoring='f1', verbose=2) \n",
      "        Best model: GridSearchCV(cv=5, estimator=GradientBoostingClassifier(), n_jobs=50,\n",
      "             param_grid={'learning_rate': [0.01, 0.05, 0.1, 0.5, 1.0],\n",
      "                         'max_depth': [2, 3, 5, 7, 10, 15, 20, 25, 30],\n",
      "                         'n_estimators': [3, 5, 10, 15, 21, 30, 50, 75, 100]},\n",
      "             return_train_score=True, scoring='f1', verbose=2) \n",
      "        Best estimator of the model: GradientBoostingClassifier(learning_rate=0.05, max_depth=2) \n",
      "        Best parameters of the model: {'learning_rate': 0.05, 'max_depth': 2, 'n_estimators': 100} \n",
      "        ---------------------------------------------------------------------------------------------------\n",
      "        \n",
      "\n",
      "            ---------------------------------------------------------------------------------------------------\n",
      "            Best model index calculation  \n",
      "            \n",
      "\n",
      "            ***************************************************************************************************\n",
      "            TRAINING 2 END... \n",
      "            \n",
      "\n",
      "            *** MODEL TRAINING AND VALIDATION PHASE FOR TEST 1 \n",
      "            TRAINING 3 START... XXXXX \n",
      "            ***************************************************************************************************\n",
      "            Validation=> 20 ['nfle7', 'rbd21', 'ins2', 'rbd19', 'SC4371', 'sdb3', 'nfle20', 'SC4551', 'nfle25', 'rbd10', 'n4', 'SC4362', 'plm9', 'nfle17', 'nfle29', 'SC4111', 'rbd11', 'nfle37', 'n13', 'SC4561'] \n",
      "            Training=> 146 ['SC4031', 'nfle27', 'SC4511', 'nfle36', 'nfle1', 'nfle30', 'rbd5', 'SC4181', 'rbd17', 'nfle8', 'SC4421', 'nfle13', 'SC4011', 'narco1', 'SC4121', 'SC4301', 'ins3', 'rbd14', 'nfle10', 'sdb2', 'SC4041', 'n5', 'nfle5', 'nfle40', 'plm1', 'sdb1', 'rbd18', 'SC4061', 'nfle28', 'n12', 'nfle18', 'rbd13', 'SC4501', 'SC4191', 'plm5', 'SC4071', 'SC4251', 'SC4221', 'SC4161', 'nfle34', 'SC4271', 'SC4211', 'SC4341', 'SC4241', 'n15', 'nfle6', 'nfle14', 'SC4541', 'n2', 'SC4471', 'n1', 'narco2', 'rbd2', 'SC4581', 'narco4', 'SC4411', 'SC4231', 'rbd16', 'n16', 'SC4522', 'SC4451', 'rbd15', 'nfle21', 'SC4351', 'nfle23', 'SC4441', 'SC4461', 'nfle2', 'rbd9', 'SC4491', 'SC4281', 'ins7', 'sdb4', 'nfle12', 'nfle4', 'plm2', 'SC4331', 'nfle24', 'narco5', 'n10', 'ins6', 'n14', 'rbd8', 'SC4001', 'nfle26', 'ins9', 'nfle15', 'rbd3', 'SC4381', 'nfle9', 'plm10', 'n11', 'ins1', 'brux1', 'rbd6', 'plm8', 'nfle11', 'ins8', 'ins5', 'SC4051', 'rbd7', 'ins4', 'nfle16', 'nfle19', 'SC4291', 'nfle22', 'rbd12', 'SC4171', 'rbd22', 'SC4151', 'nfle39', 'SC4481', 'n9', 'SC4571', 'plm4', 'SC4201', 'n6', 'rbd4', 'nfle3', 'rbd1', 'plm6', 'n3', 'plm3', 'rbd20', 'nfle33', 'nfle38', 'SC4431', 'SC4131', 'SC4261', 'nfle35', 'nfle32', 'SC4531', 'SC4141', 'SC4081', 'SC4321', 'n8', 'n7', 'plm7', 'SC4401', 'SC4311', 'narco3', 'SC4021', 'brux2', 'SC4091', 'SC4101', 'nfle31'] \n",
      "            \n",
      "\n",
      "            *** ML MODEL FOR TEST:1, TRAINING:3 AND MODEL: LR \n",
      "            ---------------------------------------------------------------------------------------------------\n",
      "            \n",
      "Calling method: logistic_regression_parameters\n",
      "All parameters: ['penalty', 'solver', 'max_iter', 'C'], [['l2', 'elasticnet'], [50, 100, 130, 150, 170, 200], [0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1.0]], [0, 2, 3]\n",
      "Parameters:  {'penalty': ['l2', 'elasticnet'], 'max_iter': [50, 100, 130, 150, 170, 200], 'C': [0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1.0]}\n",
      "\n",
      "        From training? True, Data shape: (146, 38), Indices: [111  46 158  55  20  49  74 126  86  27 149  32 109  15 120 138   8  83\n",
      "  29   3 112  96  24  59  60   2  87 114  47 103  37  82 157 127  64 115\n",
      " 133 130 124  53 135 129 142 132 106  25  33 161  93 154  92  16  71 165\n",
      "  18 148 131  85 107 159 152  84  40 143  42 151 153  21  78 156 136  12\n",
      "   5  31  23  61 141  43  19 101  11 105  77 108  45  14  34  72 146  28\n",
      "  69 102   6   0  75  67  30  13  10 113  76   9  35  38 137  41  81 125\n",
      "  91 123  58 155 100 164  63 128  97  73  22  70  65  94  62  89  52  57\n",
      " 150 121 134  54  51 160 122 116 140  99  98  66 147 139  17 110   1 117\n",
      " 118  50]\n",
      "        All Columns: ['Dataset', 'Category', 'Subject_Name', 'Class', 'W->S1', 'W->S2', 'W->S3', 'W->S4', 'W->REM', 'S1->W', 'S1->S1', 'S1->S2', 'S1->S3', 'S1->S4', 'S1->REM', 'S2->W', 'S2->S1', 'S2->S2', 'S2->S3', 'S2->S4', 'S2->REM', 'S3->W', 'S3->S1', 'S3->S2', 'S3->S3', 'S3->S4', 'S3->REM', 'S4->W', 'S4->S1', 'S4->S2', 'S4->S3', 'S4->S4', 'S4->REM', 'REM->W', 'REM->S1', 'REM->S2', 'REM->S3', 'REM->REM']\n",
      "        \n",
      "\n",
      "        Feature shape: (146, 34), Target shape: (146,), Metadata: (146, 3) \n",
      "        \n",
      "\n",
      "        GridSearch: LR - {'penalty': ['l2', 'elasticnet'], 'max_iter': [50, 100, 130, 150, 170, 200], 'C': [0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1.0]} \n",
      "        ---------------------------------------------------------------------------------------------------\n",
      "        \n",
      "Refitting the model with best parameter f1 == True\n",
      "Fitting 5 folds for each of 84 candidates, totalling 420 fits\n",
      "\n",
      "        From training? False, Data shape: (20, 38), Indices: [ 26  90   7  88 145   4  39 162  44  79  95 144  68  36  48 119  80  56\n",
      " 104 163]\n",
      "        All Columns: ['Dataset', 'Category', 'Subject_Name', 'Class', 'W->S1', 'W->S2', 'W->S3', 'W->S4', 'W->REM', 'S1->W', 'S1->S1', 'S1->S2', 'S1->S3', 'S1->S4', 'S1->REM', 'S2->W', 'S2->S1', 'S2->S2', 'S2->S3', 'S2->S4', 'S2->REM', 'S3->W', 'S3->S1', 'S3->S2', 'S3->S3', 'S3->S4', 'S3->REM', 'S4->W', 'S4->S1', 'S4->S2', 'S4->S3', 'S4->S4', 'S4->REM', 'REM->W', 'REM->S1', 'REM->S2', 'REM->S3', 'REM->REM']\n",
      "        \n",
      "\n",
      "        Feature shape: (20, 34), Target shape: (20,), Metadata: (20, 3) \n",
      "        \n",
      "[0 1] [0 1]\n",
      "[1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0] [1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0]\n",
      "[[ 5  2]\n",
      " [ 1 12]]\n",
      "[[12  1  2  5]\n",
      " [ 5  2  1 12]]\n",
      "[[17  3]\n",
      " [ 3 17]]\n",
      "Class-wise info: For multilevel internal scores fo label 0: \n",
      " Accuracy = 85.0\n",
      " Precision = [0.85714286 0.83333333]\n",
      " Recall = [0.92307692 0.71428571]\n",
      " F1 score = [0.88888889 0.76923077]\n",
      " AUC score = 81.86813186813188\n",
      " Support = [13  7]\n",
      "\n",
      "Class-wise info: For multilevel internal scores fo label 1: \n",
      " Accuracy = 85.0\n",
      " Precision = [0.83333333 0.85714286]\n",
      " Recall = [0.71428571 0.92307692]\n",
      " F1 score = [0.76923077 0.88888889]\n",
      " AUC score = 81.86813186813187\n",
      " Support = [ 7 13]\n",
      "\n",
      "CLASSIFICATION MERICS:\n",
      " _______________________________________________________\n",
      " Confusion Matrix: \n",
      "[[ 5  2]\n",
      " [ 1 12]]\n",
      " Accuracy (acc): 85.0\n",
      " Precision (prc): 85.714\n",
      " Recall (rec): 92.308\n",
      " Sensitivity (sns): 92.308\n",
      " Specificity (spc): 71.429\n",
      " F1 Score (f1s): 88.889\n",
      " ROC AUC (AUC): 0.819\n",
      "Score columns: (1, 12) ['method', 'model', 'model_parameters', 'model_scores', 'confusion_matrix', 'accuracy', 'precision', 'recall', 'sensitivity', 'specificity', 'f1_score', 'roc_auc']\n",
      "\n",
      "        Best model (GriveSearchCV): GridSearchCV(cv=5, estimator=LogisticRegression(), n_jobs=50,\n",
      "             param_grid={'C': [0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1.0],\n",
      "                         'max_iter': [50, 100, 130, 150, 170, 200],\n",
      "                         'penalty': ['l2', 'elasticnet']},\n",
      "             return_train_score=True, scoring='f1', verbose=2) \n",
      "        Best model: GridSearchCV(cv=5, estimator=LogisticRegression(), n_jobs=50,\n",
      "             param_grid={'C': [0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1.0],\n",
      "                         'max_iter': [50, 100, 130, 150, 170, 200],\n",
      "                         'penalty': ['l2', 'elasticnet']},\n",
      "             return_train_score=True, scoring='f1', verbose=2) \n",
      "        Best estimator of the model: LogisticRegression(max_iter=50) \n",
      "        Best parameters of the model: {'C': 1.0, 'max_iter': 50, 'penalty': 'l2'} \n",
      "        ---------------------------------------------------------------------------------------------------\n",
      "        \n",
      "\n",
      "            *** ML MODEL FOR TEST:1, TRAINING:3 AND MODEL: SVC \n",
      "            ---------------------------------------------------------------------------------------------------\n",
      "            \n",
      "Calling method: support_vector_classifier_parameters\n",
      "All parameters: ['probability', 'C', 'kernel', 'gamma', 'degree', 'class_weightdict'], [[True], [0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1.0], ['linear', 'rbf', 'poly']], [0, 1, 2]\n",
      "Parameters:  {'probability': [True], 'C': [0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1.0], 'kernel': ['linear', 'rbf', 'poly']}\n",
      "\n",
      "        From training? True, Data shape: (146, 38), Indices: [111  46 158  55  20  49  74 126  86  27 149  32 109  15 120 138   8  83\n",
      "  29   3 112  96  24  59  60   2  87 114  47 103  37  82 157 127  64 115\n",
      " 133 130 124  53 135 129 142 132 106  25  33 161  93 154  92  16  71 165\n",
      "  18 148 131  85 107 159 152  84  40 143  42 151 153  21  78 156 136  12\n",
      "   5  31  23  61 141  43  19 101  11 105  77 108  45  14  34  72 146  28\n",
      "  69 102   6   0  75  67  30  13  10 113  76   9  35  38 137  41  81 125\n",
      "  91 123  58 155 100 164  63 128  97  73  22  70  65  94  62  89  52  57\n",
      " 150 121 134  54  51 160 122 116 140  99  98  66 147 139  17 110   1 117\n",
      " 118  50]\n",
      "        All Columns: ['Dataset', 'Category', 'Subject_Name', 'Class', 'W->S1', 'W->S2', 'W->S3', 'W->S4', 'W->REM', 'S1->W', 'S1->S1', 'S1->S2', 'S1->S3', 'S1->S4', 'S1->REM', 'S2->W', 'S2->S1', 'S2->S2', 'S2->S3', 'S2->S4', 'S2->REM', 'S3->W', 'S3->S1', 'S3->S2', 'S3->S3', 'S3->S4', 'S3->REM', 'S4->W', 'S4->S1', 'S4->S2', 'S4->S3', 'S4->S4', 'S4->REM', 'REM->W', 'REM->S1', 'REM->S2', 'REM->S3', 'REM->REM']\n",
      "        \n",
      "\n",
      "        Feature shape: (146, 34), Target shape: (146,), Metadata: (146, 3) \n",
      "        \n",
      "\n",
      "        GridSearch: SVC - {'probability': [True], 'C': [0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1.0], 'kernel': ['linear', 'rbf', 'poly']} \n",
      "        ---------------------------------------------------------------------------------------------------\n",
      "        \n",
      "Refitting the model with best parameter f1 == True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aliem\\.conda\\envs\\MyPython37Work\\lib\\site-packages\\sklearn\\model_selection\\_search.py:921: UserWarning: One or more of the test scores are non-finite: [0.70216074        nan 0.70216074        nan 0.70216074        nan\n",
      " 0.70216074        nan 0.70216074        nan 0.70216074        nan\n",
      " 0.70216074        nan 0.70216074        nan 0.70216074        nan\n",
      " 0.70216074        nan 0.70216074        nan 0.70216074        nan\n",
      " 0.75265547        nan 0.75265547        nan 0.75265547        nan\n",
      " 0.75265547        nan 0.75265547        nan 0.75265547        nan\n",
      " 0.84532695        nan 0.84532695        nan 0.84532695        nan\n",
      " 0.84532695        nan 0.84532695        nan 0.84532695        nan\n",
      " 0.86903952        nan 0.86903952        nan 0.86903952        nan\n",
      " 0.86903952        nan 0.86903952        nan 0.86903952        nan\n",
      " 0.88400306        nan 0.88400306        nan 0.88400306        nan\n",
      " 0.88400306        nan 0.88400306        nan 0.88400306        nan\n",
      " 0.88870894        nan 0.88870894        nan 0.88870894        nan\n",
      " 0.88870894        nan 0.88870894        nan 0.88870894        nan]\n",
      "  category=UserWarning\n",
      "C:\\Users\\aliem\\.conda\\envs\\MyPython37Work\\lib\\site-packages\\sklearn\\model_selection\\_search.py:921: UserWarning: One or more of the train scores are non-finite: [0.70221859        nan 0.70221859        nan 0.70221859        nan\n",
      " 0.70221859        nan 0.70221859        nan 0.70221859        nan\n",
      " 0.70221859        nan 0.70221859        nan 0.70221859        nan\n",
      " 0.70221859        nan 0.70221859        nan 0.70221859        nan\n",
      " 0.76106973        nan 0.76106973        nan 0.76106973        nan\n",
      " 0.76106973        nan 0.76106973        nan 0.76106973        nan\n",
      " 0.85682706        nan 0.85682706        nan 0.85682706        nan\n",
      " 0.85682706        nan 0.85682706        nan 0.85682706        nan\n",
      " 0.86894282        nan 0.86894282        nan 0.86894282        nan\n",
      " 0.86894282        nan 0.86894282        nan 0.86894282        nan\n",
      " 0.89173837        nan 0.89173837        nan 0.89173837        nan\n",
      " 0.89173837        nan 0.89173837        nan 0.89173837        nan\n",
      " 0.90880658        nan 0.90880658        nan 0.90880658        nan\n",
      " 0.90880658        nan 0.90880658        nan 0.90880658        nan]\n",
      "  category=UserWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 21 candidates, totalling 105 fits\n",
      "\n",
      "        From training? False, Data shape: (20, 38), Indices: [ 26  90   7  88 145   4  39 162  44  79  95 144  68  36  48 119  80  56\n",
      " 104 163]\n",
      "        All Columns: ['Dataset', 'Category', 'Subject_Name', 'Class', 'W->S1', 'W->S2', 'W->S3', 'W->S4', 'W->REM', 'S1->W', 'S1->S1', 'S1->S2', 'S1->S3', 'S1->S4', 'S1->REM', 'S2->W', 'S2->S1', 'S2->S2', 'S2->S3', 'S2->S4', 'S2->REM', 'S3->W', 'S3->S1', 'S3->S2', 'S3->S3', 'S3->S4', 'S3->REM', 'S4->W', 'S4->S1', 'S4->S2', 'S4->S3', 'S4->S4', 'S4->REM', 'REM->W', 'REM->S1', 'REM->S2', 'REM->S3', 'REM->REM']\n",
      "        \n",
      "\n",
      "        Feature shape: (20, 34), Target shape: (20,), Metadata: (20, 3) \n",
      "        \n",
      "[0 1] [0 1]\n",
      "[1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0] [1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0]\n",
      "[[ 5  2]\n",
      " [ 0 13]]\n",
      "[[13  0  2  5]\n",
      " [ 5  2  0 13]]\n",
      "[[18  2]\n",
      " [ 2 18]]\n",
      "Class-wise info: For multilevel internal scores fo label 0: \n",
      " Accuracy = 90.0\n",
      " Precision = [0.86666667 1.        ]\n",
      " Recall = [1.         0.71428571]\n",
      " F1 score = [0.92857143 0.83333333]\n",
      " AUC score = 85.71428571428572\n",
      " Support = [13  7]\n",
      "\n",
      "Class-wise info: For multilevel internal scores fo label 1: \n",
      " Accuracy = 90.0\n",
      " Precision = [1.         0.86666667]\n",
      " Recall = [0.71428571 1.        ]\n",
      " F1 score = [0.83333333 0.92857143]\n",
      " AUC score = 85.71428571428572\n",
      " Support = [ 7 13]\n",
      "\n",
      "CLASSIFICATION MERICS:\n",
      " _______________________________________________________\n",
      " Confusion Matrix: \n",
      "[[ 5  2]\n",
      " [ 0 13]]\n",
      " Accuracy (acc): 90.0\n",
      " Precision (prc): 86.667\n",
      " Recall (rec): 100.0\n",
      " Sensitivity (sns): 100.0\n",
      " Specificity (spc): 71.429\n",
      " F1 Score (f1s): 92.857\n",
      " ROC AUC (AUC): 0.857\n",
      "Score columns: (1, 12) ['method', 'model', 'model_parameters', 'model_scores', 'confusion_matrix', 'accuracy', 'precision', 'recall', 'sensitivity', 'specificity', 'f1_score', 'roc_auc']\n",
      "\n",
      "        Best model (GriveSearchCV): GridSearchCV(cv=5, estimator=SVC(), n_jobs=50,\n",
      "             param_grid={'C': [0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1.0],\n",
      "                         'kernel': ['linear', 'rbf', 'poly'],\n",
      "                         'probability': [True]},\n",
      "             return_train_score=True, scoring='f1', verbose=2) \n",
      "        Best model: GridSearchCV(cv=5, estimator=SVC(), n_jobs=50,\n",
      "             param_grid={'C': [0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1.0],\n",
      "                         'kernel': ['linear', 'rbf', 'poly'],\n",
      "                         'probability': [True]},\n",
      "             return_train_score=True, scoring='f1', verbose=2) \n",
      "        Best estimator of the model: SVC(kernel='linear', probability=True) \n",
      "        Best parameters of the model: {'C': 1.0, 'kernel': 'linear', 'probability': True} \n",
      "        ---------------------------------------------------------------------------------------------------\n",
      "        \n",
      "\n",
      "            *** ML MODEL FOR TEST:1, TRAINING:3 AND MODEL: NB \n",
      "            ---------------------------------------------------------------------------------------------------\n",
      "            \n",
      "Calling method: naive_bayes_parameters\n",
      "All parameters: ['var_smoothing'], [[1.0, 0.005623413251903491, 3.1622776601683795e-05, 1.7782794100389227e-07, 1e-09]], [0]\n",
      "Parameters:  {'var_smoothing': [1.0, 0.005623413251903491, 3.1622776601683795e-05, 1.7782794100389227e-07, 1e-09]}\n",
      "\n",
      "        From training? True, Data shape: (146, 38), Indices: [111  46 158  55  20  49  74 126  86  27 149  32 109  15 120 138   8  83\n",
      "  29   3 112  96  24  59  60   2  87 114  47 103  37  82 157 127  64 115\n",
      " 133 130 124  53 135 129 142 132 106  25  33 161  93 154  92  16  71 165\n",
      "  18 148 131  85 107 159 152  84  40 143  42 151 153  21  78 156 136  12\n",
      "   5  31  23  61 141  43  19 101  11 105  77 108  45  14  34  72 146  28\n",
      "  69 102   6   0  75  67  30  13  10 113  76   9  35  38 137  41  81 125\n",
      "  91 123  58 155 100 164  63 128  97  73  22  70  65  94  62  89  52  57\n",
      " 150 121 134  54  51 160 122 116 140  99  98  66 147 139  17 110   1 117\n",
      " 118  50]\n",
      "        All Columns: ['Dataset', 'Category', 'Subject_Name', 'Class', 'W->S1', 'W->S2', 'W->S3', 'W->S4', 'W->REM', 'S1->W', 'S1->S1', 'S1->S2', 'S1->S3', 'S1->S4', 'S1->REM', 'S2->W', 'S2->S1', 'S2->S2', 'S2->S3', 'S2->S4', 'S2->REM', 'S3->W', 'S3->S1', 'S3->S2', 'S3->S3', 'S3->S4', 'S3->REM', 'S4->W', 'S4->S1', 'S4->S2', 'S4->S3', 'S4->S4', 'S4->REM', 'REM->W', 'REM->S1', 'REM->S2', 'REM->S3', 'REM->REM']\n",
      "        \n",
      "\n",
      "        Feature shape: (146, 34), Target shape: (146,), Metadata: (146, 3) \n",
      "        \n",
      "\n",
      "        GridSearch: NB - {'var_smoothing': [1.0, 0.005623413251903491, 3.1622776601683795e-05, 1.7782794100389227e-07, 1e-09]} \n",
      "        ---------------------------------------------------------------------------------------------------\n",
      "        \n",
      "Refitting the model with best parameter f1 == True\n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "\n",
      "        From training? False, Data shape: (20, 38), Indices: [ 26  90   7  88 145   4  39 162  44  79  95 144  68  36  48 119  80  56\n",
      " 104 163]\n",
      "        All Columns: ['Dataset', 'Category', 'Subject_Name', 'Class', 'W->S1', 'W->S2', 'W->S3', 'W->S4', 'W->REM', 'S1->W', 'S1->S1', 'S1->S2', 'S1->S3', 'S1->S4', 'S1->REM', 'S2->W', 'S2->S1', 'S2->S2', 'S2->S3', 'S2->S4', 'S2->REM', 'S3->W', 'S3->S1', 'S3->S2', 'S3->S3', 'S3->S4', 'S3->REM', 'S4->W', 'S4->S1', 'S4->S2', 'S4->S3', 'S4->S4', 'S4->REM', 'REM->W', 'REM->S1', 'REM->S2', 'REM->S3', 'REM->REM']\n",
      "        \n",
      "\n",
      "        Feature shape: (20, 34), Target shape: (20,), Metadata: (20, 3) \n",
      "        \n",
      "[0 1] [0 1]\n",
      "[1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0] [1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0]\n",
      "[[ 5  2]\n",
      " [ 1 12]]\n",
      "[[12  1  2  5]\n",
      " [ 5  2  1 12]]\n",
      "[[17  3]\n",
      " [ 3 17]]\n",
      "Class-wise info: For multilevel internal scores fo label 0: \n",
      " Accuracy = 85.0\n",
      " Precision = [0.85714286 0.83333333]\n",
      " Recall = [0.92307692 0.71428571]\n",
      " F1 score = [0.88888889 0.76923077]\n",
      " AUC score = 81.86813186813188\n",
      " Support = [13  7]\n",
      "\n",
      "Class-wise info: For multilevel internal scores fo label 1: \n",
      " Accuracy = 85.0\n",
      " Precision = [0.83333333 0.85714286]\n",
      " Recall = [0.71428571 0.92307692]\n",
      " F1 score = [0.76923077 0.88888889]\n",
      " AUC score = 81.86813186813187\n",
      " Support = [ 7 13]\n",
      "\n",
      "CLASSIFICATION MERICS:\n",
      " _______________________________________________________\n",
      " Confusion Matrix: \n",
      "[[ 5  2]\n",
      " [ 1 12]]\n",
      " Accuracy (acc): 85.0\n",
      " Precision (prc): 85.714\n",
      " Recall (rec): 92.308\n",
      " Sensitivity (sns): 92.308\n",
      " Specificity (spc): 71.429\n",
      " F1 Score (f1s): 88.889\n",
      " ROC AUC (AUC): 0.819\n",
      "Score columns: (1, 12) ['method', 'model', 'model_parameters', 'model_scores', 'confusion_matrix', 'accuracy', 'precision', 'recall', 'sensitivity', 'specificity', 'f1_score', 'roc_auc']\n",
      "\n",
      "        Best model (GriveSearchCV): GridSearchCV(cv=5, estimator=GaussianNB(), n_jobs=50,\n",
      "             param_grid={'var_smoothing': [1.0, 0.005623413251903491,\n",
      "                                           3.1622776601683795e-05,\n",
      "                                           1.7782794100389227e-07, 1e-09]},\n",
      "             return_train_score=True, scoring='f1', verbose=2) \n",
      "        Best model: GridSearchCV(cv=5, estimator=GaussianNB(), n_jobs=50,\n",
      "             param_grid={'var_smoothing': [1.0, 0.005623413251903491,\n",
      "                                           3.1622776601683795e-05,\n",
      "                                           1.7782794100389227e-07, 1e-09]},\n",
      "             return_train_score=True, scoring='f1', verbose=2) \n",
      "        Best estimator of the model: GaussianNB(var_smoothing=0.005623413251903491) \n",
      "        Best parameters of the model: {'var_smoothing': 0.005623413251903491} \n",
      "        ---------------------------------------------------------------------------------------------------\n",
      "        \n",
      "\n",
      "            *** ML MODEL FOR TEST:1, TRAINING:3 AND MODEL: KNN \n",
      "            ---------------------------------------------------------------------------------------------------\n",
      "            \n",
      "Calling method: k_nearest_neighbors_parameters\n",
      "All parameters: ['n_neighbors', 'p', 'metric', 'n_splits'], [[2, 3, 5, 10, 15, 25, 35], ['manhattan', 'minkowski', 'euclidean']], [0, 2]\n",
      "Parameters:  {'n_neighbors': [2, 3, 5, 10, 15, 25, 35], 'metric': ['manhattan', 'minkowski', 'euclidean']}\n",
      "\n",
      "        From training? True, Data shape: (146, 38), Indices: [111  46 158  55  20  49  74 126  86  27 149  32 109  15 120 138   8  83\n",
      "  29   3 112  96  24  59  60   2  87 114  47 103  37  82 157 127  64 115\n",
      " 133 130 124  53 135 129 142 132 106  25  33 161  93 154  92  16  71 165\n",
      "  18 148 131  85 107 159 152  84  40 143  42 151 153  21  78 156 136  12\n",
      "   5  31  23  61 141  43  19 101  11 105  77 108  45  14  34  72 146  28\n",
      "  69 102   6   0  75  67  30  13  10 113  76   9  35  38 137  41  81 125\n",
      "  91 123  58 155 100 164  63 128  97  73  22  70  65  94  62  89  52  57\n",
      " 150 121 134  54  51 160 122 116 140  99  98  66 147 139  17 110   1 117\n",
      " 118  50]\n",
      "        All Columns: ['Dataset', 'Category', 'Subject_Name', 'Class', 'W->S1', 'W->S2', 'W->S3', 'W->S4', 'W->REM', 'S1->W', 'S1->S1', 'S1->S2', 'S1->S3', 'S1->S4', 'S1->REM', 'S2->W', 'S2->S1', 'S2->S2', 'S2->S3', 'S2->S4', 'S2->REM', 'S3->W', 'S3->S1', 'S3->S2', 'S3->S3', 'S3->S4', 'S3->REM', 'S4->W', 'S4->S1', 'S4->S2', 'S4->S3', 'S4->S4', 'S4->REM', 'REM->W', 'REM->S1', 'REM->S2', 'REM->S3', 'REM->REM']\n",
      "        \n",
      "\n",
      "        Feature shape: (146, 34), Target shape: (146,), Metadata: (146, 3) \n",
      "        \n",
      "\n",
      "        GridSearch: KNN - {'n_neighbors': [2, 3, 5, 10, 15, 25, 35], 'metric': ['manhattan', 'minkowski', 'euclidean']} \n",
      "        ---------------------------------------------------------------------------------------------------\n",
      "        \n",
      "Refitting the model with best parameter f1 == True\n",
      "Fitting 5 folds for each of 21 candidates, totalling 105 fits\n",
      "\n",
      "        From training? False, Data shape: (20, 38), Indices: [ 26  90   7  88 145   4  39 162  44  79  95 144  68  36  48 119  80  56\n",
      " 104 163]\n",
      "        All Columns: ['Dataset', 'Category', 'Subject_Name', 'Class', 'W->S1', 'W->S2', 'W->S3', 'W->S4', 'W->REM', 'S1->W', 'S1->S1', 'S1->S2', 'S1->S3', 'S1->S4', 'S1->REM', 'S2->W', 'S2->S1', 'S2->S2', 'S2->S3', 'S2->S4', 'S2->REM', 'S3->W', 'S3->S1', 'S3->S2', 'S3->S3', 'S3->S4', 'S3->REM', 'S4->W', 'S4->S1', 'S4->S2', 'S4->S3', 'S4->S4', 'S4->REM', 'REM->W', 'REM->S1', 'REM->S2', 'REM->S3', 'REM->REM']\n",
      "        \n",
      "\n",
      "        Feature shape: (20, 34), Target shape: (20,), Metadata: (20, 3) \n",
      "        \n",
      "[0 1] [0 1]\n",
      "[1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0] [1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0]\n",
      "[[ 5  2]\n",
      " [ 0 13]]\n",
      "[[13  0  2  5]\n",
      " [ 5  2  0 13]]\n",
      "[[18  2]\n",
      " [ 2 18]]\n",
      "Class-wise info: For multilevel internal scores fo label 0: \n",
      " Accuracy = 90.0\n",
      " Precision = [0.86666667 1.        ]\n",
      " Recall = [1.         0.71428571]\n",
      " F1 score = [0.92857143 0.83333333]\n",
      " AUC score = 85.71428571428572\n",
      " Support = [13  7]\n",
      "\n",
      "Class-wise info: For multilevel internal scores fo label 1: \n",
      " Accuracy = 90.0\n",
      " Precision = [1.         0.86666667]\n",
      " Recall = [0.71428571 1.        ]\n",
      " F1 score = [0.83333333 0.92857143]\n",
      " AUC score = 85.71428571428572\n",
      " Support = [ 7 13]\n",
      "\n",
      "CLASSIFICATION MERICS:\n",
      " _______________________________________________________\n",
      " Confusion Matrix: \n",
      "[[ 5  2]\n",
      " [ 0 13]]\n",
      " Accuracy (acc): 90.0\n",
      " Precision (prc): 86.667\n",
      " Recall (rec): 100.0\n",
      " Sensitivity (sns): 100.0\n",
      " Specificity (spc): 71.429\n",
      " F1 Score (f1s): 92.857\n",
      " ROC AUC (AUC): 0.857\n",
      "Score columns: (1, 12) ['method', 'model', 'model_parameters', 'model_scores', 'confusion_matrix', 'accuracy', 'precision', 'recall', 'sensitivity', 'specificity', 'f1_score', 'roc_auc']\n",
      "\n",
      "        Best model (GriveSearchCV): GridSearchCV(cv=5, estimator=KNeighborsClassifier(), n_jobs=50,\n",
      "             param_grid={'metric': ['manhattan', 'minkowski', 'euclidean'],\n",
      "                         'n_neighbors': [2, 3, 5, 10, 15, 25, 35]},\n",
      "             return_train_score=True, scoring='f1', verbose=2) \n",
      "        Best model: GridSearchCV(cv=5, estimator=KNeighborsClassifier(), n_jobs=50,\n",
      "             param_grid={'metric': ['manhattan', 'minkowski', 'euclidean'],\n",
      "                         'n_neighbors': [2, 3, 5, 10, 15, 25, 35]},\n",
      "             return_train_score=True, scoring='f1', verbose=2) \n",
      "        Best estimator of the model: KNeighborsClassifier(metric='manhattan', n_neighbors=15) \n",
      "        Best parameters of the model: {'metric': 'manhattan', 'n_neighbors': 15} \n",
      "        ---------------------------------------------------------------------------------------------------\n",
      "        \n",
      "\n",
      "            *** ML MODEL FOR TEST:1, TRAINING:3 AND MODEL: DT \n",
      "            ---------------------------------------------------------------------------------------------------\n",
      "            \n",
      "Calling method: decision_tree_parameters\n",
      "All parameters: ['max_depth', 'criterion', 'splitter', 'min_samples_split', 'min_samples_leaf', 'max_leaf_nodes'], [[2, 3, 5, 7, 10, 15, 20, 25, 30], ['gini', 'entropy', 'log_loss']], [0, 1]\n",
      "Parameters:  {'max_depth': [2, 3, 5, 7, 10, 15, 20, 25, 30], 'criterion': ['gini', 'entropy', 'log_loss']}\n",
      "\n",
      "        From training? True, Data shape: (146, 38), Indices: [111  46 158  55  20  49  74 126  86  27 149  32 109  15 120 138   8  83\n",
      "  29   3 112  96  24  59  60   2  87 114  47 103  37  82 157 127  64 115\n",
      " 133 130 124  53 135 129 142 132 106  25  33 161  93 154  92  16  71 165\n",
      "  18 148 131  85 107 159 152  84  40 143  42 151 153  21  78 156 136  12\n",
      "   5  31  23  61 141  43  19 101  11 105  77 108  45  14  34  72 146  28\n",
      "  69 102   6   0  75  67  30  13  10 113  76   9  35  38 137  41  81 125\n",
      "  91 123  58 155 100 164  63 128  97  73  22  70  65  94  62  89  52  57\n",
      " 150 121 134  54  51 160 122 116 140  99  98  66 147 139  17 110   1 117\n",
      " 118  50]\n",
      "        All Columns: ['Dataset', 'Category', 'Subject_Name', 'Class', 'W->S1', 'W->S2', 'W->S3', 'W->S4', 'W->REM', 'S1->W', 'S1->S1', 'S1->S2', 'S1->S3', 'S1->S4', 'S1->REM', 'S2->W', 'S2->S1', 'S2->S2', 'S2->S3', 'S2->S4', 'S2->REM', 'S3->W', 'S3->S1', 'S3->S2', 'S3->S3', 'S3->S4', 'S3->REM', 'S4->W', 'S4->S1', 'S4->S2', 'S4->S3', 'S4->S4', 'S4->REM', 'REM->W', 'REM->S1', 'REM->S2', 'REM->S3', 'REM->REM']\n",
      "        \n",
      "\n",
      "        Feature shape: (146, 34), Target shape: (146,), Metadata: (146, 3) \n",
      "        \n",
      "\n",
      "        GridSearch: DT - {'max_depth': [2, 3, 5, 7, 10, 15, 20, 25, 30], 'criterion': ['gini', 'entropy', 'log_loss']} \n",
      "        ---------------------------------------------------------------------------------------------------\n",
      "        \n",
      "Refitting the model with best parameter f1 == True\n",
      "Fitting 5 folds for each of 27 candidates, totalling 135 fits\n",
      "\n",
      "        From training? False, Data shape: (20, 38), Indices: [ 26  90   7  88 145   4  39 162  44  79  95 144  68  36  48 119  80  56\n",
      " 104 163]\n",
      "        All Columns: ['Dataset', 'Category', 'Subject_Name', 'Class', 'W->S1', 'W->S2', 'W->S3', 'W->S4', 'W->REM', 'S1->W', 'S1->S1', 'S1->S2', 'S1->S3', 'S1->S4', 'S1->REM', 'S2->W', 'S2->S1', 'S2->S2', 'S2->S3', 'S2->S4', 'S2->REM', 'S3->W', 'S3->S1', 'S3->S2', 'S3->S3', 'S3->S4', 'S3->REM', 'S4->W', 'S4->S1', 'S4->S2', 'S4->S3', 'S4->S4', 'S4->REM', 'REM->W', 'REM->S1', 'REM->S2', 'REM->S3', 'REM->REM']\n",
      "        \n",
      "\n",
      "        Feature shape: (20, 34), Target shape: (20,), Metadata: (20, 3) \n",
      "        \n",
      "[0 1] [0 1]\n",
      "[1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0] [1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0]\n",
      "[[ 5  2]\n",
      " [ 0 13]]\n",
      "[[13  0  2  5]\n",
      " [ 5  2  0 13]]\n",
      "[[18  2]\n",
      " [ 2 18]]\n",
      "Class-wise info: For multilevel internal scores fo label 0: \n",
      " Accuracy = 90.0\n",
      " Precision = [0.86666667 1.        ]\n",
      " Recall = [1.         0.71428571]\n",
      " F1 score = [0.92857143 0.83333333]\n",
      " AUC score = 85.71428571428572\n",
      " Support = [13  7]\n",
      "\n",
      "Class-wise info: For multilevel internal scores fo label 1: \n",
      " Accuracy = 90.0\n",
      " Precision = [1.         0.86666667]\n",
      " Recall = [0.71428571 1.        ]\n",
      " F1 score = [0.83333333 0.92857143]\n",
      " AUC score = 85.71428571428572\n",
      " Support = [ 7 13]\n",
      "\n",
      "CLASSIFICATION MERICS:\n",
      " _______________________________________________________\n",
      " Confusion Matrix: \n",
      "[[ 5  2]\n",
      " [ 0 13]]\n",
      " Accuracy (acc): 90.0\n",
      " Precision (prc): 86.667\n",
      " Recall (rec): 100.0\n",
      " Sensitivity (sns): 100.0\n",
      " Specificity (spc): 71.429\n",
      " F1 Score (f1s): 92.857\n",
      " ROC AUC (AUC): 0.857\n",
      "Score columns: (1, 12) ['method', 'model', 'model_parameters', 'model_scores', 'confusion_matrix', 'accuracy', 'precision', 'recall', 'sensitivity', 'specificity', 'f1_score', 'roc_auc']\n",
      "\n",
      "        Best model (GriveSearchCV): GridSearchCV(cv=5, estimator=DecisionTreeClassifier(), n_jobs=50,\n",
      "             param_grid={'criterion': ['gini', 'entropy', 'log_loss'],\n",
      "                         'max_depth': [2, 3, 5, 7, 10, 15, 20, 25, 30]},\n",
      "             return_train_score=True, scoring='f1', verbose=2) \n",
      "        Best model: GridSearchCV(cv=5, estimator=DecisionTreeClassifier(), n_jobs=50,\n",
      "             param_grid={'criterion': ['gini', 'entropy', 'log_loss'],\n",
      "                         'max_depth': [2, 3, 5, 7, 10, 15, 20, 25, 30]},\n",
      "             return_train_score=True, scoring='f1', verbose=2) \n",
      "        Best estimator of the model: DecisionTreeClassifier(max_depth=2) \n",
      "        Best parameters of the model: {'criterion': 'gini', 'max_depth': 2} \n",
      "        ---------------------------------------------------------------------------------------------------\n",
      "        \n",
      "\n",
      "            *** ML MODEL FOR TEST:1, TRAINING:3 AND MODEL: RF \n",
      "            ---------------------------------------------------------------------------------------------------\n",
      "            \n",
      "Calling method: random_forest_parameters\n",
      "All parameters: ['n_estimators', 'max_depth', 'criterion', 'splitter', 'max_features', 'min_samples_split', 'min_samples_leaf', 'max_leaf_nodes'], [[3, 5, 10, 15, 21, 30, 50, 75, 100], [2, 3, 5, 7, 10, 15, 20, 25, 30], ['gini', 'entropy', 'log_loss']], [0, 1, 2]\n",
      "Parameters:  {'n_estimators': [3, 5, 10, 15, 21, 30, 50, 75, 100], 'max_depth': [2, 3, 5, 7, 10, 15, 20, 25, 30], 'criterion': ['gini', 'entropy', 'log_loss']}\n",
      "\n",
      "        From training? True, Data shape: (146, 38), Indices: [111  46 158  55  20  49  74 126  86  27 149  32 109  15 120 138   8  83\n",
      "  29   3 112  96  24  59  60   2  87 114  47 103  37  82 157 127  64 115\n",
      " 133 130 124  53 135 129 142 132 106  25  33 161  93 154  92  16  71 165\n",
      "  18 148 131  85 107 159 152  84  40 143  42 151 153  21  78 156 136  12\n",
      "   5  31  23  61 141  43  19 101  11 105  77 108  45  14  34  72 146  28\n",
      "  69 102   6   0  75  67  30  13  10 113  76   9  35  38 137  41  81 125\n",
      "  91 123  58 155 100 164  63 128  97  73  22  70  65  94  62  89  52  57\n",
      " 150 121 134  54  51 160 122 116 140  99  98  66 147 139  17 110   1 117\n",
      " 118  50]\n",
      "        All Columns: ['Dataset', 'Category', 'Subject_Name', 'Class', 'W->S1', 'W->S2', 'W->S3', 'W->S4', 'W->REM', 'S1->W', 'S1->S1', 'S1->S2', 'S1->S3', 'S1->S4', 'S1->REM', 'S2->W', 'S2->S1', 'S2->S2', 'S2->S3', 'S2->S4', 'S2->REM', 'S3->W', 'S3->S1', 'S3->S2', 'S3->S3', 'S3->S4', 'S3->REM', 'S4->W', 'S4->S1', 'S4->S2', 'S4->S3', 'S4->S4', 'S4->REM', 'REM->W', 'REM->S1', 'REM->S2', 'REM->S3', 'REM->REM']\n",
      "        \n",
      "\n",
      "        Feature shape: (146, 34), Target shape: (146,), Metadata: (146, 3) \n",
      "        \n",
      "\n",
      "        GridSearch: RF - {'n_estimators': [3, 5, 10, 15, 21, 30, 50, 75, 100], 'max_depth': [2, 3, 5, 7, 10, 15, 20, 25, 30], 'criterion': ['gini', 'entropy', 'log_loss']} \n",
      "        ---------------------------------------------------------------------------------------------------\n",
      "        \n",
      "Refitting the model with best parameter f1 == True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aliem\\.conda\\envs\\MyPython37Work\\lib\\site-packages\\sklearn\\model_selection\\_search.py:921: UserWarning: One or more of the test scores are non-finite: [0.9058518  0.85744782 0.8205319  0.79386524 0.82115168 0.83553987\n",
      " 0.83752655 0.85491641 0.84992009 0.9058518  0.87822831 0.83271421\n",
      " 0.81531674 0.80601716 0.83501371 0.82869697 0.85051708 0.82824009\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan]\n",
      "  category=UserWarning\n",
      "C:\\Users\\aliem\\.conda\\envs\\MyPython37Work\\lib\\site-packages\\sklearn\\model_selection\\_search.py:921: UserWarning: One or more of the train scores are non-finite: [0.92399873 0.93346421 0.98392051 0.9984252  1.         1.\n",
      " 1.         1.         1.         0.92399873 0.93127631 0.97758319\n",
      " 1.         1.         1.         1.         1.         1.\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan]\n",
      "  category=UserWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 243 candidates, totalling 1215 fits\n",
      "\n",
      "        From training? False, Data shape: (20, 38), Indices: [ 26  90   7  88 145   4  39 162  44  79  95 144  68  36  48 119  80  56\n",
      " 104 163]\n",
      "        All Columns: ['Dataset', 'Category', 'Subject_Name', 'Class', 'W->S1', 'W->S2', 'W->S3', 'W->S4', 'W->REM', 'S1->W', 'S1->S1', 'S1->S2', 'S1->S3', 'S1->S4', 'S1->REM', 'S2->W', 'S2->S1', 'S2->S2', 'S2->S3', 'S2->S4', 'S2->REM', 'S3->W', 'S3->S1', 'S3->S2', 'S3->S3', 'S3->S4', 'S3->REM', 'S4->W', 'S4->S1', 'S4->S2', 'S4->S3', 'S4->S4', 'S4->REM', 'REM->W', 'REM->S1', 'REM->S2', 'REM->S3', 'REM->REM']\n",
      "        \n",
      "\n",
      "        Feature shape: (20, 34), Target shape: (20,), Metadata: (20, 3) \n",
      "        \n",
      "[0 1] [0 1]\n",
      "[1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0] [1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0]\n",
      "[[ 5  2]\n",
      " [ 1 12]]\n",
      "[[12  1  2  5]\n",
      " [ 5  2  1 12]]\n",
      "[[17  3]\n",
      " [ 3 17]]\n",
      "Class-wise info: For multilevel internal scores fo label 0: \n",
      " Accuracy = 85.0\n",
      " Precision = [0.85714286 0.83333333]\n",
      " Recall = [0.92307692 0.71428571]\n",
      " F1 score = [0.88888889 0.76923077]\n",
      " AUC score = 81.86813186813188\n",
      " Support = [13  7]\n",
      "\n",
      "Class-wise info: For multilevel internal scores fo label 1: \n",
      " Accuracy = 85.0\n",
      " Precision = [0.83333333 0.85714286]\n",
      " Recall = [0.71428571 0.92307692]\n",
      " F1 score = [0.76923077 0.88888889]\n",
      " AUC score = 81.86813186813187\n",
      " Support = [ 7 13]\n",
      "\n",
      "CLASSIFICATION MERICS:\n",
      " _______________________________________________________\n",
      " Confusion Matrix: \n",
      "[[ 5  2]\n",
      " [ 1 12]]\n",
      " Accuracy (acc): 85.0\n",
      " Precision (prc): 85.714\n",
      " Recall (rec): 92.308\n",
      " Sensitivity (sns): 92.308\n",
      " Specificity (spc): 71.429\n",
      " F1 Score (f1s): 88.889\n",
      " ROC AUC (AUC): 0.819\n",
      "Score columns: (1, 12) ['method', 'model', 'model_parameters', 'model_scores', 'confusion_matrix', 'accuracy', 'precision', 'recall', 'sensitivity', 'specificity', 'f1_score', 'roc_auc']\n",
      "\n",
      "        Best model (GriveSearchCV): GridSearchCV(cv=5, estimator=RandomForestClassifier(), n_jobs=50,\n",
      "             param_grid={'criterion': ['gini', 'entropy', 'log_loss'],\n",
      "                         'max_depth': [2, 3, 5, 7, 10, 15, 20, 25, 30],\n",
      "                         'n_estimators': [3, 5, 10, 15, 21, 30, 50, 75, 100]},\n",
      "             return_train_score=True, scoring='f1', verbose=2) \n",
      "        Best model: GridSearchCV(cv=5, estimator=RandomForestClassifier(), n_jobs=50,\n",
      "             param_grid={'criterion': ['gini', 'entropy', 'log_loss'],\n",
      "                         'max_depth': [2, 3, 5, 7, 10, 15, 20, 25, 30],\n",
      "                         'n_estimators': [3, 5, 10, 15, 21, 30, 50, 75, 100]},\n",
      "             return_train_score=True, scoring='f1', verbose=2) \n",
      "        Best estimator of the model: RandomForestClassifier(max_depth=5, n_estimators=30) \n",
      "        Best parameters of the model: {'criterion': 'gini', 'max_depth': 5, 'n_estimators': 30} \n",
      "        ---------------------------------------------------------------------------------------------------\n",
      "        \n",
      "\n",
      "            *** ML MODEL FOR TEST:1, TRAINING:3 AND MODEL: GB \n",
      "            ---------------------------------------------------------------------------------------------------\n",
      "            \n",
      "Calling method: gradient_boosting_parameters\n",
      "All parameters: ['n_estimators', 'max_depth', 'learning_rate', 'max_features', 'loss', 'min_samples_split', 'min_samples_leaf'], [[3, 5, 10, 15, 21, 30, 50, 75, 100], [2, 3, 5, 7, 10, 15, 20, 25, 30], [0.01, 0.05, 0.1, 0.5, 1.0]], [0, 1, 2]\n",
      "Parameters:  {'n_estimators': [3, 5, 10, 15, 21, 30, 50, 75, 100], 'max_depth': [2, 3, 5, 7, 10, 15, 20, 25, 30], 'learning_rate': [0.01, 0.05, 0.1, 0.5, 1.0]}\n",
      "\n",
      "        From training? True, Data shape: (146, 38), Indices: [111  46 158  55  20  49  74 126  86  27 149  32 109  15 120 138   8  83\n",
      "  29   3 112  96  24  59  60   2  87 114  47 103  37  82 157 127  64 115\n",
      " 133 130 124  53 135 129 142 132 106  25  33 161  93 154  92  16  71 165\n",
      "  18 148 131  85 107 159 152  84  40 143  42 151 153  21  78 156 136  12\n",
      "   5  31  23  61 141  43  19 101  11 105  77 108  45  14  34  72 146  28\n",
      "  69 102   6   0  75  67  30  13  10 113  76   9  35  38 137  41  81 125\n",
      "  91 123  58 155 100 164  63 128  97  73  22  70  65  94  62  89  52  57\n",
      " 150 121 134  54  51 160 122 116 140  99  98  66 147 139  17 110   1 117\n",
      " 118  50]\n",
      "        All Columns: ['Dataset', 'Category', 'Subject_Name', 'Class', 'W->S1', 'W->S2', 'W->S3', 'W->S4', 'W->REM', 'S1->W', 'S1->S1', 'S1->S2', 'S1->S3', 'S1->S4', 'S1->REM', 'S2->W', 'S2->S1', 'S2->S2', 'S2->S3', 'S2->S4', 'S2->REM', 'S3->W', 'S3->S1', 'S3->S2', 'S3->S3', 'S3->S4', 'S3->REM', 'S4->W', 'S4->S1', 'S4->S2', 'S4->S3', 'S4->S4', 'S4->REM', 'REM->W', 'REM->S1', 'REM->S2', 'REM->S3', 'REM->REM']\n",
      "        \n",
      "\n",
      "        Feature shape: (146, 34), Target shape: (146,), Metadata: (146, 3) \n",
      "        \n",
      "\n",
      "        GridSearch: GB - {'n_estimators': [3, 5, 10, 15, 21, 30, 50, 75, 100], 'max_depth': [2, 3, 5, 7, 10, 15, 20, 25, 30], 'learning_rate': [0.01, 0.05, 0.1, 0.5, 1.0]} \n",
      "        ---------------------------------------------------------------------------------------------------\n",
      "        \n",
      "Refitting the model with best parameter f1 == True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aliem\\.conda\\envs\\MyPython37Work\\lib\\site-packages\\sklearn\\model_selection\\_search.py:921: UserWarning: One or more of the test scores are non-finite: [0.86605509 0.89676937 0.91354554 0.91892369 0.91257448 0.91892369\n",
      " 0.9058518  0.91892369 0.91892369 0.87375223 0.91220779 0.90715898\n",
      " 0.90615737 0.91892369 0.91892369 0.91892369 0.91892369 0.91892369\n",
      " 0.84200794 0.88900772 0.9056884  0.90618793 0.91186147 0.92462779\n",
      " 0.92462779 0.92462779 0.91821068 0.79788561 0.86942322 0.8913552\n",
      " 0.91688121 0.90031025 0.92462779 0.92462779 0.92462779 0.9181884\n",
      " 0.8316848  0.85976808 0.90217532 0.89159982 0.8985978  0.90500594\n",
      " 0.9113925  0.92462779 0.92462779 0.8270088  0.8735023  0.88502637\n",
      " 0.91177128 0.88493088 0.91137021 0.92462779 0.91177128 0.92462779\n",
      " 0.86630937 0.90411215 0.89516106 0.8986039  0.89856724 0.89856724\n",
      " 0.92462779 0.92462779 0.92462779 0.82507512 0.875403   0.90144958\n",
      " 0.9113925  0.90504329 0.91250658 0.91647186 0.91177128 0.9181884\n",
      " 0.85017538 0.86958916 0.88475936 0.91183919 0.90491645 0.9113925\n",
      " 0.90491645 0.92462779 0.92462779 0.88695696 0.89045663 0.91892369\n",
      " 0.90615737 0.91892369 0.91892369 0.91892369 0.91892369 0.91892369\n",
      " 0.9056884  0.89395425 0.9056884  0.91892369 0.91892369 0.91892369\n",
      " 0.91892369 0.91892369 0.91892369 0.88123249 0.88506494 0.89843033\n",
      " 0.90442577 0.91182412 0.91250658 0.92462779 0.91892369 0.91892369\n",
      " 0.87111224 0.9045514  0.9049531  0.8983206  0.89798638 0.91189203\n",
      " 0.92462779 0.91821068 0.92462779 0.89448949 0.87928571 0.85470588\n",
      " 0.89769504 0.91186147 0.91177128 0.92462779 0.9113925  0.92462779\n",
      " 0.88137158 0.8986039  0.87548574 0.92462779 0.91821068 0.92462779\n",
      " 0.92462779 0.92462779 0.92462779 0.87367003 0.85722486 0.90360926\n",
      " 0.90413443 0.8986039  0.92462779 0.91133356 0.92462779 0.92462779\n",
      " 0.86549865 0.88449099 0.86087822 0.9027744  0.9181884  0.9049531\n",
      " 0.9181884  0.91821068 0.92462779 0.86853134 0.90415033 0.88678716\n",
      " 0.91177128 0.91685065 0.9049531  0.91821068 0.91821068 0.9181884\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan]\n",
      "  category=UserWarning\n",
      "C:\\Users\\aliem\\.conda\\envs\\MyPython37Work\\lib\\site-packages\\sklearn\\model_selection\\_search.py:921: UserWarning: One or more of the train scores are non-finite: [0.90748389 0.91837189 0.91654001 0.92129327 0.91995869 0.91995869\n",
      " 0.91862578 0.91862578 0.91862578 0.92520397 0.92133124 0.92535124\n",
      " 0.92535124 0.92407678 0.92535124 0.92672379 0.92399873 0.92266582\n",
      " 0.94428662 0.95717682 0.96499812 0.9604904  0.96645422 0.97540574\n",
      " 0.96788963 0.97239735 0.97383331 0.97379851 0.98141604 0.99064903\n",
      " 0.99072004 0.99527559 0.99532461 0.99687481 0.9984252  0.9984252\n",
      " 0.96690815 0.98296903 0.99527559 0.99530001 1.         1.\n",
      " 1.         1.         1.         0.96743282 0.98144004 0.99215001\n",
      " 0.9984252  0.9984252  0.996875   1.         1.         1.\n",
      " 0.98892461 0.98143986 0.996875   0.98602135 0.99687481 0.9984252\n",
      " 1.         1.         1.         0.96828847 0.98897521 0.9984252\n",
      " 0.9984252  0.9953002  1.         1.         1.         1.\n",
      " 0.95932163 0.98611622 0.99227135 0.99692308 0.99534827 1.\n",
      " 1.         1.         1.         0.91252291 0.91019882 0.91862578\n",
      " 0.91220444 0.91995869 0.91731205 0.91862578 0.91862578 0.91862578\n",
      " 0.92607538 0.92113561 0.93203397 0.92535124 0.92262618 0.91999833\n",
      " 0.92266582 0.92266582 0.92129327 0.9479422  0.96760382 0.96196927\n",
      " 0.96946085 0.9561828  0.96517954 0.96201361 0.96934695 0.97089413\n",
      " 0.96876049 0.96913016 0.99374981 0.9937252  0.99217501 0.99685039\n",
      " 0.9984252  1.         1.         0.97312797 0.98449519 0.9984252\n",
      " 0.99527559 1.         0.99844961 1.         1.         1.\n",
      " 0.97066133 0.98282327 0.99364919 0.99687481 0.9953002  1.\n",
      " 1.         1.         1.         0.97332443 0.98437346 0.99217501\n",
      " 0.99379808 1.         0.9984252  1.         1.         1.\n",
      " 0.96334877 0.98287155 0.99370079 0.9984252  0.9937252  0.99687481\n",
      " 1.         1.         1.         0.97957677 0.98112522 0.99527559\n",
      " 0.99685039 0.9953002  1.         1.         1.         1.\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan]\n",
      "  category=UserWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 405 candidates, totalling 2025 fits\n",
      "\n",
      "        From training? False, Data shape: (20, 38), Indices: [ 26  90   7  88 145   4  39 162  44  79  95 144  68  36  48 119  80  56\n",
      " 104 163]\n",
      "        All Columns: ['Dataset', 'Category', 'Subject_Name', 'Class', 'W->S1', 'W->S2', 'W->S3', 'W->S4', 'W->REM', 'S1->W', 'S1->S1', 'S1->S2', 'S1->S3', 'S1->S4', 'S1->REM', 'S2->W', 'S2->S1', 'S2->S2', 'S2->S3', 'S2->S4', 'S2->REM', 'S3->W', 'S3->S1', 'S3->S2', 'S3->S3', 'S3->S4', 'S3->REM', 'S4->W', 'S4->S1', 'S4->S2', 'S4->S3', 'S4->S4', 'S4->REM', 'REM->W', 'REM->S1', 'REM->S2', 'REM->S3', 'REM->REM']\n",
      "        \n",
      "\n",
      "        Feature shape: (20, 34), Target shape: (20,), Metadata: (20, 3) \n",
      "        \n",
      "[0 1] [0 1]\n",
      "[1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0] [1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0]\n",
      "[[ 5  2]\n",
      " [ 0 13]]\n",
      "[[13  0  2  5]\n",
      " [ 5  2  0 13]]\n",
      "[[18  2]\n",
      " [ 2 18]]\n",
      "Class-wise info: For multilevel internal scores fo label 0: \n",
      " Accuracy = 90.0\n",
      " Precision = [0.86666667 1.        ]\n",
      " Recall = [1.         0.71428571]\n",
      " F1 score = [0.92857143 0.83333333]\n",
      " AUC score = 85.71428571428572\n",
      " Support = [13  7]\n",
      "\n",
      "Class-wise info: For multilevel internal scores fo label 1: \n",
      " Accuracy = 90.0\n",
      " Precision = [1.         0.86666667]\n",
      " Recall = [0.71428571 1.        ]\n",
      " F1 score = [0.83333333 0.92857143]\n",
      " AUC score = 85.71428571428572\n",
      " Support = [ 7 13]\n",
      "\n",
      "CLASSIFICATION MERICS:\n",
      " _______________________________________________________\n",
      " Confusion Matrix: \n",
      "[[ 5  2]\n",
      " [ 0 13]]\n",
      " Accuracy (acc): 90.0\n",
      " Precision (prc): 86.667\n",
      " Recall (rec): 100.0\n",
      " Sensitivity (sns): 100.0\n",
      " Specificity (spc): 71.429\n",
      " F1 Score (f1s): 92.857\n",
      " ROC AUC (AUC): 0.857\n",
      "Score columns: (1, 12) ['method', 'model', 'model_parameters', 'model_scores', 'confusion_matrix', 'accuracy', 'precision', 'recall', 'sensitivity', 'specificity', 'f1_score', 'roc_auc']\n",
      "\n",
      "        Best model (GriveSearchCV): GridSearchCV(cv=5, estimator=GradientBoostingClassifier(), n_jobs=50,\n",
      "             param_grid={'learning_rate': [0.01, 0.05, 0.1, 0.5, 1.0],\n",
      "                         'max_depth': [2, 3, 5, 7, 10, 15, 20, 25, 30],\n",
      "                         'n_estimators': [3, 5, 10, 15, 21, 30, 50, 75, 100]},\n",
      "             return_train_score=True, scoring='f1', verbose=2) \n",
      "        Best model: GridSearchCV(cv=5, estimator=GradientBoostingClassifier(), n_jobs=50,\n",
      "             param_grid={'learning_rate': [0.01, 0.05, 0.1, 0.5, 1.0],\n",
      "                         'max_depth': [2, 3, 5, 7, 10, 15, 20, 25, 30],\n",
      "                         'n_estimators': [3, 5, 10, 15, 21, 30, 50, 75, 100]},\n",
      "             return_train_score=True, scoring='f1', verbose=2) \n",
      "        Best estimator of the model: GradientBoostingClassifier(learning_rate=0.01, max_depth=2, n_estimators=10) \n",
      "        Best parameters of the model: {'learning_rate': 0.01, 'max_depth': 2, 'n_estimators': 10} \n",
      "        ---------------------------------------------------------------------------------------------------\n",
      "        \n",
      "\n",
      "            ---------------------------------------------------------------------------------------------------\n",
      "            Best model index calculation  \n",
      "            \n",
      "\n",
      "            ***************************************************************************************************\n",
      "            TRAINING 3 END... \n",
      "            \n",
      "\n",
      "            *** MODEL TRAINING AND VALIDATION PHASE FOR TEST 1 \n",
      "            TRAINING 4 START... XXXXX \n",
      "            ***************************************************************************************************\n",
      "            Validation=> 20 ['SC4451', 'nfle14', 'SC4441', 'plm4', 'ins9', 'SC4481', 'SC4341', 'SC4371', 'SC4421', 'n13', 'ins1', 'narco3', 'nfle2', 'SC4141', 'plm2', 'n1', 'rbd1', 'rbd19', 'SC4071', 'nfle29'] \n",
      "            Training=> 146 ['ins7', 'SC4541', 'nfle37', 'nfle20', 'SC4511', 'plm10', 'SC4161', 'ins4', 'SC4461', 'sdb2', 'plm3', 'plm8', 'SC4411', 'SC4561', 'SC4221', 'SC4261', 'n11', 'nfle39', 'SC4101', 'nfle35', 'ins8', 'nfle21', 'SC4171', 'SC4061', 'rbd17', 'SC4551', 'nfle4', 'nfle23', 'rbd16', 'ins3', 'rbd2', 'nfle1', 'SC4291', 'sdb4', 'n2', 'rbd15', 'nfle31', 'nfle19', 'SC4531', 'SC4362', 'n12', 'SC4091', 'rbd7', 'n14', 'narco4', 'rbd5', 'rbd13', 'rbd10', 'nfle17', 'rbd11', 'SC4581', 'SC4241', 'rbd6', 'SC4321', 'ins2', 'narco1', 'ins5', 'nfle6', 'plm1', 'SC4281', 'SC4301', 'rbd20', 'nfle9', 'SC4311', 'nfle12', 'n4', 'n6', 'nfle25', 'SC4011', 'SC4381', 'SC4021', 'narco5', 'nfle30', 'SC4571', 'nfle22', 'SC4431', 'nfle27', 'nfle40', 'nfle26', 'n15', 'rbd9', 'nfle38', 'nfle3', 'SC4231', 'brux2', 'nfle34', 'nfle18', 'n10', 'n7', 'SC4351', 'rbd21', 'nfle7', 'SC4191', 'SC4201', 'SC4121', 'SC4151', 'n9', 'rbd22', 'SC4522', 'plm7', 'sdb3', 'SC4051', 'SC4471', 'narco2', 'SC4211', 'SC4181', 'SC4331', 'nfle32', 'n8', 'plm5', 'SC4031', 'nfle11', 'nfle33', 'nfle8', 'sdb1', 'SC4131', 'SC4001', 'nfle36', 'nfle5', 'SC4401', 'nfle24', 'plm6', 'plm9', 'SC4501', 'nfle28', 'rbd4', 'rbd14', 'n5', 'nfle10', 'SC4271', 'nfle16', 'SC4081', 'rbd18', 'brux1', 'ins6', 'n16', 'SC4111', 'rbd3', 'rbd8', 'rbd12', 'SC4491', 'SC4041', 'SC4251', 'nfle13', 'n3', 'nfle15'] \n",
      "            \n",
      "\n",
      "            *** ML MODEL FOR TEST:1, TRAINING:4 AND MODEL: LR \n",
      "            ---------------------------------------------------------------------------------------------------\n",
      "            \n",
      "Calling method: logistic_regression_parameters\n",
      "All parameters: ['penalty', 'solver', 'max_iter', 'C'], [['l2', 'elasticnet'], [50, 100, 130, 150, 170, 200], [0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1.0]], [0, 2, 3]\n",
      "Parameters:  {'penalty': ['l2', 'elasticnet'], 'max_iter': [50, 100, 130, 150, 170, 200], 'C': [0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1.0]}\n",
      "\n",
      "        From training? True, Data shape: (146, 38), Indices: [ 12 161  56  39 158  69 124   9 153   3  62  67 148 163 130 134 102  58\n",
      " 118  54  13  40 125 114  86 162  23  42  85   8  71  20 137   5  93  84\n",
      "  50  38 160 144 103 117  76 105  18  74  82  79  36  80 165 132  75 140\n",
      "   7  15  10  25  60 136 138  89  28 139  31  95  97  44 109 146 110  19\n",
      "  49 164  41 150  46  59  45 106  78  57  22 131   1  53  37 101  98 143\n",
      "  90  26 127 128 120 123 100  91 159  66   4 113 154  16 129 126 141  51\n",
      "  99  64 111  30  52  27   2 121 108  55  24 147  43  65  68 157  47  73\n",
      "  83  96  29 135  35 116  87   0  11 107 119  72  77  81 156 112 133  32\n",
      "  94  34]\n",
      "        All Columns: ['Dataset', 'Category', 'Subject_Name', 'Class', 'W->S1', 'W->S2', 'W->S3', 'W->S4', 'W->REM', 'S1->W', 'S1->S1', 'S1->S2', 'S1->S3', 'S1->S4', 'S1->REM', 'S2->W', 'S2->S1', 'S2->S2', 'S2->S3', 'S2->S4', 'S2->REM', 'S3->W', 'S3->S1', 'S3->S2', 'S3->S3', 'S3->S4', 'S3->REM', 'S4->W', 'S4->S1', 'S4->S2', 'S4->S3', 'S4->S4', 'S4->REM', 'REM->W', 'REM->S1', 'REM->S2', 'REM->S3', 'REM->REM']\n",
      "        \n",
      "\n",
      "        Feature shape: (146, 34), Target shape: (146,), Metadata: (146, 3) \n",
      "        \n",
      "\n",
      "        GridSearch: LR - {'penalty': ['l2', 'elasticnet'], 'max_iter': [50, 100, 130, 150, 170, 200], 'C': [0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1.0]} \n",
      "        ---------------------------------------------------------------------------------------------------\n",
      "        \n",
      "Refitting the model with best parameter f1 == True\n",
      "Fitting 5 folds for each of 84 candidates, totalling 420 fits\n",
      "\n",
      "        From training? False, Data shape: (20, 38), Indices: [152  33 151  63  14 155 142 145 149 104   6  17  21 122  61  92  70  88\n",
      " 115  48]\n",
      "        All Columns: ['Dataset', 'Category', 'Subject_Name', 'Class', 'W->S1', 'W->S2', 'W->S3', 'W->S4', 'W->REM', 'S1->W', 'S1->S1', 'S1->S2', 'S1->S3', 'S1->S4', 'S1->REM', 'S2->W', 'S2->S1', 'S2->S2', 'S2->S3', 'S2->S4', 'S2->REM', 'S3->W', 'S3->S1', 'S3->S2', 'S3->S3', 'S3->S4', 'S3->REM', 'S4->W', 'S4->S1', 'S4->S2', 'S4->S3', 'S4->S4', 'S4->REM', 'REM->W', 'REM->S1', 'REM->S2', 'REM->S3', 'REM->REM']\n",
      "        \n",
      "\n",
      "        Feature shape: (20, 34), Target shape: (20,), Metadata: (20, 3) \n",
      "        \n",
      "[0 1] [0 1]\n",
      "[0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1] [1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1]\n",
      "[[ 7  3]\n",
      " [ 0 10]]\n",
      "[[10  0  3  7]\n",
      " [ 7  3  0 10]]\n",
      "[[17  3]\n",
      " [ 3 17]]\n",
      "Class-wise info: For multilevel internal scores fo label 0: \n",
      " Accuracy = 85.0\n",
      " Precision = [0.76923077 1.        ]\n",
      " Recall = [1.  0.7]\n",
      " F1 score = [0.86956522 0.82352941]\n",
      " AUC score = 85.0\n",
      " Support = [10 10]\n",
      "\n",
      "Class-wise info: For multilevel internal scores fo label 1: \n",
      " Accuracy = 85.0\n",
      " Precision = [1.         0.76923077]\n",
      " Recall = [0.7 1. ]\n",
      " F1 score = [0.82352941 0.86956522]\n",
      " AUC score = 85.0\n",
      " Support = [10 10]\n",
      "\n",
      "CLASSIFICATION MERICS:\n",
      " _______________________________________________________\n",
      " Confusion Matrix: \n",
      "[[ 7  3]\n",
      " [ 0 10]]\n",
      " Accuracy (acc): 85.0\n",
      " Precision (prc): 76.923\n",
      " Recall (rec): 100.0\n",
      " Sensitivity (sns): 100.0\n",
      " Specificity (spc): 70.0\n",
      " F1 Score (f1s): 86.957\n",
      " ROC AUC (AUC): 0.85\n",
      "Score columns: (1, 12) ['method', 'model', 'model_parameters', 'model_scores', 'confusion_matrix', 'accuracy', 'precision', 'recall', 'sensitivity', 'specificity', 'f1_score', 'roc_auc']\n",
      "\n",
      "        Best model (GriveSearchCV): GridSearchCV(cv=5, estimator=LogisticRegression(), n_jobs=50,\n",
      "             param_grid={'C': [0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1.0],\n",
      "                         'max_iter': [50, 100, 130, 150, 170, 200],\n",
      "                         'penalty': ['l2', 'elasticnet']},\n",
      "             return_train_score=True, scoring='f1', verbose=2) \n",
      "        Best model: GridSearchCV(cv=5, estimator=LogisticRegression(), n_jobs=50,\n",
      "             param_grid={'C': [0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1.0],\n",
      "                         'max_iter': [50, 100, 130, 150, 170, 200],\n",
      "                         'penalty': ['l2', 'elasticnet']},\n",
      "             return_train_score=True, scoring='f1', verbose=2) \n",
      "        Best estimator of the model: LogisticRegression(C=0.5, max_iter=50) \n",
      "        Best parameters of the model: {'C': 0.5, 'max_iter': 50, 'penalty': 'l2'} \n",
      "        ---------------------------------------------------------------------------------------------------\n",
      "        \n",
      "\n",
      "            *** ML MODEL FOR TEST:1, TRAINING:4 AND MODEL: SVC \n",
      "            ---------------------------------------------------------------------------------------------------\n",
      "            \n",
      "Calling method: support_vector_classifier_parameters\n",
      "All parameters: ['probability', 'C', 'kernel', 'gamma', 'degree', 'class_weightdict'], [[True], [0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1.0], ['linear', 'rbf', 'poly']], [0, 1, 2]\n",
      "Parameters:  {'probability': [True], 'C': [0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1.0], 'kernel': ['linear', 'rbf', 'poly']}\n",
      "\n",
      "        From training? True, Data shape: (146, 38), Indices: [ 12 161  56  39 158  69 124   9 153   3  62  67 148 163 130 134 102  58\n",
      " 118  54  13  40 125 114  86 162  23  42  85   8  71  20 137   5  93  84\n",
      "  50  38 160 144 103 117  76 105  18  74  82  79  36  80 165 132  75 140\n",
      "   7  15  10  25  60 136 138  89  28 139  31  95  97  44 109 146 110  19\n",
      "  49 164  41 150  46  59  45 106  78  57  22 131   1  53  37 101  98 143\n",
      "  90  26 127 128 120 123 100  91 159  66   4 113 154  16 129 126 141  51\n",
      "  99  64 111  30  52  27   2 121 108  55  24 147  43  65  68 157  47  73\n",
      "  83  96  29 135  35 116  87   0  11 107 119  72  77  81 156 112 133  32\n",
      "  94  34]\n",
      "        All Columns: ['Dataset', 'Category', 'Subject_Name', 'Class', 'W->S1', 'W->S2', 'W->S3', 'W->S4', 'W->REM', 'S1->W', 'S1->S1', 'S1->S2', 'S1->S3', 'S1->S4', 'S1->REM', 'S2->W', 'S2->S1', 'S2->S2', 'S2->S3', 'S2->S4', 'S2->REM', 'S3->W', 'S3->S1', 'S3->S2', 'S3->S3', 'S3->S4', 'S3->REM', 'S4->W', 'S4->S1', 'S4->S2', 'S4->S3', 'S4->S4', 'S4->REM', 'REM->W', 'REM->S1', 'REM->S2', 'REM->S3', 'REM->REM']\n",
      "        \n",
      "\n",
      "        Feature shape: (146, 34), Target shape: (146,), Metadata: (146, 3) \n",
      "        \n",
      "\n",
      "        GridSearch: SVC - {'probability': [True], 'C': [0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1.0], 'kernel': ['linear', 'rbf', 'poly']} \n",
      "        ---------------------------------------------------------------------------------------------------\n",
      "        \n",
      "Refitting the model with best parameter f1 == True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aliem\\.conda\\envs\\MyPython37Work\\lib\\site-packages\\sklearn\\model_selection\\_search.py:921: UserWarning: One or more of the test scores are non-finite: [0.7191736         nan 0.7191736         nan 0.7191736         nan\n",
      " 0.7191736         nan 0.7191736         nan 0.7191736         nan\n",
      " 0.7191736         nan 0.7191736         nan 0.7191736         nan\n",
      " 0.7191736         nan 0.7191736         nan 0.7191736         nan\n",
      " 0.7191736         nan 0.7191736         nan 0.7191736         nan\n",
      " 0.7191736         nan 0.7191736         nan 0.7191736         nan\n",
      " 0.84928037        nan 0.84928037        nan 0.84928037        nan\n",
      " 0.84928037        nan 0.84928037        nan 0.84928037        nan\n",
      " 0.86844273        nan 0.86844273        nan 0.86844273        nan\n",
      " 0.86844273        nan 0.86844273        nan 0.86844273        nan\n",
      " 0.88789361        nan 0.88789361        nan 0.88789361        nan\n",
      " 0.88789361        nan 0.88789361        nan 0.88789361        nan\n",
      " 0.88789361        nan 0.88789361        nan 0.88789361        nan\n",
      " 0.88789361        nan 0.88789361        nan 0.88789361        nan]\n",
      "  category=UserWarning\n",
      "C:\\Users\\aliem\\.conda\\envs\\MyPython37Work\\lib\\site-packages\\sklearn\\model_selection\\_search.py:921: UserWarning: One or more of the train scores are non-finite: [0.71929044        nan 0.71929044        nan 0.71929044        nan\n",
      " 0.71929044        nan 0.71929044        nan 0.71929044        nan\n",
      " 0.71929044        nan 0.71929044        nan 0.71929044        nan\n",
      " 0.71929044        nan 0.71929044        nan 0.71929044        nan\n",
      " 0.72332595        nan 0.72332595        nan 0.72332595        nan\n",
      " 0.72332595        nan 0.72332595        nan 0.72332595        nan\n",
      " 0.85456272        nan 0.85456272        nan 0.85456272        nan\n",
      " 0.85456272        nan 0.85456272        nan 0.85456272        nan\n",
      " 0.87072269        nan 0.87072269        nan 0.87072269        nan\n",
      " 0.87072269        nan 0.87072269        nan 0.87072269        nan\n",
      " 0.8907515         nan 0.8907515         nan 0.8907515         nan\n",
      " 0.8907515         nan 0.8907515         nan 0.8907515         nan\n",
      " 0.89759631        nan 0.89759631        nan 0.89759631        nan\n",
      " 0.89759631        nan 0.89759631        nan 0.89759631        nan]\n",
      "  category=UserWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 21 candidates, totalling 105 fits\n",
      "\n",
      "        From training? False, Data shape: (20, 38), Indices: [152  33 151  63  14 155 142 145 149 104   6  17  21 122  61  92  70  88\n",
      " 115  48]\n",
      "        All Columns: ['Dataset', 'Category', 'Subject_Name', 'Class', 'W->S1', 'W->S2', 'W->S3', 'W->S4', 'W->REM', 'S1->W', 'S1->S1', 'S1->S2', 'S1->S3', 'S1->S4', 'S1->REM', 'S2->W', 'S2->S1', 'S2->S2', 'S2->S3', 'S2->S4', 'S2->REM', 'S3->W', 'S3->S1', 'S3->S2', 'S3->S3', 'S3->S4', 'S3->REM', 'S4->W', 'S4->S1', 'S4->S2', 'S4->S3', 'S4->S4', 'S4->REM', 'REM->W', 'REM->S1', 'REM->S2', 'REM->S3', 'REM->REM']\n",
      "        \n",
      "\n",
      "        Feature shape: (20, 34), Target shape: (20,), Metadata: (20, 3) \n",
      "        \n",
      "[0 1] [0 1]\n",
      "[0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1] [0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1]\n",
      "[[ 8  2]\n",
      " [ 0 10]]\n",
      "[[10  0  2  8]\n",
      " [ 8  2  0 10]]\n",
      "[[18  2]\n",
      " [ 2 18]]\n",
      "Class-wise info: For multilevel internal scores fo label 0: \n",
      " Accuracy = 90.0\n",
      " Precision = [0.83333333 1.        ]\n",
      " Recall = [1.  0.8]\n",
      " F1 score = [0.90909091 0.88888889]\n",
      " AUC score = 90.0\n",
      " Support = [10 10]\n",
      "\n",
      "Class-wise info: For multilevel internal scores fo label 1: \n",
      " Accuracy = 90.0\n",
      " Precision = [1.         0.83333333]\n",
      " Recall = [0.8 1. ]\n",
      " F1 score = [0.88888889 0.90909091]\n",
      " AUC score = 90.0\n",
      " Support = [10 10]\n",
      "\n",
      "CLASSIFICATION MERICS:\n",
      " _______________________________________________________\n",
      " Confusion Matrix: \n",
      "[[ 8  2]\n",
      " [ 0 10]]\n",
      " Accuracy (acc): 90.0\n",
      " Precision (prc): 83.333\n",
      " Recall (rec): 100.0\n",
      " Sensitivity (sns): 100.0\n",
      " Specificity (spc): 80.0\n",
      " F1 Score (f1s): 90.909\n",
      " ROC AUC (AUC): 0.9\n",
      "Score columns: (1, 12) ['method', 'model', 'model_parameters', 'model_scores', 'confusion_matrix', 'accuracy', 'precision', 'recall', 'sensitivity', 'specificity', 'f1_score', 'roc_auc']\n",
      "\n",
      "        Best model (GriveSearchCV): GridSearchCV(cv=5, estimator=SVC(), n_jobs=50,\n",
      "             param_grid={'C': [0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1.0],\n",
      "                         'kernel': ['linear', 'rbf', 'poly'],\n",
      "                         'probability': [True]},\n",
      "             return_train_score=True, scoring='f1', verbose=2) \n",
      "        Best model: GridSearchCV(cv=5, estimator=SVC(), n_jobs=50,\n",
      "             param_grid={'C': [0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1.0],\n",
      "                         'kernel': ['linear', 'rbf', 'poly'],\n",
      "                         'probability': [True]},\n",
      "             return_train_score=True, scoring='f1', verbose=2) \n",
      "        Best estimator of the model: SVC(kernel='linear', probability=True) \n",
      "        Best parameters of the model: {'C': 1.0, 'kernel': 'linear', 'probability': True} \n",
      "        ---------------------------------------------------------------------------------------------------\n",
      "        \n",
      "\n",
      "            *** ML MODEL FOR TEST:1, TRAINING:4 AND MODEL: NB \n",
      "            ---------------------------------------------------------------------------------------------------\n",
      "            \n",
      "Calling method: naive_bayes_parameters\n",
      "All parameters: ['var_smoothing'], [[1.0, 0.005623413251903491, 3.1622776601683795e-05, 1.7782794100389227e-07, 1e-09]], [0]\n",
      "Parameters:  {'var_smoothing': [1.0, 0.005623413251903491, 3.1622776601683795e-05, 1.7782794100389227e-07, 1e-09]}\n",
      "\n",
      "        From training? True, Data shape: (146, 38), Indices: [ 12 161  56  39 158  69 124   9 153   3  62  67 148 163 130 134 102  58\n",
      " 118  54  13  40 125 114  86 162  23  42  85   8  71  20 137   5  93  84\n",
      "  50  38 160 144 103 117  76 105  18  74  82  79  36  80 165 132  75 140\n",
      "   7  15  10  25  60 136 138  89  28 139  31  95  97  44 109 146 110  19\n",
      "  49 164  41 150  46  59  45 106  78  57  22 131   1  53  37 101  98 143\n",
      "  90  26 127 128 120 123 100  91 159  66   4 113 154  16 129 126 141  51\n",
      "  99  64 111  30  52  27   2 121 108  55  24 147  43  65  68 157  47  73\n",
      "  83  96  29 135  35 116  87   0  11 107 119  72  77  81 156 112 133  32\n",
      "  94  34]\n",
      "        All Columns: ['Dataset', 'Category', 'Subject_Name', 'Class', 'W->S1', 'W->S2', 'W->S3', 'W->S4', 'W->REM', 'S1->W', 'S1->S1', 'S1->S2', 'S1->S3', 'S1->S4', 'S1->REM', 'S2->W', 'S2->S1', 'S2->S2', 'S2->S3', 'S2->S4', 'S2->REM', 'S3->W', 'S3->S1', 'S3->S2', 'S3->S3', 'S3->S4', 'S3->REM', 'S4->W', 'S4->S1', 'S4->S2', 'S4->S3', 'S4->S4', 'S4->REM', 'REM->W', 'REM->S1', 'REM->S2', 'REM->S3', 'REM->REM']\n",
      "        \n",
      "\n",
      "        Feature shape: (146, 34), Target shape: (146,), Metadata: (146, 3) \n",
      "        \n",
      "\n",
      "        GridSearch: NB - {'var_smoothing': [1.0, 0.005623413251903491, 3.1622776601683795e-05, 1.7782794100389227e-07, 1e-09]} \n",
      "        ---------------------------------------------------------------------------------------------------\n",
      "        \n",
      "Refitting the model with best parameter f1 == True\n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "\n",
      "        From training? False, Data shape: (20, 38), Indices: [152  33 151  63  14 155 142 145 149 104   6  17  21 122  61  92  70  88\n",
      " 115  48]\n",
      "        All Columns: ['Dataset', 'Category', 'Subject_Name', 'Class', 'W->S1', 'W->S2', 'W->S3', 'W->S4', 'W->REM', 'S1->W', 'S1->S1', 'S1->S2', 'S1->S3', 'S1->S4', 'S1->REM', 'S2->W', 'S2->S1', 'S2->S2', 'S2->S3', 'S2->S4', 'S2->REM', 'S3->W', 'S3->S1', 'S3->S2', 'S3->S3', 'S3->S4', 'S3->REM', 'S4->W', 'S4->S1', 'S4->S2', 'S4->S3', 'S4->S4', 'S4->REM', 'REM->W', 'REM->S1', 'REM->S2', 'REM->S3', 'REM->REM']\n",
      "        \n",
      "\n",
      "        Feature shape: (20, 34), Target shape: (20,), Metadata: (20, 3) \n",
      "        \n",
      "[0 1] [0 1]\n",
      "[0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1] [0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1]\n",
      "[[ 8  2]\n",
      " [ 0 10]]\n",
      "[[10  0  2  8]\n",
      " [ 8  2  0 10]]\n",
      "[[18  2]\n",
      " [ 2 18]]\n",
      "Class-wise info: For multilevel internal scores fo label 0: \n",
      " Accuracy = 90.0\n",
      " Precision = [0.83333333 1.        ]\n",
      " Recall = [1.  0.8]\n",
      " F1 score = [0.90909091 0.88888889]\n",
      " AUC score = 90.0\n",
      " Support = [10 10]\n",
      "\n",
      "Class-wise info: For multilevel internal scores fo label 1: \n",
      " Accuracy = 90.0\n",
      " Precision = [1.         0.83333333]\n",
      " Recall = [0.8 1. ]\n",
      " F1 score = [0.88888889 0.90909091]\n",
      " AUC score = 90.0\n",
      " Support = [10 10]\n",
      "\n",
      "CLASSIFICATION MERICS:\n",
      " _______________________________________________________\n",
      " Confusion Matrix: \n",
      "[[ 8  2]\n",
      " [ 0 10]]\n",
      " Accuracy (acc): 90.0\n",
      " Precision (prc): 83.333\n",
      " Recall (rec): 100.0\n",
      " Sensitivity (sns): 100.0\n",
      " Specificity (spc): 80.0\n",
      " F1 Score (f1s): 90.909\n",
      " ROC AUC (AUC): 0.9\n",
      "Score columns: (1, 12) ['method', 'model', 'model_parameters', 'model_scores', 'confusion_matrix', 'accuracy', 'precision', 'recall', 'sensitivity', 'specificity', 'f1_score', 'roc_auc']\n",
      "\n",
      "        Best model (GriveSearchCV): GridSearchCV(cv=5, estimator=GaussianNB(), n_jobs=50,\n",
      "             param_grid={'var_smoothing': [1.0, 0.005623413251903491,\n",
      "                                           3.1622776601683795e-05,\n",
      "                                           1.7782794100389227e-07, 1e-09]},\n",
      "             return_train_score=True, scoring='f1', verbose=2) \n",
      "        Best model: GridSearchCV(cv=5, estimator=GaussianNB(), n_jobs=50,\n",
      "             param_grid={'var_smoothing': [1.0, 0.005623413251903491,\n",
      "                                           3.1622776601683795e-05,\n",
      "                                           1.7782794100389227e-07, 1e-09]},\n",
      "             return_train_score=True, scoring='f1', verbose=2) \n",
      "        Best estimator of the model: GaussianNB(var_smoothing=0.005623413251903491) \n",
      "        Best parameters of the model: {'var_smoothing': 0.005623413251903491} \n",
      "        ---------------------------------------------------------------------------------------------------\n",
      "        \n",
      "\n",
      "            *** ML MODEL FOR TEST:1, TRAINING:4 AND MODEL: KNN \n",
      "            ---------------------------------------------------------------------------------------------------\n",
      "            \n",
      "Calling method: k_nearest_neighbors_parameters\n",
      "All parameters: ['n_neighbors', 'p', 'metric', 'n_splits'], [[2, 3, 5, 10, 15, 25, 35], ['manhattan', 'minkowski', 'euclidean']], [0, 2]\n",
      "Parameters:  {'n_neighbors': [2, 3, 5, 10, 15, 25, 35], 'metric': ['manhattan', 'minkowski', 'euclidean']}\n",
      "\n",
      "        From training? True, Data shape: (146, 38), Indices: [ 12 161  56  39 158  69 124   9 153   3  62  67 148 163 130 134 102  58\n",
      " 118  54  13  40 125 114  86 162  23  42  85   8  71  20 137   5  93  84\n",
      "  50  38 160 144 103 117  76 105  18  74  82  79  36  80 165 132  75 140\n",
      "   7  15  10  25  60 136 138  89  28 139  31  95  97  44 109 146 110  19\n",
      "  49 164  41 150  46  59  45 106  78  57  22 131   1  53  37 101  98 143\n",
      "  90  26 127 128 120 123 100  91 159  66   4 113 154  16 129 126 141  51\n",
      "  99  64 111  30  52  27   2 121 108  55  24 147  43  65  68 157  47  73\n",
      "  83  96  29 135  35 116  87   0  11 107 119  72  77  81 156 112 133  32\n",
      "  94  34]\n",
      "        All Columns: ['Dataset', 'Category', 'Subject_Name', 'Class', 'W->S1', 'W->S2', 'W->S3', 'W->S4', 'W->REM', 'S1->W', 'S1->S1', 'S1->S2', 'S1->S3', 'S1->S4', 'S1->REM', 'S2->W', 'S2->S1', 'S2->S2', 'S2->S3', 'S2->S4', 'S2->REM', 'S3->W', 'S3->S1', 'S3->S2', 'S3->S3', 'S3->S4', 'S3->REM', 'S4->W', 'S4->S1', 'S4->S2', 'S4->S3', 'S4->S4', 'S4->REM', 'REM->W', 'REM->S1', 'REM->S2', 'REM->S3', 'REM->REM']\n",
      "        \n",
      "\n",
      "        Feature shape: (146, 34), Target shape: (146,), Metadata: (146, 3) \n",
      "        \n",
      "\n",
      "        GridSearch: KNN - {'n_neighbors': [2, 3, 5, 10, 15, 25, 35], 'metric': ['manhattan', 'minkowski', 'euclidean']} \n",
      "        ---------------------------------------------------------------------------------------------------\n",
      "        \n",
      "Refitting the model with best parameter f1 == True\n",
      "Fitting 5 folds for each of 21 candidates, totalling 105 fits\n",
      "\n",
      "        From training? False, Data shape: (20, 38), Indices: [152  33 151  63  14 155 142 145 149 104   6  17  21 122  61  92  70  88\n",
      " 115  48]\n",
      "        All Columns: ['Dataset', 'Category', 'Subject_Name', 'Class', 'W->S1', 'W->S2', 'W->S3', 'W->S4', 'W->REM', 'S1->W', 'S1->S1', 'S1->S2', 'S1->S3', 'S1->S4', 'S1->REM', 'S2->W', 'S2->S1', 'S2->S2', 'S2->S3', 'S2->S4', 'S2->REM', 'S3->W', 'S3->S1', 'S3->S2', 'S3->S3', 'S3->S4', 'S3->REM', 'S4->W', 'S4->S1', 'S4->S2', 'S4->S3', 'S4->S4', 'S4->REM', 'REM->W', 'REM->S1', 'REM->S2', 'REM->S3', 'REM->REM']\n",
      "        \n",
      "\n",
      "        Feature shape: (20, 34), Target shape: (20,), Metadata: (20, 3) \n",
      "        \n",
      "[0 1] [0 1]\n",
      "[0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1] [0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1]\n",
      "[[ 8  2]\n",
      " [ 0 10]]\n",
      "[[10  0  2  8]\n",
      " [ 8  2  0 10]]\n",
      "[[18  2]\n",
      " [ 2 18]]\n",
      "Class-wise info: For multilevel internal scores fo label 0: \n",
      " Accuracy = 90.0\n",
      " Precision = [0.83333333 1.        ]\n",
      " Recall = [1.  0.8]\n",
      " F1 score = [0.90909091 0.88888889]\n",
      " AUC score = 90.0\n",
      " Support = [10 10]\n",
      "\n",
      "Class-wise info: For multilevel internal scores fo label 1: \n",
      " Accuracy = 90.0\n",
      " Precision = [1.         0.83333333]\n",
      " Recall = [0.8 1. ]\n",
      " F1 score = [0.88888889 0.90909091]\n",
      " AUC score = 90.0\n",
      " Support = [10 10]\n",
      "\n",
      "CLASSIFICATION MERICS:\n",
      " _______________________________________________________\n",
      " Confusion Matrix: \n",
      "[[ 8  2]\n",
      " [ 0 10]]\n",
      " Accuracy (acc): 90.0\n",
      " Precision (prc): 83.333\n",
      " Recall (rec): 100.0\n",
      " Sensitivity (sns): 100.0\n",
      " Specificity (spc): 80.0\n",
      " F1 Score (f1s): 90.909\n",
      " ROC AUC (AUC): 0.9\n",
      "Score columns: (1, 12) ['method', 'model', 'model_parameters', 'model_scores', 'confusion_matrix', 'accuracy', 'precision', 'recall', 'sensitivity', 'specificity', 'f1_score', 'roc_auc']\n",
      "\n",
      "        Best model (GriveSearchCV): GridSearchCV(cv=5, estimator=KNeighborsClassifier(), n_jobs=50,\n",
      "             param_grid={'metric': ['manhattan', 'minkowski', 'euclidean'],\n",
      "                         'n_neighbors': [2, 3, 5, 10, 15, 25, 35]},\n",
      "             return_train_score=True, scoring='f1', verbose=2) \n",
      "        Best model: GridSearchCV(cv=5, estimator=KNeighborsClassifier(), n_jobs=50,\n",
      "             param_grid={'metric': ['manhattan', 'minkowski', 'euclidean'],\n",
      "                         'n_neighbors': [2, 3, 5, 10, 15, 25, 35]},\n",
      "             return_train_score=True, scoring='f1', verbose=2) \n",
      "        Best estimator of the model: KNeighborsClassifier(metric='manhattan', n_neighbors=15) \n",
      "        Best parameters of the model: {'metric': 'manhattan', 'n_neighbors': 15} \n",
      "        ---------------------------------------------------------------------------------------------------\n",
      "        \n",
      "\n",
      "            *** ML MODEL FOR TEST:1, TRAINING:4 AND MODEL: DT \n",
      "            ---------------------------------------------------------------------------------------------------\n",
      "            \n",
      "Calling method: decision_tree_parameters\n",
      "All parameters: ['max_depth', 'criterion', 'splitter', 'min_samples_split', 'min_samples_leaf', 'max_leaf_nodes'], [[2, 3, 5, 7, 10, 15, 20, 25, 30], ['gini', 'entropy', 'log_loss']], [0, 1]\n",
      "Parameters:  {'max_depth': [2, 3, 5, 7, 10, 15, 20, 25, 30], 'criterion': ['gini', 'entropy', 'log_loss']}\n",
      "\n",
      "        From training? True, Data shape: (146, 38), Indices: [ 12 161  56  39 158  69 124   9 153   3  62  67 148 163 130 134 102  58\n",
      " 118  54  13  40 125 114  86 162  23  42  85   8  71  20 137   5  93  84\n",
      "  50  38 160 144 103 117  76 105  18  74  82  79  36  80 165 132  75 140\n",
      "   7  15  10  25  60 136 138  89  28 139  31  95  97  44 109 146 110  19\n",
      "  49 164  41 150  46  59  45 106  78  57  22 131   1  53  37 101  98 143\n",
      "  90  26 127 128 120 123 100  91 159  66   4 113 154  16 129 126 141  51\n",
      "  99  64 111  30  52  27   2 121 108  55  24 147  43  65  68 157  47  73\n",
      "  83  96  29 135  35 116  87   0  11 107 119  72  77  81 156 112 133  32\n",
      "  94  34]\n",
      "        All Columns: ['Dataset', 'Category', 'Subject_Name', 'Class', 'W->S1', 'W->S2', 'W->S3', 'W->S4', 'W->REM', 'S1->W', 'S1->S1', 'S1->S2', 'S1->S3', 'S1->S4', 'S1->REM', 'S2->W', 'S2->S1', 'S2->S2', 'S2->S3', 'S2->S4', 'S2->REM', 'S3->W', 'S3->S1', 'S3->S2', 'S3->S3', 'S3->S4', 'S3->REM', 'S4->W', 'S4->S1', 'S4->S2', 'S4->S3', 'S4->S4', 'S4->REM', 'REM->W', 'REM->S1', 'REM->S2', 'REM->S3', 'REM->REM']\n",
      "        \n",
      "\n",
      "        Feature shape: (146, 34), Target shape: (146,), Metadata: (146, 3) \n",
      "        \n",
      "\n",
      "        GridSearch: DT - {'max_depth': [2, 3, 5, 7, 10, 15, 20, 25, 30], 'criterion': ['gini', 'entropy', 'log_loss']} \n",
      "        ---------------------------------------------------------------------------------------------------\n",
      "        \n",
      "Refitting the model with best parameter f1 == True\n",
      "Fitting 5 folds for each of 27 candidates, totalling 135 fits\n",
      "\n",
      "        From training? False, Data shape: (20, 38), Indices: [152  33 151  63  14 155 142 145 149 104   6  17  21 122  61  92  70  88\n",
      " 115  48]\n",
      "        All Columns: ['Dataset', 'Category', 'Subject_Name', 'Class', 'W->S1', 'W->S2', 'W->S3', 'W->S4', 'W->REM', 'S1->W', 'S1->S1', 'S1->S2', 'S1->S3', 'S1->S4', 'S1->REM', 'S2->W', 'S2->S1', 'S2->S2', 'S2->S3', 'S2->S4', 'S2->REM', 'S3->W', 'S3->S1', 'S3->S2', 'S3->S3', 'S3->S4', 'S3->REM', 'S4->W', 'S4->S1', 'S4->S2', 'S4->S3', 'S4->S4', 'S4->REM', 'REM->W', 'REM->S1', 'REM->S2', 'REM->S3', 'REM->REM']\n",
      "        \n",
      "\n",
      "        Feature shape: (20, 34), Target shape: (20,), Metadata: (20, 3) \n",
      "        \n",
      "[0 1] [0 1]\n",
      "[0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1] [0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1]\n",
      "[[ 8  2]\n",
      " [ 0 10]]\n",
      "[[10  0  2  8]\n",
      " [ 8  2  0 10]]\n",
      "[[18  2]\n",
      " [ 2 18]]\n",
      "Class-wise info: For multilevel internal scores fo label 0: \n",
      " Accuracy = 90.0\n",
      " Precision = [0.83333333 1.        ]\n",
      " Recall = [1.  0.8]\n",
      " F1 score = [0.90909091 0.88888889]\n",
      " AUC score = 90.0\n",
      " Support = [10 10]\n",
      "\n",
      "Class-wise info: For multilevel internal scores fo label 1: \n",
      " Accuracy = 90.0\n",
      " Precision = [1.         0.83333333]\n",
      " Recall = [0.8 1. ]\n",
      " F1 score = [0.88888889 0.90909091]\n",
      " AUC score = 90.0\n",
      " Support = [10 10]\n",
      "\n",
      "CLASSIFICATION MERICS:\n",
      " _______________________________________________________\n",
      " Confusion Matrix: \n",
      "[[ 8  2]\n",
      " [ 0 10]]\n",
      " Accuracy (acc): 90.0\n",
      " Precision (prc): 83.333\n",
      " Recall (rec): 100.0\n",
      " Sensitivity (sns): 100.0\n",
      " Specificity (spc): 80.0\n",
      " F1 Score (f1s): 90.909\n",
      " ROC AUC (AUC): 0.9\n",
      "Score columns: (1, 12) ['method', 'model', 'model_parameters', 'model_scores', 'confusion_matrix', 'accuracy', 'precision', 'recall', 'sensitivity', 'specificity', 'f1_score', 'roc_auc']\n",
      "\n",
      "        Best model (GriveSearchCV): GridSearchCV(cv=5, estimator=DecisionTreeClassifier(), n_jobs=50,\n",
      "             param_grid={'criterion': ['gini', 'entropy', 'log_loss'],\n",
      "                         'max_depth': [2, 3, 5, 7, 10, 15, 20, 25, 30]},\n",
      "             return_train_score=True, scoring='f1', verbose=2) \n",
      "        Best model: GridSearchCV(cv=5, estimator=DecisionTreeClassifier(), n_jobs=50,\n",
      "             param_grid={'criterion': ['gini', 'entropy', 'log_loss'],\n",
      "                         'max_depth': [2, 3, 5, 7, 10, 15, 20, 25, 30]},\n",
      "             return_train_score=True, scoring='f1', verbose=2) \n",
      "        Best estimator of the model: DecisionTreeClassifier(criterion='entropy', max_depth=2) \n",
      "        Best parameters of the model: {'criterion': 'entropy', 'max_depth': 2} \n",
      "        ---------------------------------------------------------------------------------------------------\n",
      "        \n",
      "\n",
      "            *** ML MODEL FOR TEST:1, TRAINING:4 AND MODEL: RF \n",
      "            ---------------------------------------------------------------------------------------------------\n",
      "            \n",
      "Calling method: random_forest_parameters\n",
      "All parameters: ['n_estimators', 'max_depth', 'criterion', 'splitter', 'max_features', 'min_samples_split', 'min_samples_leaf', 'max_leaf_nodes'], [[3, 5, 10, 15, 21, 30, 50, 75, 100], [2, 3, 5, 7, 10, 15, 20, 25, 30], ['gini', 'entropy', 'log_loss']], [0, 1, 2]\n",
      "Parameters:  {'n_estimators': [3, 5, 10, 15, 21, 30, 50, 75, 100], 'max_depth': [2, 3, 5, 7, 10, 15, 20, 25, 30], 'criterion': ['gini', 'entropy', 'log_loss']}\n",
      "\n",
      "        From training? True, Data shape: (146, 38), Indices: [ 12 161  56  39 158  69 124   9 153   3  62  67 148 163 130 134 102  58\n",
      " 118  54  13  40 125 114  86 162  23  42  85   8  71  20 137   5  93  84\n",
      "  50  38 160 144 103 117  76 105  18  74  82  79  36  80 165 132  75 140\n",
      "   7  15  10  25  60 136 138  89  28 139  31  95  97  44 109 146 110  19\n",
      "  49 164  41 150  46  59  45 106  78  57  22 131   1  53  37 101  98 143\n",
      "  90  26 127 128 120 123 100  91 159  66   4 113 154  16 129 126 141  51\n",
      "  99  64 111  30  52  27   2 121 108  55  24 147  43  65  68 157  47  73\n",
      "  83  96  29 135  35 116  87   0  11 107 119  72  77  81 156 112 133  32\n",
      "  94  34]\n",
      "        All Columns: ['Dataset', 'Category', 'Subject_Name', 'Class', 'W->S1', 'W->S2', 'W->S3', 'W->S4', 'W->REM', 'S1->W', 'S1->S1', 'S1->S2', 'S1->S3', 'S1->S4', 'S1->REM', 'S2->W', 'S2->S1', 'S2->S2', 'S2->S3', 'S2->S4', 'S2->REM', 'S3->W', 'S3->S1', 'S3->S2', 'S3->S3', 'S3->S4', 'S3->REM', 'S4->W', 'S4->S1', 'S4->S2', 'S4->S3', 'S4->S4', 'S4->REM', 'REM->W', 'REM->S1', 'REM->S2', 'REM->S3', 'REM->REM']\n",
      "        \n",
      "\n",
      "        Feature shape: (146, 34), Target shape: (146,), Metadata: (146, 3) \n",
      "        \n",
      "\n",
      "        GridSearch: RF - {'n_estimators': [3, 5, 10, 15, 21, 30, 50, 75, 100], 'max_depth': [2, 3, 5, 7, 10, 15, 20, 25, 30], 'criterion': ['gini', 'entropy', 'log_loss']} \n",
      "        ---------------------------------------------------------------------------------------------------\n",
      "        \n",
      "Refitting the model with best parameter f1 == True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aliem\\.conda\\envs\\MyPython37Work\\lib\\site-packages\\sklearn\\model_selection\\_search.py:921: UserWarning: One or more of the test scores are non-finite: [0.90974235 0.85825075 0.76993531 0.8140376  0.80142111 0.82249638\n",
      " 0.79513476 0.83753743 0.79054553 0.91574835 0.88769936 0.79368152\n",
      " 0.80415328 0.81733716 0.81121211 0.80347017 0.81174603 0.80878786\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan]\n",
      "  category=UserWarning\n",
      "C:\\Users\\aliem\\.conda\\envs\\MyPython37Work\\lib\\site-packages\\sklearn\\model_selection\\_search.py:921: UserWarning: One or more of the train scores are non-finite: [0.92926931 0.9468736  0.98036856 0.99844961 1.         1.\n",
      " 1.         1.         1.         0.9265778  0.93590303 0.97465041\n",
      " 0.99699248 1.         1.         1.         1.         1.\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan]\n",
      "  category=UserWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 243 candidates, totalling 1215 fits\n",
      "\n",
      "        From training? False, Data shape: (20, 38), Indices: [152  33 151  63  14 155 142 145 149 104   6  17  21 122  61  92  70  88\n",
      " 115  48]\n",
      "        All Columns: ['Dataset', 'Category', 'Subject_Name', 'Class', 'W->S1', 'W->S2', 'W->S3', 'W->S4', 'W->REM', 'S1->W', 'S1->S1', 'S1->S2', 'S1->S3', 'S1->S4', 'S1->REM', 'S2->W', 'S2->S1', 'S2->S2', 'S2->S3', 'S2->S4', 'S2->REM', 'S3->W', 'S3->S1', 'S3->S2', 'S3->S3', 'S3->S4', 'S3->REM', 'S4->W', 'S4->S1', 'S4->S2', 'S4->S3', 'S4->S4', 'S4->REM', 'REM->W', 'REM->S1', 'REM->S2', 'REM->S3', 'REM->REM']\n",
      "        \n",
      "\n",
      "        Feature shape: (20, 34), Target shape: (20,), Metadata: (20, 3) \n",
      "        \n",
      "[0 1] [0 1]\n",
      "[0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1] [0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1]\n",
      "[[ 8  2]\n",
      " [ 0 10]]\n",
      "[[10  0  2  8]\n",
      " [ 8  2  0 10]]\n",
      "[[18  2]\n",
      " [ 2 18]]\n",
      "Class-wise info: For multilevel internal scores fo label 0: \n",
      " Accuracy = 90.0\n",
      " Precision = [0.83333333 1.        ]\n",
      " Recall = [1.  0.8]\n",
      " F1 score = [0.90909091 0.88888889]\n",
      " AUC score = 90.0\n",
      " Support = [10 10]\n",
      "\n",
      "Class-wise info: For multilevel internal scores fo label 1: \n",
      " Accuracy = 90.0\n",
      " Precision = [1.         0.83333333]\n",
      " Recall = [0.8 1. ]\n",
      " F1 score = [0.88888889 0.90909091]\n",
      " AUC score = 90.0\n",
      " Support = [10 10]\n",
      "\n",
      "CLASSIFICATION MERICS:\n",
      " _______________________________________________________\n",
      " Confusion Matrix: \n",
      "[[ 8  2]\n",
      " [ 0 10]]\n",
      " Accuracy (acc): 90.0\n",
      " Precision (prc): 83.333\n",
      " Recall (rec): 100.0\n",
      " Sensitivity (sns): 100.0\n",
      " Specificity (spc): 80.0\n",
      " F1 Score (f1s): 90.909\n",
      " ROC AUC (AUC): 0.9\n",
      "Score columns: (1, 12) ['method', 'model', 'model_parameters', 'model_scores', 'confusion_matrix', 'accuracy', 'precision', 'recall', 'sensitivity', 'specificity', 'f1_score', 'roc_auc']\n",
      "\n",
      "        Best model (GriveSearchCV): GridSearchCV(cv=5, estimator=RandomForestClassifier(), n_jobs=50,\n",
      "             param_grid={'criterion': ['gini', 'entropy', 'log_loss'],\n",
      "                         'max_depth': [2, 3, 5, 7, 10, 15, 20, 25, 30],\n",
      "                         'n_estimators': [3, 5, 10, 15, 21, 30, 50, 75, 100]},\n",
      "             return_train_score=True, scoring='f1', verbose=2) \n",
      "        Best model: GridSearchCV(cv=5, estimator=RandomForestClassifier(), n_jobs=50,\n",
      "             param_grid={'criterion': ['gini', 'entropy', 'log_loss'],\n",
      "                         'max_depth': [2, 3, 5, 7, 10, 15, 20, 25, 30],\n",
      "                         'n_estimators': [3, 5, 10, 15, 21, 30, 50, 75, 100]},\n",
      "             return_train_score=True, scoring='f1', verbose=2) \n",
      "        Best estimator of the model: RandomForestClassifier(max_depth=7, n_estimators=50) \n",
      "        Best parameters of the model: {'criterion': 'gini', 'max_depth': 7, 'n_estimators': 50} \n",
      "        ---------------------------------------------------------------------------------------------------\n",
      "        \n",
      "\n",
      "            *** ML MODEL FOR TEST:1, TRAINING:4 AND MODEL: GB \n",
      "            ---------------------------------------------------------------------------------------------------\n",
      "            \n",
      "Calling method: gradient_boosting_parameters\n",
      "All parameters: ['n_estimators', 'max_depth', 'learning_rate', 'max_features', 'loss', 'min_samples_split', 'min_samples_leaf'], [[3, 5, 10, 15, 21, 30, 50, 75, 100], [2, 3, 5, 7, 10, 15, 20, 25, 30], [0.01, 0.05, 0.1, 0.5, 1.0]], [0, 1, 2]\n",
      "Parameters:  {'n_estimators': [3, 5, 10, 15, 21, 30, 50, 75, 100], 'max_depth': [2, 3, 5, 7, 10, 15, 20, 25, 30], 'learning_rate': [0.01, 0.05, 0.1, 0.5, 1.0]}\n",
      "\n",
      "        From training? True, Data shape: (146, 38), Indices: [ 12 161  56  39 158  69 124   9 153   3  62  67 148 163 130 134 102  58\n",
      " 118  54  13  40 125 114  86 162  23  42  85   8  71  20 137   5  93  84\n",
      "  50  38 160 144 103 117  76 105  18  74  82  79  36  80 165 132  75 140\n",
      "   7  15  10  25  60 136 138  89  28 139  31  95  97  44 109 146 110  19\n",
      "  49 164  41 150  46  59  45 106  78  57  22 131   1  53  37 101  98 143\n",
      "  90  26 127 128 120 123 100  91 159  66   4 113 154  16 129 126 141  51\n",
      "  99  64 111  30  52  27   2 121 108  55  24 147  43  65  68 157  47  73\n",
      "  83  96  29 135  35 116  87   0  11 107 119  72  77  81 156 112 133  32\n",
      "  94  34]\n",
      "        All Columns: ['Dataset', 'Category', 'Subject_Name', 'Class', 'W->S1', 'W->S2', 'W->S3', 'W->S4', 'W->REM', 'S1->W', 'S1->S1', 'S1->S2', 'S1->S3', 'S1->S4', 'S1->REM', 'S2->W', 'S2->S1', 'S2->S2', 'S2->S3', 'S2->S4', 'S2->REM', 'S3->W', 'S3->S1', 'S3->S2', 'S3->S3', 'S3->S4', 'S3->REM', 'S4->W', 'S4->S1', 'S4->S2', 'S4->S3', 'S4->S4', 'S4->REM', 'REM->W', 'REM->S1', 'REM->S2', 'REM->S3', 'REM->REM']\n",
      "        \n",
      "\n",
      "        Feature shape: (146, 34), Target shape: (146,), Metadata: (146, 3) \n",
      "        \n",
      "\n",
      "        GridSearch: GB - {'n_estimators': [3, 5, 10, 15, 21, 30, 50, 75, 100], 'max_depth': [2, 3, 5, 7, 10, 15, 20, 25, 30], 'learning_rate': [0.01, 0.05, 0.1, 0.5, 1.0]} \n",
      "        ---------------------------------------------------------------------------------------------------\n",
      "        \n",
      "Refitting the model with best parameter f1 == True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aliem\\.conda\\envs\\MyPython37Work\\lib\\site-packages\\sklearn\\model_selection\\_search.py:921: UserWarning: One or more of the test scores are non-finite: [0.89910945 0.88428317 0.91574835 0.9161289  0.9161289  0.92213491\n",
      " 0.92213491 0.92213491 0.92213491 0.90315593 0.87583077 0.90336258\n",
      " 0.92213491 0.91574835 0.92213491 0.92213491 0.92213491 0.9161289\n",
      " 0.88824738 0.91149648 0.9136584  0.91376238 0.9161289  0.9161289\n",
      " 0.9161289  0.9161289  0.9161289  0.80118596 0.89851875 0.90238474\n",
      " 0.90933124 0.90271069 0.90296873 0.92784919 0.9161289  0.91007848\n",
      " 0.84247983 0.88597572 0.86010927 0.90196881 0.91007848 0.90974235\n",
      " 0.91482171 0.90971179 0.90369193 0.86410557 0.86120827 0.850268\n",
      " 0.87522342 0.90974235 0.90939603 0.92120827 0.91574835 0.92120827\n",
      " 0.86709122 0.85002996 0.8875817  0.90715898 0.86310221 0.90849673\n",
      " 0.90974235 0.91574835 0.9161289  0.83623867 0.9009944  0.88793821\n",
      " 0.90846617 0.90238474 0.92692255 0.92692255 0.91482171 0.91515785\n",
      " 0.8671855  0.88876238 0.8905691  0.92659339 0.89691831 0.90199767\n",
      " 0.91482171 0.9161289  0.9161289  0.8923007  0.89922158 0.92146264\n",
      " 0.9161289  0.92213491 0.92213491 0.9161289  0.92213491 0.92213491\n",
      " 0.91250362 0.88835112 0.91578258 0.9161289  0.92213491 0.92213491\n",
      " 0.92213491 0.9161289  0.9161289  0.83374346 0.86950853 0.90941149\n",
      " 0.89650705 0.90366137 0.9161289  0.92213491 0.9161289  0.9161289\n",
      " 0.85576454 0.89616073 0.90868301 0.89727481 0.91515785 0.92120827\n",
      " 0.92120827 0.92120827 0.9161289  0.90890047 0.8751483  0.86737585\n",
      " 0.91468902 0.92664799 0.91515785 0.92120827 0.91482171 0.92120827\n",
      " 0.90462715 0.90277056 0.90199767 0.90971179 0.92143208 0.90971179\n",
      " 0.91482171 0.92120827 0.91515785 0.83029221 0.91480831 0.89524443\n",
      " 0.91454715 0.91007848 0.90340548 0.91007848 0.91482171 0.92120827\n",
      " 0.87539893 0.87642602 0.8774293  0.90909573 0.89734272 0.92093371\n",
      " 0.91007848 0.92120827 0.92120827 0.87119939 0.88321004 0.92011816\n",
      " 0.89727481 0.91482171 0.90296873 0.90974235 0.9161289  0.91007848\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan]\n",
      "  category=UserWarning\n",
      "C:\\Users\\aliem\\.conda\\envs\\MyPython37Work\\lib\\site-packages\\sklearn\\model_selection\\_search.py:921: UserWarning: One or more of the train scores are non-finite: [0.91236425 0.91237639 0.91966194 0.92094399 0.92139811 0.92268016\n",
      " 0.92139811 0.92139811 0.92139811 0.92643089 0.92991658 0.9292346\n",
      " 0.93064438 0.92921518 0.92789338 0.93186838 0.92398027 0.93049503\n",
      " 0.95225391 0.96315079 0.97341822 0.98202222 0.97193706 0.97487438\n",
      " 0.96901849 0.96899782 0.97049964 0.96781363 0.98340804 0.993962\n",
      " 0.99095415 0.99250365 0.99847328 1.         1.         1.\n",
      " 0.97285816 0.98195335 0.99694656 0.99396149 0.99696952 1.\n",
      " 1.         1.         1.         0.98053732 0.98195285 0.99238937\n",
      " 0.99849624 1.         0.99544281 1.         1.         1.\n",
      " 0.95776935 0.9909303  0.99546576 0.99849624 0.99847328 0.99847328\n",
      " 1.         1.         1.         0.97133403 0.97908069 0.99546576\n",
      " 0.99546576 1.         1.         1.         1.         1.\n",
      " 0.96825134 0.98194769 0.99544209 0.99847328 0.99847328 0.99847328\n",
      " 1.         0.99847328 1.         0.91432316 0.90011069 0.91968328\n",
      " 0.91992044 0.92401534 0.92271523 0.91988131 0.92139811 0.92139811\n",
      " 0.92578735 0.93179282 0.92919349 0.92659432 0.92663346 0.9265778\n",
      " 0.92527769 0.92529739 0.92397862 0.965498   0.96044781 0.9662237\n",
      " 0.97344034 0.97489649 0.97041329 0.96622632 0.97054052 0.97335302\n",
      " 0.96987815 0.9790351  0.98356985 0.98796907 0.99699248 0.99694656\n",
      " 0.99696952 0.99696952 1.         0.97580159 0.98502839 0.99243546\n",
      " 0.99847328 0.99699248 1.         1.         1.         1.\n",
      " 0.96815601 0.98053922 0.99694656 0.99694656 1.         1.\n",
      " 1.         1.         1.         0.97725063 0.98040417 0.99849624\n",
      " 0.99696952 0.99696952 0.99696952 1.         1.         1.\n",
      " 0.98015018 0.98348109 0.99243424 0.99847328 1.         0.99847328\n",
      " 1.         1.         1.         0.97431651 0.9849595  0.99548821\n",
      " 1.         0.99849624 1.         1.         0.99847328 1.\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan]\n",
      "  category=UserWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 405 candidates, totalling 2025 fits\n",
      "\n",
      "        From training? False, Data shape: (20, 38), Indices: [152  33 151  63  14 155 142 145 149 104   6  17  21 122  61  92  70  88\n",
      " 115  48]\n",
      "        All Columns: ['Dataset', 'Category', 'Subject_Name', 'Class', 'W->S1', 'W->S2', 'W->S3', 'W->S4', 'W->REM', 'S1->W', 'S1->S1', 'S1->S2', 'S1->S3', 'S1->S4', 'S1->REM', 'S2->W', 'S2->S1', 'S2->S2', 'S2->S3', 'S2->S4', 'S2->REM', 'S3->W', 'S3->S1', 'S3->S2', 'S3->S3', 'S3->S4', 'S3->REM', 'S4->W', 'S4->S1', 'S4->S2', 'S4->S3', 'S4->S4', 'S4->REM', 'REM->W', 'REM->S1', 'REM->S2', 'REM->S3', 'REM->REM']\n",
      "        \n",
      "\n",
      "        Feature shape: (20, 34), Target shape: (20,), Metadata: (20, 3) \n",
      "        \n",
      "[0 1] [0 1]\n",
      "[0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1] [0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1]\n",
      "[[ 8  2]\n",
      " [ 0 10]]\n",
      "[[10  0  2  8]\n",
      " [ 8  2  0 10]]\n",
      "[[18  2]\n",
      " [ 2 18]]\n",
      "Class-wise info: For multilevel internal scores fo label 0: \n",
      " Accuracy = 90.0\n",
      " Precision = [0.83333333 1.        ]\n",
      " Recall = [1.  0.8]\n",
      " F1 score = [0.90909091 0.88888889]\n",
      " AUC score = 90.0\n",
      " Support = [10 10]\n",
      "\n",
      "Class-wise info: For multilevel internal scores fo label 1: \n",
      " Accuracy = 90.0\n",
      " Precision = [1.         0.83333333]\n",
      " Recall = [0.8 1. ]\n",
      " F1 score = [0.88888889 0.90909091]\n",
      " AUC score = 90.0\n",
      " Support = [10 10]\n",
      "\n",
      "CLASSIFICATION MERICS:\n",
      " _______________________________________________________\n",
      " Confusion Matrix: \n",
      "[[ 8  2]\n",
      " [ 0 10]]\n",
      " Accuracy (acc): 90.0\n",
      " Precision (prc): 83.333\n",
      " Recall (rec): 100.0\n",
      " Sensitivity (sns): 100.0\n",
      " Specificity (spc): 80.0\n",
      " F1 Score (f1s): 90.909\n",
      " ROC AUC (AUC): 0.9\n",
      "Score columns: (1, 12) ['method', 'model', 'model_parameters', 'model_scores', 'confusion_matrix', 'accuracy', 'precision', 'recall', 'sensitivity', 'specificity', 'f1_score', 'roc_auc']\n",
      "\n",
      "        Best model (GriveSearchCV): GridSearchCV(cv=5, estimator=GradientBoostingClassifier(), n_jobs=50,\n",
      "             param_grid={'learning_rate': [0.01, 0.05, 0.1, 0.5, 1.0],\n",
      "                         'max_depth': [2, 3, 5, 7, 10, 15, 20, 25, 30],\n",
      "                         'n_estimators': [3, 5, 10, 15, 21, 30, 50, 75, 100]},\n",
      "             return_train_score=True, scoring='f1', verbose=2) \n",
      "        Best model: GridSearchCV(cv=5, estimator=GradientBoostingClassifier(), n_jobs=50,\n",
      "             param_grid={'learning_rate': [0.01, 0.05, 0.1, 0.5, 1.0],\n",
      "                         'max_depth': [2, 3, 5, 7, 10, 15, 20, 25, 30],\n",
      "                         'n_estimators': [3, 5, 10, 15, 21, 30, 50, 75, 100]},\n",
      "             return_train_score=True, scoring='f1', verbose=2) \n",
      "        Best estimator of the model: GradientBoostingClassifier(learning_rate=0.05, max_depth=2, n_estimators=30) \n",
      "        Best parameters of the model: {'learning_rate': 0.05, 'max_depth': 2, 'n_estimators': 30} \n",
      "        ---------------------------------------------------------------------------------------------------\n",
      "        \n",
      "\n",
      "            ---------------------------------------------------------------------------------------------------\n",
      "            Best model index calculation  \n",
      "            \n",
      "\n",
      "            ***************************************************************************************************\n",
      "            TRAINING 4 END... \n",
      "            \n",
      "\n",
      "            *** MODEL TRAINING AND VALIDATION PHASE FOR TEST 1 \n",
      "            TRAINING 5 START... XXXXX \n",
      "            ***************************************************************************************************\n",
      "            Validation=> 20 ['rbd14', 'plm6', 'nfle10', 'plm2', 'n4', 'plm8', 'nfle6', 'SC4431', 'rbd7', 'nfle7', 'SC4151', 'plm4', 'SC4441', 'SC4421', 'n6', 'brux1', 'SC4321', 'n8', 'plm10', 'SC4171'] \n",
      "            Training=> 146 ['n15', 'nfle35', 'ins9', 'ins3', 'rbd16', 'nfle21', 'SC4111', 'brux2', 'rbd15', 'rbd6', 'nfle27', 'rbd22', 'SC4551', 'SC4411', 'rbd5', 'n3', 'SC4181', 'nfle39', 'SC4401', 'SC4491', 'SC4461', 'SC4131', 'sdb4', 'SC4531', 'plm5', 'plm1', 'n16', 'SC4311', 'SC4021', 'SC4101', 'plm9', 'SC4331', 'n7', 'SC4381', 'SC4241', 'nfle4', 'ins2', 'rbd18', 'rbd13', 'nfle33', 'nfle34', 'rbd3', 'n2', 'nfle37', 'nfle8', 'SC4161', 'SC4271', 'SC4281', 'n9', 'rbd17', 'ins1', 'rbd8', 'SC4351', 'SC4251', 'SC4231', 'rbd2', 'SC4121', 'SC4301', 'SC4091', 'n1', 'nfle24', 'nfle1', 'nfle13', 'SC4511', 'nfle40', 'nfle5', 'ins6', 'nfle12', 'ins4', 'SC4451', 'SC4211', 'nfle30', 'SC4362', 'nfle36', 'rbd1', 'SC4011', 'SC4141', 'rbd4', 'SC4081', 'nfle32', 'nfle18', 'nfle28', 'rbd20', 'n13', 'SC4481', 'plm3', 'nfle2', 'SC4221', 'n11', 'SC4501', 'nfle29', 'ins7', 'sdb3', 'SC4571', 'nfle11', 'narco4', 'rbd19', 'n14', 'SC4001', 'nfle22', 'rbd9', 'SC4031', 'nfle16', 'narco3', 'nfle38', 'SC4341', 'nfle26', 'SC4041', 'sdb1', 'nfle20', 'n10', 'ins5', 'SC4061', 'SC4071', 'SC4191', 'nfle31', 'plm7', 'nfle25', 'nfle19', 'narco2', 'SC4471', 'n12', 'SC4371', 'nfle9', 'ins8', 'narco1', 'SC4051', 'SC4561', 'nfle15', 'rbd10', 'rbd12', 'SC4261', 'SC4201', 'narco5', 'n5', 'SC4522', 'SC4581', 'nfle3', 'nfle23', 'nfle14', 'sdb2', 'SC4541', 'rbd21', 'SC4291', 'rbd11', 'nfle17'] \n",
      "            \n",
      "\n",
      "            *** ML MODEL FOR TEST:1, TRAINING:5 AND MODEL: LR \n",
      "            ---------------------------------------------------------------------------------------------------\n",
      "            \n",
      "Calling method: logistic_regression_parameters\n",
      "All parameters: ['penalty', 'solver', 'max_iter', 'C'], [['l2', 'elasticnet'], [50, 100, 130, 150, 170, 200], [0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1.0]], [0, 2, 3]\n",
      "Parameters:  {'penalty': ['l2', 'elasticnet'], 'max_iter': [50, 100, 130, 150, 170, 200], 'C': [0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1.0]}\n",
      "\n",
      "        From training? True, Data shape: (146, 38), Indices: [106  54  14   8  85  40 119   1  84  75  46  91 162 148  74  94 126  58\n",
      " 147 156 153 121   5 160  64  60 107 139 110 118  68 141  98 146 132  23\n",
      "   7  87  82  52  53  72  93  56  27 124 135 136 100  86   6  77 143 133\n",
      " 131  71 120 138 117  92  43  20  32 158  59  24  11  31   9 152 129  49\n",
      " 144  55  70 109 122  73 116  51  37  47  89 104 155  62  21 130 102 157\n",
      "  48  12   4 164  30  18  88 105 108  41  78 111  35  17  57 142  45 112\n",
      "   2  39 101  10 114 115 127  50  66  44  38  16 154 103 145  28  13  15\n",
      " 113 163  34  79  81 134 128  19  96 159 165  22  42  33   3 161  90 137\n",
      "  80  36]\n",
      "        All Columns: ['Dataset', 'Category', 'Subject_Name', 'Class', 'W->S1', 'W->S2', 'W->S3', 'W->S4', 'W->REM', 'S1->W', 'S1->S1', 'S1->S2', 'S1->S3', 'S1->S4', 'S1->REM', 'S2->W', 'S2->S1', 'S2->S2', 'S2->S3', 'S2->S4', 'S2->REM', 'S3->W', 'S3->S1', 'S3->S2', 'S3->S3', 'S3->S4', 'S3->REM', 'S4->W', 'S4->S1', 'S4->S2', 'S4->S3', 'S4->S4', 'S4->REM', 'REM->W', 'REM->S1', 'REM->S2', 'REM->S3', 'REM->REM']\n",
      "        \n",
      "\n",
      "        Feature shape: (146, 34), Target shape: (146,), Metadata: (146, 3) \n",
      "        \n",
      "\n",
      "        GridSearch: LR - {'penalty': ['l2', 'elasticnet'], 'max_iter': [50, 100, 130, 150, 170, 200], 'C': [0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1.0]} \n",
      "        ---------------------------------------------------------------------------------------------------\n",
      "        \n",
      "Refitting the model with best parameter f1 == True\n",
      "Fitting 5 folds for each of 84 candidates, totalling 420 fits\n",
      "\n",
      "        From training? False, Data shape: (20, 38), Indices: [ 83  65  29  61  95  67  25 150  76  26 123  63 151 149  97   0 140  99\n",
      "  69 125]\n",
      "        All Columns: ['Dataset', 'Category', 'Subject_Name', 'Class', 'W->S1', 'W->S2', 'W->S3', 'W->S4', 'W->REM', 'S1->W', 'S1->S1', 'S1->S2', 'S1->S3', 'S1->S4', 'S1->REM', 'S2->W', 'S2->S1', 'S2->S2', 'S2->S3', 'S2->S4', 'S2->REM', 'S3->W', 'S3->S1', 'S3->S2', 'S3->S3', 'S3->S4', 'S3->REM', 'S4->W', 'S4->S1', 'S4->S2', 'S4->S3', 'S4->S4', 'S4->REM', 'REM->W', 'REM->S1', 'REM->S2', 'REM->S3', 'REM->REM']\n",
      "        \n",
      "\n",
      "        Feature shape: (20, 34), Target shape: (20,), Metadata: (20, 3) \n",
      "        \n",
      "[0 1] [0 1]\n",
      "[1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0] [1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0]\n",
      "[[ 6  3]\n",
      " [ 0 11]]\n",
      "[[11  0  3  6]\n",
      " [ 6  3  0 11]]\n",
      "[[17  3]\n",
      " [ 3 17]]\n",
      "Class-wise info: For multilevel internal scores fo label 0: \n",
      " Accuracy = 85.0\n",
      " Precision = [0.78571429 1.        ]\n",
      " Recall = [1.         0.66666667]\n",
      " F1 score = [0.88 0.8 ]\n",
      " AUC score = 83.33333333333333\n",
      " Support = [11  9]\n",
      "\n",
      "Class-wise info: For multilevel internal scores fo label 1: \n",
      " Accuracy = 85.0\n",
      " Precision = [1.         0.78571429]\n",
      " Recall = [0.66666667 1.        ]\n",
      " F1 score = [0.8  0.88]\n",
      " AUC score = 83.33333333333334\n",
      " Support = [ 9 11]\n",
      "\n",
      "CLASSIFICATION MERICS:\n",
      " _______________________________________________________\n",
      " Confusion Matrix: \n",
      "[[ 6  3]\n",
      " [ 0 11]]\n",
      " Accuracy (acc): 85.0\n",
      " Precision (prc): 78.571\n",
      " Recall (rec): 100.0\n",
      " Sensitivity (sns): 100.0\n",
      " Specificity (spc): 66.667\n",
      " F1 Score (f1s): 88.0\n",
      " ROC AUC (AUC): 0.833\n",
      "Score columns: (1, 12) ['method', 'model', 'model_parameters', 'model_scores', 'confusion_matrix', 'accuracy', 'precision', 'recall', 'sensitivity', 'specificity', 'f1_score', 'roc_auc']\n",
      "\n",
      "        Best model (GriveSearchCV): GridSearchCV(cv=5, estimator=LogisticRegression(), n_jobs=50,\n",
      "             param_grid={'C': [0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1.0],\n",
      "                         'max_iter': [50, 100, 130, 150, 170, 200],\n",
      "                         'penalty': ['l2', 'elasticnet']},\n",
      "             return_train_score=True, scoring='f1', verbose=2) \n",
      "        Best model: GridSearchCV(cv=5, estimator=LogisticRegression(), n_jobs=50,\n",
      "             param_grid={'C': [0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1.0],\n",
      "                         'max_iter': [50, 100, 130, 150, 170, 200],\n",
      "                         'penalty': ['l2', 'elasticnet']},\n",
      "             return_train_score=True, scoring='f1', verbose=2) \n",
      "        Best estimator of the model: LogisticRegression(max_iter=50) \n",
      "        Best parameters of the model: {'C': 1.0, 'max_iter': 50, 'penalty': 'l2'} \n",
      "        ---------------------------------------------------------------------------------------------------\n",
      "        \n",
      "\n",
      "            *** ML MODEL FOR TEST:1, TRAINING:5 AND MODEL: SVC \n",
      "            ---------------------------------------------------------------------------------------------------\n",
      "            \n",
      "Calling method: support_vector_classifier_parameters\n",
      "All parameters: ['probability', 'C', 'kernel', 'gamma', 'degree', 'class_weightdict'], [[True], [0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1.0], ['linear', 'rbf', 'poly']], [0, 1, 2]\n",
      "Parameters:  {'probability': [True], 'C': [0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1.0], 'kernel': ['linear', 'rbf', 'poly']}\n",
      "\n",
      "        From training? True, Data shape: (146, 38), Indices: [106  54  14   8  85  40 119   1  84  75  46  91 162 148  74  94 126  58\n",
      " 147 156 153 121   5 160  64  60 107 139 110 118  68 141  98 146 132  23\n",
      "   7  87  82  52  53  72  93  56  27 124 135 136 100  86   6  77 143 133\n",
      " 131  71 120 138 117  92  43  20  32 158  59  24  11  31   9 152 129  49\n",
      " 144  55  70 109 122  73 116  51  37  47  89 104 155  62  21 130 102 157\n",
      "  48  12   4 164  30  18  88 105 108  41  78 111  35  17  57 142  45 112\n",
      "   2  39 101  10 114 115 127  50  66  44  38  16 154 103 145  28  13  15\n",
      " 113 163  34  79  81 134 128  19  96 159 165  22  42  33   3 161  90 137\n",
      "  80  36]\n",
      "        All Columns: ['Dataset', 'Category', 'Subject_Name', 'Class', 'W->S1', 'W->S2', 'W->S3', 'W->S4', 'W->REM', 'S1->W', 'S1->S1', 'S1->S2', 'S1->S3', 'S1->S4', 'S1->REM', 'S2->W', 'S2->S1', 'S2->S2', 'S2->S3', 'S2->S4', 'S2->REM', 'S3->W', 'S3->S1', 'S3->S2', 'S3->S3', 'S3->S4', 'S3->REM', 'S4->W', 'S4->S1', 'S4->S2', 'S4->S3', 'S4->S4', 'S4->REM', 'REM->W', 'REM->S1', 'REM->S2', 'REM->S3', 'REM->REM']\n",
      "        \n",
      "\n",
      "        Feature shape: (146, 34), Target shape: (146,), Metadata: (146, 3) \n",
      "        \n",
      "\n",
      "        GridSearch: SVC - {'probability': [True], 'C': [0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1.0], 'kernel': ['linear', 'rbf', 'poly']} \n",
      "        ---------------------------------------------------------------------------------------------------\n",
      "        \n",
      "Refitting the model with best parameter f1 == True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aliem\\.conda\\envs\\MyPython37Work\\lib\\site-packages\\sklearn\\model_selection\\_search.py:921: UserWarning: One or more of the test scores are non-finite: [0.71356974        nan 0.71356974        nan 0.71356974        nan\n",
      " 0.71356974        nan 0.71356974        nan 0.71356974        nan\n",
      " 0.71356974        nan 0.71356974        nan 0.71356974        nan\n",
      " 0.71356974        nan 0.71356974        nan 0.71356974        nan\n",
      " 0.73292929        nan 0.73292929        nan 0.73292929        nan\n",
      " 0.73292929        nan 0.73292929        nan 0.73292929        nan\n",
      " 0.85132704        nan 0.85132704        nan 0.85132704        nan\n",
      " 0.85132704        nan 0.85132704        nan 0.85132704        nan\n",
      " 0.86298614        nan 0.86298614        nan 0.86298614        nan\n",
      " 0.86298614        nan 0.86298614        nan 0.86298614        nan\n",
      " 0.88604969        nan 0.88604969        nan 0.88604969        nan\n",
      " 0.88604969        nan 0.88604969        nan 0.88604969        nan\n",
      " 0.90912459        nan 0.90912459        nan 0.90912459        nan\n",
      " 0.90912459        nan 0.90912459        nan 0.90912459        nan]\n",
      "  category=UserWarning\n",
      "C:\\Users\\aliem\\.conda\\envs\\MyPython37Work\\lib\\site-packages\\sklearn\\model_selection\\_search.py:921: UserWarning: One or more of the train scores are non-finite: [0.71365079        nan 0.71365079        nan 0.71365079        nan\n",
      " 0.71365079        nan 0.71365079        nan 0.71365079        nan\n",
      " 0.71365079        nan 0.71365079        nan 0.71365079        nan\n",
      " 0.71365079        nan 0.71365079        nan 0.71365079        nan\n",
      " 0.73304658        nan 0.73304658        nan 0.73304658        nan\n",
      " 0.73304658        nan 0.73304658        nan 0.73304658        nan\n",
      " 0.85298717        nan 0.85298717        nan 0.85298717        nan\n",
      " 0.85298717        nan 0.85298717        nan 0.85298717        nan\n",
      " 0.87181235        nan 0.87181235        nan 0.87181235        nan\n",
      " 0.87181235        nan 0.87181235        nan 0.87181235        nan\n",
      " 0.90055721        nan 0.90055721        nan 0.90055721        nan\n",
      " 0.90055721        nan 0.90055721        nan 0.90055721        nan\n",
      " 0.90883296        nan 0.90883296        nan 0.90883296        nan\n",
      " 0.90883296        nan 0.90883296        nan 0.90883296        nan]\n",
      "  category=UserWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 21 candidates, totalling 105 fits\n",
      "\n",
      "        From training? False, Data shape: (20, 38), Indices: [ 83  65  29  61  95  67  25 150  76  26 123  63 151 149  97   0 140  99\n",
      "  69 125]\n",
      "        All Columns: ['Dataset', 'Category', 'Subject_Name', 'Class', 'W->S1', 'W->S2', 'W->S3', 'W->S4', 'W->REM', 'S1->W', 'S1->S1', 'S1->S2', 'S1->S3', 'S1->S4', 'S1->REM', 'S2->W', 'S2->S1', 'S2->S2', 'S2->S3', 'S2->S4', 'S2->REM', 'S3->W', 'S3->S1', 'S3->S2', 'S3->S3', 'S3->S4', 'S3->REM', 'S4->W', 'S4->S1', 'S4->S2', 'S4->S3', 'S4->S4', 'S4->REM', 'REM->W', 'REM->S1', 'REM->S2', 'REM->S3', 'REM->REM']\n",
      "        \n",
      "\n",
      "        Feature shape: (20, 34), Target shape: (20,), Metadata: (20, 3) \n",
      "        \n",
      "[0 1] [0 1]\n",
      "[1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0] [1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0]\n",
      "[[ 6  3]\n",
      " [ 0 11]]\n",
      "[[11  0  3  6]\n",
      " [ 6  3  0 11]]\n",
      "[[17  3]\n",
      " [ 3 17]]\n",
      "Class-wise info: For multilevel internal scores fo label 0: \n",
      " Accuracy = 85.0\n",
      " Precision = [0.78571429 1.        ]\n",
      " Recall = [1.         0.66666667]\n",
      " F1 score = [0.88 0.8 ]\n",
      " AUC score = 83.33333333333333\n",
      " Support = [11  9]\n",
      "\n",
      "Class-wise info: For multilevel internal scores fo label 1: \n",
      " Accuracy = 85.0\n",
      " Precision = [1.         0.78571429]\n",
      " Recall = [0.66666667 1.        ]\n",
      " F1 score = [0.8  0.88]\n",
      " AUC score = 83.33333333333334\n",
      " Support = [ 9 11]\n",
      "\n",
      "CLASSIFICATION MERICS:\n",
      " _______________________________________________________\n",
      " Confusion Matrix: \n",
      "[[ 6  3]\n",
      " [ 0 11]]\n",
      " Accuracy (acc): 85.0\n",
      " Precision (prc): 78.571\n",
      " Recall (rec): 100.0\n",
      " Sensitivity (sns): 100.0\n",
      " Specificity (spc): 66.667\n",
      " F1 Score (f1s): 88.0\n",
      " ROC AUC (AUC): 0.833\n",
      "Score columns: (1, 12) ['method', 'model', 'model_parameters', 'model_scores', 'confusion_matrix', 'accuracy', 'precision', 'recall', 'sensitivity', 'specificity', 'f1_score', 'roc_auc']\n",
      "\n",
      "        Best model (GriveSearchCV): GridSearchCV(cv=5, estimator=SVC(), n_jobs=50,\n",
      "             param_grid={'C': [0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1.0],\n",
      "                         'kernel': ['linear', 'rbf', 'poly'],\n",
      "                         'probability': [True]},\n",
      "             return_train_score=True, scoring='f1', verbose=2) \n",
      "        Best model: GridSearchCV(cv=5, estimator=SVC(), n_jobs=50,\n",
      "             param_grid={'C': [0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1.0],\n",
      "                         'kernel': ['linear', 'rbf', 'poly'],\n",
      "                         'probability': [True]},\n",
      "             return_train_score=True, scoring='f1', verbose=2) \n",
      "        Best estimator of the model: SVC(kernel='linear', probability=True) \n",
      "        Best parameters of the model: {'C': 1.0, 'kernel': 'linear', 'probability': True} \n",
      "        ---------------------------------------------------------------------------------------------------\n",
      "        \n",
      "\n",
      "            *** ML MODEL FOR TEST:1, TRAINING:5 AND MODEL: NB \n",
      "            ---------------------------------------------------------------------------------------------------\n",
      "            \n",
      "Calling method: naive_bayes_parameters\n",
      "All parameters: ['var_smoothing'], [[1.0, 0.005623413251903491, 3.1622776601683795e-05, 1.7782794100389227e-07, 1e-09]], [0]\n",
      "Parameters:  {'var_smoothing': [1.0, 0.005623413251903491, 3.1622776601683795e-05, 1.7782794100389227e-07, 1e-09]}\n",
      "\n",
      "        From training? True, Data shape: (146, 38), Indices: [106  54  14   8  85  40 119   1  84  75  46  91 162 148  74  94 126  58\n",
      " 147 156 153 121   5 160  64  60 107 139 110 118  68 141  98 146 132  23\n",
      "   7  87  82  52  53  72  93  56  27 124 135 136 100  86   6  77 143 133\n",
      " 131  71 120 138 117  92  43  20  32 158  59  24  11  31   9 152 129  49\n",
      " 144  55  70 109 122  73 116  51  37  47  89 104 155  62  21 130 102 157\n",
      "  48  12   4 164  30  18  88 105 108  41  78 111  35  17  57 142  45 112\n",
      "   2  39 101  10 114 115 127  50  66  44  38  16 154 103 145  28  13  15\n",
      " 113 163  34  79  81 134 128  19  96 159 165  22  42  33   3 161  90 137\n",
      "  80  36]\n",
      "        All Columns: ['Dataset', 'Category', 'Subject_Name', 'Class', 'W->S1', 'W->S2', 'W->S3', 'W->S4', 'W->REM', 'S1->W', 'S1->S1', 'S1->S2', 'S1->S3', 'S1->S4', 'S1->REM', 'S2->W', 'S2->S1', 'S2->S2', 'S2->S3', 'S2->S4', 'S2->REM', 'S3->W', 'S3->S1', 'S3->S2', 'S3->S3', 'S3->S4', 'S3->REM', 'S4->W', 'S4->S1', 'S4->S2', 'S4->S3', 'S4->S4', 'S4->REM', 'REM->W', 'REM->S1', 'REM->S2', 'REM->S3', 'REM->REM']\n",
      "        \n",
      "\n",
      "        Feature shape: (146, 34), Target shape: (146,), Metadata: (146, 3) \n",
      "        \n",
      "\n",
      "        GridSearch: NB - {'var_smoothing': [1.0, 0.005623413251903491, 3.1622776601683795e-05, 1.7782794100389227e-07, 1e-09]} \n",
      "        ---------------------------------------------------------------------------------------------------\n",
      "        \n",
      "Refitting the model with best parameter f1 == True\n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "\n",
      "        From training? False, Data shape: (20, 38), Indices: [ 83  65  29  61  95  67  25 150  76  26 123  63 151 149  97   0 140  99\n",
      "  69 125]\n",
      "        All Columns: ['Dataset', 'Category', 'Subject_Name', 'Class', 'W->S1', 'W->S2', 'W->S3', 'W->S4', 'W->REM', 'S1->W', 'S1->S1', 'S1->S2', 'S1->S3', 'S1->S4', 'S1->REM', 'S2->W', 'S2->S1', 'S2->S2', 'S2->S3', 'S2->S4', 'S2->REM', 'S3->W', 'S3->S1', 'S3->S2', 'S3->S3', 'S3->S4', 'S3->REM', 'S4->W', 'S4->S1', 'S4->S2', 'S4->S3', 'S4->S4', 'S4->REM', 'REM->W', 'REM->S1', 'REM->S2', 'REM->S3', 'REM->REM']\n",
      "        \n",
      "\n",
      "        Feature shape: (20, 34), Target shape: (20,), Metadata: (20, 3) \n",
      "        \n",
      "[0 1] [0 1]\n",
      "[1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0] [1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0]\n",
      "[[ 6  3]\n",
      " [ 0 11]]\n",
      "[[11  0  3  6]\n",
      " [ 6  3  0 11]]\n",
      "[[17  3]\n",
      " [ 3 17]]\n",
      "Class-wise info: For multilevel internal scores fo label 0: \n",
      " Accuracy = 85.0\n",
      " Precision = [0.78571429 1.        ]\n",
      " Recall = [1.         0.66666667]\n",
      " F1 score = [0.88 0.8 ]\n",
      " AUC score = 83.33333333333333\n",
      " Support = [11  9]\n",
      "\n",
      "Class-wise info: For multilevel internal scores fo label 1: \n",
      " Accuracy = 85.0\n",
      " Precision = [1.         0.78571429]\n",
      " Recall = [0.66666667 1.        ]\n",
      " F1 score = [0.8  0.88]\n",
      " AUC score = 83.33333333333334\n",
      " Support = [ 9 11]\n",
      "\n",
      "CLASSIFICATION MERICS:\n",
      " _______________________________________________________\n",
      " Confusion Matrix: \n",
      "[[ 6  3]\n",
      " [ 0 11]]\n",
      " Accuracy (acc): 85.0\n",
      " Precision (prc): 78.571\n",
      " Recall (rec): 100.0\n",
      " Sensitivity (sns): 100.0\n",
      " Specificity (spc): 66.667\n",
      " F1 Score (f1s): 88.0\n",
      " ROC AUC (AUC): 0.833\n",
      "Score columns: (1, 12) ['method', 'model', 'model_parameters', 'model_scores', 'confusion_matrix', 'accuracy', 'precision', 'recall', 'sensitivity', 'specificity', 'f1_score', 'roc_auc']\n",
      "\n",
      "        Best model (GriveSearchCV): GridSearchCV(cv=5, estimator=GaussianNB(), n_jobs=50,\n",
      "             param_grid={'var_smoothing': [1.0, 0.005623413251903491,\n",
      "                                           3.1622776601683795e-05,\n",
      "                                           1.7782794100389227e-07, 1e-09]},\n",
      "             return_train_score=True, scoring='f1', verbose=2) \n",
      "        Best model: GridSearchCV(cv=5, estimator=GaussianNB(), n_jobs=50,\n",
      "             param_grid={'var_smoothing': [1.0, 0.005623413251903491,\n",
      "                                           3.1622776601683795e-05,\n",
      "                                           1.7782794100389227e-07, 1e-09]},\n",
      "             return_train_score=True, scoring='f1', verbose=2) \n",
      "        Best estimator of the model: GaussianNB(var_smoothing=0.005623413251903491) \n",
      "        Best parameters of the model: {'var_smoothing': 0.005623413251903491} \n",
      "        ---------------------------------------------------------------------------------------------------\n",
      "        \n",
      "\n",
      "            *** ML MODEL FOR TEST:1, TRAINING:5 AND MODEL: KNN \n",
      "            ---------------------------------------------------------------------------------------------------\n",
      "            \n",
      "Calling method: k_nearest_neighbors_parameters\n",
      "All parameters: ['n_neighbors', 'p', 'metric', 'n_splits'], [[2, 3, 5, 10, 15, 25, 35], ['manhattan', 'minkowski', 'euclidean']], [0, 2]\n",
      "Parameters:  {'n_neighbors': [2, 3, 5, 10, 15, 25, 35], 'metric': ['manhattan', 'minkowski', 'euclidean']}\n",
      "\n",
      "        From training? True, Data shape: (146, 38), Indices: [106  54  14   8  85  40 119   1  84  75  46  91 162 148  74  94 126  58\n",
      " 147 156 153 121   5 160  64  60 107 139 110 118  68 141  98 146 132  23\n",
      "   7  87  82  52  53  72  93  56  27 124 135 136 100  86   6  77 143 133\n",
      " 131  71 120 138 117  92  43  20  32 158  59  24  11  31   9 152 129  49\n",
      " 144  55  70 109 122  73 116  51  37  47  89 104 155  62  21 130 102 157\n",
      "  48  12   4 164  30  18  88 105 108  41  78 111  35  17  57 142  45 112\n",
      "   2  39 101  10 114 115 127  50  66  44  38  16 154 103 145  28  13  15\n",
      " 113 163  34  79  81 134 128  19  96 159 165  22  42  33   3 161  90 137\n",
      "  80  36]\n",
      "        All Columns: ['Dataset', 'Category', 'Subject_Name', 'Class', 'W->S1', 'W->S2', 'W->S3', 'W->S4', 'W->REM', 'S1->W', 'S1->S1', 'S1->S2', 'S1->S3', 'S1->S4', 'S1->REM', 'S2->W', 'S2->S1', 'S2->S2', 'S2->S3', 'S2->S4', 'S2->REM', 'S3->W', 'S3->S1', 'S3->S2', 'S3->S3', 'S3->S4', 'S3->REM', 'S4->W', 'S4->S1', 'S4->S2', 'S4->S3', 'S4->S4', 'S4->REM', 'REM->W', 'REM->S1', 'REM->S2', 'REM->S3', 'REM->REM']\n",
      "        \n",
      "\n",
      "        Feature shape: (146, 34), Target shape: (146,), Metadata: (146, 3) \n",
      "        \n",
      "\n",
      "        GridSearch: KNN - {'n_neighbors': [2, 3, 5, 10, 15, 25, 35], 'metric': ['manhattan', 'minkowski', 'euclidean']} \n",
      "        ---------------------------------------------------------------------------------------------------\n",
      "        \n",
      "Refitting the model with best parameter f1 == True\n",
      "Fitting 5 folds for each of 21 candidates, totalling 105 fits\n",
      "\n",
      "        From training? False, Data shape: (20, 38), Indices: [ 83  65  29  61  95  67  25 150  76  26 123  63 151 149  97   0 140  99\n",
      "  69 125]\n",
      "        All Columns: ['Dataset', 'Category', 'Subject_Name', 'Class', 'W->S1', 'W->S2', 'W->S3', 'W->S4', 'W->REM', 'S1->W', 'S1->S1', 'S1->S2', 'S1->S3', 'S1->S4', 'S1->REM', 'S2->W', 'S2->S1', 'S2->S2', 'S2->S3', 'S2->S4', 'S2->REM', 'S3->W', 'S3->S1', 'S3->S2', 'S3->S3', 'S3->S4', 'S3->REM', 'S4->W', 'S4->S1', 'S4->S2', 'S4->S3', 'S4->S4', 'S4->REM', 'REM->W', 'REM->S1', 'REM->S2', 'REM->S3', 'REM->REM']\n",
      "        \n",
      "\n",
      "        Feature shape: (20, 34), Target shape: (20,), Metadata: (20, 3) \n",
      "        \n",
      "[0 1] [0 1]\n",
      "[1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0] [1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0]\n",
      "[[ 5  4]\n",
      " [ 0 11]]\n",
      "[[11  0  4  5]\n",
      " [ 5  4  0 11]]\n",
      "[[16  4]\n",
      " [ 4 16]]\n",
      "Class-wise info: For multilevel internal scores fo label 0: \n",
      " Accuracy = 80.0\n",
      " Precision = [0.73333333 1.        ]\n",
      " Recall = [1.         0.55555556]\n",
      " F1 score = [0.84615385 0.71428571]\n",
      " AUC score = 77.77777777777779\n",
      " Support = [11  9]\n",
      "\n",
      "Class-wise info: For multilevel internal scores fo label 1: \n",
      " Accuracy = 80.0\n",
      " Precision = [1.         0.73333333]\n",
      " Recall = [0.55555556 1.        ]\n",
      " F1 score = [0.71428571 0.84615385]\n",
      " AUC score = 77.77777777777779\n",
      " Support = [ 9 11]\n",
      "\n",
      "CLASSIFICATION MERICS:\n",
      " _______________________________________________________\n",
      " Confusion Matrix: \n",
      "[[ 5  4]\n",
      " [ 0 11]]\n",
      " Accuracy (acc): 80.0\n",
      " Precision (prc): 73.333\n",
      " Recall (rec): 100.0\n",
      " Sensitivity (sns): 100.0\n",
      " Specificity (spc): 55.556\n",
      " F1 Score (f1s): 84.615\n",
      " ROC AUC (AUC): 0.778\n",
      "Score columns: (1, 12) ['method', 'model', 'model_parameters', 'model_scores', 'confusion_matrix', 'accuracy', 'precision', 'recall', 'sensitivity', 'specificity', 'f1_score', 'roc_auc']\n",
      "\n",
      "        Best model (GriveSearchCV): GridSearchCV(cv=5, estimator=KNeighborsClassifier(), n_jobs=50,\n",
      "             param_grid={'metric': ['manhattan', 'minkowski', 'euclidean'],\n",
      "                         'n_neighbors': [2, 3, 5, 10, 15, 25, 35]},\n",
      "             return_train_score=True, scoring='f1', verbose=2) \n",
      "        Best model: GridSearchCV(cv=5, estimator=KNeighborsClassifier(), n_jobs=50,\n",
      "             param_grid={'metric': ['manhattan', 'minkowski', 'euclidean'],\n",
      "                         'n_neighbors': [2, 3, 5, 10, 15, 25, 35]},\n",
      "             return_train_score=True, scoring='f1', verbose=2) \n",
      "        Best estimator of the model: KNeighborsClassifier(metric='manhattan', n_neighbors=15) \n",
      "        Best parameters of the model: {'metric': 'manhattan', 'n_neighbors': 15} \n",
      "        ---------------------------------------------------------------------------------------------------\n",
      "        \n",
      "\n",
      "            *** ML MODEL FOR TEST:1, TRAINING:5 AND MODEL: DT \n",
      "            ---------------------------------------------------------------------------------------------------\n",
      "            \n",
      "Calling method: decision_tree_parameters\n",
      "All parameters: ['max_depth', 'criterion', 'splitter', 'min_samples_split', 'min_samples_leaf', 'max_leaf_nodes'], [[2, 3, 5, 7, 10, 15, 20, 25, 30], ['gini', 'entropy', 'log_loss']], [0, 1]\n",
      "Parameters:  {'max_depth': [2, 3, 5, 7, 10, 15, 20, 25, 30], 'criterion': ['gini', 'entropy', 'log_loss']}\n",
      "\n",
      "        From training? True, Data shape: (146, 38), Indices: [106  54  14   8  85  40 119   1  84  75  46  91 162 148  74  94 126  58\n",
      " 147 156 153 121   5 160  64  60 107 139 110 118  68 141  98 146 132  23\n",
      "   7  87  82  52  53  72  93  56  27 124 135 136 100  86   6  77 143 133\n",
      " 131  71 120 138 117  92  43  20  32 158  59  24  11  31   9 152 129  49\n",
      " 144  55  70 109 122  73 116  51  37  47  89 104 155  62  21 130 102 157\n",
      "  48  12   4 164  30  18  88 105 108  41  78 111  35  17  57 142  45 112\n",
      "   2  39 101  10 114 115 127  50  66  44  38  16 154 103 145  28  13  15\n",
      " 113 163  34  79  81 134 128  19  96 159 165  22  42  33   3 161  90 137\n",
      "  80  36]\n",
      "        All Columns: ['Dataset', 'Category', 'Subject_Name', 'Class', 'W->S1', 'W->S2', 'W->S3', 'W->S4', 'W->REM', 'S1->W', 'S1->S1', 'S1->S2', 'S1->S3', 'S1->S4', 'S1->REM', 'S2->W', 'S2->S1', 'S2->S2', 'S2->S3', 'S2->S4', 'S2->REM', 'S3->W', 'S3->S1', 'S3->S2', 'S3->S3', 'S3->S4', 'S3->REM', 'S4->W', 'S4->S1', 'S4->S2', 'S4->S3', 'S4->S4', 'S4->REM', 'REM->W', 'REM->S1', 'REM->S2', 'REM->S3', 'REM->REM']\n",
      "        \n",
      "\n",
      "        Feature shape: (146, 34), Target shape: (146,), Metadata: (146, 3) \n",
      "        \n",
      "\n",
      "        GridSearch: DT - {'max_depth': [2, 3, 5, 7, 10, 15, 20, 25, 30], 'criterion': ['gini', 'entropy', 'log_loss']} \n",
      "        ---------------------------------------------------------------------------------------------------\n",
      "        \n",
      "Refitting the model with best parameter f1 == True\n",
      "Fitting 5 folds for each of 27 candidates, totalling 135 fits\n",
      "\n",
      "        From training? False, Data shape: (20, 38), Indices: [ 83  65  29  61  95  67  25 150  76  26 123  63 151 149  97   0 140  99\n",
      "  69 125]\n",
      "        All Columns: ['Dataset', 'Category', 'Subject_Name', 'Class', 'W->S1', 'W->S2', 'W->S3', 'W->S4', 'W->REM', 'S1->W', 'S1->S1', 'S1->S2', 'S1->S3', 'S1->S4', 'S1->REM', 'S2->W', 'S2->S1', 'S2->S2', 'S2->S3', 'S2->S4', 'S2->REM', 'S3->W', 'S3->S1', 'S3->S2', 'S3->S3', 'S3->S4', 'S3->REM', 'S4->W', 'S4->S1', 'S4->S2', 'S4->S3', 'S4->S4', 'S4->REM', 'REM->W', 'REM->S1', 'REM->S2', 'REM->S3', 'REM->REM']\n",
      "        \n",
      "\n",
      "        Feature shape: (20, 34), Target shape: (20,), Metadata: (20, 3) \n",
      "        \n",
      "[0 1] [0 1]\n",
      "[1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0] [1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0]\n",
      "[[ 6  3]\n",
      " [ 1 10]]\n",
      "[[10  1  3  6]\n",
      " [ 6  3  1 10]]\n",
      "[[16  4]\n",
      " [ 4 16]]\n",
      "Class-wise info: For multilevel internal scores fo label 0: \n",
      " Accuracy = 80.0\n",
      " Precision = [0.76923077 0.85714286]\n",
      " Recall = [0.90909091 0.66666667]\n",
      " F1 score = [0.83333333 0.75      ]\n",
      " AUC score = 78.78787878787877\n",
      " Support = [11  9]\n",
      "\n",
      "Class-wise info: For multilevel internal scores fo label 1: \n",
      " Accuracy = 80.0\n",
      " Precision = [0.85714286 0.76923077]\n",
      " Recall = [0.66666667 0.90909091]\n",
      " F1 score = [0.75       0.83333333]\n",
      " AUC score = 78.7878787878788\n",
      " Support = [ 9 11]\n",
      "\n",
      "CLASSIFICATION MERICS:\n",
      " _______________________________________________________\n",
      " Confusion Matrix: \n",
      "[[ 6  3]\n",
      " [ 1 10]]\n",
      " Accuracy (acc): 80.0\n",
      " Precision (prc): 76.923\n",
      " Recall (rec): 90.909\n",
      " Sensitivity (sns): 90.909\n",
      " Specificity (spc): 66.667\n",
      " F1 Score (f1s): 83.333\n",
      " ROC AUC (AUC): 0.788\n",
      "Score columns: (1, 12) ['method', 'model', 'model_parameters', 'model_scores', 'confusion_matrix', 'accuracy', 'precision', 'recall', 'sensitivity', 'specificity', 'f1_score', 'roc_auc']\n",
      "\n",
      "        Best model (GriveSearchCV): GridSearchCV(cv=5, estimator=DecisionTreeClassifier(), n_jobs=50,\n",
      "             param_grid={'criterion': ['gini', 'entropy', 'log_loss'],\n",
      "                         'max_depth': [2, 3, 5, 7, 10, 15, 20, 25, 30]},\n",
      "             return_train_score=True, scoring='f1', verbose=2) \n",
      "        Best model: GridSearchCV(cv=5, estimator=DecisionTreeClassifier(), n_jobs=50,\n",
      "             param_grid={'criterion': ['gini', 'entropy', 'log_loss'],\n",
      "                         'max_depth': [2, 3, 5, 7, 10, 15, 20, 25, 30]},\n",
      "             return_train_score=True, scoring='f1', verbose=2) \n",
      "        Best estimator of the model: DecisionTreeClassifier(max_depth=2) \n",
      "        Best parameters of the model: {'criterion': 'gini', 'max_depth': 2} \n",
      "        ---------------------------------------------------------------------------------------------------\n",
      "        \n",
      "\n",
      "            *** ML MODEL FOR TEST:1, TRAINING:5 AND MODEL: RF \n",
      "            ---------------------------------------------------------------------------------------------------\n",
      "            \n",
      "Calling method: random_forest_parameters\n",
      "All parameters: ['n_estimators', 'max_depth', 'criterion', 'splitter', 'max_features', 'min_samples_split', 'min_samples_leaf', 'max_leaf_nodes'], [[3, 5, 10, 15, 21, 30, 50, 75, 100], [2, 3, 5, 7, 10, 15, 20, 25, 30], ['gini', 'entropy', 'log_loss']], [0, 1, 2]\n",
      "Parameters:  {'n_estimators': [3, 5, 10, 15, 21, 30, 50, 75, 100], 'max_depth': [2, 3, 5, 7, 10, 15, 20, 25, 30], 'criterion': ['gini', 'entropy', 'log_loss']}\n",
      "\n",
      "        From training? True, Data shape: (146, 38), Indices: [106  54  14   8  85  40 119   1  84  75  46  91 162 148  74  94 126  58\n",
      " 147 156 153 121   5 160  64  60 107 139 110 118  68 141  98 146 132  23\n",
      "   7  87  82  52  53  72  93  56  27 124 135 136 100  86   6  77 143 133\n",
      " 131  71 120 138 117  92  43  20  32 158  59  24  11  31   9 152 129  49\n",
      " 144  55  70 109 122  73 116  51  37  47  89 104 155  62  21 130 102 157\n",
      "  48  12   4 164  30  18  88 105 108  41  78 111  35  17  57 142  45 112\n",
      "   2  39 101  10 114 115 127  50  66  44  38  16 154 103 145  28  13  15\n",
      " 113 163  34  79  81 134 128  19  96 159 165  22  42  33   3 161  90 137\n",
      "  80  36]\n",
      "        All Columns: ['Dataset', 'Category', 'Subject_Name', 'Class', 'W->S1', 'W->S2', 'W->S3', 'W->S4', 'W->REM', 'S1->W', 'S1->S1', 'S1->S2', 'S1->S3', 'S1->S4', 'S1->REM', 'S2->W', 'S2->S1', 'S2->S2', 'S2->S3', 'S2->S4', 'S2->REM', 'S3->W', 'S3->S1', 'S3->S2', 'S3->S3', 'S3->S4', 'S3->REM', 'S4->W', 'S4->S1', 'S4->S2', 'S4->S3', 'S4->S4', 'S4->REM', 'REM->W', 'REM->S1', 'REM->S2', 'REM->S3', 'REM->REM']\n",
      "        \n",
      "\n",
      "        Feature shape: (146, 34), Target shape: (146,), Metadata: (146, 3) \n",
      "        \n",
      "\n",
      "        GridSearch: RF - {'n_estimators': [3, 5, 10, 15, 21, 30, 50, 75, 100], 'max_depth': [2, 3, 5, 7, 10, 15, 20, 25, 30], 'criterion': ['gini', 'entropy', 'log_loss']} \n",
      "        ---------------------------------------------------------------------------------------------------\n",
      "        \n",
      "Refitting the model with best parameter f1 == True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aliem\\.conda\\envs\\MyPython37Work\\lib\\site-packages\\sklearn\\model_selection\\_search.py:921: UserWarning: One or more of the test scores are non-finite: [0.91955155 0.87241151 0.83623023 0.80577048 0.82652406 0.81172741\n",
      " 0.81831933 0.82117647 0.81842991 0.91955155 0.8280163  0.77544198\n",
      " 0.81330945 0.82616756 0.79969697 0.77679654 0.79610722 0.79778474\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan]\n",
      "  category=UserWarning\n",
      "C:\\Users\\aliem\\.conda\\envs\\MyPython37Work\\lib\\site-packages\\sklearn\\model_selection\\_search.py:921: UserWarning: One or more of the train scores are non-finite: [0.93105453 0.95419427 0.99692308 1.         1.         1.\n",
      " 1.         1.         1.         0.93105453 0.94973145 0.98254585\n",
      " 0.99847328 1.         1.         1.         1.         1.\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan]\n",
      "  category=UserWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 243 candidates, totalling 1215 fits\n",
      "\n",
      "        From training? False, Data shape: (20, 38), Indices: [ 83  65  29  61  95  67  25 150  76  26 123  63 151 149  97   0 140  99\n",
      "  69 125]\n",
      "        All Columns: ['Dataset', 'Category', 'Subject_Name', 'Class', 'W->S1', 'W->S2', 'W->S3', 'W->S4', 'W->REM', 'S1->W', 'S1->S1', 'S1->S2', 'S1->S3', 'S1->S4', 'S1->REM', 'S2->W', 'S2->S1', 'S2->S2', 'S2->S3', 'S2->S4', 'S2->REM', 'S3->W', 'S3->S1', 'S3->S2', 'S3->S3', 'S3->S4', 'S3->REM', 'S4->W', 'S4->S1', 'S4->S2', 'S4->S3', 'S4->S4', 'S4->REM', 'REM->W', 'REM->S1', 'REM->S2', 'REM->S3', 'REM->REM']\n",
      "        \n",
      "\n",
      "        Feature shape: (20, 34), Target shape: (20,), Metadata: (20, 3) \n",
      "        \n",
      "[0 1] [0 1]\n",
      "[1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0] [1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0]\n",
      "[[ 7  2]\n",
      " [ 1 10]]\n",
      "[[10  1  2  7]\n",
      " [ 7  2  1 10]]\n",
      "[[17  3]\n",
      " [ 3 17]]\n",
      "Class-wise info: For multilevel internal scores fo label 0: \n",
      " Accuracy = 85.0\n",
      " Precision = [0.83333333 0.875     ]\n",
      " Recall = [0.90909091 0.77777778]\n",
      " F1 score = [0.86956522 0.82352941]\n",
      " AUC score = 84.34343434343432\n",
      " Support = [11  9]\n",
      "\n",
      "Class-wise info: For multilevel internal scores fo label 1: \n",
      " Accuracy = 85.0\n",
      " Precision = [0.875      0.83333333]\n",
      " Recall = [0.77777778 0.90909091]\n",
      " F1 score = [0.82352941 0.86956522]\n",
      " AUC score = 84.34343434343434\n",
      " Support = [ 9 11]\n",
      "\n",
      "CLASSIFICATION MERICS:\n",
      " _______________________________________________________\n",
      " Confusion Matrix: \n",
      "[[ 7  2]\n",
      " [ 1 10]]\n",
      " Accuracy (acc): 85.0\n",
      " Precision (prc): 83.333\n",
      " Recall (rec): 90.909\n",
      " Sensitivity (sns): 90.909\n",
      " Specificity (spc): 77.778\n",
      " F1 Score (f1s): 86.957\n",
      " ROC AUC (AUC): 0.843\n",
      "Score columns: (1, 12) ['method', 'model', 'model_parameters', 'model_scores', 'confusion_matrix', 'accuracy', 'precision', 'recall', 'sensitivity', 'specificity', 'f1_score', 'roc_auc']\n",
      "\n",
      "        Best model (GriveSearchCV): GridSearchCV(cv=5, estimator=RandomForestClassifier(), n_jobs=50,\n",
      "             param_grid={'criterion': ['gini', 'entropy', 'log_loss'],\n",
      "                         'max_depth': [2, 3, 5, 7, 10, 15, 20, 25, 30],\n",
      "                         'n_estimators': [3, 5, 10, 15, 21, 30, 50, 75, 100]},\n",
      "             return_train_score=True, scoring='f1', verbose=2) \n",
      "        Best model: GridSearchCV(cv=5, estimator=RandomForestClassifier(), n_jobs=50,\n",
      "             param_grid={'criterion': ['gini', 'entropy', 'log_loss'],\n",
      "                         'max_depth': [2, 3, 5, 7, 10, 15, 20, 25, 30],\n",
      "                         'n_estimators': [3, 5, 10, 15, 21, 30, 50, 75, 100]},\n",
      "             return_train_score=True, scoring='f1', verbose=2) \n",
      "        Best estimator of the model: RandomForestClassifier(criterion='entropy', max_depth=25, n_estimators=15) \n",
      "        Best parameters of the model: {'criterion': 'entropy', 'max_depth': 25, 'n_estimators': 15} \n",
      "        ---------------------------------------------------------------------------------------------------\n",
      "        \n",
      "\n",
      "            *** ML MODEL FOR TEST:1, TRAINING:5 AND MODEL: GB \n",
      "            ---------------------------------------------------------------------------------------------------\n",
      "            \n",
      "Calling method: gradient_boosting_parameters\n",
      "All parameters: ['n_estimators', 'max_depth', 'learning_rate', 'max_features', 'loss', 'min_samples_split', 'min_samples_leaf'], [[3, 5, 10, 15, 21, 30, 50, 75, 100], [2, 3, 5, 7, 10, 15, 20, 25, 30], [0.01, 0.05, 0.1, 0.5, 1.0]], [0, 1, 2]\n",
      "Parameters:  {'n_estimators': [3, 5, 10, 15, 21, 30, 50, 75, 100], 'max_depth': [2, 3, 5, 7, 10, 15, 20, 25, 30], 'learning_rate': [0.01, 0.05, 0.1, 0.5, 1.0]}\n",
      "\n",
      "        From training? True, Data shape: (146, 38), Indices: [106  54  14   8  85  40 119   1  84  75  46  91 162 148  74  94 126  58\n",
      " 147 156 153 121   5 160  64  60 107 139 110 118  68 141  98 146 132  23\n",
      "   7  87  82  52  53  72  93  56  27 124 135 136 100  86   6  77 143 133\n",
      " 131  71 120 138 117  92  43  20  32 158  59  24  11  31   9 152 129  49\n",
      " 144  55  70 109 122  73 116  51  37  47  89 104 155  62  21 130 102 157\n",
      "  48  12   4 164  30  18  88 105 108  41  78 111  35  17  57 142  45 112\n",
      "   2  39 101  10 114 115 127  50  66  44  38  16 154 103 145  28  13  15\n",
      " 113 163  34  79  81 134 128  19  96 159 165  22  42  33   3 161  90 137\n",
      "  80  36]\n",
      "        All Columns: ['Dataset', 'Category', 'Subject_Name', 'Class', 'W->S1', 'W->S2', 'W->S3', 'W->S4', 'W->REM', 'S1->W', 'S1->S1', 'S1->S2', 'S1->S3', 'S1->S4', 'S1->REM', 'S2->W', 'S2->S1', 'S2->S2', 'S2->S3', 'S2->S4', 'S2->REM', 'S3->W', 'S3->S1', 'S3->S2', 'S3->S3', 'S3->S4', 'S3->REM', 'S4->W', 'S4->S1', 'S4->S2', 'S4->S3', 'S4->S4', 'S4->REM', 'REM->W', 'REM->S1', 'REM->S2', 'REM->S3', 'REM->REM']\n",
      "        \n",
      "\n",
      "        Feature shape: (146, 34), Target shape: (146,), Metadata: (146, 3) \n",
      "        \n",
      "\n",
      "        GridSearch: GB - {'n_estimators': [3, 5, 10, 15, 21, 30, 50, 75, 100], 'max_depth': [2, 3, 5, 7, 10, 15, 20, 25, 30], 'learning_rate': [0.01, 0.05, 0.1, 0.5, 1.0]} \n",
      "        ---------------------------------------------------------------------------------------------------\n",
      "        \n",
      "Refitting the model with best parameter f1 == True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aliem\\.conda\\envs\\MyPython37Work\\lib\\site-packages\\sklearn\\model_selection\\_search.py:921: UserWarning: One or more of the test scores are non-finite: [0.8982817  0.90142433 0.9195821  0.92596866 0.9195821  0.9195821\n",
      " 0.92596866 0.92596866 0.92596866 0.89569986 0.90535241 0.92596866\n",
      " 0.92596866 0.92596866 0.92596866 0.9195821  0.92596866 0.92596866\n",
      " 0.88572511 0.91954843 0.89248366 0.9195821  0.93134681 0.92596866\n",
      " 0.92596866 0.92596866 0.92596866 0.87398268 0.88657818 0.89801923\n",
      " 0.91316499 0.9195821  0.9195821  0.92596866 0.91955155 0.92596866\n",
      " 0.8590404  0.90557486 0.9048985  0.90495134 0.90677844 0.92596866\n",
      " 0.91955155 0.9195821  0.91316499 0.86749512 0.8932563  0.91313443\n",
      " 0.90715898 0.89853423 0.91854314 0.9249297  0.91955155 0.9195821\n",
      " 0.86502358 0.91679951 0.91103423 0.92596866 0.90808563 0.91924964\n",
      " 0.9195821  0.92596866 0.9195821  0.89565544 0.90735033 0.89709001\n",
      " 0.93134681 0.9195821  0.91818664 0.91851258 0.92596866 0.92596866\n",
      " 0.89151812 0.87807103 0.89970291 0.9195821  0.90561151 0.91248254\n",
      " 0.90672736 0.92596866 0.91955155 0.88368301 0.9195821  0.90325026\n",
      " 0.91955155 0.92596866 0.92596866 0.92596866 0.92596866 0.92596866\n",
      " 0.88506739 0.90966632 0.9195821  0.91996265 0.91955155 0.92596866\n",
      " 0.9195821  0.92596866 0.92596866 0.87725999 0.89168727 0.89996025\n",
      " 0.91886909 0.92596866 0.92596866 0.92596866 0.91955155 0.92596866\n",
      " 0.84826229 0.86963861 0.89356718 0.90604314 0.90038537 0.92596866\n",
      " 0.91280848 0.91955155 0.92596866 0.83543589 0.90912459 0.9195821\n",
      " 0.90715898 0.92496025 0.90639137 0.93134681 0.91955155 0.92596866\n",
      " 0.88158626 0.89970291 0.92525565 0.92424724 0.91319555 0.91316499\n",
      " 0.92596866 0.92596866 0.92596866 0.83842642 0.9023985  0.8991944\n",
      " 0.92496025 0.92596866 0.9195821  0.92596866 0.91955155 0.91955155\n",
      " 0.87647541 0.8444656  0.87313492 0.93167276 0.92596866 0.89957319\n",
      " 0.9306338  0.9195821  0.91955155 0.85471245 0.89358771 0.93061151\n",
      " 0.91922736 0.92596866 0.9195821  0.91955155 0.92596866 0.91955155\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan]\n",
      "  category=UserWarning\n",
      "C:\\Users\\aliem\\.conda\\envs\\MyPython37Work\\lib\\site-packages\\sklearn\\model_selection\\_search.py:921: UserWarning: One or more of the train scores are non-finite: [0.92660964 0.92554419 0.92842166 0.9241645  0.92704727 0.92708421\n",
      " 0.92573014 0.92704727 0.92706622 0.93709672 0.93783132 0.92971941\n",
      " 0.93107348 0.93111139 0.93105453 0.92973741 0.92973741 0.93105453\n",
      " 0.94794583 0.95951354 0.97156086 0.9601873  0.96581135 0.96433158\n",
      " 0.97600394 0.97021071 0.97306301 0.96264388 0.98190758 0.99539618\n",
      " 0.99234292 0.99386964 0.99250313 0.99539618 1.         1.\n",
      " 0.96649803 0.98477873 0.99544298 0.99694656 1.         1.\n",
      " 1.         1.         1.         0.97121476 0.98329811 0.9969697\n",
      " 0.99241268 0.99847328 0.99692289 1.         1.         1.\n",
      " 0.96962546 0.99234274 0.9879014  0.9969697  0.99386946 1.\n",
      " 1.         1.         1.         0.97734678 0.98172442 1.\n",
      " 0.99389259 1.         0.99844961 1.         1.         1.\n",
      " 0.96910214 0.98028832 1.         0.99386964 0.99389259 1.\n",
      " 0.99847328 1.         1.         0.92298593 0.92439556 0.92550058\n",
      " 0.92573014 0.92842029 0.92573014 0.92573014 0.92573014 0.92573014\n",
      " 0.91857874 0.93222147 0.93649525 0.92840229 0.92573014 0.92973741\n",
      " 0.92838334 0.92838334 0.92977572 0.96413098 0.96971373 0.95712173\n",
      " 0.96601863 0.96875023 0.96866429 0.98042576 0.97299812 0.96889891\n",
      " 0.97711653 0.97889082 0.99250313 0.99389259 0.99238901 1.\n",
      " 0.99847328 0.99844961 0.99844961 0.97055478 0.98627997 0.99386964\n",
      " 1.         0.99389259 1.         0.99847328 1.         1.\n",
      " 0.96820758 0.97128801 0.99847328 0.99847328 0.99694656 0.99847328\n",
      " 1.         1.         1.         0.96926025 0.98040075 0.98933557\n",
      " 0.98783217 0.99692289 1.         0.99847328 1.         1.\n",
      " 0.97583865 0.98473087 0.99541985 0.99236587 0.99393833 1.\n",
      " 1.         1.         1.         0.97732506 0.97548763 0.99847328\n",
      " 0.99541985 0.99847328 1.         1.         1.         1.\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan]\n",
      "  category=UserWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 405 candidates, totalling 2025 fits\n",
      "\n",
      "        From training? False, Data shape: (20, 38), Indices: [ 83  65  29  61  95  67  25 150  76  26 123  63 151 149  97   0 140  99\n",
      "  69 125]\n",
      "        All Columns: ['Dataset', 'Category', 'Subject_Name', 'Class', 'W->S1', 'W->S2', 'W->S3', 'W->S4', 'W->REM', 'S1->W', 'S1->S1', 'S1->S2', 'S1->S3', 'S1->S4', 'S1->REM', 'S2->W', 'S2->S1', 'S2->S2', 'S2->S3', 'S2->S4', 'S2->REM', 'S3->W', 'S3->S1', 'S3->S2', 'S3->S3', 'S3->S4', 'S3->REM', 'S4->W', 'S4->S1', 'S4->S2', 'S4->S3', 'S4->S4', 'S4->REM', 'REM->W', 'REM->S1', 'REM->S2', 'REM->S3', 'REM->REM']\n",
      "        \n",
      "\n",
      "        Feature shape: (20, 34), Target shape: (20,), Metadata: (20, 3) \n",
      "        \n",
      "[0 1] [0 1]\n",
      "[1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0] [1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0]\n",
      "[[ 6  3]\n",
      " [ 1 10]]\n",
      "[[10  1  3  6]\n",
      " [ 6  3  1 10]]\n",
      "[[16  4]\n",
      " [ 4 16]]\n",
      "Class-wise info: For multilevel internal scores fo label 0: \n",
      " Accuracy = 80.0\n",
      " Precision = [0.76923077 0.85714286]\n",
      " Recall = [0.90909091 0.66666667]\n",
      " F1 score = [0.83333333 0.75      ]\n",
      " AUC score = 78.78787878787877\n",
      " Support = [11  9]\n",
      "\n",
      "Class-wise info: For multilevel internal scores fo label 1: \n",
      " Accuracy = 80.0\n",
      " Precision = [0.85714286 0.76923077]\n",
      " Recall = [0.66666667 0.90909091]\n",
      " F1 score = [0.75       0.83333333]\n",
      " AUC score = 78.7878787878788\n",
      " Support = [ 9 11]\n",
      "\n",
      "CLASSIFICATION MERICS:\n",
      " _______________________________________________________\n",
      " Confusion Matrix: \n",
      "[[ 6  3]\n",
      " [ 1 10]]\n",
      " Accuracy (acc): 80.0\n",
      " Precision (prc): 76.923\n",
      " Recall (rec): 90.909\n",
      " Sensitivity (sns): 90.909\n",
      " Specificity (spc): 66.667\n",
      " F1 Score (f1s): 83.333\n",
      " ROC AUC (AUC): 0.788\n",
      "Score columns: (1, 12) ['method', 'model', 'model_parameters', 'model_scores', 'confusion_matrix', 'accuracy', 'precision', 'recall', 'sensitivity', 'specificity', 'f1_score', 'roc_auc']\n",
      "\n",
      "        Best model (GriveSearchCV): GridSearchCV(cv=5, estimator=GradientBoostingClassifier(), n_jobs=50,\n",
      "             param_grid={'learning_rate': [0.01, 0.05, 0.1, 0.5, 1.0],\n",
      "                         'max_depth': [2, 3, 5, 7, 10, 15, 20, 25, 30],\n",
      "                         'n_estimators': [3, 5, 10, 15, 21, 30, 50, 75, 100]},\n",
      "             return_train_score=True, scoring='f1', verbose=2) \n",
      "        Best model: GridSearchCV(cv=5, estimator=GradientBoostingClassifier(), n_jobs=50,\n",
      "             param_grid={'learning_rate': [0.01, 0.05, 0.1, 0.5, 1.0],\n",
      "                         'max_depth': [2, 3, 5, 7, 10, 15, 20, 25, 30],\n",
      "                         'n_estimators': [3, 5, 10, 15, 21, 30, 50, 75, 100]},\n",
      "             return_train_score=True, scoring='f1', verbose=2) \n",
      "        Best estimator of the model: GradientBoostingClassifier(learning_rate=0.01, max_depth=2, n_estimators=15) \n",
      "        Best parameters of the model: {'learning_rate': 0.01, 'max_depth': 2, 'n_estimators': 15} \n",
      "        ---------------------------------------------------------------------------------------------------\n",
      "        \n",
      "\n",
      "            ---------------------------------------------------------------------------------------------------\n",
      "            Best model index calculation  \n",
      "            \n",
      "\n",
      "            ***************************************************************************************************\n",
      "            TRAINING 5 END... \n",
      "            \n",
      "\n",
      "        ### MODEL EVALUATION PHASE \n",
      "        EVALUATION 1 START... XXXXX \n",
      "        ---------------------------------------------------------------------------------------------------\n",
      "        \n",
      "\n",
      "        From training? False, Data shape: (42, 38), Indices: [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107 108\n",
      " 109 110 111 112 113 114]\n",
      "        All Columns: ['Dataset', 'Category', 'Subject_Name', 'Class', 'W->S1', 'W->S2', 'W->S3', 'W->S4', 'W->REM', 'S1->W', 'S1->S1', 'S1->S2', 'S1->S3', 'S1->S4', 'S1->REM', 'S2->W', 'S2->S1', 'S2->S2', 'S2->S3', 'S2->S4', 'S2->REM', 'S3->W', 'S3->S1', 'S3->S2', 'S3->S3', 'S3->S4', 'S3->REM', 'S4->W', 'S4->S1', 'S4->S2', 'S4->S3', 'S4->S4', 'S4->REM', 'REM->W', 'REM->S1', 'REM->S2', 'REM->S3', 'REM->REM']\n",
      "        \n",
      "\n",
      "        Feature shape: (42, 34), Target shape: (42,), Metadata: (42, 3) \n",
      "        \n",
      "[0 1] [0 1]\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] [1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]\n",
      "[[ 7 16]\n",
      " [ 1 18]]\n",
      "[[18  1 16  7]\n",
      " [ 7 16  1 18]]\n",
      "[[25 17]\n",
      " [17 25]]\n",
      "Class-wise info: For multilevel internal scores fo label 0: \n",
      " Accuracy = 59.523809523809526\n",
      " Precision = [0.52941176 0.875     ]\n",
      " Recall = [0.94736842 0.30434783]\n",
      " F1 score = [0.67924528 0.4516129 ]\n",
      " AUC score = 62.58581235697941\n",
      " Support = [19 23]\n",
      "\n",
      "Class-wise info: For multilevel internal scores fo label 1: \n",
      " Accuracy = 59.523809523809526\n",
      " Precision = [0.875      0.52941176]\n",
      " Recall = [0.30434783 0.94736842]\n",
      " F1 score = [0.4516129  0.67924528]\n",
      " AUC score = 62.585812356979396\n",
      " Support = [23 19]\n",
      "\n",
      "CLASSIFICATION MERICS:\n",
      " _______________________________________________________\n",
      " Confusion Matrix: \n",
      "[[ 7 16]\n",
      " [ 1 18]]\n",
      " Accuracy (acc): 59.524\n",
      " Precision (prc): 52.941\n",
      " Recall (rec): 94.737\n",
      " Sensitivity (sns): 94.737\n",
      " Specificity (spc): 30.435\n",
      " F1 Score (f1s): 67.925\n",
      " ROC AUC (AUC): 0.626\n",
      "Score columns: (1, 12) ['method', 'model', 'model_parameters', 'model_scores', 'confusion_matrix', 'accuracy', 'precision', 'recall', 'sensitivity', 'specificity', 'f1_score', 'roc_auc']\n",
      "[0 1] [0 1]\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]\n",
      "[[ 7 16]\n",
      " [ 0 19]]\n",
      "[[19  0 16  7]\n",
      " [ 7 16  0 19]]\n",
      "[[26 16]\n",
      " [16 26]]\n",
      "Class-wise info: For multilevel internal scores fo label 0: \n",
      " Accuracy = 61.904761904761905\n",
      " Precision = [0.54285714 1.        ]\n",
      " Recall = [1.         0.30434783]\n",
      " F1 score = [0.7037037  0.46666667]\n",
      " AUC score = 65.21739130434783\n",
      " Support = [19 23]\n",
      "\n",
      "Class-wise info: For multilevel internal scores fo label 1: \n",
      " Accuracy = 61.904761904761905\n",
      " Precision = [1.         0.54285714]\n",
      " Recall = [0.30434783 1.        ]\n",
      " F1 score = [0.46666667 0.7037037 ]\n",
      " AUC score = 65.21739130434783\n",
      " Support = [23 19]\n",
      "\n",
      "CLASSIFICATION MERICS:\n",
      " _______________________________________________________\n",
      " Confusion Matrix: \n",
      "[[ 7 16]\n",
      " [ 0 19]]\n",
      " Accuracy (acc): 61.905\n",
      " Precision (prc): 54.286\n",
      " Recall (rec): 100.0\n",
      " Sensitivity (sns): 100.0\n",
      " Specificity (spc): 30.435\n",
      " F1 Score (f1s): 70.37\n",
      " ROC AUC (AUC): 0.652\n",
      "Score columns: (1, 12) ['method', 'model', 'model_parameters', 'model_scores', 'confusion_matrix', 'accuracy', 'precision', 'recall', 'sensitivity', 'specificity', 'f1_score', 'roc_auc']\n",
      "[0 1] [0 1]\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] [1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]\n",
      "[[ 7 16]\n",
      " [ 1 18]]\n",
      "[[18  1 16  7]\n",
      " [ 7 16  1 18]]\n",
      "[[25 17]\n",
      " [17 25]]\n",
      "Class-wise info: For multilevel internal scores fo label 0: \n",
      " Accuracy = 59.523809523809526\n",
      " Precision = [0.52941176 0.875     ]\n",
      " Recall = [0.94736842 0.30434783]\n",
      " F1 score = [0.67924528 0.4516129 ]\n",
      " AUC score = 62.58581235697941\n",
      " Support = [19 23]\n",
      "\n",
      "Class-wise info: For multilevel internal scores fo label 1: \n",
      " Accuracy = 59.523809523809526\n",
      " Precision = [0.875      0.52941176]\n",
      " Recall = [0.30434783 0.94736842]\n",
      " F1 score = [0.4516129  0.67924528]\n",
      " AUC score = 62.585812356979396\n",
      " Support = [23 19]\n",
      "\n",
      "CLASSIFICATION MERICS:\n",
      " _______________________________________________________\n",
      " Confusion Matrix: \n",
      "[[ 7 16]\n",
      " [ 1 18]]\n",
      " Accuracy (acc): 59.524\n",
      " Precision (prc): 52.941\n",
      " Recall (rec): 94.737\n",
      " Sensitivity (sns): 94.737\n",
      " Specificity (spc): 30.435\n",
      " F1 Score (f1s): 67.925\n",
      " ROC AUC (AUC): 0.626\n",
      "Score columns: (1, 12) ['method', 'model', 'model_parameters', 'model_scores', 'confusion_matrix', 'accuracy', 'precision', 'recall', 'sensitivity', 'specificity', 'f1_score', 'roc_auc']\n",
      "[0 1] [0 1]\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1]\n",
      "[[ 6 17]\n",
      " [ 0 19]]\n",
      "[[19  0 17  6]\n",
      " [ 6 17  0 19]]\n",
      "[[25 17]\n",
      " [17 25]]\n",
      "Class-wise info: For multilevel internal scores fo label 0: \n",
      " Accuracy = 59.523809523809526\n",
      " Precision = [0.52777778 1.        ]\n",
      " Recall = [1.         0.26086957]\n",
      " F1 score = [0.69090909 0.4137931 ]\n",
      " AUC score = 63.04347826086957\n",
      " Support = [19 23]\n",
      "\n",
      "Class-wise info: For multilevel internal scores fo label 1: \n",
      " Accuracy = 59.523809523809526\n",
      " Precision = [1.         0.52777778]\n",
      " Recall = [0.26086957 1.        ]\n",
      " F1 score = [0.4137931  0.69090909]\n",
      " AUC score = 63.04347826086957\n",
      " Support = [23 19]\n",
      "\n",
      "CLASSIFICATION MERICS:\n",
      " _______________________________________________________\n",
      " Confusion Matrix: \n",
      "[[ 6 17]\n",
      " [ 0 19]]\n",
      " Accuracy (acc): 59.524\n",
      " Precision (prc): 52.778\n",
      " Recall (rec): 100.0\n",
      " Sensitivity (sns): 100.0\n",
      " Specificity (spc): 26.087\n",
      " F1 Score (f1s): 69.091\n",
      " ROC AUC (AUC): 0.63\n",
      "Score columns: (1, 12) ['method', 'model', 'model_parameters', 'model_scores', 'confusion_matrix', 'accuracy', 'precision', 'recall', 'sensitivity', 'specificity', 'f1_score', 'roc_auc']\n",
      "[0 1] [0 1]\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]\n",
      "[[ 8 15]\n",
      " [ 0 19]]\n",
      "[[19  0 15  8]\n",
      " [ 8 15  0 19]]\n",
      "[[27 15]\n",
      " [15 27]]\n",
      "Class-wise info: For multilevel internal scores fo label 0: \n",
      " Accuracy = 64.28571428571429\n",
      " Precision = [0.55882353 1.        ]\n",
      " Recall = [1.         0.34782609]\n",
      " F1 score = [0.71698113 0.51612903]\n",
      " AUC score = 67.3913043478261\n",
      " Support = [19 23]\n",
      "\n",
      "Class-wise info: For multilevel internal scores fo label 1: \n",
      " Accuracy = 64.28571428571429\n",
      " Precision = [1.         0.55882353]\n",
      " Recall = [0.34782609 1.        ]\n",
      " F1 score = [0.51612903 0.71698113]\n",
      " AUC score = 67.3913043478261\n",
      " Support = [23 19]\n",
      "\n",
      "CLASSIFICATION MERICS:\n",
      " _______________________________________________________\n",
      " Confusion Matrix: \n",
      "[[ 8 15]\n",
      " [ 0 19]]\n",
      " Accuracy (acc): 64.286\n",
      " Precision (prc): 55.882\n",
      " Recall (rec): 100.0\n",
      " Sensitivity (sns): 100.0\n",
      " Specificity (spc): 34.783\n",
      " F1 Score (f1s): 71.698\n",
      " ROC AUC (AUC): 0.674\n",
      "Score columns: (1, 12) ['method', 'model', 'model_parameters', 'model_scores', 'confusion_matrix', 'accuracy', 'precision', 'recall', 'sensitivity', 'specificity', 'f1_score', 'roc_auc']\n",
      "[0 1] [0 1]\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]\n",
      "[[13 10]\n",
      " [ 0 19]]\n",
      "[[19  0 10 13]\n",
      " [13 10  0 19]]\n",
      "[[32 10]\n",
      " [10 32]]\n",
      "Class-wise info: For multilevel internal scores fo label 0: \n",
      " Accuracy = 76.19047619047619\n",
      " Precision = [0.65517241 1.        ]\n",
      " Recall = [1.         0.56521739]\n",
      " F1 score = [0.79166667 0.72222222]\n",
      " AUC score = 78.26086956521738\n",
      " Support = [19 23]\n",
      "\n",
      "Class-wise info: For multilevel internal scores fo label 1: \n",
      " Accuracy = 76.19047619047619\n",
      " Precision = [1.         0.65517241]\n",
      " Recall = [0.56521739 1.        ]\n",
      " F1 score = [0.72222222 0.79166667]\n",
      " AUC score = 78.26086956521739\n",
      " Support = [23 19]\n",
      "\n",
      "CLASSIFICATION MERICS:\n",
      " _______________________________________________________\n",
      " Confusion Matrix: \n",
      "[[13 10]\n",
      " [ 0 19]]\n",
      " Accuracy (acc): 76.19\n",
      " Precision (prc): 65.517\n",
      " Recall (rec): 100.0\n",
      " Sensitivity (sns): 100.0\n",
      " Specificity (spc): 56.522\n",
      " F1 Score (f1s): 79.167\n",
      " ROC AUC (AUC): 0.783\n",
      "Score columns: (1, 12) ['method', 'model', 'model_parameters', 'model_scores', 'confusion_matrix', 'accuracy', 'precision', 'recall', 'sensitivity', 'specificity', 'f1_score', 'roc_auc']\n",
      "[0 1] [0 1]\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]\n",
      "[[ 8 15]\n",
      " [ 0 19]]\n",
      "[[19  0 15  8]\n",
      " [ 8 15  0 19]]\n",
      "[[27 15]\n",
      " [15 27]]\n",
      "Class-wise info: For multilevel internal scores fo label 0: \n",
      " Accuracy = 64.28571428571429\n",
      " Precision = [0.55882353 1.        ]\n",
      " Recall = [1.         0.34782609]\n",
      " F1 score = [0.71698113 0.51612903]\n",
      " AUC score = 67.3913043478261\n",
      " Support = [19 23]\n",
      "\n",
      "Class-wise info: For multilevel internal scores fo label 1: \n",
      " Accuracy = 64.28571428571429\n",
      " Precision = [1.         0.55882353]\n",
      " Recall = [0.34782609 1.        ]\n",
      " F1 score = [0.51612903 0.71698113]\n",
      " AUC score = 67.3913043478261\n",
      " Support = [23 19]\n",
      "\n",
      "CLASSIFICATION MERICS:\n",
      " _______________________________________________________\n",
      " Confusion Matrix: \n",
      "[[ 8 15]\n",
      " [ 0 19]]\n",
      " Accuracy (acc): 64.286\n",
      " Precision (prc): 55.882\n",
      " Recall (rec): 100.0\n",
      " Sensitivity (sns): 100.0\n",
      " Specificity (spc): 34.783\n",
      " F1 Score (f1s): 71.698\n",
      " ROC AUC (AUC): 0.674\n",
      "Score columns: (1, 12) ['method', 'model', 'model_parameters', 'model_scores', 'confusion_matrix', 'accuracy', 'precision', 'recall', 'sensitivity', 'specificity', 'f1_score', 'roc_auc']\n",
      "\n",
      "            ===================================================================================================\n",
      "            TEST 1 END...\n",
      "            \n",
      "\n",
      "            ### MODEL TEST PHASE \n",
      "            TEST 2 START... XXXXX \n",
      "            ===================================================================================================\n",
      "            Test=> 42 ['narco5', 'nfle1', 'nfle2', 'nfle3', 'nfle4', 'nfle5', 'nfle6', 'nfle7', 'nfle8', 'nfle9', 'nfle10', 'nfle11', 'nfle12', 'nfle13', 'nfle14', 'nfle15', 'nfle16', 'nfle17', 'nfle18', 'SC4071', 'SC4081', 'SC4091', 'SC4101', 'SC4111', 'SC4121', 'SC4131', 'SC4141', 'SC4151', 'SC4161', 'SC4171', 'SC4181', 'SC4191', 'SC4201', 'SC4211', 'SC4221', 'SC4231', 'SC4241', 'SC4251', 'SC4261', 'SC4271', 'SC4281', 'SC4291'] \n",
      "            Training (Including Validation)=> 166 ['brux1', 'brux2', 'sdb1', 'sdb2', 'sdb3', 'sdb4', 'ins1', 'ins2', 'ins3', 'ins4', 'ins5', 'ins6', 'ins7', 'ins8', 'ins9', 'narco1', 'narco2', 'narco3', 'narco4', 'nfle19', 'nfle20', 'nfle21', 'nfle22', 'nfle23', 'nfle24', 'nfle25', 'nfle26', 'nfle27', 'nfle28', 'nfle29', 'nfle30', 'nfle31', 'nfle32', 'nfle33', 'nfle34', 'nfle35', 'nfle36', 'nfle37', 'nfle38', 'nfle39', 'nfle40', 'plm1', 'plm2', 'plm3', 'plm4', 'plm5', 'plm6', 'plm7', 'plm8', 'plm9', 'plm10', 'rbd1', 'rbd2', 'rbd3', 'rbd4', 'rbd5', 'rbd6', 'rbd7', 'rbd8', 'rbd9', 'rbd10', 'rbd11', 'rbd12', 'rbd13', 'rbd14', 'rbd15', 'rbd16', 'rbd17', 'rbd18', 'rbd19', 'rbd20', 'rbd21', 'rbd22', 'n1', 'n2', 'n3', 'n4', 'n5', 'n6', 'n7', 'n8', 'n9', 'n10', 'n11', 'n12', 'n13', 'n14', 'n15', 'n16', 'SC4001', 'SC4011', 'SC4021', 'SC4031', 'SC4041', 'SC4051', 'SC4061', 'SC4301', 'SC4311', 'SC4321', 'SC4331', 'SC4341', 'SC4351', 'SC4362', 'SC4371', 'SC4381', 'SC4401', 'SC4411', 'SC4421', 'SC4431', 'SC4441', 'SC4451', 'SC4461', 'SC4471', 'SC4481', 'SC4491', 'SC4501', 'SC4511', 'SC4522', 'SC4531', 'SC4541', 'SC4551', 'SC4561', 'SC4571', 'SC4581', 'SC4591', 'SC4601', 'SC4611', 'SC4621', 'SC4631', 'SC4641', 'SC4651', 'SC4661', 'SC4671', 'SC4701', 'SC4711', 'SC4721', 'SC4731', 'SC4741', 'SC4751', 'SC4761', 'SC4771', 'SC4801', 'SC4811', 'SC4821', 'ST7011', 'ST7021', 'ST7041', 'ST7051', 'ST7061', 'ST7071', 'ST7081', 'ST7091', 'ST7101', 'ST7111', 'ST7121', 'ST7131', 'ST7141', 'ST7151', 'ST7161', 'ST7171', 'ST7181', 'ST7191', 'ST7201', 'ST7211', 'ST7221', 'ST7241'] \n",
      "            \n",
      "Random 20 percentage splitting testing...\n",
      "\n",
      "            *** MODEL TRAINING AND VALIDATION PHASE FOR TEST 2 \n",
      "            TRAINING 1 START... XXXXX \n",
      "            ***************************************************************************************************\n",
      "            Validation=> 20 ['plm4', 'ins6', 'SC4351', 'SC4311', 'SC4211', 'nfle23', 'rbd6', 'nfle29', 'n2', 'nfle25', 'SC4231', 'SC4121', 'nfle40', 'SC4491', 'ins5', 'rbd4', 'n14', 'nfle15', 'SC4561', 'nfle13'] \n",
      "            Training=> 146 ['nfle11', 'nfle6', 'SC4401', 'SC4581', 'SC4191', 'nfle31', 'SC4071', 'rbd19', 'SC4291', 'SC4141', 'nfle2', 'nfle32', 'SC4381', 'nfle21', 'rbd11', 'plm9', 'nfle27', 'sdb2', 'nfle33', 'nfle18', 'narco5', 'rbd16', 'SC4551', 'SC4281', 'rbd8', 'rbd13', 'SC4301', 'nfle9', 'n10', 'n12', 'n1', 'rbd10', 'SC4321', 'n13', 'rbd7', 'nfle35', 'SC4001', 'n5', 'nfle28', 'ins9', 'plm1', 'SC4091', 'rbd17', 'rbd15', 'nfle5', 'nfle26', 'SC4371', 'SC4571', 'SC4151', 'nfle24', 'n11', 'rbd2', 'SC4131', 'nfle8', 'SC4471', 'nfle12', 'SC4421', 'SC4261', 'SC4431', 'SC4441', 'plm6', 'ins4', 'nfle14', 'nfle36', 'ins8', 'n3', 'rbd21', 'SC4061', 'SC4461', 'n7', 'nfle1', 'n8', 'plm3', 'narco4', 'SC4331', 'SC4501', 'SC4101', 'SC4341', 'brux2', 'rbd20', 'nfle38', 'rbd3', 'rbd14', 'SC4511', 'SC4481', 'n16', 'nfle10', 'SC4201', 'SC4081', 'rbd5', 'SC4271', 'SC4041', 'nfle22', 'rbd12', 'narco3', 'sdb3', 'SC4181', 'nfle39', 'SC4411', 'n4', 'SC4051', 'rbd9', 'SC4522', 'n6', 'SC4011', 'nfle16', 'nfle4', 'plm5', 'nfle7', 'SC4541', 'SC4021', 'nfle19', 'SC4111', 'SC4241', 'sdb1', 'SC4161', 'rbd22', 'SC4251', 'rbd18', 'nfle20', 'plm8', 'n9', 'plm7', 'nfle17', 'SC4221', 'nfle3', 'ins3', 'n15', 'SC4362', 'narco1', 'plm2', 'ins7', 'nfle37', 'nfle30', 'ins1', 'narco2', 'sdb4', 'brux1', 'SC4171', 'SC4451', 'ins2', 'plm10', 'nfle34', 'SC4031', 'SC4531', 'rbd1'] \n",
      "            \n",
      "\n",
      "            *** ML MODEL FOR TEST:2, TRAINING:1 AND MODEL: LR \n",
      "            ---------------------------------------------------------------------------------------------------\n",
      "            \n",
      "Calling method: logistic_regression_parameters\n",
      "All parameters: ['penalty', 'solver', 'max_iter', 'C'], [['l2', 'elasticnet'], [50, 100, 130, 150, 170, 200], [0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1.0]], [0, 2, 3]\n",
      "Parameters:  {'penalty': ['l2', 'elasticnet'], 'max_iter': [50, 100, 130, 150, 170, 200], 'C': [0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1.0]}\n",
      "\n",
      "        From training? True, Data shape: (146, 38), Indices: [ 30  25 147 165 127  50 115  88 137 122  21  51 146  40  80  68  46   3\n",
      "  52  37  19  85 162 136  77  82 138  28 101 103  92  79 140 104  76  54\n",
      " 108  96  47  14  60 117  86  84  24  45 145 164 123  43 102  71 121  27\n",
      " 154  31 149 134 150 151  65   9  33  55  13  94  90 114 153  98  20  99\n",
      "  62  18 141 157 118 142   1  89  57  72  83 158 155 107  29 128 116  74\n",
      " 135 112  41  81  17   4 126  58 148  95 113  78 159  97 109  35  23  64\n",
      "  26 161 110  38 119 132   2 124  91 133  87  39  67 100  66  36 130  22\n",
      "   8 106 144  15  61  12  56  49   6  16   5   0 125 152   7  69  53 111\n",
      " 160  70]\n",
      "        All Columns: ['Dataset', 'Category', 'Subject_Name', 'Class', 'W->S1', 'W->S2', 'W->S3', 'W->S4', 'W->REM', 'S1->W', 'S1->S1', 'S1->S2', 'S1->S3', 'S1->S4', 'S1->REM', 'S2->W', 'S2->S1', 'S2->S2', 'S2->S3', 'S2->S4', 'S2->REM', 'S3->W', 'S3->S1', 'S3->S2', 'S3->S3', 'S3->S4', 'S3->REM', 'S4->W', 'S4->S1', 'S4->S2', 'S4->S3', 'S4->S4', 'S4->REM', 'REM->W', 'REM->S1', 'REM->S2', 'REM->S3', 'REM->REM']\n",
      "        \n",
      "\"\n",
      "            Selected features: ['W->S1', 'W->S2', 'W->S3', 'W->S4', 'W->REM', 'S1->W', 'S1->S1', 'S1->S2', 'S1->S3', 'S1->S4', 'S1->REM', 'S2->W', 'S2->S1', 'S2->S2', 'S2->S3', 'S2->S4', 'S2->REM', 'S3->W', 'S3->S1', 'S3->S2', 'S3->S3', 'S3->S4', 'S3->REM', 'S4->W', 'S4->S1', 'S4->S2', 'S4->S3', 'S4->S4', 'S4->REM', 'REM->W', 'REM->S1', 'REM->S2', 'REM->S3', 'REM->REM']\n",
      "            \n",
      "\n",
      "        Feature shape: (146, 34), Target shape: (146,), Metadata: (146, 3) \n",
      "        \n",
      "\n",
      "        GridSearch: LR - {'penalty': ['l2', 'elasticnet'], 'max_iter': [50, 100, 130, 150, 170, 200], 'C': [0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1.0]} \n",
      "        ---------------------------------------------------------------------------------------------------\n",
      "        \n",
      "Refitting the model with best parameter f1 == True\n",
      "Fitting 5 folds for each of 84 candidates, totalling 420 fits\n",
      "\n",
      "        From training? False, Data shape: (20, 38), Indices: [ 63  11 143 139 129  42  75  48  93  44 131 120  59 156  10  73 105  34\n",
      " 163  32]\n",
      "        All Columns: ['Dataset', 'Category', 'Subject_Name', 'Class', 'W->S1', 'W->S2', 'W->S3', 'W->S4', 'W->REM', 'S1->W', 'S1->S1', 'S1->S2', 'S1->S3', 'S1->S4', 'S1->REM', 'S2->W', 'S2->S1', 'S2->S2', 'S2->S3', 'S2->S4', 'S2->REM', 'S3->W', 'S3->S1', 'S3->S2', 'S3->S3', 'S3->S4', 'S3->REM', 'S4->W', 'S4->S1', 'S4->S2', 'S4->S3', 'S4->S4', 'S4->REM', 'REM->W', 'REM->S1', 'REM->S2', 'REM->S3', 'REM->REM']\n",
      "        \n",
      "\n",
      "        Feature shape: (20, 34), Target shape: (20,), Metadata: (20, 3) \n",
      "        \n",
      "[0 1] [0 1]\n",
      "[1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1] [1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1]\n",
      "[[ 7  2]\n",
      " [ 0 11]]\n",
      "[[11  0  2  7]\n",
      " [ 7  2  0 11]]\n",
      "[[18  2]\n",
      " [ 2 18]]\n",
      "Class-wise info: For multilevel internal scores fo label 0: \n",
      " Accuracy = 90.0\n",
      " Precision = [0.84615385 1.        ]\n",
      " Recall = [1.         0.77777778]\n",
      " F1 score = [0.91666667 0.875     ]\n",
      " AUC score = 88.88888888888889\n",
      " Support = [11  9]\n",
      "\n",
      "Class-wise info: For multilevel internal scores fo label 1: \n",
      " Accuracy = 90.0\n",
      " Precision = [1.         0.84615385]\n",
      " Recall = [0.77777778 1.        ]\n",
      " F1 score = [0.875      0.91666667]\n",
      " AUC score = 88.88888888888889\n",
      " Support = [ 9 11]\n",
      "\n",
      "CLASSIFICATION MERICS:\n",
      " _______________________________________________________\n",
      " Confusion Matrix: \n",
      "[[ 7  2]\n",
      " [ 0 11]]\n",
      " Accuracy (acc): 90.0\n",
      " Precision (prc): 84.615\n",
      " Recall (rec): 100.0\n",
      " Sensitivity (sns): 100.0\n",
      " Specificity (spc): 77.778\n",
      " F1 Score (f1s): 91.667\n",
      " ROC AUC (AUC): 0.889\n",
      "Score columns: (1, 12) ['method', 'model', 'model_parameters', 'model_scores', 'confusion_matrix', 'accuracy', 'precision', 'recall', 'sensitivity', 'specificity', 'f1_score', 'roc_auc']\n",
      "\n",
      "        Best model (GriveSearchCV): GridSearchCV(cv=5, estimator=LogisticRegression(), n_jobs=50,\n",
      "             param_grid={'C': [0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1.0],\n",
      "                         'max_iter': [50, 100, 130, 150, 170, 200],\n",
      "                         'penalty': ['l2', 'elasticnet']},\n",
      "             return_train_score=True, scoring='f1', verbose=2) \n",
      "        Best model: GridSearchCV(cv=5, estimator=LogisticRegression(), n_jobs=50,\n",
      "             param_grid={'C': [0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1.0],\n",
      "                         'max_iter': [50, 100, 130, 150, 170, 200],\n",
      "                         'penalty': ['l2', 'elasticnet']},\n",
      "             return_train_score=True, scoring='f1', verbose=2) \n",
      "        Best estimator of the model: LogisticRegression(max_iter=50) \n",
      "        Best parameters of the model: {'C': 1.0, 'max_iter': 50, 'penalty': 'l2'} \n",
      "        ---------------------------------------------------------------------------------------------------\n",
      "        \n",
      "\n",
      "            *** ML MODEL FOR TEST:2, TRAINING:1 AND MODEL: SVC \n",
      "            ---------------------------------------------------------------------------------------------------\n",
      "            \n",
      "Calling method: support_vector_classifier_parameters\n",
      "All parameters: ['probability', 'C', 'kernel', 'gamma', 'degree', 'class_weightdict'], [[True], [0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1.0], ['linear', 'rbf', 'poly']], [0, 1, 2]\n",
      "Parameters:  {'probability': [True], 'C': [0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1.0], 'kernel': ['linear', 'rbf', 'poly']}\n",
      "\n",
      "        From training? True, Data shape: (146, 38), Indices: [ 30  25 147 165 127  50 115  88 137 122  21  51 146  40  80  68  46   3\n",
      "  52  37  19  85 162 136  77  82 138  28 101 103  92  79 140 104  76  54\n",
      " 108  96  47  14  60 117  86  84  24  45 145 164 123  43 102  71 121  27\n",
      " 154  31 149 134 150 151  65   9  33  55  13  94  90 114 153  98  20  99\n",
      "  62  18 141 157 118 142   1  89  57  72  83 158 155 107  29 128 116  74\n",
      " 135 112  41  81  17   4 126  58 148  95 113  78 159  97 109  35  23  64\n",
      "  26 161 110  38 119 132   2 124  91 133  87  39  67 100  66  36 130  22\n",
      "   8 106 144  15  61  12  56  49   6  16   5   0 125 152   7  69  53 111\n",
      " 160  70]\n",
      "        All Columns: ['Dataset', 'Category', 'Subject_Name', 'Class', 'W->S1', 'W->S2', 'W->S3', 'W->S4', 'W->REM', 'S1->W', 'S1->S1', 'S1->S2', 'S1->S3', 'S1->S4', 'S1->REM', 'S2->W', 'S2->S1', 'S2->S2', 'S2->S3', 'S2->S4', 'S2->REM', 'S3->W', 'S3->S1', 'S3->S2', 'S3->S3', 'S3->S4', 'S3->REM', 'S4->W', 'S4->S1', 'S4->S2', 'S4->S3', 'S4->S4', 'S4->REM', 'REM->W', 'REM->S1', 'REM->S2', 'REM->S3', 'REM->REM']\n",
      "        \n",
      "\n",
      "        Feature shape: (146, 34), Target shape: (146,), Metadata: (146, 3) \n",
      "        \n",
      "\n",
      "        GridSearch: SVC - {'probability': [True], 'C': [0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1.0], 'kernel': ['linear', 'rbf', 'poly']} \n",
      "        ---------------------------------------------------------------------------------------------------\n",
      "        \n",
      "Refitting the model with best parameter f1 == True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aliem\\.conda\\envs\\MyPython37Work\\lib\\site-packages\\sklearn\\model_selection\\_search.py:921: UserWarning: One or more of the test scores are non-finite: [0.71356974        nan 0.71356974        nan 0.71356974        nan\n",
      " 0.71356974        nan 0.71356974        nan 0.71356974        nan\n",
      " 0.71356974        nan 0.71356974        nan 0.71356974        nan\n",
      " 0.71356974        nan 0.71356974        nan 0.71356974        nan\n",
      " 0.71356974        nan 0.71356974        nan 0.71356974        nan\n",
      " 0.71356974        nan 0.71356974        nan 0.71356974        nan\n",
      " 0.84462064        nan 0.84462064        nan 0.84462064        nan\n",
      " 0.84462064        nan 0.84462064        nan 0.84462064        nan\n",
      " 0.86374248        nan 0.86374248        nan 0.86374248        nan\n",
      " 0.86374248        nan 0.86374248        nan 0.86374248        nan\n",
      " 0.89258609        nan 0.89258609        nan 0.89258609        nan\n",
      " 0.89258609        nan 0.89258609        nan 0.89258609        nan\n",
      " 0.90909403        nan 0.90909403        nan 0.90909403        nan\n",
      " 0.90909403        nan 0.90909403        nan 0.90909403        nan]\n",
      "  category=UserWarning\n",
      "C:\\Users\\aliem\\.conda\\envs\\MyPython37Work\\lib\\site-packages\\sklearn\\model_selection\\_search.py:921: UserWarning: One or more of the train scores are non-finite: [0.71365079        nan 0.71365079        nan 0.71365079        nan\n",
      " 0.71365079        nan 0.71365079        nan 0.71365079        nan\n",
      " 0.71365079        nan 0.71365079        nan 0.71365079        nan\n",
      " 0.71365079        nan 0.71365079        nan 0.71365079        nan\n",
      " 0.72410808        nan 0.72410808        nan 0.72410808        nan\n",
      " 0.72410808        nan 0.72410808        nan 0.72410808        nan\n",
      " 0.84750111        nan 0.84750111        nan 0.84750111        nan\n",
      " 0.84750111        nan 0.84750111        nan 0.84750111        nan\n",
      " 0.8717572         nan 0.8717572         nan 0.8717572         nan\n",
      " 0.8717572         nan 0.8717572         nan 0.8717572         nan\n",
      " 0.89297535        nan 0.89297535        nan 0.89297535        nan\n",
      " 0.89297535        nan 0.89297535        nan 0.89297535        nan\n",
      " 0.90937444        nan 0.90937444        nan 0.90937444        nan\n",
      " 0.90937444        nan 0.90937444        nan 0.90937444        nan]\n",
      "  category=UserWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 21 candidates, totalling 105 fits\n",
      "\n",
      "        From training? False, Data shape: (20, 38), Indices: [ 63  11 143 139 129  42  75  48  93  44 131 120  59 156  10  73 105  34\n",
      " 163  32]\n",
      "        All Columns: ['Dataset', 'Category', 'Subject_Name', 'Class', 'W->S1', 'W->S2', 'W->S3', 'W->S4', 'W->REM', 'S1->W', 'S1->S1', 'S1->S2', 'S1->S3', 'S1->S4', 'S1->REM', 'S2->W', 'S2->S1', 'S2->S2', 'S2->S3', 'S2->S4', 'S2->REM', 'S3->W', 'S3->S1', 'S3->S2', 'S3->S3', 'S3->S4', 'S3->REM', 'S4->W', 'S4->S1', 'S4->S2', 'S4->S3', 'S4->S4', 'S4->REM', 'REM->W', 'REM->S1', 'REM->S2', 'REM->S3', 'REM->REM']\n",
      "        \n",
      "\n",
      "        Feature shape: (20, 34), Target shape: (20,), Metadata: (20, 3) \n",
      "        \n",
      "[0 1] [0 1]\n",
      "[1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1] [1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1]\n",
      "[[ 7  2]\n",
      " [ 0 11]]\n",
      "[[11  0  2  7]\n",
      " [ 7  2  0 11]]\n",
      "[[18  2]\n",
      " [ 2 18]]\n",
      "Class-wise info: For multilevel internal scores fo label 0: \n",
      " Accuracy = 90.0\n",
      " Precision = [0.84615385 1.        ]\n",
      " Recall = [1.         0.77777778]\n",
      " F1 score = [0.91666667 0.875     ]\n",
      " AUC score = 88.88888888888889\n",
      " Support = [11  9]\n",
      "\n",
      "Class-wise info: For multilevel internal scores fo label 1: \n",
      " Accuracy = 90.0\n",
      " Precision = [1.         0.84615385]\n",
      " Recall = [0.77777778 1.        ]\n",
      " F1 score = [0.875      0.91666667]\n",
      " AUC score = 88.88888888888889\n",
      " Support = [ 9 11]\n",
      "\n",
      "CLASSIFICATION MERICS:\n",
      " _______________________________________________________\n",
      " Confusion Matrix: \n",
      "[[ 7  2]\n",
      " [ 0 11]]\n",
      " Accuracy (acc): 90.0\n",
      " Precision (prc): 84.615\n",
      " Recall (rec): 100.0\n",
      " Sensitivity (sns): 100.0\n",
      " Specificity (spc): 77.778\n",
      " F1 Score (f1s): 91.667\n",
      " ROC AUC (AUC): 0.889\n",
      "Score columns: (1, 12) ['method', 'model', 'model_parameters', 'model_scores', 'confusion_matrix', 'accuracy', 'precision', 'recall', 'sensitivity', 'specificity', 'f1_score', 'roc_auc']\n",
      "\n",
      "        Best model (GriveSearchCV): GridSearchCV(cv=5, estimator=SVC(), n_jobs=50,\n",
      "             param_grid={'C': [0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1.0],\n",
      "                         'kernel': ['linear', 'rbf', 'poly'],\n",
      "                         'probability': [True]},\n",
      "             return_train_score=True, scoring='f1', verbose=2) \n",
      "        Best model: GridSearchCV(cv=5, estimator=SVC(), n_jobs=50,\n",
      "             param_grid={'C': [0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1.0],\n",
      "                         'kernel': ['linear', 'rbf', 'poly'],\n",
      "                         'probability': [True]},\n",
      "             return_train_score=True, scoring='f1', verbose=2) \n",
      "        Best estimator of the model: SVC(kernel='linear', probability=True) \n",
      "        Best parameters of the model: {'C': 1.0, 'kernel': 'linear', 'probability': True} \n",
      "        ---------------------------------------------------------------------------------------------------\n",
      "        \n",
      "\n",
      "            *** ML MODEL FOR TEST:2, TRAINING:1 AND MODEL: NB \n",
      "            ---------------------------------------------------------------------------------------------------\n",
      "            \n",
      "Calling method: naive_bayes_parameters\n",
      "All parameters: ['var_smoothing'], [[1.0, 0.005623413251903491, 3.1622776601683795e-05, 1.7782794100389227e-07, 1e-09]], [0]\n",
      "Parameters:  {'var_smoothing': [1.0, 0.005623413251903491, 3.1622776601683795e-05, 1.7782794100389227e-07, 1e-09]}\n",
      "\n",
      "        From training? True, Data shape: (146, 38), Indices: [ 30  25 147 165 127  50 115  88 137 122  21  51 146  40  80  68  46   3\n",
      "  52  37  19  85 162 136  77  82 138  28 101 103  92  79 140 104  76  54\n",
      " 108  96  47  14  60 117  86  84  24  45 145 164 123  43 102  71 121  27\n",
      " 154  31 149 134 150 151  65   9  33  55  13  94  90 114 153  98  20  99\n",
      "  62  18 141 157 118 142   1  89  57  72  83 158 155 107  29 128 116  74\n",
      " 135 112  41  81  17   4 126  58 148  95 113  78 159  97 109  35  23  64\n",
      "  26 161 110  38 119 132   2 124  91 133  87  39  67 100  66  36 130  22\n",
      "   8 106 144  15  61  12  56  49   6  16   5   0 125 152   7  69  53 111\n",
      " 160  70]\n",
      "        All Columns: ['Dataset', 'Category', 'Subject_Name', 'Class', 'W->S1', 'W->S2', 'W->S3', 'W->S4', 'W->REM', 'S1->W', 'S1->S1', 'S1->S2', 'S1->S3', 'S1->S4', 'S1->REM', 'S2->W', 'S2->S1', 'S2->S2', 'S2->S3', 'S2->S4', 'S2->REM', 'S3->W', 'S3->S1', 'S3->S2', 'S3->S3', 'S3->S4', 'S3->REM', 'S4->W', 'S4->S1', 'S4->S2', 'S4->S3', 'S4->S4', 'S4->REM', 'REM->W', 'REM->S1', 'REM->S2', 'REM->S3', 'REM->REM']\n",
      "        \n",
      "\n",
      "        Feature shape: (146, 34), Target shape: (146,), Metadata: (146, 3) \n",
      "        \n",
      "\n",
      "        GridSearch: NB - {'var_smoothing': [1.0, 0.005623413251903491, 3.1622776601683795e-05, 1.7782794100389227e-07, 1e-09]} \n",
      "        ---------------------------------------------------------------------------------------------------\n",
      "        \n",
      "Refitting the model with best parameter f1 == True\n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "\n",
      "        From training? False, Data shape: (20, 38), Indices: [ 63  11 143 139 129  42  75  48  93  44 131 120  59 156  10  73 105  34\n",
      " 163  32]\n",
      "        All Columns: ['Dataset', 'Category', 'Subject_Name', 'Class', 'W->S1', 'W->S2', 'W->S3', 'W->S4', 'W->REM', 'S1->W', 'S1->S1', 'S1->S2', 'S1->S3', 'S1->S4', 'S1->REM', 'S2->W', 'S2->S1', 'S2->S2', 'S2->S3', 'S2->S4', 'S2->REM', 'S3->W', 'S3->S1', 'S3->S2', 'S3->S3', 'S3->S4', 'S3->REM', 'S4->W', 'S4->S1', 'S4->S2', 'S4->S3', 'S4->S4', 'S4->REM', 'REM->W', 'REM->S1', 'REM->S2', 'REM->S3', 'REM->REM']\n",
      "        \n",
      "\n",
      "        Feature shape: (20, 34), Target shape: (20,), Metadata: (20, 3) \n",
      "        \n",
      "[0 1] [0 1]\n",
      "[1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1] [1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1]\n",
      "[[ 7  2]\n",
      " [ 0 11]]\n",
      "[[11  0  2  7]\n",
      " [ 7  2  0 11]]\n",
      "[[18  2]\n",
      " [ 2 18]]\n",
      "Class-wise info: For multilevel internal scores fo label 0: \n",
      " Accuracy = 90.0\n",
      " Precision = [0.84615385 1.        ]\n",
      " Recall = [1.         0.77777778]\n",
      " F1 score = [0.91666667 0.875     ]\n",
      " AUC score = 88.88888888888889\n",
      " Support = [11  9]\n",
      "\n",
      "Class-wise info: For multilevel internal scores fo label 1: \n",
      " Accuracy = 90.0\n",
      " Precision = [1.         0.84615385]\n",
      " Recall = [0.77777778 1.        ]\n",
      " F1 score = [0.875      0.91666667]\n",
      " AUC score = 88.88888888888889\n",
      " Support = [ 9 11]\n",
      "\n",
      "CLASSIFICATION MERICS:\n",
      " _______________________________________________________\n",
      " Confusion Matrix: \n",
      "[[ 7  2]\n",
      " [ 0 11]]\n",
      " Accuracy (acc): 90.0\n",
      " Precision (prc): 84.615\n",
      " Recall (rec): 100.0\n",
      " Sensitivity (sns): 100.0\n",
      " Specificity (spc): 77.778\n",
      " F1 Score (f1s): 91.667\n",
      " ROC AUC (AUC): 0.889\n",
      "Score columns: (1, 12) ['method', 'model', 'model_parameters', 'model_scores', 'confusion_matrix', 'accuracy', 'precision', 'recall', 'sensitivity', 'specificity', 'f1_score', 'roc_auc']\n",
      "\n",
      "        Best model (GriveSearchCV): GridSearchCV(cv=5, estimator=GaussianNB(), n_jobs=50,\n",
      "             param_grid={'var_smoothing': [1.0, 0.005623413251903491,\n",
      "                                           3.1622776601683795e-05,\n",
      "                                           1.7782794100389227e-07, 1e-09]},\n",
      "             return_train_score=True, scoring='f1', verbose=2) \n",
      "        Best model: GridSearchCV(cv=5, estimator=GaussianNB(), n_jobs=50,\n",
      "             param_grid={'var_smoothing': [1.0, 0.005623413251903491,\n",
      "                                           3.1622776601683795e-05,\n",
      "                                           1.7782794100389227e-07, 1e-09]},\n",
      "             return_train_score=True, scoring='f1', verbose=2) \n",
      "        Best estimator of the model: GaussianNB(var_smoothing=0.005623413251903491) \n",
      "        Best parameters of the model: {'var_smoothing': 0.005623413251903491} \n",
      "        ---------------------------------------------------------------------------------------------------\n",
      "        \n",
      "\n",
      "            *** ML MODEL FOR TEST:2, TRAINING:1 AND MODEL: KNN \n",
      "            ---------------------------------------------------------------------------------------------------\n",
      "            \n",
      "Calling method: k_nearest_neighbors_parameters\n",
      "All parameters: ['n_neighbors', 'p', 'metric', 'n_splits'], [[2, 3, 5, 10, 15, 25, 35], ['manhattan', 'minkowski', 'euclidean']], [0, 2]\n",
      "Parameters:  {'n_neighbors': [2, 3, 5, 10, 15, 25, 35], 'metric': ['manhattan', 'minkowski', 'euclidean']}\n",
      "\n",
      "        From training? True, Data shape: (146, 38), Indices: [ 30  25 147 165 127  50 115  88 137 122  21  51 146  40  80  68  46   3\n",
      "  52  37  19  85 162 136  77  82 138  28 101 103  92  79 140 104  76  54\n",
      " 108  96  47  14  60 117  86  84  24  45 145 164 123  43 102  71 121  27\n",
      " 154  31 149 134 150 151  65   9  33  55  13  94  90 114 153  98  20  99\n",
      "  62  18 141 157 118 142   1  89  57  72  83 158 155 107  29 128 116  74\n",
      " 135 112  41  81  17   4 126  58 148  95 113  78 159  97 109  35  23  64\n",
      "  26 161 110  38 119 132   2 124  91 133  87  39  67 100  66  36 130  22\n",
      "   8 106 144  15  61  12  56  49   6  16   5   0 125 152   7  69  53 111\n",
      " 160  70]\n",
      "        All Columns: ['Dataset', 'Category', 'Subject_Name', 'Class', 'W->S1', 'W->S2', 'W->S3', 'W->S4', 'W->REM', 'S1->W', 'S1->S1', 'S1->S2', 'S1->S3', 'S1->S4', 'S1->REM', 'S2->W', 'S2->S1', 'S2->S2', 'S2->S3', 'S2->S4', 'S2->REM', 'S3->W', 'S3->S1', 'S3->S2', 'S3->S3', 'S3->S4', 'S3->REM', 'S4->W', 'S4->S1', 'S4->S2', 'S4->S3', 'S4->S4', 'S4->REM', 'REM->W', 'REM->S1', 'REM->S2', 'REM->S3', 'REM->REM']\n",
      "        \n",
      "\n",
      "        Feature shape: (146, 34), Target shape: (146,), Metadata: (146, 3) \n",
      "        \n",
      "\n",
      "        GridSearch: KNN - {'n_neighbors': [2, 3, 5, 10, 15, 25, 35], 'metric': ['manhattan', 'minkowski', 'euclidean']} \n",
      "        ---------------------------------------------------------------------------------------------------\n",
      "        \n",
      "Refitting the model with best parameter f1 == True\n",
      "Fitting 5 folds for each of 21 candidates, totalling 105 fits\n",
      "\n",
      "        From training? False, Data shape: (20, 38), Indices: [ 63  11 143 139 129  42  75  48  93  44 131 120  59 156  10  73 105  34\n",
      " 163  32]\n",
      "        All Columns: ['Dataset', 'Category', 'Subject_Name', 'Class', 'W->S1', 'W->S2', 'W->S3', 'W->S4', 'W->REM', 'S1->W', 'S1->S1', 'S1->S2', 'S1->S3', 'S1->S4', 'S1->REM', 'S2->W', 'S2->S1', 'S2->S2', 'S2->S3', 'S2->S4', 'S2->REM', 'S3->W', 'S3->S1', 'S3->S2', 'S3->S3', 'S3->S4', 'S3->REM', 'S4->W', 'S4->S1', 'S4->S2', 'S4->S3', 'S4->S4', 'S4->REM', 'REM->W', 'REM->S1', 'REM->S2', 'REM->S3', 'REM->REM']\n",
      "        \n",
      "\n",
      "        Feature shape: (20, 34), Target shape: (20,), Metadata: (20, 3) \n",
      "        \n",
      "[0 1] [0 1]\n",
      "[1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1] [1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1]\n",
      "[[ 7  2]\n",
      " [ 0 11]]\n",
      "[[11  0  2  7]\n",
      " [ 7  2  0 11]]\n",
      "[[18  2]\n",
      " [ 2 18]]\n",
      "Class-wise info: For multilevel internal scores fo label 0: \n",
      " Accuracy = 90.0\n",
      " Precision = [0.84615385 1.        ]\n",
      " Recall = [1.         0.77777778]\n",
      " F1 score = [0.91666667 0.875     ]\n",
      " AUC score = 88.88888888888889\n",
      " Support = [11  9]\n",
      "\n",
      "Class-wise info: For multilevel internal scores fo label 1: \n",
      " Accuracy = 90.0\n",
      " Precision = [1.         0.84615385]\n",
      " Recall = [0.77777778 1.        ]\n",
      " F1 score = [0.875      0.91666667]\n",
      " AUC score = 88.88888888888889\n",
      " Support = [ 9 11]\n",
      "\n",
      "CLASSIFICATION MERICS:\n",
      " _______________________________________________________\n",
      " Confusion Matrix: \n",
      "[[ 7  2]\n",
      " [ 0 11]]\n",
      " Accuracy (acc): 90.0\n",
      " Precision (prc): 84.615\n",
      " Recall (rec): 100.0\n",
      " Sensitivity (sns): 100.0\n",
      " Specificity (spc): 77.778\n",
      " F1 Score (f1s): 91.667\n",
      " ROC AUC (AUC): 0.889\n",
      "Score columns: (1, 12) ['method', 'model', 'model_parameters', 'model_scores', 'confusion_matrix', 'accuracy', 'precision', 'recall', 'sensitivity', 'specificity', 'f1_score', 'roc_auc']\n",
      "\n",
      "        Best model (GriveSearchCV): GridSearchCV(cv=5, estimator=KNeighborsClassifier(), n_jobs=50,\n",
      "             param_grid={'metric': ['manhattan', 'minkowski', 'euclidean'],\n",
      "                         'n_neighbors': [2, 3, 5, 10, 15, 25, 35]},\n",
      "             return_train_score=True, scoring='f1', verbose=2) \n",
      "        Best model: GridSearchCV(cv=5, estimator=KNeighborsClassifier(), n_jobs=50,\n",
      "             param_grid={'metric': ['manhattan', 'minkowski', 'euclidean'],\n",
      "                         'n_neighbors': [2, 3, 5, 10, 15, 25, 35]},\n",
      "             return_train_score=True, scoring='f1', verbose=2) \n",
      "        Best estimator of the model: KNeighborsClassifier(metric='manhattan', n_neighbors=15) \n",
      "        Best parameters of the model: {'metric': 'manhattan', 'n_neighbors': 15} \n",
      "        ---------------------------------------------------------------------------------------------------\n",
      "        \n",
      "\n",
      "            *** ML MODEL FOR TEST:2, TRAINING:1 AND MODEL: DT \n",
      "            ---------------------------------------------------------------------------------------------------\n",
      "            \n",
      "Calling method: decision_tree_parameters\n",
      "All parameters: ['max_depth', 'criterion', 'splitter', 'min_samples_split', 'min_samples_leaf', 'max_leaf_nodes'], [[2, 3, 5, 7, 10, 15, 20, 25, 30], ['gini', 'entropy', 'log_loss']], [0, 1]\n",
      "Parameters:  {'max_depth': [2, 3, 5, 7, 10, 15, 20, 25, 30], 'criterion': ['gini', 'entropy', 'log_loss']}\n",
      "\n",
      "        From training? True, Data shape: (146, 38), Indices: [ 30  25 147 165 127  50 115  88 137 122  21  51 146  40  80  68  46   3\n",
      "  52  37  19  85 162 136  77  82 138  28 101 103  92  79 140 104  76  54\n",
      " 108  96  47  14  60 117  86  84  24  45 145 164 123  43 102  71 121  27\n",
      " 154  31 149 134 150 151  65   9  33  55  13  94  90 114 153  98  20  99\n",
      "  62  18 141 157 118 142   1  89  57  72  83 158 155 107  29 128 116  74\n",
      " 135 112  41  81  17   4 126  58 148  95 113  78 159  97 109  35  23  64\n",
      "  26 161 110  38 119 132   2 124  91 133  87  39  67 100  66  36 130  22\n",
      "   8 106 144  15  61  12  56  49   6  16   5   0 125 152   7  69  53 111\n",
      " 160  70]\n",
      "        All Columns: ['Dataset', 'Category', 'Subject_Name', 'Class', 'W->S1', 'W->S2', 'W->S3', 'W->S4', 'W->REM', 'S1->W', 'S1->S1', 'S1->S2', 'S1->S3', 'S1->S4', 'S1->REM', 'S2->W', 'S2->S1', 'S2->S2', 'S2->S3', 'S2->S4', 'S2->REM', 'S3->W', 'S3->S1', 'S3->S2', 'S3->S3', 'S3->S4', 'S3->REM', 'S4->W', 'S4->S1', 'S4->S2', 'S4->S3', 'S4->S4', 'S4->REM', 'REM->W', 'REM->S1', 'REM->S2', 'REM->S3', 'REM->REM']\n",
      "        \n",
      "\n",
      "        Feature shape: (146, 34), Target shape: (146,), Metadata: (146, 3) \n",
      "        \n",
      "\n",
      "        GridSearch: DT - {'max_depth': [2, 3, 5, 7, 10, 15, 20, 25, 30], 'criterion': ['gini', 'entropy', 'log_loss']} \n",
      "        ---------------------------------------------------------------------------------------------------\n",
      "        \n",
      "Refitting the model with best parameter f1 == True\n",
      "Fitting 5 folds for each of 27 candidates, totalling 135 fits\n",
      "\n",
      "        From training? False, Data shape: (20, 38), Indices: [ 63  11 143 139 129  42  75  48  93  44 131 120  59 156  10  73 105  34\n",
      " 163  32]\n",
      "        All Columns: ['Dataset', 'Category', 'Subject_Name', 'Class', 'W->S1', 'W->S2', 'W->S3', 'W->S4', 'W->REM', 'S1->W', 'S1->S1', 'S1->S2', 'S1->S3', 'S1->S4', 'S1->REM', 'S2->W', 'S2->S1', 'S2->S2', 'S2->S3', 'S2->S4', 'S2->REM', 'S3->W', 'S3->S1', 'S3->S2', 'S3->S3', 'S3->S4', 'S3->REM', 'S4->W', 'S4->S1', 'S4->S2', 'S4->S3', 'S4->S4', 'S4->REM', 'REM->W', 'REM->S1', 'REM->S2', 'REM->S3', 'REM->REM']\n",
      "        \n",
      "\n",
      "        Feature shape: (20, 34), Target shape: (20,), Metadata: (20, 3) \n",
      "        \n",
      "[0 1] [0 1]\n",
      "[1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1] [1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1]\n",
      "[[ 7  2]\n",
      " [ 0 11]]\n",
      "[[11  0  2  7]\n",
      " [ 7  2  0 11]]\n",
      "[[18  2]\n",
      " [ 2 18]]\n",
      "Class-wise info: For multilevel internal scores fo label 0: \n",
      " Accuracy = 90.0\n",
      " Precision = [0.84615385 1.        ]\n",
      " Recall = [1.         0.77777778]\n",
      " F1 score = [0.91666667 0.875     ]\n",
      " AUC score = 88.88888888888889\n",
      " Support = [11  9]\n",
      "\n",
      "Class-wise info: For multilevel internal scores fo label 1: \n",
      " Accuracy = 90.0\n",
      " Precision = [1.         0.84615385]\n",
      " Recall = [0.77777778 1.        ]\n",
      " F1 score = [0.875      0.91666667]\n",
      " AUC score = 88.88888888888889\n",
      " Support = [ 9 11]\n",
      "\n",
      "CLASSIFICATION MERICS:\n",
      " _______________________________________________________\n",
      " Confusion Matrix: \n",
      "[[ 7  2]\n",
      " [ 0 11]]\n",
      " Accuracy (acc): 90.0\n",
      " Precision (prc): 84.615\n",
      " Recall (rec): 100.0\n",
      " Sensitivity (sns): 100.0\n",
      " Specificity (spc): 77.778\n",
      " F1 Score (f1s): 91.667\n",
      " ROC AUC (AUC): 0.889\n",
      "Score columns: (1, 12) ['method', 'model', 'model_parameters', 'model_scores', 'confusion_matrix', 'accuracy', 'precision', 'recall', 'sensitivity', 'specificity', 'f1_score', 'roc_auc']\n",
      "\n",
      "        Best model (GriveSearchCV): GridSearchCV(cv=5, estimator=DecisionTreeClassifier(), n_jobs=50,\n",
      "             param_grid={'criterion': ['gini', 'entropy', 'log_loss'],\n",
      "                         'max_depth': [2, 3, 5, 7, 10, 15, 20, 25, 30]},\n",
      "             return_train_score=True, scoring='f1', verbose=2) \n",
      "        Best model: GridSearchCV(cv=5, estimator=DecisionTreeClassifier(), n_jobs=50,\n",
      "             param_grid={'criterion': ['gini', 'entropy', 'log_loss'],\n",
      "                         'max_depth': [2, 3, 5, 7, 10, 15, 20, 25, 30]},\n",
      "             return_train_score=True, scoring='f1', verbose=2) \n",
      "        Best estimator of the model: DecisionTreeClassifier(max_depth=2) \n",
      "        Best parameters of the model: {'criterion': 'gini', 'max_depth': 2} \n",
      "        ---------------------------------------------------------------------------------------------------\n",
      "        \n",
      "\n",
      "            *** ML MODEL FOR TEST:2, TRAINING:1 AND MODEL: RF \n",
      "            ---------------------------------------------------------------------------------------------------\n",
      "            \n",
      "Calling method: random_forest_parameters\n",
      "All parameters: ['n_estimators', 'max_depth', 'criterion', 'splitter', 'max_features', 'min_samples_split', 'min_samples_leaf', 'max_leaf_nodes'], [[3, 5, 10, 15, 21, 30, 50, 75, 100], [2, 3, 5, 7, 10, 15, 20, 25, 30], ['gini', 'entropy', 'log_loss']], [0, 1, 2]\n",
      "Parameters:  {'n_estimators': [3, 5, 10, 15, 21, 30, 50, 75, 100], 'max_depth': [2, 3, 5, 7, 10, 15, 20, 25, 30], 'criterion': ['gini', 'entropy', 'log_loss']}\n",
      "\n",
      "        From training? True, Data shape: (146, 38), Indices: [ 30  25 147 165 127  50 115  88 137 122  21  51 146  40  80  68  46   3\n",
      "  52  37  19  85 162 136  77  82 138  28 101 103  92  79 140 104  76  54\n",
      " 108  96  47  14  60 117  86  84  24  45 145 164 123  43 102  71 121  27\n",
      " 154  31 149 134 150 151  65   9  33  55  13  94  90 114 153  98  20  99\n",
      "  62  18 141 157 118 142   1  89  57  72  83 158 155 107  29 128 116  74\n",
      " 135 112  41  81  17   4 126  58 148  95 113  78 159  97 109  35  23  64\n",
      "  26 161 110  38 119 132   2 124  91 133  87  39  67 100  66  36 130  22\n",
      "   8 106 144  15  61  12  56  49   6  16   5   0 125 152   7  69  53 111\n",
      " 160  70]\n",
      "        All Columns: ['Dataset', 'Category', 'Subject_Name', 'Class', 'W->S1', 'W->S2', 'W->S3', 'W->S4', 'W->REM', 'S1->W', 'S1->S1', 'S1->S2', 'S1->S3', 'S1->S4', 'S1->REM', 'S2->W', 'S2->S1', 'S2->S2', 'S2->S3', 'S2->S4', 'S2->REM', 'S3->W', 'S3->S1', 'S3->S2', 'S3->S3', 'S3->S4', 'S3->REM', 'S4->W', 'S4->S1', 'S4->S2', 'S4->S3', 'S4->S4', 'S4->REM', 'REM->W', 'REM->S1', 'REM->S2', 'REM->S3', 'REM->REM']\n",
      "        \n",
      "\n",
      "        Feature shape: (146, 34), Target shape: (146,), Metadata: (146, 3) \n",
      "        \n"
     ]
    }
   ],
   "source": [
    "### Set the classifier parameters in the \"HumachLab_ML_CLassifiers\" class file to run with the parameter \n",
    "# best_tr_model, tr_model, tr_model_scores_df, tr_target_and_prediction_df, ts_model, ts_model_scores_df, ts_target_and_prediction_df, ts_fold_info_df, exp_info_df\n",
    "best_tr_model, tr_model, tr_model_scores_df, tr_target_and_prediction_df, ts_model, ts_model_scores_df, ts_target_and_prediction_df, ts_fold_info_df, exp_info_df = classifier_obj.classify(\n",
    "    should_use_params=should_use_params, splitting_crieteria=splitting_crieteria, model_list=model_list, is_validate_models=is_validate_models, \n",
    "    result_save_path=result_save_path, exp_name=exp_name, exp_detail=exp_detail, apply_feature_selection=apply_feature_selection, custom_splitter=custom_splitter) \n",
    "\n",
    "stop_logger(logger) \n",
    "\n",
    "exp_sum_df = modify_experiment_information_summarry(result_directory, dict_dat=exp_detail) \n",
    "exp_sum_df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "latter-rhythm",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LogisticRegression?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "patient-break",
   "metadata": {},
   "outputs": [],
   "source": [
    "# best_tr_model, tr_model, tr_model_scores_df, tr_target_and_prediction_df, ts_model, ts_model_scores_df, ts_target_and_prediction_df, ts_fold_info_df, exp_info_df\n",
    "# all_best_tr_model, all_tr_model, all_tr_scores_df, all_tr_prediction_df, all_ts_model, all_ts_scores_df, all_ts_prediction_df, all_ts_fold_info_df, all_exp_info_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "portuguese-wheel",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ts_model \n",
    "# best_tr_model\n",
    "# tr_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "extended-wound",
   "metadata": {},
   "outputs": [],
   "source": [
    "print( len(ts_fold_info_df[:1]['Test'].values[0]), ts_fold_info_df[:1]['Test'].values[0] ) \n",
    "print( len(ts_fold_info_df[:1]['Validation'].values[0]), ts_fold_info_df[:1]['Validation'].values[0] ) \n",
    "print( len(ts_fold_info_df[:1]['Training'].values[0]), ts_fold_info_df[:1]['Training'].values[0] ) \n",
    "21+20+167 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "limiting-relaxation",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_info_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "suffering-wallace",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_fold_info_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "supported-magnitude",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "id": "iraqi-bulgaria",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Test_No</th>\n",
       "      <th>Model_No</th>\n",
       "      <th>method</th>\n",
       "      <th>model</th>\n",
       "      <th>model_parameters</th>\n",
       "      <th>model_scores</th>\n",
       "      <th>confusion_matrix</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>sensitivity</th>\n",
       "      <th>specificity</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>roc_auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>GridSearchCV(cv=5, estimator=LogisticRegressio...</td>\n",
       "      <td>LogisticRegression(max_iter=50)</td>\n",
       "      <td>{'C': 1.0, 'max_iter': 50, 'penalty': 'l2'}</td>\n",
       "      <td>89.65</td>\n",
       "      <td>[[19, 5], [1, 18]]</td>\n",
       "      <td>86.047</td>\n",
       "      <td>78.261</td>\n",
       "      <td>94.737</td>\n",
       "      <td>94.737</td>\n",
       "      <td>79.167</td>\n",
       "      <td>85.714</td>\n",
       "      <td>0.870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>GridSearchCV(cv=5, estimator=LogisticRegressio...</td>\n",
       "      <td>LogisticRegression(max_iter=50)</td>\n",
       "      <td>{'C': 1.0, 'max_iter': 50, 'penalty': 'l2'}</td>\n",
       "      <td>90.91</td>\n",
       "      <td>[[20, 3], [0, 19]]</td>\n",
       "      <td>92.857</td>\n",
       "      <td>86.364</td>\n",
       "      <td>100.000</td>\n",
       "      <td>100.000</td>\n",
       "      <td>86.957</td>\n",
       "      <td>92.683</td>\n",
       "      <td>0.935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>GridSearchCV(cv=5, estimator=LogisticRegressio...</td>\n",
       "      <td>LogisticRegression(max_iter=50)</td>\n",
       "      <td>{'C': 1.0, 'max_iter': 50, 'penalty': 'l2'}</td>\n",
       "      <td>90.28</td>\n",
       "      <td>[[20, 3], [0, 18]]</td>\n",
       "      <td>92.683</td>\n",
       "      <td>85.714</td>\n",
       "      <td>100.000</td>\n",
       "      <td>100.000</td>\n",
       "      <td>86.957</td>\n",
       "      <td>92.308</td>\n",
       "      <td>0.935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>GridSearchCV(cv=5, estimator=LogisticRegressio...</td>\n",
       "      <td>LogisticRegression(max_iter=50)</td>\n",
       "      <td>{'C': 1.0, 'max_iter': 50, 'penalty': 'l2'}</td>\n",
       "      <td>90.28</td>\n",
       "      <td>[[20, 3], [0, 18]]</td>\n",
       "      <td>92.683</td>\n",
       "      <td>85.714</td>\n",
       "      <td>100.000</td>\n",
       "      <td>100.000</td>\n",
       "      <td>86.957</td>\n",
       "      <td>92.308</td>\n",
       "      <td>0.935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>GridSearchCV(cv=5, estimator=LogisticRegressio...</td>\n",
       "      <td>LogisticRegression(max_iter=50)</td>\n",
       "      <td>{'C': 1.0, 'max_iter': 50, 'penalty': 'l2'}</td>\n",
       "      <td>90.28</td>\n",
       "      <td>[[18, 5], [0, 18]]</td>\n",
       "      <td>87.805</td>\n",
       "      <td>78.261</td>\n",
       "      <td>100.000</td>\n",
       "      <td>100.000</td>\n",
       "      <td>78.261</td>\n",
       "      <td>87.805</td>\n",
       "      <td>0.891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>GridSearchCV(cv=5, estimator=SVC(), n_jobs=50,...</td>\n",
       "      <td>SVC(kernel='linear', probability=True)</td>\n",
       "      <td>{'C': 1.0, 'kernel': 'linear', 'probability': ...</td>\n",
       "      <td>91.61</td>\n",
       "      <td>[[20, 4], [0, 19]]</td>\n",
       "      <td>90.698</td>\n",
       "      <td>82.609</td>\n",
       "      <td>100.000</td>\n",
       "      <td>100.000</td>\n",
       "      <td>83.333</td>\n",
       "      <td>90.476</td>\n",
       "      <td>0.917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>GridSearchCV(cv=5, estimator=SVC(), n_jobs=50,...</td>\n",
       "      <td>SVC(kernel='linear', probability=True)</td>\n",
       "      <td>{'C': 1.0, 'kernel': 'linear', 'probability': ...</td>\n",
       "      <td>92.06</td>\n",
       "      <td>[[20, 3], [0, 19]]</td>\n",
       "      <td>92.857</td>\n",
       "      <td>86.364</td>\n",
       "      <td>100.000</td>\n",
       "      <td>100.000</td>\n",
       "      <td>86.957</td>\n",
       "      <td>92.683</td>\n",
       "      <td>0.935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>GridSearchCV(cv=5, estimator=SVC(), n_jobs=50,...</td>\n",
       "      <td>SVC(kernel='linear', probability=True)</td>\n",
       "      <td>{'C': 1.0, 'kernel': 'linear', 'probability': ...</td>\n",
       "      <td>92.06</td>\n",
       "      <td>[[19, 4], [0, 18]]</td>\n",
       "      <td>90.244</td>\n",
       "      <td>81.818</td>\n",
       "      <td>100.000</td>\n",
       "      <td>100.000</td>\n",
       "      <td>82.609</td>\n",
       "      <td>90.000</td>\n",
       "      <td>0.913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>GridSearchCV(cv=5, estimator=SVC(), n_jobs=50,...</td>\n",
       "      <td>SVC(kernel='linear', probability=True)</td>\n",
       "      <td>{'C': 1.0, 'kernel': 'linear', 'probability': ...</td>\n",
       "      <td>92.06</td>\n",
       "      <td>[[20, 3], [0, 18]]</td>\n",
       "      <td>92.683</td>\n",
       "      <td>85.714</td>\n",
       "      <td>100.000</td>\n",
       "      <td>100.000</td>\n",
       "      <td>86.957</td>\n",
       "      <td>92.308</td>\n",
       "      <td>0.935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>GridSearchCV(cv=5, estimator=SVC(), n_jobs=50,...</td>\n",
       "      <td>SVC(kernel='linear', probability=True)</td>\n",
       "      <td>{'C': 1.0, 'kernel': 'linear', 'probability': ...</td>\n",
       "      <td>92.06</td>\n",
       "      <td>[[19, 4], [0, 18]]</td>\n",
       "      <td>90.244</td>\n",
       "      <td>81.818</td>\n",
       "      <td>100.000</td>\n",
       "      <td>100.000</td>\n",
       "      <td>82.609</td>\n",
       "      <td>90.000</td>\n",
       "      <td>0.913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>GridSearchCV(cv=5, estimator=GaussianNB(), n_j...</td>\n",
       "      <td>GaussianNB(var_smoothing=0.005623413251903491)</td>\n",
       "      <td>{'var_smoothing': 0.005623413251903491}</td>\n",
       "      <td>90.15</td>\n",
       "      <td>[[20, 4], [1, 18]]</td>\n",
       "      <td>88.372</td>\n",
       "      <td>81.818</td>\n",
       "      <td>94.737</td>\n",
       "      <td>94.737</td>\n",
       "      <td>83.333</td>\n",
       "      <td>87.805</td>\n",
       "      <td>0.890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>GridSearchCV(cv=5, estimator=GaussianNB(), n_j...</td>\n",
       "      <td>GaussianNB(var_smoothing=0.005623413251903491)</td>\n",
       "      <td>{'var_smoothing': 0.005623413251903491}</td>\n",
       "      <td>90.74</td>\n",
       "      <td>[[20, 3], [0, 19]]</td>\n",
       "      <td>92.857</td>\n",
       "      <td>86.364</td>\n",
       "      <td>100.000</td>\n",
       "      <td>100.000</td>\n",
       "      <td>86.957</td>\n",
       "      <td>92.683</td>\n",
       "      <td>0.935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>GridSearchCV(cv=5, estimator=GaussianNB(), n_j...</td>\n",
       "      <td>GaussianNB(var_smoothing=0.005623413251903491)</td>\n",
       "      <td>{'var_smoothing': 0.005623413251903491}</td>\n",
       "      <td>90.18</td>\n",
       "      <td>[[20, 3], [0, 18]]</td>\n",
       "      <td>92.683</td>\n",
       "      <td>85.714</td>\n",
       "      <td>100.000</td>\n",
       "      <td>100.000</td>\n",
       "      <td>86.957</td>\n",
       "      <td>92.308</td>\n",
       "      <td>0.935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>GridSearchCV(cv=5, estimator=GaussianNB(), n_j...</td>\n",
       "      <td>GaussianNB(var_smoothing=0.005623413251903491)</td>\n",
       "      <td>{'var_smoothing': 0.005623413251903491}</td>\n",
       "      <td>90.18</td>\n",
       "      <td>[[20, 3], [0, 18]]</td>\n",
       "      <td>92.683</td>\n",
       "      <td>85.714</td>\n",
       "      <td>100.000</td>\n",
       "      <td>100.000</td>\n",
       "      <td>86.957</td>\n",
       "      <td>92.308</td>\n",
       "      <td>0.935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>GridSearchCV(cv=5, estimator=GaussianNB(), n_j...</td>\n",
       "      <td>GaussianNB(var_smoothing=0.005623413251903491)</td>\n",
       "      <td>{'var_smoothing': 0.005623413251903491}</td>\n",
       "      <td>90.18</td>\n",
       "      <td>[[20, 3], [0, 18]]</td>\n",
       "      <td>92.683</td>\n",
       "      <td>85.714</td>\n",
       "      <td>100.000</td>\n",
       "      <td>100.000</td>\n",
       "      <td>86.957</td>\n",
       "      <td>92.308</td>\n",
       "      <td>0.935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>GridSearchCV(cv=5, estimator=KNeighborsClassif...</td>\n",
       "      <td>KNeighborsClassifier(metric='manhattan', n_nei...</td>\n",
       "      <td>{'metric': 'manhattan', 'n_neighbors': 15}</td>\n",
       "      <td>91.12</td>\n",
       "      <td>[[19, 5], [0, 19]]</td>\n",
       "      <td>88.372</td>\n",
       "      <td>79.167</td>\n",
       "      <td>100.000</td>\n",
       "      <td>100.000</td>\n",
       "      <td>79.167</td>\n",
       "      <td>88.372</td>\n",
       "      <td>0.896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>GridSearchCV(cv=5, estimator=KNeighborsClassif...</td>\n",
       "      <td>KNeighborsClassifier(metric='manhattan', n_nei...</td>\n",
       "      <td>{'metric': 'manhattan', 'n_neighbors': 15}</td>\n",
       "      <td>91.04</td>\n",
       "      <td>[[20, 3], [0, 19]]</td>\n",
       "      <td>92.857</td>\n",
       "      <td>86.364</td>\n",
       "      <td>100.000</td>\n",
       "      <td>100.000</td>\n",
       "      <td>86.957</td>\n",
       "      <td>92.683</td>\n",
       "      <td>0.935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>GridSearchCV(cv=5, estimator=KNeighborsClassif...</td>\n",
       "      <td>KNeighborsClassifier(metric='manhattan', n_nei...</td>\n",
       "      <td>{'metric': 'manhattan', 'n_neighbors': 15}</td>\n",
       "      <td>91.79</td>\n",
       "      <td>[[20, 3], [0, 18]]</td>\n",
       "      <td>92.683</td>\n",
       "      <td>85.714</td>\n",
       "      <td>100.000</td>\n",
       "      <td>100.000</td>\n",
       "      <td>86.957</td>\n",
       "      <td>92.308</td>\n",
       "      <td>0.935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>GridSearchCV(cv=5, estimator=KNeighborsClassif...</td>\n",
       "      <td>KNeighborsClassifier(metric='manhattan', n_nei...</td>\n",
       "      <td>{'metric': 'manhattan', 'n_neighbors': 15}</td>\n",
       "      <td>91.79</td>\n",
       "      <td>[[20, 3], [0, 18]]</td>\n",
       "      <td>92.683</td>\n",
       "      <td>85.714</td>\n",
       "      <td>100.000</td>\n",
       "      <td>100.000</td>\n",
       "      <td>86.957</td>\n",
       "      <td>92.308</td>\n",
       "      <td>0.935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>GridSearchCV(cv=5, estimator=KNeighborsClassif...</td>\n",
       "      <td>KNeighborsClassifier(metric='manhattan', n_nei...</td>\n",
       "      <td>{'metric': 'manhattan', 'n_neighbors': 15}</td>\n",
       "      <td>91.79</td>\n",
       "      <td>[[17, 6], [0, 18]]</td>\n",
       "      <td>85.366</td>\n",
       "      <td>75.000</td>\n",
       "      <td>100.000</td>\n",
       "      <td>100.000</td>\n",
       "      <td>73.913</td>\n",
       "      <td>85.714</td>\n",
       "      <td>0.870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>GridSearchCV(cv=5, estimator=DecisionTreeClass...</td>\n",
       "      <td>DecisionTreeClassifier(max_depth=2)</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 2}</td>\n",
       "      <td>91.47</td>\n",
       "      <td>[[20, 4], [0, 19]]</td>\n",
       "      <td>90.698</td>\n",
       "      <td>82.609</td>\n",
       "      <td>100.000</td>\n",
       "      <td>100.000</td>\n",
       "      <td>83.333</td>\n",
       "      <td>90.476</td>\n",
       "      <td>0.917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>GridSearchCV(cv=5, estimator=DecisionTreeClass...</td>\n",
       "      <td>DecisionTreeClassifier(max_depth=2)</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 2}</td>\n",
       "      <td>91.10</td>\n",
       "      <td>[[20, 3], [0, 19]]</td>\n",
       "      <td>92.857</td>\n",
       "      <td>86.364</td>\n",
       "      <td>100.000</td>\n",
       "      <td>100.000</td>\n",
       "      <td>86.957</td>\n",
       "      <td>92.683</td>\n",
       "      <td>0.935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>GridSearchCV(cv=5, estimator=DecisionTreeClass...</td>\n",
       "      <td>DecisionTreeClassifier(max_depth=2)</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 2}</td>\n",
       "      <td>91.58</td>\n",
       "      <td>[[19, 4], [0, 18]]</td>\n",
       "      <td>90.244</td>\n",
       "      <td>81.818</td>\n",
       "      <td>100.000</td>\n",
       "      <td>100.000</td>\n",
       "      <td>82.609</td>\n",
       "      <td>90.000</td>\n",
       "      <td>0.913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>GridSearchCV(cv=5, estimator=DecisionTreeClass...</td>\n",
       "      <td>DecisionTreeClassifier(max_depth=2)</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 2}</td>\n",
       "      <td>91.58</td>\n",
       "      <td>[[21, 2], [0, 18]]</td>\n",
       "      <td>95.122</td>\n",
       "      <td>90.000</td>\n",
       "      <td>100.000</td>\n",
       "      <td>100.000</td>\n",
       "      <td>91.304</td>\n",
       "      <td>94.737</td>\n",
       "      <td>0.957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>GridSearchCV(cv=5, estimator=DecisionTreeClass...</td>\n",
       "      <td>DecisionTreeClassifier(max_depth=2)</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 2}</td>\n",
       "      <td>91.58</td>\n",
       "      <td>[[20, 3], [0, 18]]</td>\n",
       "      <td>92.683</td>\n",
       "      <td>85.714</td>\n",
       "      <td>100.000</td>\n",
       "      <td>100.000</td>\n",
       "      <td>86.957</td>\n",
       "      <td>92.308</td>\n",
       "      <td>0.935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>GridSearchCV(cv=5, estimator=RandomForestClass...</td>\n",
       "      <td>(DecisionTreeClassifier(criterion='entropy', m...</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 20, 'n_e...</td>\n",
       "      <td>94.22</td>\n",
       "      <td>[[23, 1], [0, 19]]</td>\n",
       "      <td>97.674</td>\n",
       "      <td>95.000</td>\n",
       "      <td>100.000</td>\n",
       "      <td>100.000</td>\n",
       "      <td>95.833</td>\n",
       "      <td>97.436</td>\n",
       "      <td>0.979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>GridSearchCV(cv=5, estimator=RandomForestClass...</td>\n",
       "      <td>(DecisionTreeClassifier(max_depth=5, max_featu...</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 5, 'n_estim...</td>\n",
       "      <td>92.46</td>\n",
       "      <td>[[21, 2], [0, 19]]</td>\n",
       "      <td>95.238</td>\n",
       "      <td>90.476</td>\n",
       "      <td>100.000</td>\n",
       "      <td>100.000</td>\n",
       "      <td>91.304</td>\n",
       "      <td>95.000</td>\n",
       "      <td>0.957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>GridSearchCV(cv=5, estimator=RandomForestClass...</td>\n",
       "      <td>(DecisionTreeClassifier(criterion='entropy', m...</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 7, 'n_es...</td>\n",
       "      <td>93.68</td>\n",
       "      <td>[[23, 0], [0, 18]]</td>\n",
       "      <td>100.000</td>\n",
       "      <td>100.000</td>\n",
       "      <td>100.000</td>\n",
       "      <td>100.000</td>\n",
       "      <td>100.000</td>\n",
       "      <td>100.000</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>GridSearchCV(cv=5, estimator=RandomForestClass...</td>\n",
       "      <td>(DecisionTreeClassifier(criterion='entropy', m...</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 7, 'n_es...</td>\n",
       "      <td>93.68</td>\n",
       "      <td>[[23, 0], [0, 18]]</td>\n",
       "      <td>100.000</td>\n",
       "      <td>100.000</td>\n",
       "      <td>100.000</td>\n",
       "      <td>100.000</td>\n",
       "      <td>100.000</td>\n",
       "      <td>100.000</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>GridSearchCV(cv=5, estimator=RandomForestClass...</td>\n",
       "      <td>(DecisionTreeClassifier(criterion='entropy', m...</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 5, 'n_es...</td>\n",
       "      <td>92.69</td>\n",
       "      <td>[[21, 2], [0, 18]]</td>\n",
       "      <td>95.122</td>\n",
       "      <td>90.000</td>\n",
       "      <td>100.000</td>\n",
       "      <td>100.000</td>\n",
       "      <td>91.304</td>\n",
       "      <td>94.737</td>\n",
       "      <td>0.957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>GridSearchCV(cv=5, estimator=GradientBoostingC...</td>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "      <td>{'learning_rate': 0.5, 'max_depth': 2, 'n_esti...</td>\n",
       "      <td>92.11</td>\n",
       "      <td>[[20, 4], [0, 19]]</td>\n",
       "      <td>90.698</td>\n",
       "      <td>82.609</td>\n",
       "      <td>100.000</td>\n",
       "      <td>100.000</td>\n",
       "      <td>83.333</td>\n",
       "      <td>90.476</td>\n",
       "      <td>0.917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>GridSearchCV(cv=5, estimator=GradientBoostingC...</td>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "      <td>{'learning_rate': 0.05, 'max_depth': 2, 'n_est...</td>\n",
       "      <td>91.57</td>\n",
       "      <td>[[20, 3], [0, 19]]</td>\n",
       "      <td>92.857</td>\n",
       "      <td>86.364</td>\n",
       "      <td>100.000</td>\n",
       "      <td>100.000</td>\n",
       "      <td>86.957</td>\n",
       "      <td>92.683</td>\n",
       "      <td>0.935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>GridSearchCV(cv=5, estimator=GradientBoostingC...</td>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "      <td>{'learning_rate': 0.01, 'max_depth': 2, 'n_est...</td>\n",
       "      <td>91.58</td>\n",
       "      <td>[[19, 4], [0, 18]]</td>\n",
       "      <td>90.244</td>\n",
       "      <td>81.818</td>\n",
       "      <td>100.000</td>\n",
       "      <td>100.000</td>\n",
       "      <td>82.609</td>\n",
       "      <td>90.000</td>\n",
       "      <td>0.913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>GridSearchCV(cv=5, estimator=GradientBoostingC...</td>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "      <td>{'learning_rate': 0.01, 'max_depth': 2, 'n_est...</td>\n",
       "      <td>90.65</td>\n",
       "      <td>[[21, 2], [0, 18]]</td>\n",
       "      <td>95.122</td>\n",
       "      <td>90.000</td>\n",
       "      <td>100.000</td>\n",
       "      <td>100.000</td>\n",
       "      <td>91.304</td>\n",
       "      <td>94.737</td>\n",
       "      <td>0.957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>GridSearchCV(cv=5, estimator=GradientBoostingC...</td>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "      <td>{'learning_rate': 0.01, 'max_depth': 2, 'n_est...</td>\n",
       "      <td>91.58</td>\n",
       "      <td>[[20, 3], [0, 18]]</td>\n",
       "      <td>92.683</td>\n",
       "      <td>85.714</td>\n",
       "      <td>100.000</td>\n",
       "      <td>100.000</td>\n",
       "      <td>86.957</td>\n",
       "      <td>92.308</td>\n",
       "      <td>0.935</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Test_No  Model_No                                             method  \\\n",
       "0         1         1  GridSearchCV(cv=5, estimator=LogisticRegressio...   \n",
       "7         2         1  GridSearchCV(cv=5, estimator=LogisticRegressio...   \n",
       "14        3         1  GridSearchCV(cv=5, estimator=LogisticRegressio...   \n",
       "21        4         1  GridSearchCV(cv=5, estimator=LogisticRegressio...   \n",
       "28        5         1  GridSearchCV(cv=5, estimator=LogisticRegressio...   \n",
       "1         1         2  GridSearchCV(cv=5, estimator=SVC(), n_jobs=50,...   \n",
       "8         2         2  GridSearchCV(cv=5, estimator=SVC(), n_jobs=50,...   \n",
       "15        3         2  GridSearchCV(cv=5, estimator=SVC(), n_jobs=50,...   \n",
       "22        4         2  GridSearchCV(cv=5, estimator=SVC(), n_jobs=50,...   \n",
       "29        5         2  GridSearchCV(cv=5, estimator=SVC(), n_jobs=50,...   \n",
       "2         1         3  GridSearchCV(cv=5, estimator=GaussianNB(), n_j...   \n",
       "9         2         3  GridSearchCV(cv=5, estimator=GaussianNB(), n_j...   \n",
       "16        3         3  GridSearchCV(cv=5, estimator=GaussianNB(), n_j...   \n",
       "23        4         3  GridSearchCV(cv=5, estimator=GaussianNB(), n_j...   \n",
       "30        5         3  GridSearchCV(cv=5, estimator=GaussianNB(), n_j...   \n",
       "3         1         4  GridSearchCV(cv=5, estimator=KNeighborsClassif...   \n",
       "10        2         4  GridSearchCV(cv=5, estimator=KNeighborsClassif...   \n",
       "17        3         4  GridSearchCV(cv=5, estimator=KNeighborsClassif...   \n",
       "24        4         4  GridSearchCV(cv=5, estimator=KNeighborsClassif...   \n",
       "31        5         4  GridSearchCV(cv=5, estimator=KNeighborsClassif...   \n",
       "4         1         5  GridSearchCV(cv=5, estimator=DecisionTreeClass...   \n",
       "11        2         5  GridSearchCV(cv=5, estimator=DecisionTreeClass...   \n",
       "18        3         5  GridSearchCV(cv=5, estimator=DecisionTreeClass...   \n",
       "25        4         5  GridSearchCV(cv=5, estimator=DecisionTreeClass...   \n",
       "32        5         5  GridSearchCV(cv=5, estimator=DecisionTreeClass...   \n",
       "5         1         6  GridSearchCV(cv=5, estimator=RandomForestClass...   \n",
       "12        2         6  GridSearchCV(cv=5, estimator=RandomForestClass...   \n",
       "19        3         6  GridSearchCV(cv=5, estimator=RandomForestClass...   \n",
       "26        4         6  GridSearchCV(cv=5, estimator=RandomForestClass...   \n",
       "33        5         6  GridSearchCV(cv=5, estimator=RandomForestClass...   \n",
       "6         1         7  GridSearchCV(cv=5, estimator=GradientBoostingC...   \n",
       "13        2         7  GridSearchCV(cv=5, estimator=GradientBoostingC...   \n",
       "20        3         7  GridSearchCV(cv=5, estimator=GradientBoostingC...   \n",
       "27        4         7  GridSearchCV(cv=5, estimator=GradientBoostingC...   \n",
       "34        5         7  GridSearchCV(cv=5, estimator=GradientBoostingC...   \n",
       "\n",
       "                                                model  \\\n",
       "0                     LogisticRegression(max_iter=50)   \n",
       "7                     LogisticRegression(max_iter=50)   \n",
       "14                    LogisticRegression(max_iter=50)   \n",
       "21                    LogisticRegression(max_iter=50)   \n",
       "28                    LogisticRegression(max_iter=50)   \n",
       "1              SVC(kernel='linear', probability=True)   \n",
       "8              SVC(kernel='linear', probability=True)   \n",
       "15             SVC(kernel='linear', probability=True)   \n",
       "22             SVC(kernel='linear', probability=True)   \n",
       "29             SVC(kernel='linear', probability=True)   \n",
       "2      GaussianNB(var_smoothing=0.005623413251903491)   \n",
       "9      GaussianNB(var_smoothing=0.005623413251903491)   \n",
       "16     GaussianNB(var_smoothing=0.005623413251903491)   \n",
       "23     GaussianNB(var_smoothing=0.005623413251903491)   \n",
       "30     GaussianNB(var_smoothing=0.005623413251903491)   \n",
       "3   KNeighborsClassifier(metric='manhattan', n_nei...   \n",
       "10  KNeighborsClassifier(metric='manhattan', n_nei...   \n",
       "17  KNeighborsClassifier(metric='manhattan', n_nei...   \n",
       "24  KNeighborsClassifier(metric='manhattan', n_nei...   \n",
       "31  KNeighborsClassifier(metric='manhattan', n_nei...   \n",
       "4                 DecisionTreeClassifier(max_depth=2)   \n",
       "11                DecisionTreeClassifier(max_depth=2)   \n",
       "18                DecisionTreeClassifier(max_depth=2)   \n",
       "25                DecisionTreeClassifier(max_depth=2)   \n",
       "32                DecisionTreeClassifier(max_depth=2)   \n",
       "5   (DecisionTreeClassifier(criterion='entropy', m...   \n",
       "12  (DecisionTreeClassifier(max_depth=5, max_featu...   \n",
       "19  (DecisionTreeClassifier(criterion='entropy', m...   \n",
       "26  (DecisionTreeClassifier(criterion='entropy', m...   \n",
       "33  (DecisionTreeClassifier(criterion='entropy', m...   \n",
       "6   ([DecisionTreeRegressor(criterion='friedman_ms...   \n",
       "13  ([DecisionTreeRegressor(criterion='friedman_ms...   \n",
       "20  ([DecisionTreeRegressor(criterion='friedman_ms...   \n",
       "27  ([DecisionTreeRegressor(criterion='friedman_ms...   \n",
       "34  ([DecisionTreeRegressor(criterion='friedman_ms...   \n",
       "\n",
       "                                     model_parameters  model_scores  \\\n",
       "0         {'C': 1.0, 'max_iter': 50, 'penalty': 'l2'}         89.65   \n",
       "7         {'C': 1.0, 'max_iter': 50, 'penalty': 'l2'}         90.91   \n",
       "14        {'C': 1.0, 'max_iter': 50, 'penalty': 'l2'}         90.28   \n",
       "21        {'C': 1.0, 'max_iter': 50, 'penalty': 'l2'}         90.28   \n",
       "28        {'C': 1.0, 'max_iter': 50, 'penalty': 'l2'}         90.28   \n",
       "1   {'C': 1.0, 'kernel': 'linear', 'probability': ...         91.61   \n",
       "8   {'C': 1.0, 'kernel': 'linear', 'probability': ...         92.06   \n",
       "15  {'C': 1.0, 'kernel': 'linear', 'probability': ...         92.06   \n",
       "22  {'C': 1.0, 'kernel': 'linear', 'probability': ...         92.06   \n",
       "29  {'C': 1.0, 'kernel': 'linear', 'probability': ...         92.06   \n",
       "2             {'var_smoothing': 0.005623413251903491}         90.15   \n",
       "9             {'var_smoothing': 0.005623413251903491}         90.74   \n",
       "16            {'var_smoothing': 0.005623413251903491}         90.18   \n",
       "23            {'var_smoothing': 0.005623413251903491}         90.18   \n",
       "30            {'var_smoothing': 0.005623413251903491}         90.18   \n",
       "3          {'metric': 'manhattan', 'n_neighbors': 15}         91.12   \n",
       "10         {'metric': 'manhattan', 'n_neighbors': 15}         91.04   \n",
       "17         {'metric': 'manhattan', 'n_neighbors': 15}         91.79   \n",
       "24         {'metric': 'manhattan', 'n_neighbors': 15}         91.79   \n",
       "31         {'metric': 'manhattan', 'n_neighbors': 15}         91.79   \n",
       "4               {'criterion': 'gini', 'max_depth': 2}         91.47   \n",
       "11              {'criterion': 'gini', 'max_depth': 2}         91.10   \n",
       "18              {'criterion': 'gini', 'max_depth': 2}         91.58   \n",
       "25              {'criterion': 'gini', 'max_depth': 2}         91.58   \n",
       "32              {'criterion': 'gini', 'max_depth': 2}         91.58   \n",
       "5   {'criterion': 'entropy', 'max_depth': 20, 'n_e...         94.22   \n",
       "12  {'criterion': 'gini', 'max_depth': 5, 'n_estim...         92.46   \n",
       "19  {'criterion': 'entropy', 'max_depth': 7, 'n_es...         93.68   \n",
       "26  {'criterion': 'entropy', 'max_depth': 7, 'n_es...         93.68   \n",
       "33  {'criterion': 'entropy', 'max_depth': 5, 'n_es...         92.69   \n",
       "6   {'learning_rate': 0.5, 'max_depth': 2, 'n_esti...         92.11   \n",
       "13  {'learning_rate': 0.05, 'max_depth': 2, 'n_est...         91.57   \n",
       "20  {'learning_rate': 0.01, 'max_depth': 2, 'n_est...         91.58   \n",
       "27  {'learning_rate': 0.01, 'max_depth': 2, 'n_est...         90.65   \n",
       "34  {'learning_rate': 0.01, 'max_depth': 2, 'n_est...         91.58   \n",
       "\n",
       "      confusion_matrix  accuracy  precision   recall  sensitivity  \\\n",
       "0   [[19, 5], [1, 18]]    86.047     78.261   94.737       94.737   \n",
       "7   [[20, 3], [0, 19]]    92.857     86.364  100.000      100.000   \n",
       "14  [[20, 3], [0, 18]]    92.683     85.714  100.000      100.000   \n",
       "21  [[20, 3], [0, 18]]    92.683     85.714  100.000      100.000   \n",
       "28  [[18, 5], [0, 18]]    87.805     78.261  100.000      100.000   \n",
       "1   [[20, 4], [0, 19]]    90.698     82.609  100.000      100.000   \n",
       "8   [[20, 3], [0, 19]]    92.857     86.364  100.000      100.000   \n",
       "15  [[19, 4], [0, 18]]    90.244     81.818  100.000      100.000   \n",
       "22  [[20, 3], [0, 18]]    92.683     85.714  100.000      100.000   \n",
       "29  [[19, 4], [0, 18]]    90.244     81.818  100.000      100.000   \n",
       "2   [[20, 4], [1, 18]]    88.372     81.818   94.737       94.737   \n",
       "9   [[20, 3], [0, 19]]    92.857     86.364  100.000      100.000   \n",
       "16  [[20, 3], [0, 18]]    92.683     85.714  100.000      100.000   \n",
       "23  [[20, 3], [0, 18]]    92.683     85.714  100.000      100.000   \n",
       "30  [[20, 3], [0, 18]]    92.683     85.714  100.000      100.000   \n",
       "3   [[19, 5], [0, 19]]    88.372     79.167  100.000      100.000   \n",
       "10  [[20, 3], [0, 19]]    92.857     86.364  100.000      100.000   \n",
       "17  [[20, 3], [0, 18]]    92.683     85.714  100.000      100.000   \n",
       "24  [[20, 3], [0, 18]]    92.683     85.714  100.000      100.000   \n",
       "31  [[17, 6], [0, 18]]    85.366     75.000  100.000      100.000   \n",
       "4   [[20, 4], [0, 19]]    90.698     82.609  100.000      100.000   \n",
       "11  [[20, 3], [0, 19]]    92.857     86.364  100.000      100.000   \n",
       "18  [[19, 4], [0, 18]]    90.244     81.818  100.000      100.000   \n",
       "25  [[21, 2], [0, 18]]    95.122     90.000  100.000      100.000   \n",
       "32  [[20, 3], [0, 18]]    92.683     85.714  100.000      100.000   \n",
       "5   [[23, 1], [0, 19]]    97.674     95.000  100.000      100.000   \n",
       "12  [[21, 2], [0, 19]]    95.238     90.476  100.000      100.000   \n",
       "19  [[23, 0], [0, 18]]   100.000    100.000  100.000      100.000   \n",
       "26  [[23, 0], [0, 18]]   100.000    100.000  100.000      100.000   \n",
       "33  [[21, 2], [0, 18]]    95.122     90.000  100.000      100.000   \n",
       "6   [[20, 4], [0, 19]]    90.698     82.609  100.000      100.000   \n",
       "13  [[20, 3], [0, 19]]    92.857     86.364  100.000      100.000   \n",
       "20  [[19, 4], [0, 18]]    90.244     81.818  100.000      100.000   \n",
       "27  [[21, 2], [0, 18]]    95.122     90.000  100.000      100.000   \n",
       "34  [[20, 3], [0, 18]]    92.683     85.714  100.000      100.000   \n",
       "\n",
       "    specificity  f1_score  roc_auc  \n",
       "0        79.167    85.714    0.870  \n",
       "7        86.957    92.683    0.935  \n",
       "14       86.957    92.308    0.935  \n",
       "21       86.957    92.308    0.935  \n",
       "28       78.261    87.805    0.891  \n",
       "1        83.333    90.476    0.917  \n",
       "8        86.957    92.683    0.935  \n",
       "15       82.609    90.000    0.913  \n",
       "22       86.957    92.308    0.935  \n",
       "29       82.609    90.000    0.913  \n",
       "2        83.333    87.805    0.890  \n",
       "9        86.957    92.683    0.935  \n",
       "16       86.957    92.308    0.935  \n",
       "23       86.957    92.308    0.935  \n",
       "30       86.957    92.308    0.935  \n",
       "3        79.167    88.372    0.896  \n",
       "10       86.957    92.683    0.935  \n",
       "17       86.957    92.308    0.935  \n",
       "24       86.957    92.308    0.935  \n",
       "31       73.913    85.714    0.870  \n",
       "4        83.333    90.476    0.917  \n",
       "11       86.957    92.683    0.935  \n",
       "18       82.609    90.000    0.913  \n",
       "25       91.304    94.737    0.957  \n",
       "32       86.957    92.308    0.935  \n",
       "5        95.833    97.436    0.979  \n",
       "12       91.304    95.000    0.957  \n",
       "19      100.000   100.000    1.000  \n",
       "26      100.000   100.000    1.000  \n",
       "33       91.304    94.737    0.957  \n",
       "6        83.333    90.476    0.917  \n",
       "13       86.957    92.683    0.935  \n",
       "20       82.609    90.000    0.913  \n",
       "27       91.304    94.737    0.957  \n",
       "34       86.957    92.308    0.935  "
      ]
     },
     "execution_count": 375,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts_model_scores_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "id": "lonely-nepal",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Test_No</th>\n",
       "      <th>Model_No</th>\n",
       "      <th>method</th>\n",
       "      <th>model</th>\n",
       "      <th>model_parameters</th>\n",
       "      <th>model_scores</th>\n",
       "      <th>confusion_matrix</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>sensitivity</th>\n",
       "      <th>specificity</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>roc_auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>GridSearchCV(cv=5, estimator=RandomForestClass...</td>\n",
       "      <td>(DecisionTreeClassifier(criterion='entropy', m...</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 20, 'n_e...</td>\n",
       "      <td>94.22</td>\n",
       "      <td>[[23, 1], [0, 19]]</td>\n",
       "      <td>97.674</td>\n",
       "      <td>95.000</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>95.833</td>\n",
       "      <td>97.436</td>\n",
       "      <td>0.979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>GridSearchCV(cv=5, estimator=RandomForestClass...</td>\n",
       "      <td>(DecisionTreeClassifier(max_depth=5, max_featu...</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 5, 'n_estim...</td>\n",
       "      <td>92.46</td>\n",
       "      <td>[[21, 2], [0, 19]]</td>\n",
       "      <td>95.238</td>\n",
       "      <td>90.476</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>91.304</td>\n",
       "      <td>95.000</td>\n",
       "      <td>0.957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>GridSearchCV(cv=5, estimator=RandomForestClass...</td>\n",
       "      <td>(DecisionTreeClassifier(criterion='entropy', m...</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 7, 'n_es...</td>\n",
       "      <td>93.68</td>\n",
       "      <td>[[23, 0], [0, 18]]</td>\n",
       "      <td>100.000</td>\n",
       "      <td>100.000</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.000</td>\n",
       "      <td>100.000</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>GridSearchCV(cv=5, estimator=RandomForestClass...</td>\n",
       "      <td>(DecisionTreeClassifier(criterion='entropy', m...</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 7, 'n_es...</td>\n",
       "      <td>93.68</td>\n",
       "      <td>[[23, 0], [0, 18]]</td>\n",
       "      <td>100.000</td>\n",
       "      <td>100.000</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.000</td>\n",
       "      <td>100.000</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>GridSearchCV(cv=5, estimator=RandomForestClass...</td>\n",
       "      <td>(DecisionTreeClassifier(criterion='entropy', m...</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 5, 'n_es...</td>\n",
       "      <td>92.69</td>\n",
       "      <td>[[21, 2], [0, 18]]</td>\n",
       "      <td>95.122</td>\n",
       "      <td>90.000</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>91.304</td>\n",
       "      <td>94.737</td>\n",
       "      <td>0.957</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Test_No  Model_No                                             method  \\\n",
       "5         1         6  GridSearchCV(cv=5, estimator=RandomForestClass...   \n",
       "12        2         6  GridSearchCV(cv=5, estimator=RandomForestClass...   \n",
       "19        3         6  GridSearchCV(cv=5, estimator=RandomForestClass...   \n",
       "26        4         6  GridSearchCV(cv=5, estimator=RandomForestClass...   \n",
       "33        5         6  GridSearchCV(cv=5, estimator=RandomForestClass...   \n",
       "\n",
       "                                                model  \\\n",
       "5   (DecisionTreeClassifier(criterion='entropy', m...   \n",
       "12  (DecisionTreeClassifier(max_depth=5, max_featu...   \n",
       "19  (DecisionTreeClassifier(criterion='entropy', m...   \n",
       "26  (DecisionTreeClassifier(criterion='entropy', m...   \n",
       "33  (DecisionTreeClassifier(criterion='entropy', m...   \n",
       "\n",
       "                                     model_parameters  model_scores  \\\n",
       "5   {'criterion': 'entropy', 'max_depth': 20, 'n_e...         94.22   \n",
       "12  {'criterion': 'gini', 'max_depth': 5, 'n_estim...         92.46   \n",
       "19  {'criterion': 'entropy', 'max_depth': 7, 'n_es...         93.68   \n",
       "26  {'criterion': 'entropy', 'max_depth': 7, 'n_es...         93.68   \n",
       "33  {'criterion': 'entropy', 'max_depth': 5, 'n_es...         92.69   \n",
       "\n",
       "      confusion_matrix  accuracy  precision  recall  sensitivity  specificity  \\\n",
       "5   [[23, 1], [0, 19]]    97.674     95.000   100.0        100.0       95.833   \n",
       "12  [[21, 2], [0, 19]]    95.238     90.476   100.0        100.0       91.304   \n",
       "19  [[23, 0], [0, 18]]   100.000    100.000   100.0        100.0      100.000   \n",
       "26  [[23, 0], [0, 18]]   100.000    100.000   100.0        100.0      100.000   \n",
       "33  [[21, 2], [0, 18]]    95.122     90.000   100.0        100.0       91.304   \n",
       "\n",
       "    f1_score  roc_auc  \n",
       "5     97.436    0.979  \n",
       "12    95.000    0.957  \n",
       "19   100.000    1.000  \n",
       "26   100.000    1.000  \n",
       "33    94.737    0.957  "
      ]
     },
     "execution_count": 376,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts_model_scores_df[(ts_model_scores_df['Model_No']==6)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "obvious-essay",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf1 = ts_model[1][6].estimator \n",
    "rf1 = ts_model[1][6] \n",
    "rf1.feature_importances_ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "permanent-logan",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "searching-olive",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "spoken-karaoke",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_model_scores_df['method_name'][-5:].values, ts_model_scores_df['method_name'][-5:].values[0], type(ts_model_scores_df['method_name'][-5:].values[0]) \n",
    "ts_model_scores_df[-10:] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "anticipated-venture",
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_model_scores_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ultimate-interest",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_target_and_prediction_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hispanic-wheat",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_column, class_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "funded-sacrifice",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort the dataframe based on the list as the column values\n",
    "sorter = processed_dataset['Subject_Name'].values.tolist()\n",
    "sorter\n",
    "\n",
    "ts_target_and_prediction_df['Subject_Name'] = ts_target_and_prediction_df['Subject_Name'].astype(\"category\")\n",
    "ts_target_and_prediction_df['Subject_Name'] = ts_target_and_prediction_df['Subject_Name'].cat.set_categories(sorter)\n",
    "ts_target_and_prediction_df\n",
    "ts_target_and_prediction_df2 = ts_target_and_prediction_df.sort_values(['Subject_Name'])\n",
    "ts_target_and_prediction_df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "running-lotus",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_target_and_prediction_df2[(ts_target_and_prediction_df2['Subject_Name'].str.match(r'^n\\d')==True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "academic-instruction",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVC?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "injured-permission",
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_target_and_prediction_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "brilliant-triangle",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "senior-respect",
   "metadata": {},
   "source": [
    "### Test saved results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "lasting-disney",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./Results/_Classification/ML1001/'"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_save_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "scheduled-singapore",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./Results/_Classification/ML1001/'"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_save_path2 = result_save_path \n",
    "result_save_path2 = './Results/_Classification/ML1001/'\n",
    "result_save_path2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "apparent-guide",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Class'"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "novel-nickel",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "        Object is initialised with the following properties: \n",
      "        ###################################################################################################\n",
      "        Dataset size: (0, 1), Columns: ['Class']\n",
      "        Target class column name: Class\n",
      "        Metadata column names: ['Dataset', 'Category', 'Subject_Name']\n",
      "        Dataset split column on which the training and test sets will be devided: Class\n",
      "        Is multi-class classification: False\n",
      "        \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<__main__.HumachLab_ML_CLassifiers at 0x1961723ff08>"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if logger:\n",
    "    stop_logger(logger) \n",
    "util, logger = start_logger('./Results/', '00')\n",
    "\n",
    "classifier_obj2 = HumachLab_ML_CLassifiers(logger=logger, directory=result_save_path2, dataset=pd.DataFrame(columns=[class_name]), class_name=class_name, label_map={}, metadata_column=metadata_column, split_column=split_column, random_state_value=0, split_balance_pattern=[], check_result=True) \n",
    "\n",
    "classifier_obj2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "regular-killing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "        Data is being loaded from: ./Results/_Classification/ML1001/\n",
      "        \n",
      "Start retrieving Test Models model from file...\n",
      "Finish retrieving Test Models model from file...\n",
      "Start retrieving Training Models model from file...\n",
      "Finish retrieving Training Models model from file...\n",
      "Start retrieving Best Training Models model from file...\n",
      "Finish retrieving Best Training Models model from file...\n"
     ]
    }
   ],
   "source": [
    "best_tr_model2, tr_model2, tr_model_scores_df2, tr_target_and_prediction_df2, ts_model2, ts_model_scores_df2, ts_target_and_prediction_df2, ts_fold_info_df2, exp_info_df2  = classifier_obj2.load_results(result_save_path2)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "roman-eugene",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_fold_info_df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "global-watershed",
   "metadata": {},
   "outputs": [],
   "source": [
    "tt = ts_fold_info_df2[ ts_fold_info_df2['Model_No']==1 ] ['Selected_Features'] \n",
    "tt\n",
    "\n",
    "for t in tt:\n",
    "    print(t) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "understanding-dividend",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_model_scores_df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "abstract-removal",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.07192441, 0.05810145, 0.        , 0.        , 0.00383925,\n",
       "       0.02089143, 0.03123972, 0.01320727, 0.        , 0.00033542,\n",
       "       0.01480059, 0.02185206, 0.03852718, 0.06779852, 0.03535199,\n",
       "       0.00030042, 0.02001342, 0.01768856, 0.00402689, 0.14115883,\n",
       "       0.13452728, 0.0399399 , 0.00179775, 0.01935714, 0.00362998,\n",
       "       0.01058212, 0.05096356, 0.11031693, 0.        , 0.02200328,\n",
       "       0.00473437, 0.01572608, 0.00154661, 0.02381757])"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts_model2[1][6].best_estimator_.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "photographic-illness",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "appointed-toolbox",
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_model_scores_df2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "verified-sender",
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_model_scores_df2[ (tr_model_scores_df2['Model_No']==6) ]['accuracy'].min() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "gorgeous-travel",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ts_model_scores_df['method_name'][-5:].values, ts_model_scores_df['method_name'][-5:].values[0], type(ts_model_scores_df['method_name'][-5:].values[0]) \n",
    "ts_model_scores_df2[-30:] \n",
    "ts_model_scores_df2[ ts_model_scores_df2['Model_No']==1 ] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "defined-color",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_model_scores_df2[ ts_model_scores_df2['Model_No']==6 ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "balanced-closer",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_model_scores_df2[ ts_model_scores_df2['Model_No']==7 ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "planned-attribute",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "under-quantity",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "closed-israel",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(all_ts_model[1][1]), type(all_ts_model[1][1].estimator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "traditional-still",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fifteen-linux",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "surface-factory",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "finnish-grounds",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset.to_csv('./dataset.csv', index=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "missing-badge",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "id": "crude-magazine",
   "metadata": {},
   "outputs": [],
   "source": [
    "# best_tr_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "future-least",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "developing-screening",
   "metadata": {},
   "source": [
    "#### Show and save RF Feature selection "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "id": "grateful-alias",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([(5, 0), (5, 20)], 6)"
      ]
     },
     "execution_count": 281,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "splitting_crieteria, (splitting_crieteria[0][0]+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "id": "powerful-efficiency",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset</th>\n",
       "      <th>Category</th>\n",
       "      <th>Subject_Name</th>\n",
       "      <th>Class</th>\n",
       "      <th>W-&gt;S1</th>\n",
       "      <th>W-&gt;S2</th>\n",
       "      <th>W-&gt;S3</th>\n",
       "      <th>W-&gt;S4</th>\n",
       "      <th>W-&gt;REM</th>\n",
       "      <th>S1-&gt;W</th>\n",
       "      <th>...</th>\n",
       "      <th>S4-&gt;S1</th>\n",
       "      <th>S4-&gt;S2</th>\n",
       "      <th>S4-&gt;S3</th>\n",
       "      <th>S4-&gt;S4</th>\n",
       "      <th>S4-&gt;REM</th>\n",
       "      <th>REM-&gt;W</th>\n",
       "      <th>REM-&gt;S1</th>\n",
       "      <th>REM-&gt;S2</th>\n",
       "      <th>REM-&gt;S3</th>\n",
       "      <th>REM-&gt;REM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CAP_Sleep</td>\n",
       "      <td>brux</td>\n",
       "      <td>brux1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.190476</td>\n",
       "      <td>0.009524</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.030769</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004926</td>\n",
       "      <td>0.024631</td>\n",
       "      <td>0.970443</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.033520</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.966480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CAP_Sleep</td>\n",
       "      <td>brux</td>\n",
       "      <td>brux2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.174603</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.061728</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.012048</td>\n",
       "      <td>0.984940</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.019324</td>\n",
       "      <td>0.004831</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.975845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CAP_Sleep</td>\n",
       "      <td>sdb</td>\n",
       "      <td>sdb1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.123288</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.099237</td>\n",
       "      <td>...</td>\n",
       "      <td>0.010152</td>\n",
       "      <td>0.005076</td>\n",
       "      <td>0.030457</td>\n",
       "      <td>0.949239</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.009346</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.028037</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.962617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CAP_Sleep</td>\n",
       "      <td>sdb</td>\n",
       "      <td>sdb2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.044872</td>\n",
       "      <td>0.006410</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.011364</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.016949</td>\n",
       "      <td>0.966102</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.025641</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.974359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CAP_Sleep</td>\n",
       "      <td>sdb</td>\n",
       "      <td>sdb3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.046948</td>\n",
       "      <td>0.018779</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.108696</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.025974</td>\n",
       "      <td>0.038961</td>\n",
       "      <td>0.935065</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.937500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>Sleep_EDFX</td>\n",
       "      <td>n</td>\n",
       "      <td>ST7191</td>\n",
       "      <td>0</td>\n",
       "      <td>0.242857</td>\n",
       "      <td>0.014286</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.044118</td>\n",
       "      <td>...</td>\n",
       "      <td>0.013889</td>\n",
       "      <td>0.013889</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.805556</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>0.015000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.965000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>Sleep_EDFX</td>\n",
       "      <td>n</td>\n",
       "      <td>ST7201</td>\n",
       "      <td>0</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.014493</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>0.346154</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.044776</td>\n",
       "      <td>0.007463</td>\n",
       "      <td>0.014925</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.932836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>Sleep_EDFX</td>\n",
       "      <td>n</td>\n",
       "      <td>ST7211</td>\n",
       "      <td>0</td>\n",
       "      <td>0.099415</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.005848</td>\n",
       "      <td>0.116667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.016949</td>\n",
       "      <td>0.254237</td>\n",
       "      <td>0.728814</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.025641</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.019231</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.955128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>Sleep_EDFX</td>\n",
       "      <td>n</td>\n",
       "      <td>ST7221</td>\n",
       "      <td>0</td>\n",
       "      <td>0.180000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.052133</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.021645</td>\n",
       "      <td>0.043290</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.935065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>Sleep_EDFX</td>\n",
       "      <td>n</td>\n",
       "      <td>ST7241</td>\n",
       "      <td>0</td>\n",
       "      <td>0.275862</td>\n",
       "      <td>0.034483</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.068966</td>\n",
       "      <td>0.047619</td>\n",
       "      <td>...</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.016878</td>\n",
       "      <td>0.016878</td>\n",
       "      <td>0.008439</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.957806</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>208 rows × 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Dataset Category Subject_Name  Class     W->S1     W->S2  W->S3  \\\n",
       "0     CAP_Sleep     brux        brux1      1  0.190476  0.009524    0.0   \n",
       "1     CAP_Sleep     brux        brux2      1  0.174603  0.000000    0.0   \n",
       "2     CAP_Sleep      sdb         sdb1      1  0.123288  0.000000    0.0   \n",
       "3     CAP_Sleep      sdb         sdb2      1  0.044872  0.006410    0.0   \n",
       "4     CAP_Sleep      sdb         sdb3      1  0.046948  0.018779    0.0   \n",
       "..          ...      ...          ...    ...       ...       ...    ...   \n",
       "203  Sleep_EDFX        n       ST7191      0  0.242857  0.014286    0.0   \n",
       "204  Sleep_EDFX        n       ST7201      0  0.555556  0.055556    0.0   \n",
       "205  Sleep_EDFX        n       ST7211      0  0.099415  0.000000    0.0   \n",
       "206  Sleep_EDFX        n       ST7221      0  0.180000  0.000000    0.0   \n",
       "207  Sleep_EDFX        n       ST7241      0  0.275862  0.034483    0.0   \n",
       "\n",
       "     W->S4    W->REM     S1->W  ...    S4->S1    S4->S2    S4->S3    S4->S4  \\\n",
       "0      0.0  0.000000  0.030769  ...  0.000000  0.004926  0.024631  0.970443   \n",
       "1      0.0  0.000000  0.061728  ...  0.000000  0.000000  0.012048  0.984940   \n",
       "2      0.0  0.000000  0.099237  ...  0.010152  0.005076  0.030457  0.949239   \n",
       "3      0.0  0.000000  0.011364  ...  0.000000  0.008475  0.016949  0.966102   \n",
       "4      0.0  0.000000  0.108696  ...  0.000000  0.025974  0.038961  0.935065   \n",
       "..     ...       ...       ...  ...       ...       ...       ...       ...   \n",
       "203    0.0  0.000000  0.044118  ...  0.013889  0.013889  0.166667  0.805556   \n",
       "204    0.0  0.055556  0.014493  ...  0.000000  0.038462  0.615385  0.346154   \n",
       "205    0.0  0.005848  0.116667  ...  0.000000  0.016949  0.254237  0.728814   \n",
       "206    0.0  0.000000  0.052133  ...  0.000000  0.000000  0.000000  0.000000   \n",
       "207    0.0  0.068966  0.047619  ...  0.142857  0.142857  0.571429  0.142857   \n",
       "\n",
       "     S4->REM    REM->W   REM->S1   REM->S2  REM->S3  REM->REM  \n",
       "0        0.0  0.033520  0.000000  0.000000      0.0  0.966480  \n",
       "1        0.0  0.019324  0.004831  0.000000      0.0  0.975845  \n",
       "2        0.0  0.009346  0.000000  0.028037      0.0  0.962617  \n",
       "3        0.0  0.000000  0.000000  0.025641      0.0  0.974359  \n",
       "4        0.0  0.062500  0.000000  0.000000      0.0  0.937500  \n",
       "..       ...       ...       ...       ...      ...       ...  \n",
       "203      0.0  0.000000  0.020000  0.015000      0.0  0.965000  \n",
       "204      0.0  0.044776  0.007463  0.014925      0.0  0.932836  \n",
       "205      0.0  0.025641  0.000000  0.019231      0.0  0.955128  \n",
       "206      0.0  0.021645  0.043290  0.000000      0.0  0.935065  \n",
       "207      0.0  0.016878  0.016878  0.008439      0.0  0.957806  \n",
       "\n",
       "[208 rows x 38 columns]"
      ]
     },
     "execution_count": 282,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ts_model \n",
    "processed_dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "id": "secondary-relaxation",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_model[3][6].feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "id": "distinct-certificate",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['W->S1', 'W->S2', 'W->S3', 'W->S4', 'W->REM', 'S1->W', 'S1->S1',\n",
       "        'S1->S2', 'S1->S3', 'S1->S4', 'S1->REM', 'S2->W', 'S2->S1',\n",
       "        'S2->S2', 'S2->S3', 'S2->S4', 'S2->REM', 'S3->W', 'S3->S1',\n",
       "        'S3->S2', 'S3->S3', 'S3->S4', 'S3->REM', 'S4->W', 'S4->S1',\n",
       "        'S4->S2', 'S4->S3', 'S4->S4', 'S4->REM', 'REM->W', 'REM->S1',\n",
       "        'REM->S2', 'REM->S3', 'REM->REM'], dtype=object),\n",
       " array([0.06424144, 0.06910475, 0.        , 0.        , 0.0019275 ,\n",
       "        0.01064262, 0.01663351, 0.02011725, 0.        , 0.        ,\n",
       "        0.01722061, 0.02255312, 0.02964559, 0.06868744, 0.03052843,\n",
       "        0.        , 0.02427807, 0.01375296, 0.0005258 , 0.08010924,\n",
       "        0.1580388 , 0.04769964, 0.        , 0.01180538, 0.00118775,\n",
       "        0.01821783, 0.05968414, 0.12281662, 0.        , 0.02361403,\n",
       "        0.01474488, 0.0396913 , 0.        , 0.0325313 ]))"
      ]
     },
     "execution_count": 377,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ts_model[1][6].best_estimator_.feature_names = ['hi', 'hello', 5, 1.5] \n",
    "ts_model[1][6].feature_names, ts_model[1][6].best_estimator_.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "id": "annual-packaging",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for lll in range(1, 6):\n",
    "#     print(lll, ts_model[lll][6].best_estimator_, len(ts_model[lll][6].feature_names), ts_model[lll][6].best_estimator_.feature_importances_.shape[0], ts_model[lll][6].feature_names, ts_model[lll][6].best_estimator_.feature_importances_) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "id": "bibliographic-acoustic",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rf_feat_importance_df = pd.DataFrame() \n",
    "\n",
    "# for feat_ss in range(1, (splitting_crieteria[0][0]+1)):\n",
    "# # #     print('---> ', feat_ss, rf_feat_importance_df)\n",
    "# #     rf_feat_importance_df[f'Feature-{feat_ss}'] = ts_model[feat_ss][6].feature_names  \n",
    "# # #     print(feat_ss, ts_model[fld_ss][6].best_estimator_.feature_importances_)\n",
    "# #     rf_feat_importance_df[f'Fold-{feat_ss}'] = ts_model[feat_ss][6].best_estimator_.feature_importances_ \n",
    "#     tdf = pd.DataFrame({f'Feature-{feat_ss}': ts_model[feat_ss][6].feature_names,\n",
    "#                        f'Fold-{feat_ss}': ts_model[feat_ss][6].best_estimator_.feature_importances_ }) \n",
    "#     rf_feat_importance_df = pd.concat([rf_feat_importance_df, tdf], axis=1) \n",
    "    \n",
    "# rf_feat_importance_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "id": "about-restriction",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>Fold-1</th>\n",
       "      <th>Fold-2</th>\n",
       "      <th>Fold-3</th>\n",
       "      <th>Fold-4</th>\n",
       "      <th>Fold-5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>W-&gt;S1</td>\n",
       "      <td>0.040020</td>\n",
       "      <td>0.048111</td>\n",
       "      <td>0.064094</td>\n",
       "      <td>0.081140</td>\n",
       "      <td>0.048286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>W-&gt;S2</td>\n",
       "      <td>0.052056</td>\n",
       "      <td>0.032538</td>\n",
       "      <td>0.077730</td>\n",
       "      <td>0.051324</td>\n",
       "      <td>0.065048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>W-&gt;S3</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001050</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>W-&gt;S4</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000519</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>W-&gt;REM</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001828</td>\n",
       "      <td>0.003813</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>S1-&gt;W</td>\n",
       "      <td>0.019573</td>\n",
       "      <td>0.028132</td>\n",
       "      <td>0.032371</td>\n",
       "      <td>0.014908</td>\n",
       "      <td>0.017060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>S1-&gt;S1</td>\n",
       "      <td>0.037258</td>\n",
       "      <td>0.018897</td>\n",
       "      <td>0.017770</td>\n",
       "      <td>0.021126</td>\n",
       "      <td>0.018986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>S1-&gt;S2</td>\n",
       "      <td>0.012524</td>\n",
       "      <td>0.007842</td>\n",
       "      <td>0.021617</td>\n",
       "      <td>0.016889</td>\n",
       "      <td>0.010687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>S1-&gt;S3</td>\n",
       "      <td>0.001264</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000389</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>S1-&gt;S4</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>S1-&gt;REM</td>\n",
       "      <td>0.004776</td>\n",
       "      <td>0.024092</td>\n",
       "      <td>0.014516</td>\n",
       "      <td>0.005890</td>\n",
       "      <td>0.008284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>S2-&gt;W</td>\n",
       "      <td>0.031242</td>\n",
       "      <td>0.013299</td>\n",
       "      <td>0.029737</td>\n",
       "      <td>0.020212</td>\n",
       "      <td>0.029743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>S2-&gt;S1</td>\n",
       "      <td>0.023401</td>\n",
       "      <td>0.018441</td>\n",
       "      <td>0.046602</td>\n",
       "      <td>0.042463</td>\n",
       "      <td>0.039150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>S2-&gt;S2</td>\n",
       "      <td>0.046205</td>\n",
       "      <td>0.065098</td>\n",
       "      <td>0.038685</td>\n",
       "      <td>0.081748</td>\n",
       "      <td>0.047008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>S2-&gt;S3</td>\n",
       "      <td>0.028363</td>\n",
       "      <td>0.042853</td>\n",
       "      <td>0.025906</td>\n",
       "      <td>0.025622</td>\n",
       "      <td>0.043496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>S2-&gt;S4</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>S2-&gt;REM</td>\n",
       "      <td>0.027736</td>\n",
       "      <td>0.011940</td>\n",
       "      <td>0.024289</td>\n",
       "      <td>0.030987</td>\n",
       "      <td>0.038488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>S3-&gt;W</td>\n",
       "      <td>0.013012</td>\n",
       "      <td>0.008159</td>\n",
       "      <td>0.008109</td>\n",
       "      <td>0.011307</td>\n",
       "      <td>0.013703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>S3-&gt;S1</td>\n",
       "      <td>0.004847</td>\n",
       "      <td>0.008524</td>\n",
       "      <td>0.003741</td>\n",
       "      <td>0.006164</td>\n",
       "      <td>0.002506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>S3-&gt;S2</td>\n",
       "      <td>0.119594</td>\n",
       "      <td>0.109855</td>\n",
       "      <td>0.140740</td>\n",
       "      <td>0.043897</td>\n",
       "      <td>0.154539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>S3-&gt;S3</td>\n",
       "      <td>0.232702</td>\n",
       "      <td>0.274747</td>\n",
       "      <td>0.158173</td>\n",
       "      <td>0.173035</td>\n",
       "      <td>0.148293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>S3-&gt;S4</td>\n",
       "      <td>0.017062</td>\n",
       "      <td>0.031109</td>\n",
       "      <td>0.036295</td>\n",
       "      <td>0.054178</td>\n",
       "      <td>0.032518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>S3-&gt;REM</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001985</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>S4-&gt;W</td>\n",
       "      <td>0.009606</td>\n",
       "      <td>0.021991</td>\n",
       "      <td>0.014762</td>\n",
       "      <td>0.009024</td>\n",
       "      <td>0.011622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>S4-&gt;S1</td>\n",
       "      <td>0.014036</td>\n",
       "      <td>0.009885</td>\n",
       "      <td>0.007173</td>\n",
       "      <td>0.005389</td>\n",
       "      <td>0.005261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>S4-&gt;S2</td>\n",
       "      <td>0.011402</td>\n",
       "      <td>0.003451</td>\n",
       "      <td>0.011062</td>\n",
       "      <td>0.019039</td>\n",
       "      <td>0.011611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>S4-&gt;S3</td>\n",
       "      <td>0.038958</td>\n",
       "      <td>0.071407</td>\n",
       "      <td>0.074224</td>\n",
       "      <td>0.032598</td>\n",
       "      <td>0.044163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>S4-&gt;S4</td>\n",
       "      <td>0.150836</td>\n",
       "      <td>0.065678</td>\n",
       "      <td>0.071113</td>\n",
       "      <td>0.163973</td>\n",
       "      <td>0.111747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>S4-&gt;REM</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>REM-&gt;W</td>\n",
       "      <td>0.018583</td>\n",
       "      <td>0.022059</td>\n",
       "      <td>0.024156</td>\n",
       "      <td>0.022293</td>\n",
       "      <td>0.030337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>REM-&gt;S1</td>\n",
       "      <td>0.008523</td>\n",
       "      <td>0.015293</td>\n",
       "      <td>0.009192</td>\n",
       "      <td>0.019656</td>\n",
       "      <td>0.009533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>REM-&gt;S2</td>\n",
       "      <td>0.004213</td>\n",
       "      <td>0.014798</td>\n",
       "      <td>0.015502</td>\n",
       "      <td>0.023814</td>\n",
       "      <td>0.017235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>REM-&gt;S3</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>REM-&gt;REM</td>\n",
       "      <td>0.032208</td>\n",
       "      <td>0.029976</td>\n",
       "      <td>0.024683</td>\n",
       "      <td>0.023323</td>\n",
       "      <td>0.038052</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Feature    Fold-1    Fold-2    Fold-3    Fold-4    Fold-5\n",
       "0      W->S1  0.040020  0.048111  0.064094  0.081140  0.048286\n",
       "1      W->S2  0.052056  0.032538  0.077730  0.051324  0.065048\n",
       "2      W->S3  0.000000  0.000000  0.001050  0.000000  0.000000\n",
       "3      W->S4  0.000000  0.000000  0.000519  0.000000  0.000248\n",
       "4     W->REM  0.000000  0.001828  0.003813  0.000000  0.001737\n",
       "5      S1->W  0.019573  0.028132  0.032371  0.014908  0.017060\n",
       "6     S1->S1  0.037258  0.018897  0.017770  0.021126  0.018986\n",
       "7     S1->S2  0.012524  0.007842  0.021617  0.016889  0.010687\n",
       "8     S1->S3  0.001264  0.000000  0.000389  0.000000  0.000000\n",
       "9     S1->S4  0.000000  0.000000  0.000000  0.000000  0.000657\n",
       "10   S1->REM  0.004776  0.024092  0.014516  0.005890  0.008284\n",
       "11     S2->W  0.031242  0.013299  0.029737  0.020212  0.029743\n",
       "12    S2->S1  0.023401  0.018441  0.046602  0.042463  0.039150\n",
       "13    S2->S2  0.046205  0.065098  0.038685  0.081748  0.047008\n",
       "14    S2->S3  0.028363  0.042853  0.025906  0.025622  0.043496\n",
       "15    S2->S4  0.000000  0.000000  0.000000  0.000000  0.000000\n",
       "16   S2->REM  0.027736  0.011940  0.024289  0.030987  0.038488\n",
       "17     S3->W  0.013012  0.008159  0.008109  0.011307  0.013703\n",
       "18    S3->S1  0.004847  0.008524  0.003741  0.006164  0.002506\n",
       "19    S3->S2  0.119594  0.109855  0.140740  0.043897  0.154539\n",
       "20    S3->S3  0.232702  0.274747  0.158173  0.173035  0.148293\n",
       "21    S3->S4  0.017062  0.031109  0.036295  0.054178  0.032518\n",
       "22   S3->REM  0.000000  0.000000  0.001985  0.000000  0.000000\n",
       "23     S4->W  0.009606  0.021991  0.014762  0.009024  0.011622\n",
       "24    S4->S1  0.014036  0.009885  0.007173  0.005389  0.005261\n",
       "25    S4->S2  0.011402  0.003451  0.011062  0.019039  0.011611\n",
       "26    S4->S3  0.038958  0.071407  0.074224  0.032598  0.044163\n",
       "27    S4->S4  0.150836  0.065678  0.071113  0.163973  0.111747\n",
       "28   S4->REM  0.000000  0.000000  0.000000  0.000000  0.000000\n",
       "29    REM->W  0.018583  0.022059  0.024156  0.022293  0.030337\n",
       "30   REM->S1  0.008523  0.015293  0.009192  0.019656  0.009533\n",
       "31   REM->S2  0.004213  0.014798  0.015502  0.023814  0.017235\n",
       "32   REM->S3  0.000000  0.000000  0.000000  0.000000  0.000000\n",
       "33  REM->REM  0.032208  0.029976  0.024683  0.023323  0.038052"
      ]
     },
     "execution_count": 385,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_feat_importance_df = pd.DataFrame() \n",
    "all_fts = processed_dataset.columns.values[4:]\n",
    "rf_feat_importance_df[f'Feature'] = all_fts \n",
    "# rf_feat_importance_df.set_index([f'Feature'])\n",
    "\n",
    "for feat_ss in range(1, (splitting_crieteria[0][0]+1)):\n",
    "#     print('---> ', feat_ss, rf_feat_importance_df)\n",
    "    fts = ts_model[feat_ss][6].feature_names \n",
    "#     print(feat_ss, ts_model[fld_ss][6].best_estimator_.feature_importances_)\n",
    "    fts_imp = ts_model[feat_ss][6].best_estimator_.feature_importances_ \n",
    "    imp_lst = [fts_imp[fts.index(f)] if (f in fts and fts.index(f)>=0) else None for f in all_fts] # [MM[LL.index(f)] for f in LL if f in NN] \n",
    "    rf_feat_importance_df[f'Fold-{feat_ss}'] = imp_lst \n",
    "    \n",
    "rf_feat_importance_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "id": "needed-encounter",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 326,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "34==23+11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "id": "worth-giant",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./Results/_Classification/ML1003/',\n",
       " './Results/_Classification/ML1003/rf_feat_importance.csv')"
      ]
     },
     "execution_count": 386,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_save_path, f'{result_save_path}rf_feat_importance.csv' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "id": "brazilian-district",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>Fold-1</th>\n",
       "      <th>Fold-2</th>\n",
       "      <th>Fold-3</th>\n",
       "      <th>Fold-4</th>\n",
       "      <th>Fold-5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>W-&gt;S1</td>\n",
       "      <td>0.040020</td>\n",
       "      <td>0.048111</td>\n",
       "      <td>0.064094</td>\n",
       "      <td>0.081140</td>\n",
       "      <td>0.048286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>W-&gt;S2</td>\n",
       "      <td>0.052056</td>\n",
       "      <td>0.032538</td>\n",
       "      <td>0.077730</td>\n",
       "      <td>0.051324</td>\n",
       "      <td>0.065048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>W-&gt;S3</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001050</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>W-&gt;S4</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000519</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>W-&gt;REM</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001828</td>\n",
       "      <td>0.003813</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>S1-&gt;W</td>\n",
       "      <td>0.019573</td>\n",
       "      <td>0.028132</td>\n",
       "      <td>0.032371</td>\n",
       "      <td>0.014908</td>\n",
       "      <td>0.017060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>S1-&gt;S1</td>\n",
       "      <td>0.037258</td>\n",
       "      <td>0.018897</td>\n",
       "      <td>0.017770</td>\n",
       "      <td>0.021126</td>\n",
       "      <td>0.018986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>S1-&gt;S2</td>\n",
       "      <td>0.012524</td>\n",
       "      <td>0.007842</td>\n",
       "      <td>0.021617</td>\n",
       "      <td>0.016889</td>\n",
       "      <td>0.010687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>S1-&gt;S3</td>\n",
       "      <td>0.001264</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000389</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>S1-&gt;S4</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>S1-&gt;REM</td>\n",
       "      <td>0.004776</td>\n",
       "      <td>0.024092</td>\n",
       "      <td>0.014516</td>\n",
       "      <td>0.005890</td>\n",
       "      <td>0.008284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>S2-&gt;W</td>\n",
       "      <td>0.031242</td>\n",
       "      <td>0.013299</td>\n",
       "      <td>0.029737</td>\n",
       "      <td>0.020212</td>\n",
       "      <td>0.029743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>S2-&gt;S1</td>\n",
       "      <td>0.023401</td>\n",
       "      <td>0.018441</td>\n",
       "      <td>0.046602</td>\n",
       "      <td>0.042463</td>\n",
       "      <td>0.039150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>S2-&gt;S2</td>\n",
       "      <td>0.046205</td>\n",
       "      <td>0.065098</td>\n",
       "      <td>0.038685</td>\n",
       "      <td>0.081748</td>\n",
       "      <td>0.047008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>S2-&gt;S3</td>\n",
       "      <td>0.028363</td>\n",
       "      <td>0.042853</td>\n",
       "      <td>0.025906</td>\n",
       "      <td>0.025622</td>\n",
       "      <td>0.043496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>S2-&gt;S4</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>S2-&gt;REM</td>\n",
       "      <td>0.027736</td>\n",
       "      <td>0.011940</td>\n",
       "      <td>0.024289</td>\n",
       "      <td>0.030987</td>\n",
       "      <td>0.038488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>S3-&gt;W</td>\n",
       "      <td>0.013012</td>\n",
       "      <td>0.008159</td>\n",
       "      <td>0.008109</td>\n",
       "      <td>0.011307</td>\n",
       "      <td>0.013703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>S3-&gt;S1</td>\n",
       "      <td>0.004847</td>\n",
       "      <td>0.008524</td>\n",
       "      <td>0.003741</td>\n",
       "      <td>0.006164</td>\n",
       "      <td>0.002506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>S3-&gt;S2</td>\n",
       "      <td>0.119594</td>\n",
       "      <td>0.109855</td>\n",
       "      <td>0.140740</td>\n",
       "      <td>0.043897</td>\n",
       "      <td>0.154539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>S3-&gt;S3</td>\n",
       "      <td>0.232702</td>\n",
       "      <td>0.274747</td>\n",
       "      <td>0.158173</td>\n",
       "      <td>0.173035</td>\n",
       "      <td>0.148293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>S3-&gt;S4</td>\n",
       "      <td>0.017062</td>\n",
       "      <td>0.031109</td>\n",
       "      <td>0.036295</td>\n",
       "      <td>0.054178</td>\n",
       "      <td>0.032518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>S3-&gt;REM</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001985</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>S4-&gt;W</td>\n",
       "      <td>0.009606</td>\n",
       "      <td>0.021991</td>\n",
       "      <td>0.014762</td>\n",
       "      <td>0.009024</td>\n",
       "      <td>0.011622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>S4-&gt;S1</td>\n",
       "      <td>0.014036</td>\n",
       "      <td>0.009885</td>\n",
       "      <td>0.007173</td>\n",
       "      <td>0.005389</td>\n",
       "      <td>0.005261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>S4-&gt;S2</td>\n",
       "      <td>0.011402</td>\n",
       "      <td>0.003451</td>\n",
       "      <td>0.011062</td>\n",
       "      <td>0.019039</td>\n",
       "      <td>0.011611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>S4-&gt;S3</td>\n",
       "      <td>0.038958</td>\n",
       "      <td>0.071407</td>\n",
       "      <td>0.074224</td>\n",
       "      <td>0.032598</td>\n",
       "      <td>0.044163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>S4-&gt;S4</td>\n",
       "      <td>0.150836</td>\n",
       "      <td>0.065678</td>\n",
       "      <td>0.071113</td>\n",
       "      <td>0.163973</td>\n",
       "      <td>0.111747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>S4-&gt;REM</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>REM-&gt;W</td>\n",
       "      <td>0.018583</td>\n",
       "      <td>0.022059</td>\n",
       "      <td>0.024156</td>\n",
       "      <td>0.022293</td>\n",
       "      <td>0.030337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>REM-&gt;S1</td>\n",
       "      <td>0.008523</td>\n",
       "      <td>0.015293</td>\n",
       "      <td>0.009192</td>\n",
       "      <td>0.019656</td>\n",
       "      <td>0.009533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>REM-&gt;S2</td>\n",
       "      <td>0.004213</td>\n",
       "      <td>0.014798</td>\n",
       "      <td>0.015502</td>\n",
       "      <td>0.023814</td>\n",
       "      <td>0.017235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>REM-&gt;S3</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>REM-&gt;REM</td>\n",
       "      <td>0.032208</td>\n",
       "      <td>0.029976</td>\n",
       "      <td>0.024683</td>\n",
       "      <td>0.023323</td>\n",
       "      <td>0.038052</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Feature    Fold-1    Fold-2    Fold-3    Fold-4    Fold-5\n",
       "0      W->S1  0.040020  0.048111  0.064094  0.081140  0.048286\n",
       "1      W->S2  0.052056  0.032538  0.077730  0.051324  0.065048\n",
       "2      W->S3  0.000000  0.000000  0.001050  0.000000  0.000000\n",
       "3      W->S4  0.000000  0.000000  0.000519  0.000000  0.000248\n",
       "4     W->REM  0.000000  0.001828  0.003813  0.000000  0.001737\n",
       "5      S1->W  0.019573  0.028132  0.032371  0.014908  0.017060\n",
       "6     S1->S1  0.037258  0.018897  0.017770  0.021126  0.018986\n",
       "7     S1->S2  0.012524  0.007842  0.021617  0.016889  0.010687\n",
       "8     S1->S3  0.001264  0.000000  0.000389  0.000000  0.000000\n",
       "9     S1->S4  0.000000  0.000000  0.000000  0.000000  0.000657\n",
       "10   S1->REM  0.004776  0.024092  0.014516  0.005890  0.008284\n",
       "11     S2->W  0.031242  0.013299  0.029737  0.020212  0.029743\n",
       "12    S2->S1  0.023401  0.018441  0.046602  0.042463  0.039150\n",
       "13    S2->S2  0.046205  0.065098  0.038685  0.081748  0.047008\n",
       "14    S2->S3  0.028363  0.042853  0.025906  0.025622  0.043496\n",
       "15    S2->S4  0.000000  0.000000  0.000000  0.000000  0.000000\n",
       "16   S2->REM  0.027736  0.011940  0.024289  0.030987  0.038488\n",
       "17     S3->W  0.013012  0.008159  0.008109  0.011307  0.013703\n",
       "18    S3->S1  0.004847  0.008524  0.003741  0.006164  0.002506\n",
       "19    S3->S2  0.119594  0.109855  0.140740  0.043897  0.154539\n",
       "20    S3->S3  0.232702  0.274747  0.158173  0.173035  0.148293\n",
       "21    S3->S4  0.017062  0.031109  0.036295  0.054178  0.032518\n",
       "22   S3->REM  0.000000  0.000000  0.001985  0.000000  0.000000\n",
       "23     S4->W  0.009606  0.021991  0.014762  0.009024  0.011622\n",
       "24    S4->S1  0.014036  0.009885  0.007173  0.005389  0.005261\n",
       "25    S4->S2  0.011402  0.003451  0.011062  0.019039  0.011611\n",
       "26    S4->S3  0.038958  0.071407  0.074224  0.032598  0.044163\n",
       "27    S4->S4  0.150836  0.065678  0.071113  0.163973  0.111747\n",
       "28   S4->REM  0.000000  0.000000  0.000000  0.000000  0.000000\n",
       "29    REM->W  0.018583  0.022059  0.024156  0.022293  0.030337\n",
       "30   REM->S1  0.008523  0.015293  0.009192  0.019656  0.009533\n",
       "31   REM->S2  0.004213  0.014798  0.015502  0.023814  0.017235\n",
       "32   REM->S3  0.000000  0.000000  0.000000  0.000000  0.000000\n",
       "33  REM->REM  0.032208  0.029976  0.024683  0.023323  0.038052"
      ]
     },
     "execution_count": 387,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_feat_importance_df.to_csv(f'{result_save_path}rf_feat_importance.csv', index=False)  \n",
    "rf_feat_importance_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "id": "heavy-logging",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>Fold-1</th>\n",
       "      <th>Fold-2</th>\n",
       "      <th>Fold-3</th>\n",
       "      <th>Fold-4</th>\n",
       "      <th>Fold-5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>W-&gt;S1</td>\n",
       "      <td>0.040020</td>\n",
       "      <td>0.048111</td>\n",
       "      <td>0.064094</td>\n",
       "      <td>0.081140</td>\n",
       "      <td>0.048286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>W-&gt;S2</td>\n",
       "      <td>0.052056</td>\n",
       "      <td>0.032538</td>\n",
       "      <td>0.077730</td>\n",
       "      <td>0.051324</td>\n",
       "      <td>0.065048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>W-&gt;S3</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001050</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>W-&gt;S4</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000519</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>W-&gt;REM</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001828</td>\n",
       "      <td>0.003813</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>S1-&gt;W</td>\n",
       "      <td>0.019573</td>\n",
       "      <td>0.028132</td>\n",
       "      <td>0.032371</td>\n",
       "      <td>0.014908</td>\n",
       "      <td>0.017060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>S1-&gt;S1</td>\n",
       "      <td>0.037258</td>\n",
       "      <td>0.018897</td>\n",
       "      <td>0.017770</td>\n",
       "      <td>0.021126</td>\n",
       "      <td>0.018986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>S1-&gt;S2</td>\n",
       "      <td>0.012524</td>\n",
       "      <td>0.007842</td>\n",
       "      <td>0.021617</td>\n",
       "      <td>0.016889</td>\n",
       "      <td>0.010687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>S1-&gt;S3</td>\n",
       "      <td>0.001264</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000389</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>S1-&gt;S4</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>S1-&gt;REM</td>\n",
       "      <td>0.004776</td>\n",
       "      <td>0.024092</td>\n",
       "      <td>0.014516</td>\n",
       "      <td>0.005890</td>\n",
       "      <td>0.008284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>S2-&gt;W</td>\n",
       "      <td>0.031242</td>\n",
       "      <td>0.013299</td>\n",
       "      <td>0.029737</td>\n",
       "      <td>0.020212</td>\n",
       "      <td>0.029743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>S2-&gt;S1</td>\n",
       "      <td>0.023401</td>\n",
       "      <td>0.018441</td>\n",
       "      <td>0.046602</td>\n",
       "      <td>0.042463</td>\n",
       "      <td>0.039150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>S2-&gt;S2</td>\n",
       "      <td>0.046205</td>\n",
       "      <td>0.065098</td>\n",
       "      <td>0.038685</td>\n",
       "      <td>0.081748</td>\n",
       "      <td>0.047008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>S2-&gt;S3</td>\n",
       "      <td>0.028363</td>\n",
       "      <td>0.042853</td>\n",
       "      <td>0.025906</td>\n",
       "      <td>0.025622</td>\n",
       "      <td>0.043496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>S2-&gt;S4</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>S2-&gt;REM</td>\n",
       "      <td>0.027736</td>\n",
       "      <td>0.011940</td>\n",
       "      <td>0.024289</td>\n",
       "      <td>0.030987</td>\n",
       "      <td>0.038488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>S3-&gt;W</td>\n",
       "      <td>0.013012</td>\n",
       "      <td>0.008159</td>\n",
       "      <td>0.008109</td>\n",
       "      <td>0.011307</td>\n",
       "      <td>0.013703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>S3-&gt;S1</td>\n",
       "      <td>0.004847</td>\n",
       "      <td>0.008524</td>\n",
       "      <td>0.003741</td>\n",
       "      <td>0.006164</td>\n",
       "      <td>0.002506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>S3-&gt;S2</td>\n",
       "      <td>0.119594</td>\n",
       "      <td>0.109855</td>\n",
       "      <td>0.140740</td>\n",
       "      <td>0.043897</td>\n",
       "      <td>0.154539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>S3-&gt;S3</td>\n",
       "      <td>0.232702</td>\n",
       "      <td>0.274747</td>\n",
       "      <td>0.158173</td>\n",
       "      <td>0.173035</td>\n",
       "      <td>0.148293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>S3-&gt;S4</td>\n",
       "      <td>0.017062</td>\n",
       "      <td>0.031109</td>\n",
       "      <td>0.036295</td>\n",
       "      <td>0.054178</td>\n",
       "      <td>0.032518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>S3-&gt;REM</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001985</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>S4-&gt;W</td>\n",
       "      <td>0.009606</td>\n",
       "      <td>0.021991</td>\n",
       "      <td>0.014762</td>\n",
       "      <td>0.009024</td>\n",
       "      <td>0.011622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>S4-&gt;S1</td>\n",
       "      <td>0.014036</td>\n",
       "      <td>0.009885</td>\n",
       "      <td>0.007173</td>\n",
       "      <td>0.005389</td>\n",
       "      <td>0.005261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>S4-&gt;S2</td>\n",
       "      <td>0.011402</td>\n",
       "      <td>0.003451</td>\n",
       "      <td>0.011062</td>\n",
       "      <td>0.019039</td>\n",
       "      <td>0.011611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>S4-&gt;S3</td>\n",
       "      <td>0.038958</td>\n",
       "      <td>0.071407</td>\n",
       "      <td>0.074224</td>\n",
       "      <td>0.032598</td>\n",
       "      <td>0.044163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>S4-&gt;S4</td>\n",
       "      <td>0.150836</td>\n",
       "      <td>0.065678</td>\n",
       "      <td>0.071113</td>\n",
       "      <td>0.163973</td>\n",
       "      <td>0.111747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>S4-&gt;REM</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>REM-&gt;W</td>\n",
       "      <td>0.018583</td>\n",
       "      <td>0.022059</td>\n",
       "      <td>0.024156</td>\n",
       "      <td>0.022293</td>\n",
       "      <td>0.030337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>REM-&gt;S1</td>\n",
       "      <td>0.008523</td>\n",
       "      <td>0.015293</td>\n",
       "      <td>0.009192</td>\n",
       "      <td>0.019656</td>\n",
       "      <td>0.009533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>REM-&gt;S2</td>\n",
       "      <td>0.004213</td>\n",
       "      <td>0.014798</td>\n",
       "      <td>0.015502</td>\n",
       "      <td>0.023814</td>\n",
       "      <td>0.017235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>REM-&gt;S3</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>REM-&gt;REM</td>\n",
       "      <td>0.032208</td>\n",
       "      <td>0.029976</td>\n",
       "      <td>0.024683</td>\n",
       "      <td>0.023323</td>\n",
       "      <td>0.038052</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Feature    Fold-1    Fold-2    Fold-3    Fold-4    Fold-5\n",
       "0      W->S1  0.040020  0.048111  0.064094  0.081140  0.048286\n",
       "1      W->S2  0.052056  0.032538  0.077730  0.051324  0.065048\n",
       "2      W->S3  0.000000  0.000000  0.001050  0.000000  0.000000\n",
       "3      W->S4  0.000000  0.000000  0.000519  0.000000  0.000248\n",
       "4     W->REM  0.000000  0.001828  0.003813  0.000000  0.001737\n",
       "5      S1->W  0.019573  0.028132  0.032371  0.014908  0.017060\n",
       "6     S1->S1  0.037258  0.018897  0.017770  0.021126  0.018986\n",
       "7     S1->S2  0.012524  0.007842  0.021617  0.016889  0.010687\n",
       "8     S1->S3  0.001264  0.000000  0.000389  0.000000  0.000000\n",
       "9     S1->S4  0.000000  0.000000  0.000000  0.000000  0.000657\n",
       "10   S1->REM  0.004776  0.024092  0.014516  0.005890  0.008284\n",
       "11     S2->W  0.031242  0.013299  0.029737  0.020212  0.029743\n",
       "12    S2->S1  0.023401  0.018441  0.046602  0.042463  0.039150\n",
       "13    S2->S2  0.046205  0.065098  0.038685  0.081748  0.047008\n",
       "14    S2->S3  0.028363  0.042853  0.025906  0.025622  0.043496\n",
       "15    S2->S4  0.000000  0.000000  0.000000  0.000000  0.000000\n",
       "16   S2->REM  0.027736  0.011940  0.024289  0.030987  0.038488\n",
       "17     S3->W  0.013012  0.008159  0.008109  0.011307  0.013703\n",
       "18    S3->S1  0.004847  0.008524  0.003741  0.006164  0.002506\n",
       "19    S3->S2  0.119594  0.109855  0.140740  0.043897  0.154539\n",
       "20    S3->S3  0.232702  0.274747  0.158173  0.173035  0.148293\n",
       "21    S3->S4  0.017062  0.031109  0.036295  0.054178  0.032518\n",
       "22   S3->REM  0.000000  0.000000  0.001985  0.000000  0.000000\n",
       "23     S4->W  0.009606  0.021991  0.014762  0.009024  0.011622\n",
       "24    S4->S1  0.014036  0.009885  0.007173  0.005389  0.005261\n",
       "25    S4->S2  0.011402  0.003451  0.011062  0.019039  0.011611\n",
       "26    S4->S3  0.038958  0.071407  0.074224  0.032598  0.044163\n",
       "27    S4->S4  0.150836  0.065678  0.071113  0.163973  0.111747\n",
       "28   S4->REM  0.000000  0.000000  0.000000  0.000000  0.000000\n",
       "29    REM->W  0.018583  0.022059  0.024156  0.022293  0.030337\n",
       "30   REM->S1  0.008523  0.015293  0.009192  0.019656  0.009533\n",
       "31   REM->S2  0.004213  0.014798  0.015502  0.023814  0.017235\n",
       "32   REM->S3  0.000000  0.000000  0.000000  0.000000  0.000000\n",
       "33  REM->REM  0.032208  0.029976  0.024683  0.023323  0.038052"
      ]
     },
     "execution_count": 388,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_feat_importance_df = pd.read_csv(f'{result_save_path}rf_feat_importance.csv') \n",
    "rf_feat_importance_df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "technical-reform",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eight-heavy",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "liquid-barcelona",
   "metadata": {},
   "source": [
    "# ML Classifier class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "collected-voice",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Data preprocessor class \n",
    "from scipy.stats import ttest_ind\n",
    "\n",
    "class DataPreprocessor():\n",
    "    \n",
    "    def __init__(self):\n",
    "        return\n",
    "    \n",
    "    def calculate_p_and_auc_for_feature(self, feat_data, label_data, binary_class=True): \n",
    "        # Extract the independent variable and dependent variable as dataframe and series \n",
    "        X = feat_data.copy()  # Replace 'independent_variable' with your column name\n",
    "        y = label_data.copy()  # Replace 'dependent_variable' with your column name\n",
    "        # print(X, y) \n",
    "        #print(\"111 Binary classification?\", binary_class)\n",
    "\n",
    "        # Perform a one-way ANOVA and calculate the p-value\n",
    "        p_value = 1.0\n",
    "        if binary_class:\n",
    "            _, p_value = ttest_ind(X[y==0], X[y==1])  # Assuming binary classification \n",
    "            #print(\"222 Binary classification?\", binary_class)\n",
    "        else: \n",
    "            groups = [X[y == label] for label in np.unique(y)] # For multiclass classification \n",
    "            _, p_value = f_oneway(*groups)\n",
    "            #print(\"222 Not binary classification?\", binary_class)\n",
    "        p_value = p_value[0] \n",
    "\n",
    "        # Display the p-value\n",
    "        #print(\"P-value:\", p_value)\n",
    "\n",
    "        # Encode the target variable - For multiclass \n",
    "        if not binary_class: \n",
    "            label_encoder = LabelEncoder()\n",
    "            y = label_encoder.fit_transform(y)\n",
    "            #print(\"333 Not binary classification?\", binary_class)\n",
    "\n",
    "        # Fit a logistic regression model and calculate the AUC\n",
    "        model = None \n",
    "        #if binary_class:\n",
    "        #    model = LogisticRegression()\n",
    "        #else:\n",
    "        #    model = LogisticRegression(multi_class='multinomial', solver='lbfgs')\n",
    "        # model = LogisticRegression()\n",
    "        # model = LogisticRegression(multi_class='multinomial', solver='lbfgs')\n",
    "        model = SVC(probability=True)\n",
    "        # model = SVC(C=1.0, random_state=1, kernel='linear', probability=True)\n",
    "        model.fit(X, y)\n",
    "        y_pred_proba = model.predict_proba(X)\n",
    "        if binary_class: \n",
    "            y_pred_proba = y_pred_proba[:, 1]\n",
    "            #print(\"444 Binary classification?\", binary_class)\n",
    "\n",
    "        # print(y_pred_proba) \n",
    "        auc = 0.0 \n",
    "        if binary_class:\n",
    "            auc = roc_auc_score(y, y_pred_proba)\n",
    "            #print(\"555 Binary classification?\", binary_class)\n",
    "        else:\n",
    "            auc = roc_auc_score(y, y_pred_proba, multi_class='ovr')\n",
    "            #print(\"555 Not binary classification?\", binary_class)\n",
    "\n",
    "        # Display the AUC\n",
    "        #print(\"AUC:\", auc)\n",
    "        return p_value, auc \n",
    "    \n",
    "    def calculate_p_and_auc_for_dataset(self, all_feats_df, label_df, binary_class=True): \n",
    "        feat_cols = all_feats_df.columns.values.tolist() \n",
    "\n",
    "        all_p_list = [] \n",
    "        all_auc_list = [] \n",
    "        for ft in feat_cols:\n",
    "            feat_data = all_feats_df[[ft]].copy() \n",
    "            label_data = label_df.copy() \n",
    "            # print(\"HHHHHH\", feat_data.shape, type(feat_data), label_data.shape, type(label_data), binary_class)\n",
    "            p, auc = self.calculate_p_and_auc_for_feature(feat_data, label_data, binary_class=binary_class) \n",
    "            all_p_list.append(p) \n",
    "            all_auc_list.append(auc) \n",
    "\n",
    "        all_p_and_auc_df = pd.DataFrame( {\"Features\": feat_cols, f\"P_Value_{'bin' if binary_class else 'multi'}\": all_p_list, f\"AUC_{'bin' if binary_class else 'multi'}\": all_auc_list} )    \n",
    "        return all_p_and_auc_df \n",
    "    \n",
    "    def get_selected_feature_list_based_on_PAUC(self, tmp_df, p_threshold=0.05, auc_threshold=0.5, sort=False): \n",
    "        cols = tmp_df['Features'].values.tolist() \n",
    "        if p_threshold:\n",
    "            tmp_df = tmp_df[(tmp_df['P_Value_bin']<=p_threshold)]\n",
    "        if auc_threshold:\n",
    "            tmp_df = tmp_df[(tmp_df['AUC_bin']>=auc_threshold)]\n",
    "        if sort:\n",
    "            tmp_df = tmp_df.sort_values(['P_Value_bin', 'AUC_bin'], ascending = [True, False])\n",
    "        selected_features = tmp_df['Features'].values.tolist() \n",
    "        return selected_features\n",
    "    \n",
    "    def select_pandauc_based_features(self, all_feats_df, label_df, binary_class=True, p_threshold=None, auc_threshold=None, sort=False): \n",
    "        tmp_df = self.calculate_p_and_auc_for_dataset(all_feats_df, label_df, binary_class=binary_class)\n",
    "        selected_features = self.get_selected_feature_list_based_on_PAUC(tmp_df, p_threshold=p_threshold, auc_threshold=auc_threshold, sort=sort)        \n",
    "        return selected_features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "opposed-prefix",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Custom splitter class \n",
    "import math\n",
    "from sklearn.model_selection import BaseCrossValidator\n",
    "\n",
    "# class MyCustomSplitter(BaseCrossValidator):\n",
    "class MyCustomSplitter():\n",
    "#     def __init__(self, n_splits):\n",
    "#         self.n_splits = n_splits\n",
    "        \n",
    "#     def set_criteria(self, splt_cri, groups=[['n'], ['SC', 'ST']]):\n",
    "#         self.splt_cri = splt_cri\n",
    "#         self.groups = groups\n",
    "        \n",
    "    def __init__(self, splt_cri, groups=[['n'], ['SC', 'ST']]):\n",
    "        self.splt_cri = splt_cri\n",
    "        self.groups = groups\n",
    "\n",
    "    def split(self, x, y=None):\n",
    "        groups = self.groups \n",
    "        fold = self.splt_cri[0] \n",
    "        percent = self.splt_cri[1]\n",
    "        y = np.array(y) \n",
    "        unique_y = np.unique(y)\n",
    "        num_y = len(unique_y)\n",
    "        y_indices = np.arange(num_y)\n",
    "        # print('AAAA--->> ', unique_y, y_indices)\n",
    "\n",
    "        remain_x = [i for i,v in enumerate(x)]\n",
    "        all_filterred_x = []\n",
    "        for grp in groups:\n",
    "            # print('Group', grp)\n",
    "            tmp_filterred_x = [] \n",
    "            for it in grp: \n",
    "                gg = f\"^{it}\\d\"\n",
    "                r = re.compile(gg) \n",
    "                filterred_x = list(filter(r.match, x))\n",
    "                # print('BBBB--->> ', gg, filterred_x) \n",
    "                filterred_x_ind = [i for i,v in enumerate(x) if v in filterred_x]\n",
    "                tmp_filterred_x.extend(filterred_x_ind) \n",
    "                # tmp_filterred_x.extend(filterred_x) \n",
    "            remain_x = [i for i in remain_x if i not in tmp_filterred_x] \n",
    "            all_filterred_x.append(tmp_filterred_x) \n",
    "            # print('CCCC--->> ', all_filterred_x)\n",
    "            # print('222--->', grp, remain_x) \n",
    "\n",
    "        # print('--->', remain_x) \n",
    "        remain_x_ind = [i for i,v in enumerate(x) if i in remain_x]\n",
    "        all_filterred_x.append(remain_x_ind) \n",
    "        # all_filterred_x.append(remain_x)     \n",
    "        all_dat = [item for row in all_filterred_x for item in row]\n",
    "        # print('DDDD--->> ', all_filterred_x, all_dat)\n",
    "\n",
    "        num_groups = len(all_filterred_x) \n",
    "        groups_item_len = [len(it) for it in all_filterred_x] \n",
    "        groups_item_ratio = [int(it/fold) if (it/fold)==int(it/fold) else int(it/fold+1) for it in groups_item_len] \n",
    "        # print('EEEE--->> ', num_groups, groups_item_len, groups_item_ratio)\n",
    "\n",
    "        main_grps = [it//fold  for it in groups_item_len]  # math.floor(it/fold) \n",
    "        ext_grps = [it%fold for it in groups_item_len] \n",
    "        # print('FFFF--->> ', main_grps, ext_grps)  \n",
    "\n",
    "        all_fold_values = [[] for _ in range(fold)] \n",
    "        for i, dat in enumerate(all_fold_values):\n",
    "            test_dat = [] \n",
    "            for l, (j,k,fd) in enumerate(zip(main_grps, ext_grps, all_filterred_x)): \n",
    "                # print('---->> ', i, j, k, i*j, i*j+j*1, i<k, fold*j+i)\n",
    "                dd = fd[i*j : i*j+j*1]\n",
    "                ex_dd = [fd[fold*j+i]] if i<k else []\n",
    "                dd.extend(ex_dd)\n",
    "                # print('---->> ', i, j, k, i*j, i*j+j*1, i<k, fold*j+i, dd, ex_dd)\n",
    "                test_dat.extend( dd ) \n",
    "            test_dat = list(set(test_dat))\n",
    "            train_dat = list( set(all_dat)-set(test_dat) ) \n",
    "            # print('GGGG--->> ', test_dat, train_dat)\n",
    "            yield train_dat, test_dat "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "id": "sixth-ranking",
   "metadata": {},
   "outputs": [],
   "source": [
    "### ML Classifier class \n",
    "##### import random\n",
    "import multiprocessing as mp\n",
    "\n",
    "from sklearn.model_selection import StratifiedShuffleSplit, StratifiedKFold, ShuffleSplit, LeavePOut, KFold, ParameterGrid\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "\n",
    "\n",
    "\n",
    "###########################################################\n",
    "# HumachLab_ML_CLassifiers     \n",
    "\n",
    "\n",
    "\n",
    "# ### All models' implementation\n",
    "\n",
    "class HumachLab_ML_CLassifiers:\n",
    "    \n",
    "    def print_message(self):\n",
    "#         ---------------------------------------------------------------------------------------------------\n",
    "#         ===================================================================================================\n",
    "#         ###################################################################################################\n",
    "#         ***************************************************************************************************\n",
    "        self.logger.info(f\"Hello from HumachLab_ML_CLassifiers class\")\n",
    "    \n",
    "    \n",
    "    \n",
    "    def __init__(self, logger, directory, dataset, class_name, label_map, metadata_column, split_column, random_state_value, split_balance_pattern, check_result=False): \n",
    "        self.logger = logger \n",
    "        self.directory = directory\n",
    "        self.dataset = dataset \n",
    "        self.class_name = class_name\n",
    "        self.label_map = label_map\n",
    "        self.metadata_column = metadata_column\n",
    "        self.split_column = split_column \n",
    "        self.is_multiclass = True if len(dataset[class_name].unique().tolist())>2 else False\n",
    "        self.random_state_value = random_state_value\n",
    "        self.split_balance_pattern = split_balance_pattern\n",
    "        if not check_result:\n",
    "            self.experiment_info = {\n",
    "                'logger':logger, 'directory':directory, 'dataset_size':dataset.shape, 'dataset_columns':dataset.columns.values.tolist(), 'metadata_column':metadata_column, \n",
    "                'class_name':class_name, 'label_map':label_map, 'split_column':split_column, 'total_unique_classes':dataset[class_name].value_counts().keys().tolist(), \n",
    "                'total_unique_classes':dataset[class_name].value_counts().values.tolist()\n",
    "                }\n",
    "        \n",
    "        self.best_model_scoring_metrics=[ML_Performace_Metrics.RECL, ML_Performace_Metrics.F1SCR] \n",
    "        \n",
    "        self.logger.info(f\"\"\"\n",
    "        Object is initialised with the following properties: \n",
    "        ###################################################################################################\n",
    "        Dataset size: {self.dataset.shape}, Columns: {self.dataset.columns.values.tolist()}\n",
    "        Target class column name: {self.class_name}\n",
    "        Metadata column names: {self.metadata_column}\n",
    "        Dataset split column on which the training and test sets will be devided: {self.split_column}\n",
    "        Is multi-class classification: {self.is_multiclass}\n",
    "        \"\"\") \n",
    "        return  \n",
    "    \n",
    "    \n",
    "    def convert_list_to_string(self, lst):\n",
    "        lst = [str(l) for l in lst]        \n",
    "        return '* '.join(lst) \n",
    "    \n",
    "    \n",
    "    \n",
    "    def classify(self, should_use_params, splitting_crieteria, model_list, is_validate_models, result_save_path, exp_name, exp_detail, apply_feature_selection, custom_splitter):\n",
    "        self.splitting_crieteria = splitting_crieteria    ### for test & training (validation) splitting_crieteria (n): n=0 -loso, n>0 -n-fold, n<0 -shuffled random splitting with n% testing\n",
    "        self.model_list = model_list \n",
    "        self.should_use_params = should_use_params\n",
    "        self.is_validate_models = is_validate_models \n",
    "        self.result_save_path = result_save_path \n",
    "        self.exp_name = exp_name \n",
    "        self.exp_detail = exp_detail \n",
    "        self.is_binary_classification = not self.is_multiclass\n",
    "        self.apply_feature_selection = apply_feature_selection \n",
    "        self.selected_features = None \n",
    "        self.custom_splitter = custom_splitter\n",
    "        \n",
    "        # self.experiment_info['exp_name'] = exp_name \n",
    "        self.experiment_info.update(exp_detail)\n",
    "        self.experiment_info['apply_feature_selection'] = apply_feature_selection\n",
    "        #self.experiment_info['selected_features'] = self.selected_features \n",
    "        self.experiment_info['is_multiclass_classification'] = self.is_multiclass\n",
    "        self.experiment_info['model_list'] = model_list \n",
    "        self.experiment_info['should_use_params'] = should_use_params\n",
    "        self.experiment_info['is_validate_models'] = is_validate_models\n",
    "        self.experiment_info['result_save_path'] = result_save_path\n",
    "        self.experiment_info['random_state_value'] = self.random_state_value \n",
    "        self.experiment_info['custom_splitter'] = self.custom_splitter\n",
    "        self.experiment_info['split_balance_pattern'] = self.split_balance_pattern\n",
    "        tmp = splitting_crieteria[0] \n",
    "        self.experiment_info['test_split_crieteria'] = tmp \n",
    "        self.experiment_info['test_split_details'] = f'Leave-one-out' if tmp[0]==0 else (f'{tmp[0]}-fold cross validation' if (tmp[0]>0 and tmp[1]<=0) else f'{tmp[0]}-fold {tmp[1]}% random test splitting') \n",
    "        tmp = splitting_crieteria[1] \n",
    "        self.experiment_info['training_split_crieteria'] = tmp \n",
    "        self.experiment_info['training_split_details'] = f'Leave-one-out' if tmp[0]==0 else (f'{tmp[0]}-fold cross validation' if (tmp[0]>0 and tmp[1]<=0) else f'{tmp[0]}-fold {tmp[1]}% random test splitting') \n",
    "        self.experiment_info['model_selection_matrics'] = self.best_model_scoring_metrics \n",
    "                                                                                                  \n",
    "                                                                                                                      \n",
    "        self.logger.info(f\"\"\"\n",
    "        Classification is set with the following parameters: \n",
    "        ###################################################################################################\n",
    "        Splitting crieteria: {self.splitting_crieteria}\n",
    "        Test split: {f'Leave-one-out' if splitting_crieteria[0] [0]==0 else (f'{splitting_crieteria[0] [0]}-fold cross validation' if (splitting_crieteria[0] [0]>0 and splitting_crieteria[0] [1]<=0) else f'{splitting_crieteria[0] [0]}-fold {splitting_crieteria[0] [1]}% random test splitting') }\n",
    "        Training split: {f'Leave-one-out' if splitting_crieteria[1] [0]==0 else (f'{splitting_crieteria[1] [0]}-fold cross validation' if (splitting_crieteria[1] [0]>0 and splitting_crieteria[1] [1]<=0) else f'{splitting_crieteria[1] [0]}-fold {splitting_crieteria[1] [1]}% random test splitting') }\n",
    "        List of ML models that will be applied: {[mn.value for mn in self.model_list]}\n",
    "        Use parameters for model: {self.should_use_params}\n",
    "        Is validate the model (or only train): {self.is_validate_models} \n",
    "        Classification results will be saved in the directory: {self.result_save_path}\n",
    "        \"\"\") \n",
    "        all_exp_info_df = pd.DataFrame(self.experiment_info.items(), columns=['Information', 'Description']) \n",
    "        all_best_tr_model, all_tr_model, all_tr_scores_df, all_tr_prediction_df, all_ts_model, all_ts_scores_df, all_ts_prediction_df, all_ts_fold_info_df  = self.test() \n",
    "        \n",
    "        self.save_results(self.directory, all_best_tr_model, all_tr_model, all_tr_scores_df, all_tr_prediction_df, all_ts_model, all_ts_scores_df, all_ts_prediction_df, all_ts_fold_info_df, all_exp_info_df) \n",
    "        \n",
    "        return all_best_tr_model, all_tr_model, all_tr_scores_df, all_tr_prediction_df, all_ts_model, all_ts_scores_df, all_ts_prediction_df, all_ts_fold_info_df, all_exp_info_df \n",
    "    \n",
    "    \n",
    "    \n",
    "    def load_results(self, save_directory):\n",
    "        # './Results/_Classification/ML001/'\n",
    "        self.logger.info(f\"\"\"\n",
    "        Data is being loaded from: {save_directory}\n",
    "        \"\"\") \n",
    "        save_path = f\"{save_directory}all_tr_scores.csv\" \n",
    "        all_tr_scores_df = pd.read_csv(save_path) \n",
    "        \n",
    "        save_path = f\"{save_directory}all_tr_prediction.csv\" \n",
    "        all_tr_prediction_df = pd.read_csv(save_path) \n",
    "        \n",
    "        save_path = f\"{save_directory}all_ts_scores.csv\" \n",
    "        all_ts_scores_df = pd.read_csv(save_path) \n",
    "        \n",
    "        save_path = f\"{save_directory}all_ts_prediction.csv\" \n",
    "        all_ts_prediction_df = pd.read_csv(save_path)         \n",
    "        \n",
    "        save_path = f\"{save_directory}all_ts_fold_info.csv\" \n",
    "        all_ts_fold_info_df = pd.read_csv(save_path)         \n",
    "        \n",
    "        save_path = f\"{save_directory}all_exp_info.csv\" \n",
    "        all_exp_info_df = pd.read_csv(save_path)  \n",
    "        \n",
    "        new_save_directory = f\"{save_directory}/Models/\"\n",
    "        \n",
    "        save_path = f\"{new_save_directory}ts_model\" \n",
    "        all_ts_model = self.load_models_from_file(save_path, 'Test Models')\n",
    "        \n",
    "        save_path = f\"{new_save_directory}tr_model\" \n",
    "        all_tr_model = self.load_models_from_file(save_path, 'Training Models')\n",
    "        \n",
    "        save_path = f\"{new_save_directory}best_tr_model\" \n",
    "        all_best_tr_model = self.load_models_from_file(save_path, 'Best Training Models')\n",
    "        \n",
    "        return all_best_tr_model, all_tr_model, all_tr_scores_df, all_tr_prediction_df, all_ts_model, all_ts_scores_df, all_ts_prediction_df, all_ts_fold_info_df, all_exp_info_df \n",
    "\n",
    "\n",
    "    def load_models_from_file(self, save_path, model_type):\n",
    "        models_dict = {} \n",
    "        \n",
    "        save_path = f'{save_path}*'\n",
    "        files = self.sort_string_list(glob.glob(save_path)) \n",
    "        files\n",
    "        selected_files = [[int(fn) for fn in f[len(save_path):].split('.')[0].split('_')] for f in files]\n",
    "        selected_files\n",
    "        \n",
    "        self.logger.info(f'Start retrieving {model_type} model from file...')\n",
    "        model_dict = {}  \n",
    "        for i, (ind, fl) in enumerate(zip(selected_files, files)):\n",
    "            if len(ind)==3:\n",
    "                tsi, tri, modi = ind\n",
    "                mod = None \n",
    "                with open(fl, \"rb\") as f:\n",
    "                    mod = pickle.load(f) \n",
    "                if tsi not in model_dict.keys(): \n",
    "                    model_dict[tsi] = {}\n",
    "                if tri not in model_dict[tsi].keys(): \n",
    "                    model_dict[tsi][tri] = {} \n",
    "                if modi not in model_dict[tsi][tri].keys(): \n",
    "                    model_dict[tsi][tri][modi] = mod \n",
    "            elif len(ind)==2:\n",
    "                tsi, modi = ind\n",
    "                mod = None \n",
    "                with open(fl, \"rb\") as f:\n",
    "                    mod = pickle.load(f) \n",
    "                if tsi not in model_dict.keys(): \n",
    "                    model_dict[tsi] = {}\n",
    "                if modi not in model_dict[tsi].keys(): \n",
    "                    model_dict[tsi][modi] = mod \n",
    "            else:\n",
    "                self.logger.info(f'Doesn\\'t identify {model_type} model file to retrieve...')\n",
    "        \n",
    "        model_dict\n",
    "        self.logger.info(f'Finish retrieving {model_type} model from file...')\n",
    "        return model_dict \n",
    "    \n",
    "    \n",
    "    \n",
    "    def sort_string_list(self, string_list):\n",
    "        ## ref: https://blog.codinghorror.com/sorting-for-humans-natural-sort-order/\n",
    "        \"\"\" Sort the given list in the way that humans expect.\n",
    "        \"\"\"\n",
    "        convert = lambda text: int(text) if text.isdigit() else text\n",
    "        alphanum_key = lambda key: [ convert(c.replace(\"_\",\"\")) for c in re.split('([0-9]+)', key) ]\n",
    "        string_list.sort( key=alphanum_key )\n",
    "        return string_list\n",
    "    \n",
    "    \n",
    "        \n",
    "    def save_results(self, save_directory, all_best_tr_model, all_tr_model, all_tr_scores_df, all_tr_prediction_df, all_ts_model, all_ts_scores_df, all_ts_prediction_df, all_ts_fold_info_df, all_exp_info_df):\n",
    "        # './Results/_Classification/ML001/'\n",
    "        save_path = f\"{save_directory}all_tr_scores.csv\" \n",
    "        all_tr_scores_df.to_csv(save_path, index=False) \n",
    "        \n",
    "        save_path = f\"{save_directory}all_tr_prediction.csv\" \n",
    "        all_tr_prediction_df.to_csv(save_path, index=False) \n",
    "        \n",
    "        save_path = f\"{save_directory}all_ts_scores.csv\" \n",
    "        all_ts_scores_df.to_csv(save_path, index=False) \n",
    "        \n",
    "        save_path = f\"{save_directory}all_ts_prediction.csv\" \n",
    "        all_ts_prediction_df.to_csv(save_path, index=False) \n",
    "        \n",
    "        save_path = f\"{save_directory}all_ts_fold_info.csv\" \n",
    "        all_ts_fold_info_df.to_csv(save_path, index=False) \n",
    "        \n",
    "        save_path = f\"{save_directory}all_exp_info.csv\" \n",
    "        all_exp_info_df.to_csv(save_path, index=False) \n",
    "        \n",
    "        new_save_directory = self.create_directory(save_directory, 'Models')\n",
    "        \n",
    "        save_path = f\"{new_save_directory}ts_model\" \n",
    "        self.save_models_to_file(save_path, all_ts_model, 'Test Models')\n",
    "        \n",
    "        save_path = f\"{new_save_directory}tr_model\" \n",
    "        self.save_models_to_file(save_path, all_tr_model, 'Training Models')\n",
    "        \n",
    "        save_path = f\"{new_save_directory}best_tr_model\" \n",
    "        self.save_models_to_file(save_path, all_best_tr_model, 'Best Training Models')\n",
    "        \n",
    "        return\n",
    "    \n",
    "    \n",
    "    def create_directory(self, path, dir_name): \n",
    "        new_directory = f\"{path}/{dir_name}/\"\n",
    "        \n",
    "        if (not os.path.exists(new_directory)):\n",
    "            try:\n",
    "                os.makedirs(new_directory, exist_ok = True)\n",
    "                print(f\"Directory successfully created at path: {new_directory}\") \n",
    "            except OSError as error:\n",
    "                print(f\"Directory cannot be created at path: {new_directory}\") \n",
    "        else:\n",
    "            print(f\"Directory already exists at path: {new_directory}\") \n",
    "            \n",
    "        return new_directory\n",
    "\n",
    "\n",
    "    def save_models_to_file(self, save_path, models_dict, model_type):\n",
    "        self.logger.info(f'Start saving model to file...')\n",
    "        if model_type=='Training Models':\n",
    "            for tsfi, ts_dat in models_dict.items():\n",
    "                for trfi, tr_dat in ts_dat.items():\n",
    "                    for modi, mod in tr_dat.items():\n",
    "                        new_save_path = f'{save_path}_{tsfi}_{trfi}_{modi}.dat'\n",
    "                        try:\n",
    "                            with open(new_save_path, 'wb') as f:\n",
    "                                pickle.dump(mod, f)\n",
    "                                print( f'{model_type} is written to the file: {new_save_path}\\n' )\n",
    "                        except:\n",
    "                            print( f'Problem creating {model_type} file: {new_save_path}\\n' )\n",
    "        else:\n",
    "            for tsfi, ts_dat in models_dict.items():\n",
    "                for modi, mod in ts_dat.items():\n",
    "                    new_save_path = f'{save_path}_{tsfi}_{modi}.dat'\n",
    "                    try:\n",
    "                        with open(new_save_path, 'wb') as f:\n",
    "                            pickle.dump(mod, f)\n",
    "                            print( f'{model_type} is written to the file: {new_save_path}\\n' )\n",
    "                    except:\n",
    "                        print( f'Problem creating {model_type} file: {new_save_path}\\n' )\n",
    "        self.logger.info(f'Finish saving model to file...')\n",
    "        return\n",
    "    \n",
    "    \n",
    "    \n",
    "    def evaluate_test_data(self, ind, model_list, test_ids, best_tr_model):\n",
    "        self.logger.info(f\"\"\"\n",
    "        ### MODEL EVALUATION PHASE \n",
    "        EVALUATION {ind} START... XXXXX \n",
    "        ---------------------------------------------------------------------------------------------------\n",
    "        \"\"\") \n",
    "        #print(\"HHHHHH3333\", best_tr_model)\n",
    "        \n",
    "        X_test, y_test, meta_dat_df = self._get_data_from_indices(test_ids)\n",
    "        #print(\"meta33->\", meta_dat_df)     \n",
    "#         ### Call features selection algorithm \n",
    "#         if self.selected_features: \n",
    "#             X_test = X_test[self.selected_features]\n",
    "        \n",
    "        \n",
    "        ts_score_df, ts_prediction_df = pd.DataFrame(), pd.DataFrame() \n",
    "        # all_ts_model, all_ts_scores_df, all_ts_prediction_df = {}, pd.DataFrame(), pd.DataFrame()\n",
    "        for (modi, model), classifier_method in zip(best_tr_model.items(), model_list) : \n",
    "            y_pred = model.predict(X_test) \n",
    "            y_pred_proba = model.predict_proba(X_test) \n",
    "            if modi==1:\n",
    "                # meta_dat_df.reset_index(drop=True, inplace=True) \n",
    "                ts_prediction_df = pd.concat([ts_prediction_df, meta_dat_df]) \n",
    "                ts_prediction_df.reset_index(drop=True, inplace=True) \n",
    "                ts_prediction_df[self.class_name] = y_test \n",
    "                \n",
    "            ts_prediction_df[f\"Prediction_{ML_Classifiers.get_short_form(str(classifier_method.value))}\"] = y_pred \n",
    "            for p_ind in range(y_pred_proba.shape[1]):\n",
    "                ts_prediction_df[f\"Prediction_Proba_{p_ind}_{ML_Classifiers.get_short_form(str(classifier_method.value))}\"] = y_pred_proba[:, p_ind].tolist()\n",
    "            \n",
    "            scores_df = self.calculate_model_scores(model, y_test, y_pred, y_pred_proba)\n",
    "            scores_df.insert(0, \"Model_No\", modi) \n",
    "            ts_score_df = pd.concat([ts_score_df, scores_df]) \n",
    "            \n",
    "        ts_score_df.insert(0, \"Test_No\", ind) \n",
    "        ts_prediction_df.insert(0, \"Test_No\", ind) \n",
    "        return ts_score_df, ts_prediction_df \n",
    "    \n",
    "    \n",
    "    \n",
    "    def test(self):\n",
    "        # splitter = self.get_data_splitter(self.splitting_crieteria[0], stratified=True, custom=True) #Test split cusomised: usually LOSO or 10-fold \n",
    "        # splitter = self.get_data_splitter(self.splitting_crieteria[0], stratified=True, custom=False) #Test split: usually LOSO or 10-fold \n",
    "        splitter = self.get_data_splitter(self.splitting_crieteria[0], stratified=True, custom=self.custom_splitter) #Test split cusomised: usually LOSO or 10-fold \n",
    "        split_data_list = self.dataset[self.split_column].values.tolist() \n",
    "        class_data_list = self.dataset[self.class_name].values.tolist() \n",
    "        \n",
    "        all_ts_model, all_ts_scores_df, all_ts_prediction_df, all_ts_fold_info_df = {}, pd.DataFrame(), pd.DataFrame(), pd.DataFrame()  \n",
    "        cum_best_tr_model, cum_tr_model, cum_tr_scores_df, cum_tr_prediction_df, cum_tr_fold_info_df = {}, {}, pd.DataFrame(), pd.DataFrame(), pd.DataFrame()\n",
    "        for tsi, (train_all_ids, test_ids) in enumerate(splitter.split(split_data_list, class_data_list)): \n",
    "            ### Train-test split: fold based \n",
    "            ts_dat = self.dataset[self.split_column][test_ids].values.tolist() \n",
    "            tr_all_dat = self.dataset[self.split_column][train_all_ids].values.tolist() \n",
    "            ind = tsi+1 \n",
    "            self.selected_features = None ### Resetting feature selection list \n",
    "            self.logger.info(f\"\"\"\n",
    "            ### MODEL TEST PHASE \n",
    "            TEST {ind} START... XXXXX \n",
    "            ===================================================================================================\n",
    "            Test=> {len(ts_dat)} {(ts_dat)} \n",
    "            Training (Including Validation)=> {len(tr_all_dat)} {(tr_all_dat)} \n",
    "            \"\"\") \n",
    "            best_tr_model, all_tr_model, all_tr_scores_df, all_tr_prediction_df, all_tr_fold_info_df = self.train(ind, model_list, train_all_ids, tr_splitting_crieteria=self.splitting_crieteria[1]) #tr_splitting_crieteria: <0 random split, >0 fold\n",
    "            cum_tr_model[ind] = all_tr_model \n",
    "            cum_best_tr_model[ind] = best_tr_model \n",
    "            if self.is_validate_models:\n",
    "                all_tr_scores_df.insert(0, \"Test_No\", ind) \n",
    "                all_tr_prediction_df.insert(0, \"Test_No\", ind) \n",
    "            all_tr_fold_info_df.insert(0, \"Test_No\", ind) \n",
    "            all_tr_fold_info_df.insert(4, \"Test\", [ts_dat]*all_tr_fold_info_df.shape[0]) \n",
    "            all_tr_fold_info_df.insert(4, \"Selected_Features\", [self.selected_features]*all_tr_fold_info_df.shape[0]) \n",
    "            \n",
    "            cum_tr_scores_df = pd.concat([cum_tr_scores_df, all_tr_scores_df]) \n",
    "            cum_tr_prediction_df = pd.concat([cum_tr_prediction_df, all_tr_prediction_df])\n",
    "            all_ts_fold_info_df = pd.concat([all_ts_fold_info_df, all_tr_fold_info_df])\n",
    "            \n",
    "            cum_tr_scores_df.reset_index(drop=True, inplace=True) \n",
    "            cum_tr_prediction_df.reset_index(drop=True, inplace=True) \n",
    "            all_ts_fold_info_df.reset_index(drop=True, inplace=True) \n",
    "            \n",
    "#             print(\"TTTT\", best_tr_model.keys(), best_tr_model, all_tr_scores_df.shape, all_tr_scores_df.columns, all_tr_prediction_df.shape, all_tr_prediction_df.columns) \n",
    "                        \n",
    "            ###############\n",
    "            ### Model evaluation with the test data using the best trained model  \n",
    "            all_ts_model[ind] = best_tr_model\n",
    "            ts_score_df, ts_prediction_df = self.evaluate_test_data(ind, model_list, test_ids, best_tr_model) \n",
    "            \n",
    "            all_ts_scores_df = pd.concat([all_ts_scores_df, ts_score_df]) \n",
    "            all_ts_prediction_df = pd.concat([all_ts_prediction_df, ts_prediction_df])\n",
    "            \n",
    "            all_ts_scores_df.reset_index(drop=True, inplace=True) \n",
    "            all_ts_prediction_df.reset_index(drop=True, inplace=True) \n",
    "        \n",
    "            self.logger.info(f\"\"\"\n",
    "            ===================================================================================================\n",
    "            TEST {ind} END...\n",
    "            \"\"\") \n",
    "            \n",
    "        ### Sorting scores\n",
    "#             print( 'TTRR', cum_tr_scores_df.columns.values.tolist(), cum_tr_prediction_df.columns.values.tolist() )\n",
    "        cum_tr_scores_df.sort_values(['Model_No', 'Test_No', 'Training_No'], ascending = [True, True, True], inplace=True)  \n",
    "        cum_tr_prediction_df.sort_values(['Test_No', 'Training_No'], ascending = [True, True], inplace=True)  \n",
    "\n",
    "#             print( 'TTSS', all_ts_scores_df.columns.values.tolist(), all_ts_prediction_df.columns.values.tolist() )\n",
    "        all_ts_scores_df.sort_values(['Model_No', 'Test_No'], ascending = [True, True], inplace=True) \n",
    "        all_ts_prediction_df.sort_values(['Test_No'], ascending = [True], inplace=True) \n",
    "        all_ts_fold_info_df.sort_values(['Model_No', 'Test_No', 'Training_No'], ascending = [True, True, True], inplace=True) \n",
    "        \n",
    "        all_ts_fold_info_df\n",
    "        \n",
    "        return cum_best_tr_model, cum_tr_model, cum_tr_scores_df, cum_tr_prediction_df, all_ts_model, all_ts_scores_df, all_ts_prediction_df, all_ts_fold_info_df  \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "    def train(self, tsi, model_list, train_all_ids, tr_splitting_crieteria):   \n",
    "        # tr_splitter = self.get_data_splitter(tr_splitting_crieteria, stratified=True, custom=True) #Training split customised: usually 5-fold or Random 20% split\n",
    "        tr_splitter = self.get_data_splitter(tr_splitting_crieteria, stratified=True, custom=False) #Training split: usually 5-fold or Random 20% split\n",
    "        all_tr_model, all_tr_scores_df, all_tr_prediction_df, all_tr_fold_info_df = {}, pd.DataFrame(), pd.DataFrame(), pd.DataFrame()  \n",
    "        best_tr_model, best_acc, best_rec, best_prec = {}, [], [], []  \n",
    "        class_data_list = self.dataset.iloc[train_all_ids][self.class_name].values.tolist() \n",
    "        split_data_list = self.dataset.iloc[train_all_ids][self.split_column].values.tolist() \n",
    "        # print('QQQQQQQQQQQ', split_data_list, class_data_list) \n",
    "        for tri, (train_ids, val_ids) in enumerate(tr_splitter.split(split_data_list, class_data_list)): \n",
    "        # for tri, (train_ids, val_ids) in enumerate(tr_splitter.split(split_data_list)): \n",
    "            ### Validation-train split: random percentage based \n",
    "            val_dat = self.dataset[self.split_column][val_ids].values.tolist() \n",
    "            tr_dat = self.dataset[self.split_column][train_ids].values.tolist() \n",
    "            ind = tri+1 \n",
    "            self.logger.info(f\"\"\"\n",
    "            *** MODEL TRAINING AND VALIDATION PHASE FOR TEST {tsi} \n",
    "            TRAINING {tri+1} START... XXXXX \n",
    "            ***************************************************************************************************\n",
    "            Validation=> {len(val_dat)} {(val_dat)} \n",
    "            Training=> {len(tr_dat)} {(tr_dat)} \n",
    "            \"\"\")            \n",
    "            all_mtr_model, all_mtr_scores_df, all_mtr_prediction_df, all_mtr_fold_info_df = self.train_models(model_list, train_ids, val_ids, tsi, ind)            \n",
    "            all_tr_model[ind] = all_mtr_model \n",
    "            if self.is_validate_models:\n",
    "                all_mtr_scores_df.insert(0, \"Training_No\", ind) \n",
    "                all_mtr_prediction_df.insert(0, \"Training_No\", ind) \n",
    "            all_mtr_fold_info_df.insert(0, \"Training_No\", ind) \n",
    "                \n",
    "            all_tr_scores_df = pd.concat([all_tr_scores_df, all_mtr_scores_df]) \n",
    "            all_tr_prediction_df = pd.concat([all_tr_prediction_df, all_mtr_prediction_df])\n",
    "            all_tr_fold_info_df = pd.concat([all_tr_fold_info_df, all_mtr_fold_info_df])\n",
    "            \n",
    "            all_tr_scores_df.reset_index(drop=True, inplace=True) \n",
    "            all_tr_scores_df.reset_index(drop=True, inplace=True)    \n",
    "            all_tr_fold_info_df.reset_index(drop=True, inplace=True)          \n",
    "            \n",
    "            self.logger.info(f\"\"\"\n",
    "            ---------------------------------------------------------------------------------------------------\n",
    "            Best model index calculation  \n",
    "            \"\"\")             \n",
    "#             print(\"PPPPP\", tri, ind, all_mtr_model.keys(), all_mtr_model, all_mtr_scores_df)\n",
    "            if tri==0:\n",
    "                best_tr_model = all_mtr_model.copy() \n",
    "                #print(\"HHHH\", all_mtr_scores_df.columns)\n",
    "                # best_acc, best_prec, best_rec = all_mtr_scores_df[ML_Performace_Metrics.ACC.value], all_mtr_scores_df[ML_Performace_Metrics.PREC.value], all_mtr_scores_df[ML_Performace_Metrics.RECL.value] \n",
    "                best_rec = all_mtr_scores_df[ML_Performace_Metrics.RECL.value].values.tolist()  \n",
    "            else:                \n",
    "                for jj, mn in enumerate(model_list):\n",
    "                    mod_name = ML_Classifiers.get_short_form(str(mn.value))\n",
    "                    tm_df = all_mtr_scores_df[(all_mtr_scores_df[\"Model_Name\"]==mod_name)] \n",
    "                    new = tm_df[ML_Performace_Metrics.RECL.value].values.tolist()[0] \n",
    "                    if new>best_rec[jj]: \n",
    "                        best_rec[jj] = new \n",
    "                        best_tr_model[tm_df[\"Model_No\"].values.tolist()[0]] = all_mtr_model[tm_df[\"Model_No\"].values.tolist()[0]]  \n",
    "                        \n",
    "            \n",
    "            self.logger.info(f\"\"\"\n",
    "            ***************************************************************************************************\n",
    "            TRAINING {ind} END... \n",
    "            \"\"\") \n",
    "        return best_tr_model, all_tr_model, all_tr_scores_df, all_tr_prediction_df, all_tr_fold_info_df \n",
    "    \n",
    "    \n",
    "    \n",
    "    def train_models(self, model_list, train_ids, val_ids, ts_serial, tr_serial):\n",
    "        all_mtr_model, all_mtr_scores_df, all_mtr_prediction_df, all_mtr_fold_info_df = {}, pd.DataFrame(), pd.DataFrame(), pd.DataFrame() \n",
    "        for modi, classifier_method in enumerate(model_list): \n",
    "            ind = modi+1 \n",
    "            self.logger.info(f\"\"\"\n",
    "            *** ML MODEL FOR TEST:{ts_serial}, TRAINING:{tr_serial} AND MODEL: {ML_Classifiers.get_short_form(str(classifier_method.value))} \n",
    "            ---------------------------------------------------------------------------------------------------\n",
    "            \"\"\")\n",
    "            mtr_model, mtr_scores_df, mtr_prediction_df, mtr_fold_info_df = self.start_training(classifier_method, train_ids, val_ids, tr_serial=tr_serial) \n",
    "            #print(\"HELLO2222\", mtr_model, mtr_scores_df, mtr_prediction_df) \n",
    "            all_mtr_model[ind] = mtr_model \n",
    "            #all_mtr_model[\"Model_Name\"] = ML_Classifiers.get_short_form(str(classifier_method.value))  \n",
    "            if self.is_validate_models:                   \n",
    "                if modi>0:\n",
    "                    mtr_prediction_df.drop(self.metadata_column, axis=1, inplace=True)\n",
    "                    mtr_prediction_df.drop([self.class_name], axis=1, inplace=True)                \n",
    "                               \n",
    "                mtr_scores_df.insert(0, \"Model_No\", ind) \n",
    "                mtr_scores_df.insert(1, \"Model_Name\", ML_Classifiers.get_short_form(str(classifier_method.value)))  \n",
    "#                 mtr_scores_df.insert(2, \"Selected_Features\", [self.selected_features]*mtr_scores_df.shape[0]) \n",
    "                    \n",
    "                all_mtr_scores_df = pd.concat([all_mtr_scores_df, mtr_scores_df]) \n",
    "                all_mtr_prediction_df = pd.concat([all_mtr_prediction_df, mtr_prediction_df], axis=1) \n",
    "                \n",
    "                all_mtr_scores_df.reset_index(drop=True, inplace=True) \n",
    "                all_mtr_prediction_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "            mtr_fold_info_df.insert(0, \"Model_No\", ind)    \n",
    "            mtr_fold_info_df.insert(1, \"Model_Name\", ML_Classifiers.get_short_form(str(classifier_method.value))) \n",
    "            all_mtr_fold_info_df = pd.concat([all_mtr_fold_info_df, mtr_fold_info_df]) \n",
    "            all_mtr_fold_info_df.reset_index(drop=True, inplace=True)  \n",
    "                    \n",
    "        #print(\"HELLO\", all_mtr_model, all_mtr_scores_df, all_mtr_prediction_df) \n",
    "        return all_mtr_model, all_mtr_scores_df, all_mtr_prediction_df, all_mtr_fold_info_df\n",
    "    \n",
    "    \n",
    "    \n",
    "    def get_data_splitter(self, split_crit_tuple, stratified=False, custom=False):\n",
    "        \n",
    "        if custom:\n",
    "            self.logger.info(f\"Custom splitter testing...\") \n",
    "#             splitter = MyCustomSplitter(n_splits=5)\n",
    "#             splitter.set_criteria(split_crit_tuple) \n",
    "            splitter = MyCustomSplitter(split_crit_tuple, groups=self.split_balance_pattern) ### , groups=[['n'], ['SC', 'ST']] for binary and [['n'], ['SC', 'ST']] for multi-class \n",
    "            return splitter\n",
    "        \n",
    "        spl_rand = self.random_state_value ##random.randint(1, 1000)\n",
    "        splitter = None\n",
    "        split_crit = split_crit_tuple[0] ### Fold \n",
    "        split_perc = split_crit_tuple[1] ### Fold \n",
    "        \n",
    "        if split_crit==0:\n",
    "            self.logger.info(f\"Leave-one-subject-out testing...\") \n",
    "            split_num = 1 \n",
    "            splitter = LeavePOut(p=split_num) if stratified else LeavePOut(p=split_num) \n",
    "            # splitter = StratifiedLeavePOut(p=split_num) if stratified else LeavePOut(p=split_num) \n",
    "            # splitter = LeavePOut(p=split_num) \n",
    "            # splitter = StratifiedLeavePOut(p=split_num) #Stratified\n",
    "        elif split_crit>0:\n",
    "            if split_perc<=0:\n",
    "                self.logger.info(f\"{split_crit}-fold testing\") \n",
    "                split_num = 5\n",
    "                if split_crit != split_num:\n",
    "                    split_num = split_crit \n",
    "                splitter = StratifiedKFold(n_splits=split_num, shuffle=False) if stratified else KFold(n_splits=split_num, shuffle=False) \n",
    "                # splitter = StratifiedKFold(n_splits=split_num, shuffle=True, random_state=spl_rand) if stratified else KFold(n_splits=split_num, shuffle=True, random_state=spl_rand) \n",
    "                # splitter = KFold(n_splits=split_num, shuffle=True, random_state=spl_rand)\n",
    "                # splitter = StratifiedKFold(n_splits=split_num, shuffle=True, random_state=spl_rand)\n",
    "                #splitter = KFold(n_splits=split_num, random_state=spl_rand)\n",
    "                #splitter = KFold(n_splits=split_num)\n",
    "            else:\n",
    "                split_num = split_crit \n",
    "                split_ratio = split_perc \n",
    "                self.logger.info(f\"Random {split_ratio} percentage splitting testing...\") \n",
    "                splitter = StratifiedShuffleSplit(n_splits=split_num, test_size=split_ratio, random_state=spl_rand) if stratified else ShuffleSplit(n_splits=split_num, test_size=split_ratio, random_state=spl_rand) \n",
    "                # splitter = ShuffleSplit(n_splits=split_num, test_size=split_ratio, random_state=spl_rand) #rs\n",
    "                # splitter = StratifiedShuffleSplit(n_splits=split_num, test_size=split_ratio, random_state=spl_rand) #rs\n",
    "                # splitter = ShuffleSplit(n_splits=split_num, test_size=split_ratio) #rs\n",
    "        else:\n",
    "            self.logger.info(f\"Problem with the splitting with the splitting criteria {split_crit_tuple}...\") \n",
    "            \n",
    "        # self.data_splitter = splitter \n",
    "        return splitter \n",
    "    \n",
    "    \n",
    "\n",
    "    def start_training(self, classifier_method, train_ids, val_ids, tr_serial):\n",
    "        parameters = self.get_parameters_for_ml_models(classifier_method) \n",
    "        print(\"Parameters: \", parameters)\n",
    "        model, model_scores, target_and_prediction = None, None, None\n",
    "        model, model_scores, target_and_prediction, fold_info_df = self.call_all_model_optimization(classifier_method, parameters, train_ids, val_ids, tr_serial, parameter_optimization=1)\n",
    "        return model, model_scores, target_and_prediction, fold_info_df \n",
    "\n",
    "\n",
    "    \n",
    "    def _get_data_from_indices(self, indices, from_training=False):\n",
    "        data = copy.deepcopy(self.dataset).iloc[indices] \n",
    "        ### Downsample he raining data: 1=down, 2=up, 3=bound sampling\n",
    "        #if from_training:\n",
    "        #    self.logger.info(f'Resampling training data...')\n",
    "        #    data = self.preprocessor.get_resamplled_data(data, self.class_name, self.pat_id_col, random_sampling=True, up_or_down_sampling=1, min_scale=2.0, max_scale=3.0) ## 0-no, 1-down, 2-up, 3-bound\n",
    "                    \n",
    "        self.logger.info(f\"\"\"\n",
    "        From training? {from_training}, Data shape: {data.shape}, Indices: {indices}\n",
    "        All Columns: {data.columns.values.tolist()}\n",
    "        \"\"\") \n",
    "        \n",
    "        target = data[self.class_name] \n",
    "        metadata_df = data[self.metadata_column] \n",
    "        features = data.drop([self.class_name]+self.metadata_column, axis=1) \n",
    "        \n",
    "        ### Call features selection algorithm \n",
    "        if self.apply_feature_selection and from_training and self.selected_features is None: \n",
    "            self.logger.info(f\"\"\"\"\n",
    "            Here comes to feature selection...\n",
    "            \"\"\") \n",
    "            selected_feats_list = self.select_appropriate_features(features, target, num_features=None, selection_criteria={'auc':0.7}) ### selection_criteria=None/{'auc':0.7} #'corr', 'p', 'auc', 'pandauc' \n",
    "            self.selected_features = selected_feats_list.copy() \n",
    "            self.logger.info(f\"\"\"\"\n",
    "            Selected features: {self.selected_features}\n",
    "            \"\"\") \n",
    "        elif from_training and self.selected_features is None: \n",
    "            self.selected_features = features.columns.values.tolist() \n",
    "            self.logger.info(f\"\"\"\"\n",
    "            Selected features: {self.selected_features}\n",
    "            \"\"\") \n",
    "            \n",
    "        if self.selected_features is not None:\n",
    "            # features = features.loc[:, ~features.columns.isin(self.selected_features) ]\n",
    "            features = features.loc[:, features.columns.isin(self.selected_features) ]\n",
    "            \n",
    "        self.logger.info(f\"\"\"\n",
    "        Feature shape: {features.shape}, Target shape: {target.shape}, Metadata: {metadata_df.shape} \n",
    "        \"\"\") \n",
    "        \n",
    "        target = target.values.tolist() \n",
    "        features = features.values \n",
    "        \n",
    "        return features, target, metadata_df  \n",
    "    \n",
    "    \n",
    "    \n",
    "    def select_appropriate_features(self, X_dat, y_dat, num_features=None, selection_criteria=None): ### selection_criteria={'auc':0.7} #'corr', 'p', 'auc', 'pandauc' \n",
    "        selected_features = [] \n",
    "        crit_name = selection_criteria.keys() \n",
    "        crit_name = list(crit_name)[0] \n",
    "        dpp_obj = DataPreprocessor() \n",
    "        \n",
    "        if crit_name=='corr':\n",
    "            pass\n",
    "        elif crit_name=='p':\n",
    "            selected_features = dpp_obj.select_pandauc_based_features(X_dat, y_dat, binary_class=self.is_binary_classification, p_threshold=0.05, auc_threshold=None, sort=True) \n",
    "        elif crit_name=='auc':\n",
    "            selected_features = dpp_obj.select_pandauc_based_features(X_dat, y_dat, binary_class=self.is_binary_classification, p_threshold=None, auc_threshold=0.7, sort=True) \n",
    "            pass\n",
    "        elif crit_name=='pandauc':\n",
    "            selected_features = dpp_obj.select_pandauc_based_features(X_dat, y_dat, binary_class=self.is_binary_classification, p_threshold=0.05, auc_threshold=0.7, sort=True) \n",
    "            \n",
    "        if num_features:\n",
    "            selected_features = selected_features[:num_features]\n",
    "        \n",
    "        return selected_features \n",
    "    \n",
    "    \n",
    "\n",
    "    def run_model_gridSearch(self, classifier_method, params, train_ids, val_ids, tr_serial):\n",
    "        tmp_train_ids, tmp_val_ids = train_ids.copy(), val_ids.copy()  \n",
    "        should_validate = self.is_validate_models \n",
    "        # should_validate = True \n",
    "        \n",
    "        if not should_validate:\n",
    "            # tmp_train_ids.extend(tmp_val_ids) \n",
    "            tmp_train_ids = np.concatenate((tmp_train_ids, tmp_val_ids)) \n",
    "        \n",
    "        ### Validation-train split: random percentage based \n",
    "        val_dat = self.dataset[self.split_column][val_ids].values.tolist() \n",
    "        tr_dat = self.dataset[self.split_column][train_ids].values.tolist() \n",
    "        # print('HHHHHH', val_dat, tr_dat) \n",
    "        fold_info_df = pd.DataFrame([[val_dat, tr_dat]], columns=['Validation', 'Training']) \n",
    "        \n",
    "        X_train, y_train, _ = self._get_data_from_indices(tmp_train_ids, from_training=True) \n",
    "        \n",
    "        mods = self.get_ml_model_instances(classifier_method)\n",
    "        self.logger.info(f\"\"\"\n",
    "        GridSearch: {ML_Classifiers.get_short_form(str(classifier_method.value))} - {params} \n",
    "        ---------------------------------------------------------------------------------------------------\n",
    "        \"\"\")\n",
    "        parameters = {}\n",
    "        model = mods\n",
    "        model_scores = None\n",
    "        if self.should_use_params:\n",
    "            parameters = params\n",
    "\n",
    "        scoring, refit = self.get_ml_scoring_metrices(self.best_model_scoring_metrics[0]) \n",
    "        scoring, refit = 'f1', True\n",
    "        self.logger.info(f\"\"\"Refitting the model with best parameter {scoring} == {refit}\"\"\")\n",
    "        \n",
    "        model = GridSearchCV(mods, parameters, scoring=scoring, cv=5, refit=refit, return_train_score=True, n_jobs=50, verbose=2)\n",
    "        # model = GridSearchCV(mods, parameters, scoring=scoring, cv=5, refit=refit, return_train_score=True, error_score='raise', n_jobs=50, verbose=2)\n",
    "        # model = GridSearchCV(mods, parameters, scoring=scoring, cv=5, refit=refit, return_train_score=True, n_jobs=mp.cpu_count(), verbose=2)\n",
    "\n",
    "        # ### Scoring from custom method\n",
    "        # score = make_scorer(self.custom_precision_func, greater_is_better=False)\n",
    "        # # scoring = {'precision': score, 'f1':make_scorer(f1_score)}\n",
    "        # model = GridSearchCV(mods, parameters, scoring=score, cv=self.cross_validation_rounds, refit=refit, return_train_score=True, n_jobs=-1, verbose=2)\n",
    "        \n",
    "        # X_train = np.nan_to_num(X_train)\n",
    "        model = model.fit(X_train, y_train) \n",
    "        mod = copy.deepcopy(model) \n",
    "        mod_est = model.best_estimator_ \n",
    "        mod_par = model.best_params_\n",
    "        \n",
    "        # print('KKKKKKKKK-->>>', model, mod_est, mod_par)\n",
    "        model_scores = None \n",
    "        target_and_prediction_df = pd.DataFrame() \n",
    "        \n",
    "#         ### Rebuild the model with best parameter         \n",
    "#         # if should_validate:\n",
    "#         bst_parameters = model.best_params_\n",
    "#         self.logger.info(f\"\"\"Refitting the model with best parameter\"\"\")\n",
    "#         # mod = mod.set_params(**bst_parameters)\n",
    "#         mod = mod.best_estimator_.set_params(**bst_parameters)\n",
    "#         tmp_train_ids2 = np.concatenate((train_ids.copy(), val_ids.copy()))\n",
    "#         # X_train2, y_train2, _ = self._get_data_from_indices(tmp_train_ids2, from_training=True)  \n",
    "#         X_train2, y_train2, _ = self._get_data_from_indices(tmp_train_ids2, from_training=False)    \n",
    "#         mod = mod.fit(X_train2, y_train2)\n",
    "            \n",
    "        X_val, y_val, meta_dat = self._get_data_from_indices(val_ids)   \n",
    "        y_pred = mod.predict(X_val)  \n",
    "        y_pred_proba = mod.predict_proba(X_val) \n",
    "        target_and_prediction_df.reset_index(drop=True, inplace=True) \n",
    "        meta_dat.reset_index(drop=True, inplace=True) \n",
    "        target_and_prediction_df = pd.concat([target_and_prediction_df, meta_dat]) \n",
    "        target_and_prediction_df[self.class_name] = y_val \n",
    "        # target_and_prediction_df[f\"Prediction_{str(model.__class__.__name__)}\"] = y_pred \n",
    "        target_and_prediction_df[f\"Prediction_{ML_Classifiers.get_short_form(str(classifier_method.value))}\"] = y_pred  \n",
    "        for p_ind in range(y_pred_proba.shape[1]):\n",
    "            target_and_prediction_df[f\"Prediction_Proba_{p_ind}_{ML_Classifiers.get_short_form(str(classifier_method.value))}\"] = y_pred_proba[:, p_ind].tolist()\n",
    "            \n",
    "        model.feature_names = self.selected_features \n",
    "        model_scores = self.calculate_model_scores(model, y_val, y_pred, y_pred_proba) \n",
    "\n",
    "        self.logger.info(f\"\"\"\n",
    "        Best model (GriveSearchCV): {model} \n",
    "        Best model: {mod} \n",
    "        Best estimator of the model: {mod_est} \n",
    "        Best parameters of the model: {mod_par} \n",
    "        ---------------------------------------------------------------------------------------------------\n",
    "        \"\"\")\n",
    "\n",
    "        return model, model_scores, target_and_prediction_df, fold_info_df \n",
    "        # return model, model_scores, target_and_prediction_df, fold_info_df\n",
    "\n",
    "\n",
    "    def call_all_model_optimization(self, classifier_method, parameters, train_ids, val_ids, tr_serial, parameter_optimization):\n",
    "        model, model_scores, target_and_prediction, fold_info_df = None, None, None, None \n",
    "        if parameter_optimization == 1:\n",
    "            model, model_scores, target_and_prediction, fold_info_df = self.run_model_gridSearch(classifier_method, parameters, train_ids, val_ids, tr_serial)\n",
    "        elif parameter_optimization == 2:\n",
    "            model, model_scores, target_and_prediction, fold_info_df = self.run_model_randomizedSearch(classifier_method, parameters, train_ids, val_ids, tr_serial)\n",
    "        elif parameter_optimization == 3:\n",
    "            model, model_scores, target_and_prediction, fold_info_df = self.run_model_baysianSearch(classifier_method, parameters, train_ids, val_ids, tr_serial)\n",
    "        elif parameter_optimization == 4:\n",
    "            model, model_scores, target_and_prediction, fold_info_df = self.run_model_customGridSearch(classifier_method, parameters, train_ids, val_ids, tr_serial)\n",
    "        return model, model_scores, target_and_prediction, fold_info_df\n",
    "\n",
    "\n",
    "    def get_ml_model_instances(self, classifier_method, parameters=None):\n",
    "        classifier = None\n",
    "\n",
    "        ### GPU code START\n",
    "        global GPUs\n",
    "        global HAS_GPU\n",
    "\n",
    "        # GPUs = GPUtil.getGPUs()\n",
    "        # tot_gpus = len(GPUs)\n",
    "        # HAS_GPU = True if len(GPUs) > 0 else False\n",
    "        # avl_GPUIDs = GPUtil.getAvailable(order = 'first', limit = tot_gpus, maxLoad = 0.5, maxMemory = 0.5, includeNan=False, excludeID=[], excludeUUID=[])\n",
    "        # tot_avl_gpus = len(avl_GPUIDs)\n",
    "        # print(f'For GPU based tasks. There are {tot_gpus} GPUs in the system and {tot_avl_gpus} are available. \\nAvailable GPU IDs are: {avl_GPUIDs}')\n",
    "        allGPUs, bestGPU = HumachLab_Global.get_gpu_details(show_logs=False)\n",
    "        ### GPU code END\n",
    "\n",
    "        # ####### rf #######\n",
    "        # rf - random_forest classifier\n",
    "        if classifier_method == ML_Classifiers.RF:\n",
    "            classifier = RandomForestClassifier() if (parameters is None) else RandomForestClassifier(parameters)\n",
    "        # ####### knn #######\n",
    "        # knn - k_neares_neighbours classifier\n",
    "        elif classifier_method == ML_Classifiers.kNN:\n",
    "            classifier = KNeighborsClassifier() if (parameters is None) else KNeighborsClassifier(parameters)\n",
    "        # ####### nb #######\n",
    "        # knn - naieve bayes classifier\n",
    "        elif classifier_method == ML_Classifiers.NB:\n",
    "            classifier = GaussianNB() if (parameters is None) else GaussianNB(parameters)\n",
    "        # ####### svm/svc #######\n",
    "        # knn - support vector classifier\n",
    "        elif classifier_method == ML_Classifiers.SVC:\n",
    "            classifier = SVC() if (parameters is None) else SVC(parameters)\n",
    "        # ####### knn #######\n",
    "        # knn - k_neares_neighbours classifier\n",
    "        elif classifier_method == ML_Classifiers.DT:\n",
    "            classifier = DecisionTreeClassifier() if (parameters is None) else DecisionTreeClassifier(parameters)\n",
    "        # ####### LogReg #######\n",
    "        # LogReg - logistic regression classifier\n",
    "        elif classifier_method == ML_Classifiers.LogReg:\n",
    "            classifier = LogisticRegression() if (parameters is None) else LogisticRegression(parameters)\n",
    "        # ####### GBoost #######\n",
    "        # GBoost - gradient boosting classifier\n",
    "        elif classifier_method == ML_Classifiers.GBoost:\n",
    "            classifier = GradientBoostingClassifier() if (parameters is None) else GradientBoostingClassifier(parameters)\n",
    "\n",
    "        ### GPU code - Comment it if no gpu available or not linux system or no support for RapidsAI package\n",
    "        # ####### gpu-rf #######\n",
    "        # gpu-rf - gpu-random_forest classifier\n",
    "        # elif classifier_method == ML_Classifiers.GPURF and tot_avl_gpus>0:\n",
    "        #     classifier = gpuRandomForestClassifier() if (parameters is None) else gpuRandomForestClassifier(parameters)\n",
    "\n",
    "        # ####### None #######\n",
    "        # No classifier\n",
    "        else:\n",
    "            self.logger.info(f'No classifier is selected...')\n",
    "\n",
    "        # ####### ####### #######\n",
    "        return classifier\n",
    "\n",
    "\n",
    "    def get_ml_scoring_metrices(self, reft=None):\n",
    "        model_scoring_mets = [ML_Performace_Metrics.ACC, ML_Performace_Metrics.PREC, ML_Performace_Metrics.RECL,\n",
    "                              ML_Performace_Metrics.SEN, ML_Performace_Metrics.SPEC, ML_Performace_Metrics.FPR,\n",
    "                              ML_Performace_Metrics.FNR, ML_Performace_Metrics.F1, ML_Performace_Metrics.ROC_AUC]\n",
    "\n",
    "        scoring = [ML_Performace_Metrics.ACC.value]\n",
    "        bst_mod_mets_1 = None\n",
    "        i = 0\n",
    "        for met in self.best_model_scoring_metrics:\n",
    "            if i==0:\n",
    "                scoring.clear()\n",
    "                if (reft is not None):\n",
    "                    if reft == ML_Performace_Metrics.F1SCR:\n",
    "                        reft = ML_Performace_Metrics.F1\n",
    "                    if (reft not in model_scoring_mets):\n",
    "                        reft = None\n",
    "\n",
    "            if met == ML_Performace_Metrics.F1SCR:\n",
    "                met = ML_Performace_Metrics.F1\n",
    "\n",
    "            if met in model_scoring_mets:\n",
    "                scoring.append(met.value)\n",
    "            i += 1\n",
    "\n",
    "        refit = (scoring[0]) if reft is None else reft.value\n",
    "        \n",
    "#         scoring = [ML_Performace_Metrics.F1]\n",
    "#         refit = True\n",
    "\n",
    "        return scoring, refit\n",
    "\n",
    "\n",
    "    ############################################################################\n",
    "    def get_parameters_for_ml_models(self, classifier_method):\n",
    "        parameters = {}\n",
    "        if not self.should_use_params:\n",
    "            return parameters\n",
    "\n",
    "        # Parameter generation method name\n",
    "        method_name = f'{str(classifier_method.value)}_parameters'\n",
    "\n",
    "        try:\n",
    "            method = getattr(self, method_name)\n",
    "            # Call method for parameter generation\n",
    "            self.logger.info(f'Calling method: {method_name}')\n",
    "            parameters = method()\n",
    "        except AttributeError:\n",
    "            self.logger.warning(f'No such method exists with the name: {method_name}')\n",
    "            raise NotImplementedError(\"Class `{}` does not implement `{}`\".format(self.__class__.__name__, method_name))\n",
    "\n",
    "        # ####### ####### #######\n",
    "        return parameters\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    ############################################################################\n",
    "    def generate_parameter_dictionary(self, par_names, par_vals, par_ind):\n",
    "        self.logger.info(f'All parameters: {par_names}, {par_vals}, {par_ind}')\n",
    "        final_par_names = []\n",
    "        par_dict = {}\n",
    "\n",
    "#         for i in par_ind:\n",
    "#             pn = par_names[i]\n",
    "#             pv = par_vals[i]\n",
    "#             exec(f'{pn}={pv}')\n",
    "#             final_par_names.append(pn)\n",
    "        \n",
    "        sel_par = [pp for ii,pp in enumerate(par_names) if ii in par_ind] \n",
    "        for (pn, pv) in zip(sel_par, par_vals):\n",
    "            exec(f'{pn}={pv}')\n",
    "            final_par_names.append(pn)\n",
    "\n",
    "        for par in final_par_names:\n",
    "            par_dict[par] = eval(par)\n",
    "\n",
    "        return par_dict\n",
    "\n",
    "\n",
    "    # def float_range(self, start, stop, step):\n",
    "    #     start = decimal.Decimal(start)\n",
    "    #     stop = decimal.Decimal(stop)\n",
    "    #     while start < stop:\n",
    "    #         yield float(start)\n",
    "    #         start *= decimal.Decimal(step)\n",
    "\n",
    "\n",
    "    # #########################################################################\n",
    "    # Model parameter settings\n",
    "    # #########################################################################\n",
    "    # ### ML Classifier Method Parameters\n",
    "    \n",
    "    \n",
    "    \n",
    "    def logistic_regression_parameters(self):\n",
    "\n",
    "        # ### Parameter generation using function\n",
    "        par_names = ['penalty', 'solver', 'max_iter', 'C']\n",
    "        par_vals = [['l1', 'l2', 'elasticnet'],\n",
    "                    ['lbfgs', 'liblinear', 'newton-cg', 'newton-cholesky', 'sag', 'saga'],\n",
    "                    list(range(50, 5000, 10)),\n",
    "                    list(HumachLab_StaticMethods.float_range('0.001', '1.0', '0.01'))]\n",
    "\n",
    "        par_vals = [[30, 50, 75, 100, 200, 500, 750, 1000], [2, 3, 5, 7], [5, 7, 11, 15, 21, 30, 50, 75, 100, 200, 500, 750, 1000]]\n",
    "        par_vals = [[5, 7, 11, 15, 21, 30, 50, 75, 100, 200, 500, 750, 1000]]\n",
    "        par_vals = [[15, 21, 30, 50, 75, 100, 200, 500]]\n",
    "        par_vals = [[50, 75, 100]]\n",
    "        par_vals = [[15, 21, 30, 50, 75, 100, 200, 500], [3, 5, 7, 10, 15, 20, 25, 30]]\n",
    "        par_vals = [['l1', 'l2', 'elasticnet'],[50, 100, 130, 150, 170, 200, 250, 350, 500, 750, 1000]]\n",
    "        par_vals = [['l1', 'l2', 'elasticnet'],[50, 100, 130, 150, 170, 200],[0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1.0]]\n",
    "        par_vals = [['l2', 'elasticnet'],[50, 100, 130, 150, 170, 200],[0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1.0]]\n",
    "        par_ind = [0, 2, 3]\n",
    "        parameters = self.generate_parameter_dictionary(par_names, par_vals, par_ind)\n",
    "\n",
    "        return parameters\n",
    "    \n",
    "    \n",
    "    \n",
    "    def k_nearest_neighbors_parameters(self):\n",
    "\n",
    "        # ### Parameter generation using function\n",
    "        par_names = ['n_neighbors', 'p', 'metric', 'n_splits']\n",
    "        par_vals = [list(range(2, 100)),\n",
    "                    list(range(2, 100)),\n",
    "                    ['manhattan', 'minkowski', 'euclidean'],\n",
    "                    list(range(2, 10))]\n",
    "\n",
    "        par_vals = [list(range(100, 1000, 50)), list(range(2, 11, 1)), [2, 3, 5, 9, 13, 19, 29]]\n",
    "        par_vals = [[2, 3, 5, 9, 13, 19, 29]]\n",
    "        par_vals = [[2, 3, 5, 10, 15, 25, 35], ['manhattan', 'minkowski', 'euclidean']]\n",
    "        par_ind = [0, 2]\n",
    "        parameters = self.generate_parameter_dictionary(par_names, par_vals, par_ind)\n",
    "\n",
    "        return parameters\n",
    "    \n",
    "    \n",
    "    \n",
    "    def naive_bayes_parameters(self):\n",
    "\n",
    "        # ### Parameter generation using function\n",
    "        par_names = ['var_smoothing']\n",
    "        par_vals = [list(np.logspace(0, -9, num=100))]\n",
    "        par_vals = [list(np.logspace(0, -9, num=100))]\n",
    "\n",
    "        # par_vals = []\n",
    "        # par_vals = []\n",
    "        par_vals = [list(np.logspace(0,-9, num=5))]\n",
    "        par_ind = [0]\n",
    "        parameters = self.generate_parameter_dictionary(par_names, par_vals, par_ind)\n",
    "\n",
    "        return parameters\n",
    "\n",
    "\n",
    "    def support_vector_classifier_parameters(self):\n",
    "\n",
    "        # ### Parameter generation using function #, probability=True\n",
    "        par_names = ['probability', 'C', 'kernel', 'gamma', 'degree', 'class_weightdict']\n",
    "        par_vals = [[True],\n",
    "                    list(HumachLab_StaticMethods.float_range('0.001', '1', '0.01')),\n",
    "                    ['linear', 'rbf', 'poly', 'sigmoid'],\n",
    "                    list(HumachLab_StaticMethods.float_range('0.000001', '1', '10')),\n",
    "                    list(range(1, 10)),\n",
    "                    [None, 'balanced']]\n",
    "\n",
    "        # par_vals = [list(HumachLab_StaticMethods.float_range('0.000001', '1', '10')), list(HumachLab_StaticMethods.float_range('0.00001', '1', '10')), list(HumachLab_StaticMethods.float_range('0.0001', '1', '10'))]\n",
    "        par_vals = [list(HumachLab_StaticMethods.float_range('0.001', '1.', '0.1')), ['linear', 'rbf', 'poly']]\n",
    "        par_vals = [[True],[0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1.0], ['linear', 'rbf', 'poly']]\n",
    "        par_ind = [0, 1, 2]\n",
    "        parameters = self.generate_parameter_dictionary(par_names, par_vals, par_ind)\n",
    "\n",
    "        return parameters\n",
    "    \n",
    "    \n",
    "    \n",
    "    def decision_tree_parameters(self):\n",
    "\n",
    "        # ### Parameter generation using function\n",
    "        par_names = ['max_depth', 'criterion', 'splitter', 'min_samples_split', 'min_samples_leaf', 'max_leaf_nodes']\n",
    "        par_vals = [list(range(1, 100)),\n",
    "                    ['gini', 'entropy', 'log_loss'],\n",
    "                    ['best', 'random'],\n",
    "                    list(range(1, 10)),\n",
    "                    list(range(1, 10)),\n",
    "                    list(range(1, 100))]\n",
    "\n",
    "        par_vals = [list(range(1, 100)), list(range(1, 100, 2)), list(range(1, 100, 3))]\n",
    "        par_vals = [list(range(1, 100))]\n",
    "        par_vals = [[2, 3, 5, 7, 10, 15, 20, 25, 30], ['gini', 'entropy', 'log_loss']]\n",
    "        par_ind = [0, 1]\n",
    "        parameters = self.generate_parameter_dictionary(par_names, par_vals, par_ind)\n",
    "\n",
    "        return parameters\n",
    "    \n",
    "    \n",
    "    \n",
    "    def random_forest_parameters(self): \n",
    "\n",
    "        # ### Parameter generation using function\n",
    "        par_names = ['n_estimators', 'max_depth', 'criterion', 'splitter', 'max_features', 'min_samples_split', 'min_samples_leaf', 'max_leaf_nodes']\n",
    "        par_vals = [list(range(1, 500, 5)),\n",
    "                    list(range(1, 100)),\n",
    "                    ['gini', 'entropy', 'log_loss'], \n",
    "                    ['best', 'random'],\n",
    "                    list(range(2, 20, 1)),\n",
    "                    list(range(1, 10)),\n",
    "                    list(range(1, 10)),\n",
    "                    list(range(1, 100))]\n",
    "\n",
    "        par_vals = [[30, 50, 75, 100, 200, 500, 750, 1000], [2, 3, 5, 7], [5, 7, 11, 15, 21, 30, 50, 75, 100, 200, 500, 750, 1000]]\n",
    "        par_vals = [[5, 7, 11, 15, 21, 30, 50, 75, 100, 200, 500, 750, 1000]]\n",
    "        par_vals = [[15, 21, 30, 50, 75, 100, 200, 500]]\n",
    "        par_vals = [[50, 75, 100]]\n",
    "        par_vals = [[3, 5, 10, 15, 21, 30, 50, 75, 100], [2, 3, 5, 7, 10, 15, 20, 25, 30], ['gini', 'entropy', 'log_loss']]\n",
    "        # par_vals = [[2, 3, 5, 7]]\n",
    "        par_ind = [0, 1, 2]\n",
    "        parameters = self.generate_parameter_dictionary(par_names, par_vals, par_ind)\n",
    "\n",
    "        return parameters\n",
    "    \n",
    "    \n",
    "    \n",
    "    def graphics_processing_unit_random_forest(self):\n",
    "\n",
    "        # ### Parameter generation using function\n",
    "        par_names = ['n_estimators', 'n_bins', 'n_streams', 'max_depth', 'max_features', 'criterion', 'splitter', 'min_samples_split', 'min_samples_leaf', 'max_leaf_nodes']\n",
    "        par_vals = [list(range(1, 500, 5)),\n",
    "                    list(range(1, 100)),\n",
    "                    list(range(2, 20, 1)),\n",
    "                    ['gini', 'entropy', 'log_loss'], \n",
    "                    ['best', 'random'],\n",
    "                    list(range(1, 10)),\n",
    "                    list(range(1, 10)),\n",
    "                    list(range(1, 100))]\n",
    "\n",
    "        par_vals = [[30, 50, 75, 100, 200, 500, 750, 1000], [2, 3, 5, 7], [5, 7, 11, 15, 21, 30, 50, 75, 100, 200, 500, 750, 1000]]\n",
    "        par_vals = [[5, 7, 11, 15, 21, 30, 50, 75, 100, 200, 500, 750, 1000], 15, 8]\n",
    "        # par_vals = [[2, 3, 5, 7]]\n",
    "        par_ind = [0, 1, 2]\n",
    "        parameters = self.generate_parameter_dictionary(par_names, par_vals, par_ind)\n",
    "\n",
    "        return parameters\n",
    "    \n",
    "    \n",
    "    \n",
    "    def gradient_boosting_parameters(self):\n",
    "\n",
    "        # ### Parameter generation using function \n",
    "        par_names = ['n_estimators', 'max_depth', 'learning_rate', 'max_features', 'loss', 'min_samples_split', 'min_samples_leaf']\n",
    "        par_vals = [list(range(1, 500, 5)),\n",
    "                    list(range(1, 100)),\n",
    "                    list(HumachLab_StaticMethods.float_range('0.001', '1', '0.01')), \n",
    "                    list(range(2, 20, 1)),\n",
    "                    ['log_loss', 'exponential'],\n",
    "                    list(range(1, 10)),\n",
    "                    list(range(1, 10))]\n",
    "\n",
    "        par_vals = [[30, 50, 75, 100, 200, 500, 750, 1000], [2, 3, 5, 7], [5, 7, 11, 15, 21, 30, 50, 75, 100, 200, 500, 750, 1000]]\n",
    "        par_vals = [[5, 7, 11, 15, 21, 30, 50, 75, 100, 200, 500, 750, 1000]]\n",
    "        par_vals = [[15, 21, 30, 50, 75, 100, 200, 500]]\n",
    "        par_vals = [[50, 75, 100]]\n",
    "        par_vals = [[15, 21, 30, 50, 75, 100, 200, 500], [3, 5, 7, 10, 15, 20, 25, 30], [0.01, 0.05, 0.1, 0.5, 1.0]]\n",
    "        par_vals = [[3, 5, 10, 15, 21, 30, 50, 75, 100], [2, 3, 5, 7, 10, 15, 20, 25, 30], [0.01, 0.05, 0.1, 0.5, 1.0]]\n",
    "        # par_vals = [[2, 3, 5, 7]]\n",
    "        par_ind = [0, 1, 2]\n",
    "        parameters = self.generate_parameter_dictionary(par_names, par_vals, par_ind)\n",
    "\n",
    "        return parameters\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "    # #########################################################################\n",
    "    # Calculate and save classification details and model scores\n",
    "    # #########################################################################\n",
    "    #############################\n",
    "\n",
    "    def calculate_model_scores(self, mods, y_test, y_pred, y_pred_proba): \n",
    "#         print(y_test, '\\n', y_pred, '\\n', y_pred_proba, '\\n')\n",
    "#         target_labels = np.unique(np.array(y_test)).tolist() \n",
    "        target_labels = sorted( self.dataset[self.class_name].unique().tolist() )\n",
    "        \n",
    "        y_pred = y_pred.tolist() \n",
    "        perf_scores = self.calculate_performance_scores(y_test, y_pred, y_pred_proba, labels=target_labels)  # average = 'weighted', 'macro', 'micro' \n",
    "        confMat = perf_scores['Conf_Mat']\n",
    "\n",
    "        acc = round(perf_scores['ACC'], 3) #Accuracy score or total correct prediction rate \n",
    "        prec = round(perf_scores['PREC'], 3) #precision or positive predictive value (PPV)\n",
    "        reca_sens = round(perf_scores['REC'], 3) #sensitivity, recall, hit rate, or true positive rate (TPR)\n",
    "        spec = round(perf_scores['SPE'], 3) #specificity, selectivity or true negative rate (TNR)\n",
    "        f1sc = round(perf_scores['F1SCR'], 3)\n",
    "        auc_s = round(perf_scores['AUC'], 3) \n",
    "        \n",
    "        scr_dict = {'method': str(mods), 'model': mods.best_estimator_, 'model_parameters': mods.best_params_, \n",
    "                    'model_scores': round(mods.best_score_*100,2),\n",
    "                    ML_Performace_Metrics.CONF_MAT.value: confMat, ML_Performace_Metrics.ACC.value: acc, ML_Performace_Metrics.PREC.value: prec,\n",
    "                    ML_Performace_Metrics.RECL.value: reca_sens, ML_Performace_Metrics.SEN.value: reca_sens, ML_Performace_Metrics.SPEC.value: spec,\n",
    "                    ML_Performace_Metrics.F1SCR.value: f1sc, ML_Performace_Metrics.ROC_AUC.value: auc_s}\n",
    "        \n",
    "#         scr_dict = {'method_class': str(mods.__class__.__name__), 'model_name': mods.best_estimator_, 'model_parameters': mods.best_params_, \n",
    "#                     'model_scores': round(mods.best_score_*100,2),\n",
    "#                     ML_Performace_Metrics.CONF_MAT.value: confMat, ML_Performace_Metrics.ACC.value: acc, ML_Performace_Metrics.PREC.value: prec,\n",
    "#                     ML_Performace_Metrics.RECL.value: reca_sens, ML_Performace_Metrics.SEN.value: reca_sens, ML_Performace_Metrics.SPEC.value: spec,\n",
    "#                     ML_Performace_Metrics.F1SCR.value: f1sc, ML_Performace_Metrics.ROC_AUC.value: auc_s}\n",
    "#         scr_dict = {'model_class': str(mods.__class__.__name__), 'method_name': mods.estimator, 'method_parameters': mods.best_params_, \n",
    "#                     'method_scores': round(mods.best_score_*100,2),\n",
    "#                     ML_Performace_Metrics.CONF_MAT.value: confMat, ML_Performace_Metrics.ACC.value: acc, ML_Performace_Metrics.PREC.value: prec,\n",
    "#                     ML_Performace_Metrics.RECL.value: reca_sens, ML_Performace_Metrics.SEN.value: reca_sens, ML_Performace_Metrics.SPEC.value: spec,\n",
    "#                     ML_Performace_Metrics.FPR.value: fpr, ML_Performace_Metrics.FNR.value: fnr, ML_Performace_Metrics.F1SCR.value: f1sc, ML_Performace_Metrics.ROC_AUC.value: auc_s}\n",
    "#         scr_dict = {'model_class': str(mods.__class__.__name__), 'method_name': str(mods), 'method_parameters': mods.best_params_, \n",
    "#                     'method_scores': round(mods.best_score_*100,2),\n",
    "#                     ML_Performace_Metrics.CONF_MAT.value: confMat, ML_Performace_Metrics.ACC.value: acc, ML_Performace_Metrics.PREC.value: prec,\n",
    "#                     ML_Performace_Metrics.RECL.value: reca_sens, ML_Performace_Metrics.SEN.value: reca_sens, ML_Performace_Metrics.SPEC.value: spec,\n",
    "#                     ML_Performace_Metrics.FPR.value: fpr, ML_Performace_Metrics.FNR.value: fnr, ML_Performace_Metrics.F1SCR.value: f1sc, ML_Performace_Metrics.ROC_AUC.value: auc_s}\n",
    "        scr_df = pd.DataFrame([list( scr_dict.values() )], columns=list( scr_dict.keys() )) \n",
    "        self.logger.info(f\"\"\"Score columns: {scr_df.shape} {scr_df.columns.values.tolist()}\"\"\") \n",
    "\n",
    "        return scr_df\n",
    "    \n",
    "    \n",
    "    def calculate_performance_scores(self, y_true, y_pred, y_pred_proba, labels=[0, 1], verbose=2, average='weighted'): # average = 'macro', 'micro', 'weighted' \n",
    "        #### SOURCES: https://www.youtube.com/watch?v=PCHf_7jBor8 \n",
    "        # https://www.mariakhalusova.com/posts/2019-04-17-ml-model-evaluation-metrics-p2/ \n",
    "        # https://www.mariakhalusova.com/posts/2019-04-11-ml-model-evaluation-metrics-p1/\n",
    "        # https://www.evidentlyai.com/classification-metrics/multi-class-metrics \n",
    "        # https://www.kaggle.com/code/nkitgupta/evaluation-metrics-for-multi-class-classification \n",
    "\n",
    "        model_scores = []\n",
    "        true_label_uniq = np.unique(np.array(y_true)).tolist() \n",
    "        print(np.unique(np.array(y_true)), np.unique(np.array(y_pred)))\n",
    "        print(y_true, y_pred) \n",
    "        conf_matrix = confusion_matrix(y_true, y_pred, labels=labels).tolist()\n",
    "        print(np.array(conf_matrix) )\n",
    "\n",
    "        ### For micro averaging and binary class \n",
    "        conf_matrix_arr = np.array(conf_matrix) \n",
    "        one_vs_all_confMat = []     \n",
    "        for label in labels:\n",
    "            tp_lbl = conf_matrix_arr[label, label] \n",
    "            fp_lbl = np.sum(conf_matrix_arr[:, label])-tp_lbl \n",
    "            fn_lbl = np.sum(conf_matrix_arr[label, :])-tp_lbl \n",
    "            tn_lbl = np.sum(conf_matrix_arr)-(tp_lbl+fp_lbl+fn_lbl) \n",
    "            one_vs_all_confMat.append([tn_lbl, fp_lbl, fn_lbl, tp_lbl]) \n",
    "        print(np.array(one_vs_all_confMat)) \n",
    "\n",
    "        tn_tot = np.sum( np.array(one_vs_all_confMat)[:, 0] ) \n",
    "        fp_tot = np.sum( np.array(one_vs_all_confMat)[:, 1] )  \n",
    "        fn_tot = np.sum( np.array(one_vs_all_confMat)[:, 2] )  \n",
    "        tp_tot = np.sum( np.array(one_vs_all_confMat)[:, 3] )\n",
    "\n",
    "        conf_matrix_tol = [[tn_tot, fp_tot], [fn_tot, tp_tot]] \n",
    "        print(np.array(conf_matrix_tol)) \n",
    "\n",
    "        if len(labels)==2:\n",
    "            tn_tot = one_vs_all_confMat[1][0] \n",
    "            fp_tot = one_vs_all_confMat[1][1] \n",
    "            fn_tot = one_vs_all_confMat[1][2] \n",
    "            tp_tot = one_vs_all_confMat[1][3] \n",
    "            average = \"micro\"\n",
    "\n",
    "        result = [] \n",
    "        for label in labels:\n",
    "            precision, recall, fscore, support = precision_recall_fscore_support( np.array(y_true)==label, np.array(y_pred)==label ) \n",
    "            # tmp_fpr, tmp_tpr, tmp_thresholds = roc_curve(np.array(y_true)==label, np.array(y_pred)==label, pos_label=label) \n",
    "            tmp_fpr, tmp_tpr, tmp_thresholds = roc_curve(np.array(y_true)==label, np.array(y_pred)==label) \n",
    "            auc_score = auc(tmp_fpr, tmp_tpr)*100 \n",
    "\n",
    "            if label in true_label_uniq: \n",
    "                result.append( [label, precision[1], recall[1], recall[1], recall[0], fscore[1], auc_score, support[1]] ) \n",
    "            else:\n",
    "                result.append( [label, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0] ) \n",
    "\n",
    "            accuracy = accuracy_score(np.array(y_true)==label, np.array(y_pred)==label)*100 \n",
    "            if verbose>1:\n",
    "                print(\n",
    "                    f'Class-wise info: For multilevel internal scores fo label {label}: \\n', \n",
    "                    f'Accuracy = {accuracy}\\n', \n",
    "                    f'Precision = {precision}\\n', \n",
    "                    f'Recall = {recall}\\n', \n",
    "                    f'F1 score = {fscore}\\n', \n",
    "                    f'AUC score = {auc_score}\\n', \n",
    "                    f'Support = {support}\\n', \n",
    "                )\n",
    "        tdf = pd.DataFrame(result, columns=['Label', 'Precision', 'Recall', 'Sensitivity', 'Specificity', 'F1 Score', 'AUC', 'Support']) \n",
    "\n",
    "        if average=='macro': #average = \"weighted\", \"macro\", \"micro\" \n",
    "            tdf = tdf[['Precision', 'Recall', 'Sensitivity', 'Specificity', 'F1 Score', 'AUC']].apply(lambda col:np.mean(col), axis=0) \n",
    "        elif average=='micro':\n",
    "            prc = (tp_tot / (tp_tot+fp_tot))*100 if (tp_tot+fp_tot)!=0 else 0.0 #precision or positive predictive value (PPV)\n",
    "            rec = (tp_tot / (tp_tot+fn_tot))*100 if (tp_tot+fn_tot)!=0 else 0.0 #sensitivity, recall, hit rate, or true positive rate (TPR)\n",
    "            sns = rec #sensitivity same as recall \n",
    "            spc = (tn_tot / (tn_tot+fp_tot))*100 if (tn_tot+fp_tot)!=0 else 0.0 #specificity, selectivity or true negative rate (TNR)\n",
    "            f1s = (2*tp_tot / (2*tp_tot+fp_tot+fn_tot))*100 if (2*tp_tot+fp_tot+fn_tot)!=0 else 0.0 #specificity, selectivity or true negative rate (TNR)  \n",
    "            auc_s = roc_auc_score(y_true, y_pred) if len(labels)==2 else roc_auc_score(y_true, y_pred_proba, multi_class='ovr', average=average) #multi_class='ovo', 'ovr' \n",
    "#             auc_s = 0.5\n",
    "#             if len(labels)==2:\n",
    "#                 auc_s = roc_auc_score(y_true, y_pred)  \n",
    "#             else:\n",
    "#                 auc_s = roc_auc_score(y_true, y_pred_proba, multi_class='ovr', average=average) #multi_class='ovo', 'ovr' \n",
    "            tdf = pd.Series([prc, rec, sns, spc, f1s, auc_s], index=['Precision', 'Recall', 'Sensitivity', 'Specificity', 'F1 Score', 'AUC'])  \n",
    "        else: ## Default = weighted\n",
    "            class_weights = tdf['Support']/tdf['Support'].sum() \n",
    "            tdf = tdf[['Precision', 'Recall', 'Sensitivity', 'Specificity', 'F1 Score', 'AUC']].apply(lambda col:np.sum(col*class_weights), axis=0) \n",
    "\n",
    "        acc = accuracy_score(y_true, y_pred)*100 \n",
    "        tdf_summary = pd.Series([conf_matrix, acc, tdf['Precision'], tdf['Recall'], tdf['Sensitivity'], tdf['Specificity'], tdf['F1 Score'], tdf['AUC']],\n",
    "                               index=['Conf_Mat', 'ACC', 'PREC', 'REC', 'SEN', 'SPE', 'F1SCR', 'AUC'])\n",
    "\n",
    "        if verbose>1:\n",
    "            confMat = tdf_summary['Conf_Mat']\n",
    "            acc = round(tdf_summary['ACC'], 3) #Accuracy score or total correct prediction rate \n",
    "            prec = round(tdf_summary['PREC'], 3) #precision or positive predictive value (PPV)\n",
    "            reca_sens = round(tdf_summary['REC'], 3) #sensitivity, recall, hit rate, or true positive rate (TPR)\n",
    "            spec = round(tdf_summary['SPE'], 3) #specificity, selectivity or true negative rate (TNR)\n",
    "            f1sc = round(tdf_summary['F1SCR'], 3)\n",
    "            auc_s = round(tdf_summary['AUC'], 3) \n",
    "            print(\n",
    "                f'CLASSIFICATION MERICS:\\n',\n",
    "                f'{\"_\"*55}\\n',\n",
    "                f'Confusion Matrix: \\n{np.array(conf_matrix)}\\n',\n",
    "                f'Accuracy (acc): {acc}\\n',\n",
    "                f'Precision (prc): {prec}\\n',\n",
    "                f'Recall (rec): {reca_sens}\\n',\n",
    "                f'Sensitivity (sns): {reca_sens}\\n',\n",
    "                f'Specificity (spc): {spec}\\n',\n",
    "                f'F1 Score (f1s): {f1sc}\\n',\n",
    "                f'ROC AUC (AUC): {auc_s}',\n",
    "            )\n",
    "\n",
    "        return tdf_summary\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "planned-devil",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from xgboost import XGBClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stable-cancellation",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mental-mixture",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
